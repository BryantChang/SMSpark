15/08/11 10:17:54 INFO SparkContext: Running Spark version 1.3.0
15/08/11 10:17:54 WARN Utils: Your hostname, hadoop2 resolves to a loopback address: 127.0.0.1; using 192.168.130.131 instead (on interface eth1)
15/08/11 10:17:54 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
15/08/11 10:17:54 DEBUG MutableMetricsFactory: field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)], about=, type=DEFAULT, always=false, sampleName=Ops)
15/08/11 10:17:55 DEBUG MutableMetricsFactory: field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)], about=, type=DEFAULT, always=false, sampleName=Ops)
15/08/11 10:17:55 DEBUG MutableMetricsFactory: field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, value=[GetGroups], about=, type=DEFAULT, always=false, sampleName=Ops)
15/08/11 10:17:55 DEBUG MetricsSystemImpl: UgiMetrics, User and group related metrics
15/08/11 10:17:55 DEBUG Groups:  Creating new Groups object
15/08/11 10:17:55 DEBUG NativeCodeLoader: Trying to load the custom-built native-hadoop library...
15/08/11 10:17:55 DEBUG NativeCodeLoader: Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
15/08/11 10:17:55 DEBUG NativeCodeLoader: java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
15/08/11 10:17:55 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
15/08/11 10:17:55 DEBUG JniBasedUnixGroupsMappingWithFallback: Falling back to shell based
15/08/11 10:17:55 DEBUG JniBasedUnixGroupsMappingWithFallback: Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
15/08/11 10:17:55 DEBUG Shell: Failed to detect a valid hadoop home directory
java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:265)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:290)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:76)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:92)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:76)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:239)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:255)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:232)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:718)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:703)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:605)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2006)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2006)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2006)
	at org.apache.spark.SecurityManager.<init>(SecurityManager.scala:207)
	at org.apache.spark.SparkEnv$.create(SparkEnv.scala:219)
	at org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:161)
	at org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:267)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:270)
	at org.apache.spark.examples.KMeansTest$.main(KMeansTest.scala:48)
	at org.apache.spark.examples.KMeansTest.main(KMeansTest.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:569)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:166)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:189)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:110)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
15/08/11 10:17:55 DEBUG Shell: setsid exited with exit code 0
15/08/11 10:17:55 DEBUG Groups: Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
15/08/11 10:17:55 DEBUG UserGroupInformation: hadoop login
15/08/11 10:17:55 DEBUG UserGroupInformation: hadoop login commit
15/08/11 10:17:55 DEBUG UserGroupInformation: using local user:UnixPrincipal: hadoop
15/08/11 10:17:55 DEBUG UserGroupInformation: UGI loginUser:hadoop (auth:SIMPLE)
15/08/11 10:17:55 INFO SecurityManager: Changing view acls to: hadoop
15/08/11 10:17:55 INFO SecurityManager: Changing modify acls to: hadoop
15/08/11 10:17:55 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(hadoop); users with modify permissions: Set(hadoop)
15/08/11 10:17:56 DEBUG SecurityManager: SSLConfiguration for file server: SSLOptions{enabled=false, keyStore=None, keyStorePassword=None, trustStore=None, trustStorePassword=None, protocol=None, enabledAlgorithms=Set()}
15/08/11 10:17:56 DEBUG SecurityManager: SSLConfiguration for Akka: SSLOptions{enabled=false, keyStore=None, keyStorePassword=None, trustStore=None, trustStorePassword=None, protocol=None, enabledAlgorithms=Set()}
15/08/11 10:17:56 DEBUG AkkaUtils: In createActorSystem, requireCookie is: off
15/08/11 10:17:57 INFO Slf4jLogger: Slf4jLogger started
15/08/11 10:17:57 INFO Remoting: Starting remoting
15/08/11 10:17:57 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@192.168.130.131:57038]
15/08/11 10:17:57 INFO Utils: Successfully started service 'sparkDriver' on port 57038.
15/08/11 10:17:57 DEBUG SparkEnv: Using serializer: class org.apache.spark.serializer.KryoSerializer
15/08/11 10:17:57 INFO SparkEnv: Registering MapOutputTracker
15/08/11 10:17:57 INFO SparkEnv: Registering BlockManagerMaster
15/08/11 10:17:57 DEBUG BlockManagerMasterActor: [actor] received message ExpireDeadHosts from Actor[akka://sparkDriver/user/BlockManagerMaster#1167280481]
15/08/11 10:17:57 DEBUG BlockManagerMasterActor: [actor] handled message (4.923039 ms) ExpireDeadHosts from Actor[akka://sparkDriver/user/BlockManagerMaster#1167280481]
15/08/11 10:17:58 INFO DiskBlockManager: Created local directory at /tmp/spark-53848626-8dc7-4b8d-a14b-5244af43625f/blockmgr-ce20f541-e865-4f2c-b8ca-5e9ef8bd400a
15/08/11 10:17:58 INFO MemoryStore: MemoryStore started with capacity 265.4 MB
15/08/11 10:17:58 INFO HttpFileServer: HTTP File server directory is /tmp/spark-d640e027-1d14-494c-b55a-83f4c5c997e0/httpd-a4c06416-b33e-4871-b59d-4712bb75dfd9
15/08/11 10:17:58 INFO HttpServer: Starting HTTP Server
15/08/11 10:17:58 DEBUG log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.spark-project.jetty.util.log) via org.spark-project.jetty.util.log.Slf4jLog
15/08/11 10:17:58 DEBUG Container: Container org.spark-project.jetty.server.Server@2c1da9b4 + SocketConnector@0.0.0.0:0 as connector
15/08/11 10:17:58 DEBUG Container: Container org.spark-project.jetty.server.Server@2c1da9b4 + qtp151884440{8<=0<=0/254,-1} as threadpool
15/08/11 10:17:58 DEBUG HttpServer: HttpServer is not using security
15/08/11 10:17:58 DEBUG Container: Container org.spark-project.jetty.server.handler.HandlerList@1f56e60b + org.spark-project.jetty.server.handler.ResourceHandler@218ec40 as handler
15/08/11 10:17:58 DEBUG Container: Container org.spark-project.jetty.server.handler.HandlerList@1f56e60b + org.spark-project.jetty.server.handler.DefaultHandler@323e5ed3 as handler
15/08/11 10:17:58 DEBUG Container: Container org.spark-project.jetty.server.Server@2c1da9b4 + org.spark-project.jetty.server.handler.HandlerList@1f56e60b as handler
15/08/11 10:17:58 DEBUG AbstractLifeCycle: starting org.spark-project.jetty.server.Server@2c1da9b4
15/08/11 10:17:58 INFO Server: jetty-8.y.z-SNAPSHOT
15/08/11 10:17:58 DEBUG AbstractLifeCycle: starting org.spark-project.jetty.server.handler.HandlerList@1f56e60b
15/08/11 10:17:58 DEBUG AbstractLifeCycle: starting org.spark-project.jetty.server.handler.ResourceHandler@218ec40
15/08/11 10:17:58 DEBUG AbstractHandler: starting org.spark-project.jetty.server.handler.ResourceHandler@218ec40
15/08/11 10:17:58 DEBUG AbstractLifeCycle: STARTED org.spark-project.jetty.server.handler.ResourceHandler@218ec40
15/08/11 10:17:58 DEBUG AbstractLifeCycle: starting org.spark-project.jetty.server.handler.DefaultHandler@323e5ed3
15/08/11 10:17:58 DEBUG AbstractHandler: starting org.spark-project.jetty.server.handler.DefaultHandler@323e5ed3
15/08/11 10:17:58 DEBUG AbstractLifeCycle: STARTED org.spark-project.jetty.server.handler.DefaultHandler@323e5ed3
15/08/11 10:17:58 DEBUG AbstractHandler: starting org.spark-project.jetty.server.handler.HandlerList@1f56e60b
15/08/11 10:17:58 DEBUG AbstractLifeCycle: STARTED org.spark-project.jetty.server.handler.HandlerList@1f56e60b
15/08/11 10:17:58 DEBUG AbstractHandler: starting org.spark-project.jetty.server.Server@2c1da9b4
15/08/11 10:17:58 DEBUG AbstractLifeCycle: starting qtp151884440{8<=0<=0/254,-1}
15/08/11 10:17:58 DEBUG AbstractLifeCycle: STARTED qtp151884440{8<=7<=8/254,0}
15/08/11 10:17:58 DEBUG AbstractLifeCycle: starting SocketConnector@0.0.0.0:0
15/08/11 10:17:58 DEBUG AbstractLifeCycle: starting null/null
15/08/11 10:17:58 DEBUG AbstractLifeCycle: STARTED PooledBuffers [0/1024@6144,0/1024@16384,0/1024@-]/PooledBuffers [0/1024@6144,0/1024@32768,0/1024@-]
15/08/11 10:17:58 INFO AbstractConnector: Started SocketConnector@0.0.0.0:40555
15/08/11 10:17:58 DEBUG AbstractLifeCycle: STARTED SocketConnector@0.0.0.0:40555
15/08/11 10:17:58 DEBUG AbstractLifeCycle: STARTED org.spark-project.jetty.server.Server@2c1da9b4
15/08/11 10:17:58 INFO Utils: Successfully started service 'HTTP file server' on port 40555.
15/08/11 10:17:58 DEBUG HttpFileServer: HTTP file server started at: http://192.168.130.131:40555
15/08/11 10:17:58 INFO SparkEnv: Registering OutputCommitCoordinator
15/08/11 10:17:58 DEBUG ServletHandler: filterNameMap={}
15/08/11 10:17:58 DEBUG ServletHandler: pathFilters=null
15/08/11 10:17:58 DEBUG ServletHandler: servletFilterMap=null
15/08/11 10:17:58 DEBUG ServletHandler: servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$1-79d4583d}
15/08/11 10:17:58 DEBUG ServletHandler: servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-79d4583d=org.apache.spark.ui.JettyUtils$$anon$1-79d4583d}
15/08/11 10:17:58 DEBUG ServletHandler: filterNameMap={}
15/08/11 10:17:58 DEBUG ServletHandler: pathFilters=null
15/08/11 10:17:58 DEBUG ServletHandler: servletFilterMap=null
15/08/11 10:17:58 DEBUG ServletHandler: servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$1-5cbd608}
15/08/11 10:17:58 DEBUG ServletHandler: servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-5cbd608=org.apache.spark.ui.JettyUtils$$anon$1-5cbd608}
15/08/11 10:17:58 DEBUG ServletHandler: filterNameMap={}
15/08/11 10:17:58 DEBUG ServletHandler: pathFilters=null
15/08/11 10:17:58 DEBUG ServletHandler: servletFilterMap=null
15/08/11 10:17:58 DEBUG ServletHandler: servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$1-950aa31}
15/08/11 10:17:58 DEBUG ServletHandler: servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-950aa31=org.apache.spark.ui.JettyUtils$$anon$1-950aa31}
15/08/11 10:17:58 DEBUG ServletHandler: filterNameMap={}
15/08/11 10:17:58 DEBUG ServletHandler: pathFilters=null
15/08/11 10:17:58 DEBUG ServletHandler: servletFilterMap=null
15/08/11 10:17:58 DEBUG ServletHandler: servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$1-ed57bbe}
15/08/11 10:17:58 DEBUG ServletHandler: servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-ed57bbe=org.apache.spark.ui.JettyUtils$$anon$1-ed57bbe}
15/08/11 10:17:58 DEBUG ServletHandler: filterNameMap={}
15/08/11 10:17:58 DEBUG ServletHandler: pathFilters=null
15/08/11 10:17:58 DEBUG ServletHandler: servletFilterMap=null
15/08/11 10:17:58 DEBUG ServletHandler: servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$1-18dd055e}
15/08/11 10:17:58 DEBUG ServletHandler: servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-18dd055e=org.apache.spark.ui.JettyUtils$$anon$1-18dd055e}
15/08/11 10:17:58 DEBUG ServletHandler: filterNameMap={}
15/08/11 10:17:58 DEBUG ServletHandler: pathFilters=null
15/08/11 10:17:58 DEBUG ServletHandler: servletFilterMap=null
15/08/11 10:17:58 DEBUG ServletHandler: servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$1-568b6b12}
15/08/11 10:17:58 DEBUG ServletHandler: servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-568b6b12=org.apache.spark.ui.JettyUtils$$anon$1-568b6b12}
15/08/11 10:17:58 DEBUG ServletHandler: filterNameMap={}
15/08/11 10:17:58 DEBUG ServletHandler: pathFilters=null
15/08/11 10:17:58 DEBUG ServletHandler: servletFilterMap=null
15/08/11 10:17:58 DEBUG ServletHandler: servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$1-5b229721}
15/08/11 10:17:58 DEBUG ServletHandler: servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-5b229721=org.apache.spark.ui.JettyUtils$$anon$1-5b229721}
15/08/11 10:17:58 DEBUG ServletHandler: filterNameMap={}
15/08/11 10:17:58 DEBUG ServletHandler: pathFilters=null
15/08/11 10:17:58 DEBUG ServletHandler: servletFilterMap=null
15/08/11 10:17:58 DEBUG ServletHandler: servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$1-3bf02645}
15/08/11 10:17:58 DEBUG ServletHandler: servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-3bf02645=org.apache.spark.ui.JettyUtils$$anon$1-3bf02645}
15/08/11 10:17:58 DEBUG ServletHandler: filterNameMap={}
15/08/11 10:17:58 DEBUG ServletHandler: pathFilters=null
15/08/11 10:17:58 DEBUG ServletHandler: servletFilterMap=null
15/08/11 10:17:58 DEBUG ServletHandler: servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$1-13609ac1}
15/08/11 10:17:58 DEBUG ServletHandler: servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-13609ac1=org.apache.spark.ui.JettyUtils$$anon$1-13609ac1}
15/08/11 10:17:58 DEBUG ServletHandler: filterNameMap={}
15/08/11 10:17:58 DEBUG ServletHandler: pathFilters=null
15/08/11 10:17:58 DEBUG ServletHandler: servletFilterMap=null
15/08/11 10:17:58 DEBUG ServletHandler: servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$1-2b4ffed7}
15/08/11 10:17:58 DEBUG ServletHandler: servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-2b4ffed7=org.apache.spark.ui.JettyUtils$$anon$1-2b4ffed7}
15/08/11 10:17:58 DEBUG ServletHandler: filterNameMap={}
15/08/11 10:17:58 DEBUG ServletHandler: pathFilters=null
15/08/11 10:17:58 DEBUG ServletHandler: servletFilterMap=null
15/08/11 10:17:58 DEBUG ServletHandler: servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$1-3b7b65f8}
15/08/11 10:17:58 DEBUG ServletHandler: servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-3b7b65f8=org.apache.spark.ui.JettyUtils$$anon$1-3b7b65f8}
15/08/11 10:17:58 DEBUG ServletHandler: filterNameMap={}
15/08/11 10:17:58 DEBUG ServletHandler: pathFilters=null
15/08/11 10:17:58 DEBUG ServletHandler: servletFilterMap=null
15/08/11 10:17:58 DEBUG ServletHandler: servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$1-22639b4a}
15/08/11 10:17:58 DEBUG ServletHandler: servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-22639b4a=org.apache.spark.ui.JettyUtils$$anon$1-22639b4a}
15/08/11 10:17:58 DEBUG ServletHandler: filterNameMap={}
15/08/11 10:17:58 DEBUG ServletHandler: pathFilters=null
15/08/11 10:17:58 DEBUG ServletHandler: servletFilterMap=null
15/08/11 10:17:58 DEBUG ServletHandler: servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$1-396828e9}
15/08/11 10:17:58 DEBUG ServletHandler: servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-396828e9=org.apache.spark.ui.JettyUtils$$anon$1-396828e9}
15/08/11 10:17:58 DEBUG ServletHandler: filterNameMap={}
15/08/11 10:17:58 DEBUG ServletHandler: pathFilters=null
15/08/11 10:17:58 DEBUG ServletHandler: servletFilterMap=null
15/08/11 10:17:58 DEBUG ServletHandler: servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$1-6555f670}
15/08/11 10:17:58 DEBUG ServletHandler: servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-6555f670=org.apache.spark.ui.JettyUtils$$anon$1-6555f670}
15/08/11 10:17:58 DEBUG ServletHandler: filterNameMap={}
15/08/11 10:17:58 DEBUG ServletHandler: pathFilters=null
15/08/11 10:17:58 DEBUG ServletHandler: servletFilterMap=null
15/08/11 10:17:58 DEBUG ServletHandler: servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$1-7ebb0a40}
15/08/11 10:17:58 DEBUG ServletHandler: servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-7ebb0a40=org.apache.spark.ui.JettyUtils$$anon$1-7ebb0a40}
15/08/11 10:17:58 DEBUG ServletHandler: filterNameMap={}
15/08/11 10:17:58 DEBUG ServletHandler: pathFilters=null
15/08/11 10:17:58 DEBUG ServletHandler: servletFilterMap=null
15/08/11 10:17:58 DEBUG ServletHandler: servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$1-299e30c0}
15/08/11 10:17:58 DEBUG ServletHandler: servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-299e30c0=org.apache.spark.ui.JettyUtils$$anon$1-299e30c0}
15/08/11 10:17:58 DEBUG ServletHandler: filterNameMap={}
15/08/11 10:17:58 DEBUG ServletHandler: pathFilters=null
15/08/11 10:17:58 DEBUG ServletHandler: servletFilterMap=null
15/08/11 10:17:58 DEBUG ServletHandler: servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$1-7b61a226}
15/08/11 10:17:58 DEBUG ServletHandler: servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-7b61a226=org.apache.spark.ui.JettyUtils$$anon$1-7b61a226}
15/08/11 10:17:58 DEBUG ServletHandler: filterNameMap={}
15/08/11 10:17:58 DEBUG ServletHandler: pathFilters=null
15/08/11 10:17:58 DEBUG ServletHandler: servletFilterMap=null
15/08/11 10:17:58 DEBUG ServletHandler: servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$1-46dcac12}
15/08/11 10:17:58 DEBUG ServletHandler: servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-46dcac12=org.apache.spark.ui.JettyUtils$$anon$1-46dcac12}
15/08/11 10:17:58 DEBUG ServletHandler: filterNameMap={}
15/08/11 10:17:58 DEBUG ServletHandler: pathFilters=null
15/08/11 10:17:58 DEBUG ServletHandler: servletFilterMap=null
15/08/11 10:17:58 DEBUG ServletHandler: servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$1-41a4f616}
15/08/11 10:17:58 DEBUG ServletHandler: servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-41a4f616=org.apache.spark.ui.JettyUtils$$anon$1-41a4f616}
15/08/11 10:17:58 DEBUG ServletHandler: filterNameMap={}
15/08/11 10:17:58 DEBUG ServletHandler: pathFilters=null
15/08/11 10:17:58 DEBUG ServletHandler: servletFilterMap=null
15/08/11 10:17:58 DEBUG ServletHandler: servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$1-4b13237e}
15/08/11 10:17:58 DEBUG ServletHandler: servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-4b13237e=org.apache.spark.ui.JettyUtils$$anon$1-4b13237e}
15/08/11 10:17:58 DEBUG ServletHandler: filterNameMap={}
15/08/11 10:17:58 DEBUG ServletHandler: pathFilters=null
15/08/11 10:17:58 DEBUG ServletHandler: servletFilterMap=null
15/08/11 10:17:58 DEBUG ServletHandler: servletPathMap={/=org.spark-project.jetty.servlet.DefaultServlet-8216547}
15/08/11 10:17:58 DEBUG ServletHandler: servletNameMap={org.spark-project.jetty.servlet.DefaultServlet-8216547=org.spark-project.jetty.servlet.DefaultServlet-8216547}
15/08/11 10:17:58 DEBUG ServletHandler: filterNameMap={}
15/08/11 10:17:58 DEBUG ServletHandler: pathFilters=null
15/08/11 10:17:58 DEBUG ServletHandler: servletFilterMap=null
15/08/11 10:17:58 DEBUG ServletHandler: servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-4347154c}
15/08/11 10:17:58 DEBUG ServletHandler: servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-4347154c=org.apache.spark.ui.JettyUtils$$anon$2-4347154c}
15/08/11 10:17:58 DEBUG ServletHandler: filterNameMap={}
15/08/11 10:17:58 DEBUG ServletHandler: pathFilters=null
15/08/11 10:17:58 DEBUG ServletHandler: servletFilterMap=null
15/08/11 10:17:58 DEBUG ServletHandler: servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-61b60992}
15/08/11 10:17:58 DEBUG ServletHandler: servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-61b60992=org.apache.spark.ui.JettyUtils$$anon$2-61b60992}
15/08/11 10:17:58 DEBUG Container: Container org.spark-project.jetty.server.Server@1e6520b6 + SelectChannelConnector@0.0.0.0:4040 as connector
15/08/11 10:17:58 DEBUG Container: Container org.spark-project.jetty.server.Server@1e6520b6 + qtp21404753{8<=0<=0/254,-1} as threadpool
15/08/11 10:17:58 DEBUG Container: Container org.spark-project.jetty.server.handler.ContextHandlerCollection@42c08a7e + o.s.j.s.ServletContextHandler{/jobs,null} as handler
15/08/11 10:17:58 DEBUG Container: Container org.spark-project.jetty.server.handler.ContextHandlerCollection@42c08a7e + o.s.j.s.ServletContextHandler{/jobs/json,null} as handler
15/08/11 10:17:58 DEBUG Container: Container org.spark-project.jetty.server.handler.ContextHandlerCollection@42c08a7e + o.s.j.s.ServletContextHandler{/jobs/job,null} as handler
15/08/11 10:17:58 DEBUG Container: Container org.spark-project.jetty.server.handler.ContextHandlerCollection@42c08a7e + o.s.j.s.ServletContextHandler{/jobs/job/json,null} as handler
15/08/11 10:17:58 DEBUG Container: Container org.spark-project.jetty.server.handler.ContextHandlerCollection@42c08a7e + o.s.j.s.ServletContextHandler{/stages,null} as handler
15/08/11 10:17:58 DEBUG Container: Container org.spark-project.jetty.server.handler.ContextHandlerCollection@42c08a7e + o.s.j.s.ServletContextHandler{/stages/json,null} as handler
15/08/11 10:17:58 DEBUG Container: Container org.spark-project.jetty.server.handler.ContextHandlerCollection@42c08a7e + o.s.j.s.ServletContextHandler{/stages/stage,null} as handler
15/08/11 10:17:58 DEBUG Container: Container org.spark-project.jetty.server.handler.ContextHandlerCollection@42c08a7e + o.s.j.s.ServletContextHandler{/stages/stage/json,null} as handler
15/08/11 10:17:58 DEBUG Container: Container org.spark-project.jetty.server.handler.ContextHandlerCollection@42c08a7e + o.s.j.s.ServletContextHandler{/stages/pool,null} as handler
15/08/11 10:17:58 DEBUG Container: Container org.spark-project.jetty.server.handler.ContextHandlerCollection@42c08a7e + o.s.j.s.ServletContextHandler{/stages/pool/json,null} as handler
15/08/11 10:17:58 DEBUG Container: Container org.spark-project.jetty.server.handler.ContextHandlerCollection@42c08a7e + o.s.j.s.ServletContextHandler{/storage,null} as handler
15/08/11 10:17:58 DEBUG Container: Container org.spark-project.jetty.server.handler.ContextHandlerCollection@42c08a7e + o.s.j.s.ServletContextHandler{/storage/json,null} as handler
15/08/11 10:17:58 DEBUG Container: Container org.spark-project.jetty.server.handler.ContextHandlerCollection@42c08a7e + o.s.j.s.ServletContextHandler{/storage/rdd,null} as handler
15/08/11 10:17:58 DEBUG Container: Container org.spark-project.jetty.server.handler.ContextHandlerCollection@42c08a7e + o.s.j.s.ServletContextHandler{/storage/rdd/json,null} as handler
15/08/11 10:17:58 DEBUG Container: Container org.spark-project.jetty.server.handler.ContextHandlerCollection@42c08a7e + o.s.j.s.ServletContextHandler{/environment,null} as handler
15/08/11 10:17:58 DEBUG Container: Container org.spark-project.jetty.server.handler.ContextHandlerCollection@42c08a7e + o.s.j.s.ServletContextHandler{/environment/json,null} as handler
15/08/11 10:17:58 DEBUG Container: Container org.spark-project.jetty.server.handler.ContextHandlerCollection@42c08a7e + o.s.j.s.ServletContextHandler{/executors,null} as handler
15/08/11 10:17:58 DEBUG Container: Container org.spark-project.jetty.server.handler.ContextHandlerCollection@42c08a7e + o.s.j.s.ServletContextHandler{/executors/json,null} as handler
15/08/11 10:17:58 DEBUG Container: Container org.spark-project.jetty.server.handler.ContextHandlerCollection@42c08a7e + o.s.j.s.ServletContextHandler{/executors/threadDump,null} as handler
15/08/11 10:17:58 DEBUG Container: Container org.spark-project.jetty.server.handler.ContextHandlerCollection@42c08a7e + o.s.j.s.ServletContextHandler{/executors/threadDump/json,null} as handler
15/08/11 10:17:58 DEBUG Container: Container org.spark-project.jetty.server.handler.ContextHandlerCollection@42c08a7e + o.s.j.s.ServletContextHandler{/static,null} as handler
15/08/11 10:17:58 DEBUG Container: Container org.spark-project.jetty.server.handler.ContextHandlerCollection@42c08a7e + o.s.j.s.ServletContextHandler{/,null} as handler
15/08/11 10:17:58 DEBUG Container: Container org.spark-project.jetty.server.handler.ContextHandlerCollection@42c08a7e + o.s.j.s.ServletContextHandler{/stages/stage/kill,null} as handler
15/08/11 10:17:58 DEBUG Container: Container org.spark-project.jetty.server.Server@1e6520b6 + org.spark-project.jetty.server.handler.ContextHandlerCollection@42c08a7e as handler
15/08/11 10:17:58 DEBUG AbstractLifeCycle: starting org.spark-project.jetty.server.Server@1e6520b6
15/08/11 10:17:58 INFO Server: jetty-8.y.z-SNAPSHOT
15/08/11 10:17:58 DEBUG AbstractLifeCycle: starting org.spark-project.jetty.server.handler.ContextHandlerCollection@42c08a7e
15/08/11 10:17:58 DEBUG AbstractLifeCycle: starting o.s.j.s.ServletContextHandler{/jobs,null}
15/08/11 10:17:58 DEBUG Container: Container org.spark-project.jetty.servlet.ServletHandler@73218274 + org.apache.spark.ui.JettyUtils$$anon$1-79d4583d as servlet
15/08/11 10:17:58 DEBUG Container: Container org.spark-project.jetty.servlet.ServletHandler@73218274 + [/]=>org.apache.spark.ui.JettyUtils$$anon$1-79d4583d as servletMapping
15/08/11 10:17:58 DEBUG Container: Container o.s.j.s.ServletContextHandler{/jobs,null} + org.spark-project.jetty.servlet.ServletHandler@73218274 as handler
15/08/11 10:17:58 DEBUG AbstractLifeCycle: starting org.spark-project.jetty.servlet.ServletHandler@73218274
15/08/11 10:17:58 DEBUG ServletHandler: filterNameMap={}
15/08/11 10:17:58 DEBUG ServletHandler: pathFilters=null
15/08/11 10:17:58 DEBUG ServletHandler: servletFilterMap=null
15/08/11 10:17:58 DEBUG ServletHandler: servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$1-79d4583d}
15/08/11 10:17:58 DEBUG ServletHandler: servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-79d4583d=org.apache.spark.ui.JettyUtils$$anon$1-79d4583d}
15/08/11 10:17:58 DEBUG AbstractHandler: starting org.spark-project.jetty.servlet.ServletHandler@73218274
15/08/11 10:17:58 DEBUG AbstractLifeCycle: STARTED org.spark-project.jetty.servlet.ServletHandler@73218274
15/08/11 10:17:58 DEBUG AbstractHandler: starting o.s.j.s.ServletContextHandler{/jobs,null}
15/08/11 10:17:58 DEBUG AbstractLifeCycle: starting org.apache.spark.ui.JettyUtils$$anon$1-79d4583d
15/08/11 10:17:58 DEBUG AbstractLifeCycle: STARTED org.apache.spark.ui.JettyUtils$$anon$1-79d4583d
15/08/11 10:17:58 DEBUG AbstractLifeCycle: STARTED o.s.j.s.ServletContextHandler{/jobs,null}
15/08/11 10:17:58 DEBUG AbstractLifeCycle: starting o.s.j.s.ServletContextHandler{/jobs/json,null}
15/08/11 10:17:58 DEBUG Container: Container org.spark-project.jetty.servlet.ServletHandler@69697a63 + org.apache.spark.ui.JettyUtils$$anon$1-5cbd608 as servlet
15/08/11 10:17:58 DEBUG Container: Container org.spark-project.jetty.servlet.ServletHandler@69697a63 + [/]=>org.apache.spark.ui.JettyUtils$$anon$1-5cbd608 as servletMapping
15/08/11 10:17:58 DEBUG Container: Container o.s.j.s.ServletContextHandler{/jobs/json,null} + org.spark-project.jetty.servlet.ServletHandler@69697a63 as handler
15/08/11 10:17:58 DEBUG AbstractLifeCycle: starting org.spark-project.jetty.servlet.ServletHandler@69697a63
15/08/11 10:17:58 DEBUG ServletHandler: filterNameMap={}
15/08/11 10:17:58 DEBUG ServletHandler: pathFilters=null
15/08/11 10:17:58 DEBUG ServletHandler: servletFilterMap=null
15/08/11 10:17:58 DEBUG ServletHandler: servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$1-5cbd608}
15/08/11 10:17:58 DEBUG ServletHandler: servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-5cbd608=org.apache.spark.ui.JettyUtils$$anon$1-5cbd608}
15/08/11 10:17:58 DEBUG AbstractHandler: starting org.spark-project.jetty.servlet.ServletHandler@69697a63
15/08/11 10:17:58 DEBUG AbstractLifeCycle: STARTED org.spark-project.jetty.servlet.ServletHandler@69697a63
15/08/11 10:17:58 DEBUG AbstractHandler: starting o.s.j.s.ServletContextHandler{/jobs/json,null}
15/08/11 10:17:58 DEBUG AbstractLifeCycle: starting org.apache.spark.ui.JettyUtils$$anon$1-5cbd608
15/08/11 10:17:58 DEBUG AbstractLifeCycle: STARTED org.apache.spark.ui.JettyUtils$$anon$1-5cbd608
15/08/11 10:17:58 DEBUG AbstractLifeCycle: STARTED o.s.j.s.ServletContextHandler{/jobs/json,null}
15/08/11 10:17:58 DEBUG AbstractLifeCycle: starting o.s.j.s.ServletContextHandler{/jobs/job,null}
15/08/11 10:17:58 DEBUG Container: Container org.spark-project.jetty.servlet.ServletHandler@be22fa6 + org.apache.spark.ui.JettyUtils$$anon$1-950aa31 as servlet
15/08/11 10:17:58 DEBUG Container: Container org.spark-project.jetty.servlet.ServletHandler@be22fa6 + [/]=>org.apache.spark.ui.JettyUtils$$anon$1-950aa31 as servletMapping
15/08/11 10:17:58 DEBUG Container: Container o.s.j.s.ServletContextHandler{/jobs/job,null} + org.spark-project.jetty.servlet.ServletHandler@be22fa6 as handler
15/08/11 10:17:58 DEBUG AbstractLifeCycle: starting org.spark-project.jetty.servlet.ServletHandler@be22fa6
15/08/11 10:17:58 DEBUG ServletHandler: filterNameMap={}
15/08/11 10:17:58 DEBUG ServletHandler: pathFilters=null
15/08/11 10:17:58 DEBUG ServletHandler: servletFilterMap=null
15/08/11 10:17:58 DEBUG ServletHandler: servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$1-950aa31}
15/08/11 10:17:58 DEBUG ServletHandler: servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-950aa31=org.apache.spark.ui.JettyUtils$$anon$1-950aa31}
15/08/11 10:17:58 DEBUG AbstractHandler: starting org.spark-project.jetty.servlet.ServletHandler@be22fa6
15/08/11 10:17:58 DEBUG AbstractLifeCycle: STARTED org.spark-project.jetty.servlet.ServletHandler@be22fa6
15/08/11 10:17:58 DEBUG AbstractHandler: starting o.s.j.s.ServletContextHandler{/jobs/job,null}
15/08/11 10:17:58 DEBUG AbstractLifeCycle: starting org.apache.spark.ui.JettyUtils$$anon$1-950aa31
15/08/11 10:17:58 DEBUG AbstractLifeCycle: STARTED org.apache.spark.ui.JettyUtils$$anon$1-950aa31
15/08/11 10:17:58 DEBUG AbstractLifeCycle: STARTED o.s.j.s.ServletContextHandler{/jobs/job,null}
15/08/11 10:17:58 DEBUG AbstractLifeCycle: starting o.s.j.s.ServletContextHandler{/jobs/job/json,null}
15/08/11 10:17:58 DEBUG Container: Container org.spark-project.jetty.servlet.ServletHandler@2ea64162 + org.apache.spark.ui.JettyUtils$$anon$1-ed57bbe as servlet
15/08/11 10:17:58 DEBUG Container: Container org.spark-project.jetty.servlet.ServletHandler@2ea64162 + [/]=>org.apache.spark.ui.JettyUtils$$anon$1-ed57bbe as servletMapping
15/08/11 10:17:58 DEBUG Container: Container o.s.j.s.ServletContextHandler{/jobs/job/json,null} + org.spark-project.jetty.servlet.ServletHandler@2ea64162 as handler
15/08/11 10:17:58 DEBUG AbstractLifeCycle: starting org.spark-project.jetty.servlet.ServletHandler@2ea64162
15/08/11 10:17:58 DEBUG ServletHandler: filterNameMap={}
15/08/11 10:17:58 DEBUG ServletHandler: pathFilters=null
15/08/11 10:17:58 DEBUG ServletHandler: servletFilterMap=null
15/08/11 10:17:58 DEBUG ServletHandler: servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$1-ed57bbe}
15/08/11 10:17:58 DEBUG ServletHandler: servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-ed57bbe=org.apache.spark.ui.JettyUtils$$anon$1-ed57bbe}
15/08/11 10:17:58 DEBUG AbstractHandler: starting org.spark-project.jetty.servlet.ServletHandler@2ea64162
15/08/11 10:17:58 DEBUG AbstractLifeCycle: STARTED org.spark-project.jetty.servlet.ServletHandler@2ea64162
15/08/11 10:17:58 DEBUG AbstractHandler: starting o.s.j.s.ServletContextHandler{/jobs/job/json,null}
15/08/11 10:17:58 DEBUG AbstractLifeCycle: starting org.apache.spark.ui.JettyUtils$$anon$1-ed57bbe
15/08/11 10:17:58 DEBUG AbstractLifeCycle: STARTED org.apache.spark.ui.JettyUtils$$anon$1-ed57bbe
15/08/11 10:17:58 DEBUG AbstractLifeCycle: STARTED o.s.j.s.ServletContextHandler{/jobs/job/json,null}
15/08/11 10:17:58 DEBUG AbstractLifeCycle: starting o.s.j.s.ServletContextHandler{/stages,null}
15/08/11 10:17:58 DEBUG Container: Container org.spark-project.jetty.servlet.ServletHandler@250ea0db + org.apache.spark.ui.JettyUtils$$anon$1-18dd055e as servlet
15/08/11 10:17:58 DEBUG Container: Container org.spark-project.jetty.servlet.ServletHandler@250ea0db + [/]=>org.apache.spark.ui.JettyUtils$$anon$1-18dd055e as servletMapping
15/08/11 10:17:58 DEBUG Container: Container o.s.j.s.ServletContextHandler{/stages,null} + org.spark-project.jetty.servlet.ServletHandler@250ea0db as handler
15/08/11 10:17:58 DEBUG AbstractLifeCycle: starting org.spark-project.jetty.servlet.ServletHandler@250ea0db
15/08/11 10:17:58 DEBUG ServletHandler: filterNameMap={}
15/08/11 10:17:58 DEBUG ServletHandler: pathFilters=null
15/08/11 10:17:58 DEBUG ServletHandler: servletFilterMap=null
15/08/11 10:17:58 DEBUG ServletHandler: servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$1-18dd055e}
15/08/11 10:17:58 DEBUG ServletHandler: servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-18dd055e=org.apache.spark.ui.JettyUtils$$anon$1-18dd055e}
15/08/11 10:17:58 DEBUG AbstractHandler: starting org.spark-project.jetty.servlet.ServletHandler@250ea0db
15/08/11 10:17:58 DEBUG AbstractLifeCycle: STARTED org.spark-project.jetty.servlet.ServletHandler@250ea0db
15/08/11 10:17:58 DEBUG AbstractHandler: starting o.s.j.s.ServletContextHandler{/stages,null}
15/08/11 10:17:58 DEBUG AbstractLifeCycle: starting org.apache.spark.ui.JettyUtils$$anon$1-18dd055e
15/08/11 10:17:58 DEBUG AbstractLifeCycle: STARTED org.apache.spark.ui.JettyUtils$$anon$1-18dd055e
15/08/11 10:17:58 DEBUG AbstractLifeCycle: STARTED o.s.j.s.ServletContextHandler{/stages,null}
15/08/11 10:17:58 DEBUG AbstractLifeCycle: starting o.s.j.s.ServletContextHandler{/stages/json,null}
15/08/11 10:17:58 DEBUG Container: Container org.spark-project.jetty.servlet.ServletHandler@63629cde + org.apache.spark.ui.JettyUtils$$anon$1-568b6b12 as servlet
15/08/11 10:17:58 DEBUG Container: Container org.spark-project.jetty.servlet.ServletHandler@63629cde + [/]=>org.apache.spark.ui.JettyUtils$$anon$1-568b6b12 as servletMapping
15/08/11 10:17:58 DEBUG Container: Container o.s.j.s.ServletContextHandler{/stages/json,null} + org.spark-project.jetty.servlet.ServletHandler@63629cde as handler
15/08/11 10:17:58 DEBUG AbstractLifeCycle: starting org.spark-project.jetty.servlet.ServletHandler@63629cde
15/08/11 10:17:58 DEBUG ServletHandler: filterNameMap={}
15/08/11 10:17:58 DEBUG ServletHandler: pathFilters=null
15/08/11 10:17:58 DEBUG ServletHandler: servletFilterMap=null
15/08/11 10:17:58 DEBUG ServletHandler: servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$1-568b6b12}
15/08/11 10:17:58 DEBUG ServletHandler: servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-568b6b12=org.apache.spark.ui.JettyUtils$$anon$1-568b6b12}
15/08/11 10:17:58 DEBUG AbstractHandler: starting org.spark-project.jetty.servlet.ServletHandler@63629cde
15/08/11 10:17:58 DEBUG AbstractLifeCycle: STARTED org.spark-project.jetty.servlet.ServletHandler@63629cde
15/08/11 10:17:58 DEBUG AbstractHandler: starting o.s.j.s.ServletContextHandler{/stages/json,null}
15/08/11 10:17:58 DEBUG AbstractLifeCycle: starting org.apache.spark.ui.JettyUtils$$anon$1-568b6b12
15/08/11 10:17:58 DEBUG AbstractLifeCycle: STARTED org.apache.spark.ui.JettyUtils$$anon$1-568b6b12
15/08/11 10:17:58 DEBUG AbstractLifeCycle: STARTED o.s.j.s.ServletContextHandler{/stages/json,null}
15/08/11 10:17:58 DEBUG AbstractLifeCycle: starting o.s.j.s.ServletContextHandler{/stages/stage,null}
15/08/11 10:17:58 DEBUG Container: Container org.spark-project.jetty.servlet.ServletHandler@5f28e5cb + org.apache.spark.ui.JettyUtils$$anon$1-5b229721 as servlet
15/08/11 10:17:58 DEBUG Container: Container org.spark-project.jetty.servlet.ServletHandler@5f28e5cb + [/]=>org.apache.spark.ui.JettyUtils$$anon$1-5b229721 as servletMapping
15/08/11 10:17:58 DEBUG Container: Container o.s.j.s.ServletContextHandler{/stages/stage,null} + org.spark-project.jetty.servlet.ServletHandler@5f28e5cb as handler
15/08/11 10:17:58 DEBUG AbstractLifeCycle: starting org.spark-project.jetty.servlet.ServletHandler@5f28e5cb
15/08/11 10:17:58 DEBUG ServletHandler: filterNameMap={}
15/08/11 10:17:58 DEBUG ServletHandler: pathFilters=null
15/08/11 10:17:58 DEBUG ServletHandler: servletFilterMap=null
15/08/11 10:17:58 DEBUG ServletHandler: servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$1-5b229721}
15/08/11 10:17:58 DEBUG ServletHandler: servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-5b229721=org.apache.spark.ui.JettyUtils$$anon$1-5b229721}
15/08/11 10:17:58 DEBUG AbstractHandler: starting org.spark-project.jetty.servlet.ServletHandler@5f28e5cb
15/08/11 10:17:58 DEBUG AbstractLifeCycle: STARTED org.spark-project.jetty.servlet.ServletHandler@5f28e5cb
15/08/11 10:17:58 DEBUG AbstractHandler: starting o.s.j.s.ServletContextHandler{/stages/stage,null}
15/08/11 10:17:58 DEBUG AbstractLifeCycle: starting org.apache.spark.ui.JettyUtils$$anon$1-5b229721
15/08/11 10:17:58 DEBUG AbstractLifeCycle: STARTED org.apache.spark.ui.JettyUtils$$anon$1-5b229721
15/08/11 10:17:58 DEBUG AbstractLifeCycle: STARTED o.s.j.s.ServletContextHandler{/stages/stage,null}
15/08/11 10:17:58 DEBUG AbstractLifeCycle: starting o.s.j.s.ServletContextHandler{/stages/stage/json,null}
15/08/11 10:17:58 DEBUG Container: Container org.spark-project.jetty.servlet.ServletHandler@7606a33b + org.apache.spark.ui.JettyUtils$$anon$1-3bf02645 as servlet
15/08/11 10:17:58 DEBUG Container: Container org.spark-project.jetty.servlet.ServletHandler@7606a33b + [/]=>org.apache.spark.ui.JettyUtils$$anon$1-3bf02645 as servletMapping
15/08/11 10:17:58 DEBUG Container: Container o.s.j.s.ServletContextHandler{/stages/stage/json,null} + org.spark-project.jetty.servlet.ServletHandler@7606a33b as handler
15/08/11 10:17:58 DEBUG AbstractLifeCycle: starting org.spark-project.jetty.servlet.ServletHandler@7606a33b
15/08/11 10:17:58 DEBUG ServletHandler: filterNameMap={}
15/08/11 10:17:58 DEBUG ServletHandler: pathFilters=null
15/08/11 10:17:58 DEBUG ServletHandler: servletFilterMap=null
15/08/11 10:17:58 DEBUG ServletHandler: servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$1-3bf02645}
15/08/11 10:17:58 DEBUG ServletHandler: servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-3bf02645=org.apache.spark.ui.JettyUtils$$anon$1-3bf02645}
15/08/11 10:17:58 DEBUG AbstractHandler: starting org.spark-project.jetty.servlet.ServletHandler@7606a33b
15/08/11 10:17:58 DEBUG AbstractLifeCycle: STARTED org.spark-project.jetty.servlet.ServletHandler@7606a33b
15/08/11 10:17:58 DEBUG AbstractHandler: starting o.s.j.s.ServletContextHandler{/stages/stage/json,null}
15/08/11 10:17:58 DEBUG AbstractLifeCycle: starting org.apache.spark.ui.JettyUtils$$anon$1-3bf02645
15/08/11 10:17:58 DEBUG AbstractLifeCycle: STARTED org.apache.spark.ui.JettyUtils$$anon$1-3bf02645
15/08/11 10:17:58 DEBUG AbstractLifeCycle: STARTED o.s.j.s.ServletContextHandler{/stages/stage/json,null}
15/08/11 10:17:58 DEBUG AbstractLifeCycle: starting o.s.j.s.ServletContextHandler{/stages/pool,null}
15/08/11 10:17:58 DEBUG Container: Container org.spark-project.jetty.servlet.ServletHandler@2dc6b306 + org.apache.spark.ui.JettyUtils$$anon$1-13609ac1 as servlet
15/08/11 10:17:58 DEBUG Container: Container org.spark-project.jetty.servlet.ServletHandler@2dc6b306 + [/]=>org.apache.spark.ui.JettyUtils$$anon$1-13609ac1 as servletMapping
15/08/11 10:17:58 DEBUG Container: Container o.s.j.s.ServletContextHandler{/stages/pool,null} + org.spark-project.jetty.servlet.ServletHandler@2dc6b306 as handler
15/08/11 10:17:58 DEBUG AbstractLifeCycle: starting org.spark-project.jetty.servlet.ServletHandler@2dc6b306
15/08/11 10:17:58 DEBUG ServletHandler: filterNameMap={}
15/08/11 10:17:58 DEBUG ServletHandler: pathFilters=null
15/08/11 10:17:58 DEBUG ServletHandler: servletFilterMap=null
15/08/11 10:17:58 DEBUG ServletHandler: servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$1-13609ac1}
15/08/11 10:17:58 DEBUG ServletHandler: servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-13609ac1=org.apache.spark.ui.JettyUtils$$anon$1-13609ac1}
15/08/11 10:17:58 DEBUG AbstractHandler: starting org.spark-project.jetty.servlet.ServletHandler@2dc6b306
15/08/11 10:17:58 DEBUG AbstractLifeCycle: STARTED org.spark-project.jetty.servlet.ServletHandler@2dc6b306
15/08/11 10:17:58 DEBUG AbstractHandler: starting o.s.j.s.ServletContextHandler{/stages/pool,null}
15/08/11 10:17:58 DEBUG AbstractLifeCycle: starting org.apache.spark.ui.JettyUtils$$anon$1-13609ac1
15/08/11 10:17:58 DEBUG AbstractLifeCycle: STARTED org.apache.spark.ui.JettyUtils$$anon$1-13609ac1
15/08/11 10:17:58 DEBUG AbstractLifeCycle: STARTED o.s.j.s.ServletContextHandler{/stages/pool,null}
15/08/11 10:17:58 DEBUG AbstractLifeCycle: starting o.s.j.s.ServletContextHandler{/stages/pool/json,null}
15/08/11 10:17:58 DEBUG Container: Container org.spark-project.jetty.servlet.ServletHandler@50136664 + org.apache.spark.ui.JettyUtils$$anon$1-2b4ffed7 as servlet
15/08/11 10:17:58 DEBUG Container: Container org.spark-project.jetty.servlet.ServletHandler@50136664 + [/]=>org.apache.spark.ui.JettyUtils$$anon$1-2b4ffed7 as servletMapping
15/08/11 10:17:58 DEBUG Container: Container o.s.j.s.ServletContextHandler{/stages/pool/json,null} + org.spark-project.jetty.servlet.ServletHandler@50136664 as handler
15/08/11 10:17:58 DEBUG AbstractLifeCycle: starting org.spark-project.jetty.servlet.ServletHandler@50136664
15/08/11 10:17:58 DEBUG ServletHandler: filterNameMap={}
15/08/11 10:17:58 DEBUG ServletHandler: pathFilters=null
15/08/11 10:17:58 DEBUG ServletHandler: servletFilterMap=null
15/08/11 10:17:58 DEBUG ServletHandler: servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$1-2b4ffed7}
15/08/11 10:17:58 DEBUG ServletHandler: servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-2b4ffed7=org.apache.spark.ui.JettyUtils$$anon$1-2b4ffed7}
15/08/11 10:17:58 DEBUG AbstractHandler: starting org.spark-project.jetty.servlet.ServletHandler@50136664
15/08/11 10:17:58 DEBUG AbstractLifeCycle: STARTED org.spark-project.jetty.servlet.ServletHandler@50136664
15/08/11 10:17:58 DEBUG AbstractHandler: starting o.s.j.s.ServletContextHandler{/stages/pool/json,null}
15/08/11 10:17:58 DEBUG AbstractLifeCycle: starting org.apache.spark.ui.JettyUtils$$anon$1-2b4ffed7
15/08/11 10:17:58 DEBUG AbstractLifeCycle: STARTED org.apache.spark.ui.JettyUtils$$anon$1-2b4ffed7
15/08/11 10:17:58 DEBUG AbstractLifeCycle: STARTED o.s.j.s.ServletContextHandler{/stages/pool/json,null}
15/08/11 10:17:58 DEBUG AbstractLifeCycle: starting o.s.j.s.ServletContextHandler{/storage,null}
15/08/11 10:17:58 DEBUG Container: Container org.spark-project.jetty.servlet.ServletHandler@29a7584e + org.apache.spark.ui.JettyUtils$$anon$1-3b7b65f8 as servlet
15/08/11 10:17:58 DEBUG Container: Container org.spark-project.jetty.servlet.ServletHandler@29a7584e + [/]=>org.apache.spark.ui.JettyUtils$$anon$1-3b7b65f8 as servletMapping
15/08/11 10:17:58 DEBUG Container: Container o.s.j.s.ServletContextHandler{/storage,null} + org.spark-project.jetty.servlet.ServletHandler@29a7584e as handler
15/08/11 10:17:58 DEBUG AbstractLifeCycle: starting org.spark-project.jetty.servlet.ServletHandler@29a7584e
15/08/11 10:17:58 DEBUG ServletHandler: filterNameMap={}
15/08/11 10:17:58 DEBUG ServletHandler: pathFilters=null
15/08/11 10:17:58 DEBUG ServletHandler: servletFilterMap=null
15/08/11 10:17:58 DEBUG ServletHandler: servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$1-3b7b65f8}
15/08/11 10:17:58 DEBUG ServletHandler: servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-3b7b65f8=org.apache.spark.ui.JettyUtils$$anon$1-3b7b65f8}
15/08/11 10:17:58 DEBUG AbstractHandler: starting org.spark-project.jetty.servlet.ServletHandler@29a7584e
15/08/11 10:17:58 DEBUG AbstractLifeCycle: STARTED org.spark-project.jetty.servlet.ServletHandler@29a7584e
15/08/11 10:17:58 DEBUG AbstractHandler: starting o.s.j.s.ServletContextHandler{/storage,null}
15/08/11 10:17:58 DEBUG AbstractLifeCycle: starting org.apache.spark.ui.JettyUtils$$anon$1-3b7b65f8
15/08/11 10:17:58 DEBUG AbstractLifeCycle: STARTED org.apache.spark.ui.JettyUtils$$anon$1-3b7b65f8
15/08/11 10:17:58 DEBUG AbstractLifeCycle: STARTED o.s.j.s.ServletContextHandler{/storage,null}
15/08/11 10:17:58 DEBUG AbstractLifeCycle: starting o.s.j.s.ServletContextHandler{/storage/json,null}
15/08/11 10:17:58 DEBUG Container: Container org.spark-project.jetty.servlet.ServletHandler@29967e3f + org.apache.spark.ui.JettyUtils$$anon$1-22639b4a as servlet
15/08/11 10:17:58 DEBUG Container: Container org.spark-project.jetty.servlet.ServletHandler@29967e3f + [/]=>org.apache.spark.ui.JettyUtils$$anon$1-22639b4a as servletMapping
15/08/11 10:17:58 DEBUG Container: Container o.s.j.s.ServletContextHandler{/storage/json,null} + org.spark-project.jetty.servlet.ServletHandler@29967e3f as handler
15/08/11 10:17:58 DEBUG AbstractLifeCycle: starting org.spark-project.jetty.servlet.ServletHandler@29967e3f
15/08/11 10:17:58 DEBUG ServletHandler: filterNameMap={}
15/08/11 10:17:58 DEBUG ServletHandler: pathFilters=null
15/08/11 10:17:58 DEBUG ServletHandler: servletFilterMap=null
15/08/11 10:17:58 DEBUG ServletHandler: servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$1-22639b4a}
15/08/11 10:17:58 DEBUG ServletHandler: servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-22639b4a=org.apache.spark.ui.JettyUtils$$anon$1-22639b4a}
15/08/11 10:17:58 DEBUG AbstractHandler: starting org.spark-project.jetty.servlet.ServletHandler@29967e3f
15/08/11 10:17:58 DEBUG AbstractLifeCycle: STARTED org.spark-project.jetty.servlet.ServletHandler@29967e3f
15/08/11 10:17:58 DEBUG AbstractHandler: starting o.s.j.s.ServletContextHandler{/storage/json,null}
15/08/11 10:17:58 DEBUG AbstractLifeCycle: starting org.apache.spark.ui.JettyUtils$$anon$1-22639b4a
15/08/11 10:17:58 DEBUG AbstractLifeCycle: STARTED org.apache.spark.ui.JettyUtils$$anon$1-22639b4a
15/08/11 10:17:58 DEBUG AbstractLifeCycle: STARTED o.s.j.s.ServletContextHandler{/storage/json,null}
15/08/11 10:17:58 DEBUG AbstractLifeCycle: starting o.s.j.s.ServletContextHandler{/storage/rdd,null}
15/08/11 10:17:58 DEBUG Container: Container org.spark-project.jetty.servlet.ServletHandler@573a6f6d + org.apache.spark.ui.JettyUtils$$anon$1-396828e9 as servlet
15/08/11 10:17:58 DEBUG Container: Container org.spark-project.jetty.servlet.ServletHandler@573a6f6d + [/]=>org.apache.spark.ui.JettyUtils$$anon$1-396828e9 as servletMapping
15/08/11 10:17:58 DEBUG Container: Container o.s.j.s.ServletContextHandler{/storage/rdd,null} + org.spark-project.jetty.servlet.ServletHandler@573a6f6d as handler
15/08/11 10:17:58 DEBUG AbstractLifeCycle: starting org.spark-project.jetty.servlet.ServletHandler@573a6f6d
15/08/11 10:17:58 DEBUG ServletHandler: filterNameMap={}
15/08/11 10:17:58 DEBUG ServletHandler: pathFilters=null
15/08/11 10:17:58 DEBUG ServletHandler: servletFilterMap=null
15/08/11 10:17:58 DEBUG ServletHandler: servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$1-396828e9}
15/08/11 10:17:58 DEBUG ServletHandler: servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-396828e9=org.apache.spark.ui.JettyUtils$$anon$1-396828e9}
15/08/11 10:17:58 DEBUG AbstractHandler: starting org.spark-project.jetty.servlet.ServletHandler@573a6f6d
15/08/11 10:17:58 DEBUG AbstractLifeCycle: STARTED org.spark-project.jetty.servlet.ServletHandler@573a6f6d
15/08/11 10:17:58 DEBUG AbstractHandler: starting o.s.j.s.ServletContextHandler{/storage/rdd,null}
15/08/11 10:17:58 DEBUG AbstractLifeCycle: starting org.apache.spark.ui.JettyUtils$$anon$1-396828e9
15/08/11 10:17:58 DEBUG AbstractLifeCycle: STARTED org.apache.spark.ui.JettyUtils$$anon$1-396828e9
15/08/11 10:17:58 DEBUG AbstractLifeCycle: STARTED o.s.j.s.ServletContextHandler{/storage/rdd,null}
15/08/11 10:17:58 DEBUG AbstractLifeCycle: starting o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
15/08/11 10:17:58 DEBUG Container: Container org.spark-project.jetty.servlet.ServletHandler@3d6989d8 + org.apache.spark.ui.JettyUtils$$anon$1-6555f670 as servlet
15/08/11 10:17:58 DEBUG Container: Container org.spark-project.jetty.servlet.ServletHandler@3d6989d8 + [/]=>org.apache.spark.ui.JettyUtils$$anon$1-6555f670 as servletMapping
15/08/11 10:17:58 DEBUG Container: Container o.s.j.s.ServletContextHandler{/storage/rdd/json,null} + org.spark-project.jetty.servlet.ServletHandler@3d6989d8 as handler
15/08/11 10:17:58 DEBUG AbstractLifeCycle: starting org.spark-project.jetty.servlet.ServletHandler@3d6989d8
15/08/11 10:17:58 DEBUG ServletHandler: filterNameMap={}
15/08/11 10:17:58 DEBUG ServletHandler: pathFilters=null
15/08/11 10:17:58 DEBUG ServletHandler: servletFilterMap=null
15/08/11 10:17:58 DEBUG ServletHandler: servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$1-6555f670}
15/08/11 10:17:58 DEBUG ServletHandler: servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-6555f670=org.apache.spark.ui.JettyUtils$$anon$1-6555f670}
15/08/11 10:17:58 DEBUG AbstractHandler: starting org.spark-project.jetty.servlet.ServletHandler@3d6989d8
15/08/11 10:17:58 DEBUG AbstractLifeCycle: STARTED org.spark-project.jetty.servlet.ServletHandler@3d6989d8
15/08/11 10:17:58 DEBUG AbstractHandler: starting o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
15/08/11 10:17:58 DEBUG AbstractLifeCycle: starting org.apache.spark.ui.JettyUtils$$anon$1-6555f670
15/08/11 10:17:58 DEBUG AbstractLifeCycle: STARTED org.apache.spark.ui.JettyUtils$$anon$1-6555f670
15/08/11 10:17:58 DEBUG AbstractLifeCycle: STARTED o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
15/08/11 10:17:58 DEBUG AbstractLifeCycle: starting o.s.j.s.ServletContextHandler{/environment,null}
15/08/11 10:17:58 DEBUG Container: Container org.spark-project.jetty.servlet.ServletHandler@5bd8e367 + org.apache.spark.ui.JettyUtils$$anon$1-7ebb0a40 as servlet
15/08/11 10:17:58 DEBUG Container: Container org.spark-project.jetty.servlet.ServletHandler@5bd8e367 + [/]=>org.apache.spark.ui.JettyUtils$$anon$1-7ebb0a40 as servletMapping
15/08/11 10:17:58 DEBUG Container: Container o.s.j.s.ServletContextHandler{/environment,null} + org.spark-project.jetty.servlet.ServletHandler@5bd8e367 as handler
15/08/11 10:17:58 DEBUG AbstractLifeCycle: starting org.spark-project.jetty.servlet.ServletHandler@5bd8e367
15/08/11 10:17:58 DEBUG ServletHandler: filterNameMap={}
15/08/11 10:17:58 DEBUG ServletHandler: pathFilters=null
15/08/11 10:17:58 DEBUG ServletHandler: servletFilterMap=null
15/08/11 10:17:58 DEBUG ServletHandler: servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$1-7ebb0a40}
15/08/11 10:17:58 DEBUG ServletHandler: servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-7ebb0a40=org.apache.spark.ui.JettyUtils$$anon$1-7ebb0a40}
15/08/11 10:17:58 DEBUG AbstractHandler: starting org.spark-project.jetty.servlet.ServletHandler@5bd8e367
15/08/11 10:17:58 DEBUG AbstractLifeCycle: STARTED org.spark-project.jetty.servlet.ServletHandler@5bd8e367
15/08/11 10:17:58 DEBUG AbstractHandler: starting o.s.j.s.ServletContextHandler{/environment,null}
15/08/11 10:17:58 DEBUG AbstractLifeCycle: starting org.apache.spark.ui.JettyUtils$$anon$1-7ebb0a40
15/08/11 10:17:58 DEBUG AbstractLifeCycle: STARTED org.apache.spark.ui.JettyUtils$$anon$1-7ebb0a40
15/08/11 10:17:58 DEBUG AbstractLifeCycle: STARTED o.s.j.s.ServletContextHandler{/environment,null}
15/08/11 10:17:58 DEBUG AbstractLifeCycle: starting o.s.j.s.ServletContextHandler{/environment/json,null}
15/08/11 10:17:58 DEBUG Container: Container org.spark-project.jetty.servlet.ServletHandler@7c39ae4c + org.apache.spark.ui.JettyUtils$$anon$1-299e30c0 as servlet
15/08/11 10:17:58 DEBUG Container: Container org.spark-project.jetty.servlet.ServletHandler@7c39ae4c + [/]=>org.apache.spark.ui.JettyUtils$$anon$1-299e30c0 as servletMapping
15/08/11 10:17:58 DEBUG Container: Container o.s.j.s.ServletContextHandler{/environment/json,null} + org.spark-project.jetty.servlet.ServletHandler@7c39ae4c as handler
15/08/11 10:17:58 DEBUG AbstractLifeCycle: starting org.spark-project.jetty.servlet.ServletHandler@7c39ae4c
15/08/11 10:17:58 DEBUG ServletHandler: filterNameMap={}
15/08/11 10:17:58 DEBUG ServletHandler: pathFilters=null
15/08/11 10:17:58 DEBUG ServletHandler: servletFilterMap=null
15/08/11 10:17:58 DEBUG ServletHandler: servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$1-299e30c0}
15/08/11 10:17:58 DEBUG ServletHandler: servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-299e30c0=org.apache.spark.ui.JettyUtils$$anon$1-299e30c0}
15/08/11 10:17:58 DEBUG AbstractHandler: starting org.spark-project.jetty.servlet.ServletHandler@7c39ae4c
15/08/11 10:17:58 DEBUG AbstractLifeCycle: STARTED org.spark-project.jetty.servlet.ServletHandler@7c39ae4c
15/08/11 10:17:58 DEBUG AbstractHandler: starting o.s.j.s.ServletContextHandler{/environment/json,null}
15/08/11 10:17:58 DEBUG AbstractLifeCycle: starting org.apache.spark.ui.JettyUtils$$anon$1-299e30c0
15/08/11 10:17:58 DEBUG AbstractLifeCycle: STARTED org.apache.spark.ui.JettyUtils$$anon$1-299e30c0
15/08/11 10:17:58 DEBUG AbstractLifeCycle: STARTED o.s.j.s.ServletContextHandler{/environment/json,null}
15/08/11 10:17:58 DEBUG AbstractLifeCycle: starting o.s.j.s.ServletContextHandler{/executors,null}
15/08/11 10:17:58 DEBUG Container: Container org.spark-project.jetty.servlet.ServletHandler@2ee23f4b + org.apache.spark.ui.JettyUtils$$anon$1-7b61a226 as servlet
15/08/11 10:17:58 DEBUG Container: Container org.spark-project.jetty.servlet.ServletHandler@2ee23f4b + [/]=>org.apache.spark.ui.JettyUtils$$anon$1-7b61a226 as servletMapping
15/08/11 10:17:58 DEBUG Container: Container o.s.j.s.ServletContextHandler{/executors,null} + org.spark-project.jetty.servlet.ServletHandler@2ee23f4b as handler
15/08/11 10:17:58 DEBUG AbstractLifeCycle: starting org.spark-project.jetty.servlet.ServletHandler@2ee23f4b
15/08/11 10:17:58 DEBUG ServletHandler: filterNameMap={}
15/08/11 10:17:58 DEBUG ServletHandler: pathFilters=null
15/08/11 10:17:58 DEBUG ServletHandler: servletFilterMap=null
15/08/11 10:17:58 DEBUG ServletHandler: servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$1-7b61a226}
15/08/11 10:17:58 DEBUG ServletHandler: servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-7b61a226=org.apache.spark.ui.JettyUtils$$anon$1-7b61a226}
15/08/11 10:17:58 DEBUG AbstractHandler: starting org.spark-project.jetty.servlet.ServletHandler@2ee23f4b
15/08/11 10:17:58 DEBUG AbstractLifeCycle: STARTED org.spark-project.jetty.servlet.ServletHandler@2ee23f4b
15/08/11 10:17:58 DEBUG AbstractHandler: starting o.s.j.s.ServletContextHandler{/executors,null}
15/08/11 10:17:58 DEBUG AbstractLifeCycle: starting org.apache.spark.ui.JettyUtils$$anon$1-7b61a226
15/08/11 10:17:58 DEBUG AbstractLifeCycle: STARTED org.apache.spark.ui.JettyUtils$$anon$1-7b61a226
15/08/11 10:17:58 DEBUG AbstractLifeCycle: STARTED o.s.j.s.ServletContextHandler{/executors,null}
15/08/11 10:17:58 DEBUG AbstractLifeCycle: starting o.s.j.s.ServletContextHandler{/executors/json,null}
15/08/11 10:17:58 DEBUG Container: Container org.spark-project.jetty.servlet.ServletHandler@7a96cf9 + org.apache.spark.ui.JettyUtils$$anon$1-46dcac12 as servlet
15/08/11 10:17:58 DEBUG Container: Container org.spark-project.jetty.servlet.ServletHandler@7a96cf9 + [/]=>org.apache.spark.ui.JettyUtils$$anon$1-46dcac12 as servletMapping
15/08/11 10:17:58 DEBUG Container: Container o.s.j.s.ServletContextHandler{/executors/json,null} + org.spark-project.jetty.servlet.ServletHandler@7a96cf9 as handler
15/08/11 10:17:58 DEBUG AbstractLifeCycle: starting org.spark-project.jetty.servlet.ServletHandler@7a96cf9
15/08/11 10:17:58 DEBUG ServletHandler: filterNameMap={}
15/08/11 10:17:58 DEBUG ServletHandler: pathFilters=null
15/08/11 10:17:58 DEBUG ServletHandler: servletFilterMap=null
15/08/11 10:17:58 DEBUG ServletHandler: servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$1-46dcac12}
15/08/11 10:17:58 DEBUG ServletHandler: servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-46dcac12=org.apache.spark.ui.JettyUtils$$anon$1-46dcac12}
15/08/11 10:17:58 DEBUG AbstractHandler: starting org.spark-project.jetty.servlet.ServletHandler@7a96cf9
15/08/11 10:17:58 DEBUG AbstractLifeCycle: STARTED org.spark-project.jetty.servlet.ServletHandler@7a96cf9
15/08/11 10:17:58 DEBUG AbstractHandler: starting o.s.j.s.ServletContextHandler{/executors/json,null}
15/08/11 10:17:58 DEBUG AbstractLifeCycle: starting org.apache.spark.ui.JettyUtils$$anon$1-46dcac12
15/08/11 10:17:58 DEBUG AbstractLifeCycle: STARTED org.apache.spark.ui.JettyUtils$$anon$1-46dcac12
15/08/11 10:17:58 DEBUG AbstractLifeCycle: STARTED o.s.j.s.ServletContextHandler{/executors/json,null}
15/08/11 10:17:58 DEBUG AbstractLifeCycle: starting o.s.j.s.ServletContextHandler{/executors/threadDump,null}
15/08/11 10:17:58 DEBUG Container: Container org.spark-project.jetty.servlet.ServletHandler@431535d + org.apache.spark.ui.JettyUtils$$anon$1-41a4f616 as servlet
15/08/11 10:17:58 DEBUG Container: Container org.spark-project.jetty.servlet.ServletHandler@431535d + [/]=>org.apache.spark.ui.JettyUtils$$anon$1-41a4f616 as servletMapping
15/08/11 10:17:58 DEBUG Container: Container o.s.j.s.ServletContextHandler{/executors/threadDump,null} + org.spark-project.jetty.servlet.ServletHandler@431535d as handler
15/08/11 10:17:58 DEBUG AbstractLifeCycle: starting org.spark-project.jetty.servlet.ServletHandler@431535d
15/08/11 10:17:58 DEBUG ServletHandler: filterNameMap={}
15/08/11 10:17:58 DEBUG ServletHandler: pathFilters=null
15/08/11 10:17:58 DEBUG ServletHandler: servletFilterMap=null
15/08/11 10:17:58 DEBUG ServletHandler: servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$1-41a4f616}
15/08/11 10:17:58 DEBUG ServletHandler: servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-41a4f616=org.apache.spark.ui.JettyUtils$$anon$1-41a4f616}
15/08/11 10:17:58 DEBUG AbstractHandler: starting org.spark-project.jetty.servlet.ServletHandler@431535d
15/08/11 10:17:58 DEBUG AbstractLifeCycle: STARTED org.spark-project.jetty.servlet.ServletHandler@431535d
15/08/11 10:17:58 DEBUG AbstractHandler: starting o.s.j.s.ServletContextHandler{/executors/threadDump,null}
15/08/11 10:17:58 DEBUG AbstractLifeCycle: starting org.apache.spark.ui.JettyUtils$$anon$1-41a4f616
15/08/11 10:17:58 DEBUG AbstractLifeCycle: STARTED org.apache.spark.ui.JettyUtils$$anon$1-41a4f616
15/08/11 10:17:58 DEBUG AbstractLifeCycle: STARTED o.s.j.s.ServletContextHandler{/executors/threadDump,null}
15/08/11 10:17:58 DEBUG AbstractLifeCycle: starting o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
15/08/11 10:17:58 DEBUG Container: Container org.spark-project.jetty.servlet.ServletHandler@1f9dbb5e + org.apache.spark.ui.JettyUtils$$anon$1-4b13237e as servlet
15/08/11 10:17:58 DEBUG Container: Container org.spark-project.jetty.servlet.ServletHandler@1f9dbb5e + [/]=>org.apache.spark.ui.JettyUtils$$anon$1-4b13237e as servletMapping
15/08/11 10:17:58 DEBUG Container: Container o.s.j.s.ServletContextHandler{/executors/threadDump/json,null} + org.spark-project.jetty.servlet.ServletHandler@1f9dbb5e as handler
15/08/11 10:17:58 DEBUG AbstractLifeCycle: starting org.spark-project.jetty.servlet.ServletHandler@1f9dbb5e
15/08/11 10:17:58 DEBUG ServletHandler: filterNameMap={}
15/08/11 10:17:58 DEBUG ServletHandler: pathFilters=null
15/08/11 10:17:58 DEBUG ServletHandler: servletFilterMap=null
15/08/11 10:17:58 DEBUG ServletHandler: servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$1-4b13237e}
15/08/11 10:17:58 DEBUG ServletHandler: servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-4b13237e=org.apache.spark.ui.JettyUtils$$anon$1-4b13237e}
15/08/11 10:17:58 DEBUG AbstractHandler: starting org.spark-project.jetty.servlet.ServletHandler@1f9dbb5e
15/08/11 10:17:58 DEBUG AbstractLifeCycle: STARTED org.spark-project.jetty.servlet.ServletHandler@1f9dbb5e
15/08/11 10:17:58 DEBUG AbstractHandler: starting o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
15/08/11 10:17:58 DEBUG AbstractLifeCycle: starting org.apache.spark.ui.JettyUtils$$anon$1-4b13237e
15/08/11 10:17:58 DEBUG AbstractLifeCycle: STARTED org.apache.spark.ui.JettyUtils$$anon$1-4b13237e
15/08/11 10:17:58 DEBUG AbstractLifeCycle: STARTED o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
15/08/11 10:17:58 DEBUG AbstractLifeCycle: starting o.s.j.s.ServletContextHandler{/static,null}
15/08/11 10:17:58 DEBUG Container: Container org.spark-project.jetty.servlet.ServletHandler@2c782889 + org.spark-project.jetty.servlet.DefaultServlet-8216547 as servlet
15/08/11 10:17:58 DEBUG Container: Container org.spark-project.jetty.servlet.ServletHandler@2c782889 + [/]=>org.spark-project.jetty.servlet.DefaultServlet-8216547 as servletMapping
15/08/11 10:17:58 DEBUG Container: Container o.s.j.s.ServletContextHandler{/static,null} + org.spark-project.jetty.servlet.ServletHandler@2c782889 as handler
15/08/11 10:17:58 DEBUG AbstractLifeCycle: starting org.spark-project.jetty.servlet.ServletHandler@2c782889
15/08/11 10:17:58 DEBUG ServletHandler: filterNameMap={}
15/08/11 10:17:58 DEBUG ServletHandler: pathFilters=null
15/08/11 10:17:58 DEBUG ServletHandler: servletFilterMap=null
15/08/11 10:17:58 DEBUG ServletHandler: servletPathMap={/=org.spark-project.jetty.servlet.DefaultServlet-8216547}
15/08/11 10:17:58 DEBUG ServletHandler: servletNameMap={org.spark-project.jetty.servlet.DefaultServlet-8216547=org.spark-project.jetty.servlet.DefaultServlet-8216547}
15/08/11 10:17:58 DEBUG AbstractHandler: starting org.spark-project.jetty.servlet.ServletHandler@2c782889
15/08/11 10:17:58 DEBUG AbstractLifeCycle: STARTED org.spark-project.jetty.servlet.ServletHandler@2c782889
15/08/11 10:17:58 DEBUG AbstractHandler: starting o.s.j.s.ServletContextHandler{/static,null}
15/08/11 10:17:58 DEBUG AbstractLifeCycle: starting org.spark-project.jetty.servlet.DefaultServlet-8216547
15/08/11 10:17:58 DEBUG DefaultServlet: resource base = jar:file:/home/hadoop/develop/spark/assembly/target/scala-2.10/spark-assembly-1.3.0-hadoop2.3.0.jar!/org/apache/spark/ui/static
15/08/11 10:17:58 DEBUG AbstractLifeCycle: STARTED org.spark-project.jetty.servlet.DefaultServlet-8216547
15/08/11 10:17:58 DEBUG AbstractLifeCycle: STARTED o.s.j.s.ServletContextHandler{/static,null}
15/08/11 10:17:58 DEBUG AbstractLifeCycle: starting o.s.j.s.ServletContextHandler{/,null}
15/08/11 10:17:58 DEBUG Container: Container org.spark-project.jetty.servlet.ServletHandler@4ad512e + org.apache.spark.ui.JettyUtils$$anon$2-4347154c as servlet
15/08/11 10:17:58 DEBUG Container: Container org.spark-project.jetty.servlet.ServletHandler@4ad512e + [/]=>org.apache.spark.ui.JettyUtils$$anon$2-4347154c as servletMapping
15/08/11 10:17:58 DEBUG Container: Container o.s.j.s.ServletContextHandler{/,null} + org.spark-project.jetty.servlet.ServletHandler@4ad512e as handler
15/08/11 10:17:58 DEBUG AbstractLifeCycle: starting org.spark-project.jetty.servlet.ServletHandler@4ad512e
15/08/11 10:17:58 DEBUG ServletHandler: filterNameMap={}
15/08/11 10:17:58 DEBUG ServletHandler: pathFilters=null
15/08/11 10:17:58 DEBUG ServletHandler: servletFilterMap=null
15/08/11 10:17:58 DEBUG ServletHandler: servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-4347154c}
15/08/11 10:17:58 DEBUG ServletHandler: servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-4347154c=org.apache.spark.ui.JettyUtils$$anon$2-4347154c}
15/08/11 10:17:58 DEBUG AbstractHandler: starting org.spark-project.jetty.servlet.ServletHandler@4ad512e
15/08/11 10:17:58 DEBUG AbstractLifeCycle: STARTED org.spark-project.jetty.servlet.ServletHandler@4ad512e
15/08/11 10:17:58 DEBUG AbstractHandler: starting o.s.j.s.ServletContextHandler{/,null}
15/08/11 10:17:58 DEBUG AbstractLifeCycle: starting org.apache.spark.ui.JettyUtils$$anon$2-4347154c
15/08/11 10:17:58 DEBUG AbstractLifeCycle: STARTED org.apache.spark.ui.JettyUtils$$anon$2-4347154c
15/08/11 10:17:58 DEBUG AbstractLifeCycle: STARTED o.s.j.s.ServletContextHandler{/,null}
15/08/11 10:17:58 DEBUG AbstractLifeCycle: starting o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
15/08/11 10:17:58 DEBUG Container: Container org.spark-project.jetty.servlet.ServletHandler@eaca568 + org.apache.spark.ui.JettyUtils$$anon$2-61b60992 as servlet
15/08/11 10:17:58 DEBUG Container: Container org.spark-project.jetty.servlet.ServletHandler@eaca568 + [/]=>org.apache.spark.ui.JettyUtils$$anon$2-61b60992 as servletMapping
15/08/11 10:17:58 DEBUG Container: Container o.s.j.s.ServletContextHandler{/stages/stage/kill,null} + org.spark-project.jetty.servlet.ServletHandler@eaca568 as handler
15/08/11 10:17:58 DEBUG AbstractLifeCycle: starting org.spark-project.jetty.servlet.ServletHandler@eaca568
15/08/11 10:17:58 DEBUG ServletHandler: filterNameMap={}
15/08/11 10:17:58 DEBUG ServletHandler: pathFilters=null
15/08/11 10:17:58 DEBUG ServletHandler: servletFilterMap=null
15/08/11 10:17:58 DEBUG ServletHandler: servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-61b60992}
15/08/11 10:17:58 DEBUG ServletHandler: servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-61b60992=org.apache.spark.ui.JettyUtils$$anon$2-61b60992}
15/08/11 10:17:58 DEBUG AbstractHandler: starting org.spark-project.jetty.servlet.ServletHandler@eaca568
15/08/11 10:17:58 DEBUG AbstractLifeCycle: STARTED org.spark-project.jetty.servlet.ServletHandler@eaca568
15/08/11 10:17:58 DEBUG AbstractHandler: starting o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
15/08/11 10:17:58 DEBUG AbstractLifeCycle: starting org.apache.spark.ui.JettyUtils$$anon$2-61b60992
15/08/11 10:17:58 DEBUG AbstractLifeCycle: STARTED org.apache.spark.ui.JettyUtils$$anon$2-61b60992
15/08/11 10:17:58 DEBUG AbstractLifeCycle: STARTED o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
15/08/11 10:17:58 DEBUG AbstractHandler: starting org.spark-project.jetty.server.handler.ContextHandlerCollection@42c08a7e
15/08/11 10:17:58 DEBUG AbstractLifeCycle: STARTED org.spark-project.jetty.server.handler.ContextHandlerCollection@42c08a7e
15/08/11 10:17:58 DEBUG AbstractHandler: starting org.spark-project.jetty.server.Server@1e6520b6
15/08/11 10:17:58 DEBUG AbstractLifeCycle: starting qtp21404753{8<=0<=0/254,-1}
15/08/11 10:17:58 DEBUG AbstractLifeCycle: STARTED qtp21404753{8<=7<=8/254,0}
15/08/11 10:17:58 DEBUG AbstractLifeCycle: starting SelectChannelConnector@0.0.0.0:4040
15/08/11 10:17:58 DEBUG AbstractLifeCycle: starting null/null
15/08/11 10:17:58 DEBUG AbstractLifeCycle: STARTED PooledBuffers [0/1024@6144,0/1024@16384,0/1024@-]/PooledBuffers [0/1024@6144,0/1024@32768,0/1024@-]
15/08/11 10:17:58 DEBUG AbstractLifeCycle: starting org.spark-project.jetty.server.nio.SelectChannelConnector$ConnectorSelectorManager@53d4287
15/08/11 10:17:58 DEBUG nio: Starting Thread[qtp21404753-42 Selector0,5,main] on org.spark-project.jetty.io.nio.SelectorManager$1@5437633c
15/08/11 10:17:58 DEBUG AbstractLifeCycle: STARTED org.spark-project.jetty.server.nio.SelectChannelConnector$ConnectorSelectorManager@53d4287
15/08/11 10:17:58 INFO AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040
15/08/11 10:17:58 DEBUG AbstractLifeCycle: STARTED SelectChannelConnector@0.0.0.0:4040
15/08/11 10:17:58 DEBUG AbstractLifeCycle: STARTED org.spark-project.jetty.server.Server@1e6520b6
15/08/11 10:17:58 INFO Utils: Successfully started service 'SparkUI' on port 4040.
15/08/11 10:17:58 INFO SparkUI: Started SparkUI at http://192.168.130.131:4040
15/08/11 10:17:58 INFO SparkContext: Added JAR file:/home/hadoop/develop/spark/lib/SparkExample.jar at http://192.168.130.131:40555/jars/SparkExample.jar with timestamp 1439259478742
15/08/11 10:17:58 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:17:58 INFO AppClient$ClientActor: Connecting to master akka.tcp://sparkMaster@hadoop2:7077/user/Master...
15/08/11 10:17:58 DEBUG SparkDeploySchedulerBackend: [actor] handled message (36.358502 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:17:59 DEBUG AppClient$ClientActor: [actor] received message RegisteredApplication(app-20150811101759-0000,spark://hadoop2:7077) from Actor[akka.tcp://sparkMaster@hadoop2:7077/user/Master#-812326921]
15/08/11 10:17:59 INFO SparkDeploySchedulerBackend: Connected to Spark cluster with app ID app-20150811101759-0000
15/08/11 10:17:59 DEBUG AppClient$ClientActor: [actor] handled message (3.256909 ms) RegisteredApplication(app-20150811101759-0000,spark://hadoop2:7077) from Actor[akka.tcp://sparkMaster@hadoop2:7077/user/Master#-812326921]
15/08/11 10:17:59 DEBUG AppClient$ClientActor: [actor] received message ExecutorAdded(0,worker-20150811101756-192.168.130.131-50410,192.168.130.131:50410,4,512) from Actor[akka.tcp://sparkMaster@hadoop2:7077/user/Master#-812326921]
15/08/11 10:17:59 INFO AppClient$ClientActor: Executor added: app-20150811101759-0000/0 on worker-20150811101756-192.168.130.131-50410 (192.168.130.131:50410) with 4 cores
15/08/11 10:17:59 INFO SparkDeploySchedulerBackend: Granted executor ID app-20150811101759-0000/0 on hostPort 192.168.130.131:50410 with 4 cores, 512.0 MB RAM
15/08/11 10:17:59 DEBUG AppClient$ClientActor: [actor] handled message (10.041562 ms) ExecutorAdded(0,worker-20150811101756-192.168.130.131-50410,192.168.130.131:50410,4,512) from Actor[akka.tcp://sparkMaster@hadoop2:7077/user/Master#-812326921]
15/08/11 10:17:59 DEBUG InternalLoggerFactory: Using SLF4J as the default logging framework
15/08/11 10:17:59 DEBUG PlatformDependent0: java.nio.Buffer.address: available
15/08/11 10:17:59 DEBUG PlatformDependent0: sun.misc.Unsafe.theUnsafe: available
15/08/11 10:17:59 DEBUG PlatformDependent0: sun.misc.Unsafe.copyMemory: available
15/08/11 10:17:59 DEBUG PlatformDependent0: java.nio.Bits.unaligned: true
15/08/11 10:17:59 DEBUG PlatformDependent: UID: 2000
15/08/11 10:17:59 DEBUG PlatformDependent: Java version: 7
15/08/11 10:17:59 DEBUG PlatformDependent: -Dio.netty.noUnsafe: false
15/08/11 10:17:59 DEBUG PlatformDependent: sun.misc.Unsafe: available
15/08/11 10:17:59 DEBUG PlatformDependent: -Dio.netty.noJavassist: false
15/08/11 10:17:59 DEBUG PlatformDependent: Javassist: unavailable
15/08/11 10:17:59 DEBUG PlatformDependent: You don't have Javassist in your class path or you don't have enough permission to load dynamically generated classes.  Please check the configuration for better performance.
15/08/11 10:17:59 DEBUG PlatformDependent: -Dio.netty.tmpdir: /tmp (java.io.tmpdir)
15/08/11 10:17:59 DEBUG PlatformDependent: -Dio.netty.bitMode: 64 (sun.arch.data.model)
15/08/11 10:17:59 DEBUG PlatformDependent: -Dio.netty.noPreferDirect: false
15/08/11 10:17:59 DEBUG AppClient$ClientActor: [actor] received message ExecutorUpdated(0,RUNNING,None,None) from Actor[akka.tcp://sparkMaster@hadoop2:7077/user/Master#-812326921]
15/08/11 10:17:59 INFO AppClient$ClientActor: Executor updated: app-20150811101759-0000/0 is now RUNNING
15/08/11 10:17:59 DEBUG AppClient$ClientActor: [actor] handled message (1.355572 ms) ExecutorUpdated(0,RUNNING,None,None) from Actor[akka.tcp://sparkMaster@hadoop2:7077/user/Master#-812326921]
15/08/11 10:17:59 DEBUG MultithreadEventLoopGroup: -Dio.netty.eventLoopThreads: 4
15/08/11 10:17:59 DEBUG AppClient$ClientActor: [actor] received message ExecutorUpdated(0,LOADING,None,None) from Actor[akka.tcp://sparkMaster@hadoop2:7077/user/Master#-812326921]
15/08/11 10:17:59 INFO AppClient$ClientActor: Executor updated: app-20150811101759-0000/0 is now LOADING
15/08/11 10:17:59 DEBUG AppClient$ClientActor: [actor] handled message (0.42818 ms) ExecutorUpdated(0,LOADING,None,None) from Actor[akka.tcp://sparkMaster@hadoop2:7077/user/Master#-812326921]
15/08/11 10:17:59 DEBUG NioEventLoop: -Dio.netty.noKeySetOptimization: false
15/08/11 10:17:59 DEBUG NioEventLoop: -Dio.netty.selectorAutoRebuildThreshold: 512
15/08/11 10:17:59 DEBUG PooledByteBufAllocator: -Dio.netty.allocator.numHeapArenas: 2
15/08/11 10:17:59 DEBUG PooledByteBufAllocator: -Dio.netty.allocator.numDirectArenas: 2
15/08/11 10:17:59 DEBUG PooledByteBufAllocator: -Dio.netty.allocator.pageSize: 8192
15/08/11 10:17:59 DEBUG PooledByteBufAllocator: -Dio.netty.allocator.maxOrder: 11
15/08/11 10:17:59 DEBUG PooledByteBufAllocator: -Dio.netty.allocator.chunkSize: 16777216
15/08/11 10:17:59 DEBUG PooledByteBufAllocator: -Dio.netty.allocator.tinyCacheSize: 512
15/08/11 10:17:59 DEBUG PooledByteBufAllocator: -Dio.netty.allocator.smallCacheSize: 256
15/08/11 10:17:59 DEBUG PooledByteBufAllocator: -Dio.netty.allocator.normalCacheSize: 64
15/08/11 10:17:59 DEBUG PooledByteBufAllocator: -Dio.netty.allocator.maxCachedBufferCapacity: 32768
15/08/11 10:17:59 DEBUG PooledByteBufAllocator: -Dio.netty.allocator.cacheTrimInterval: 8192
15/08/11 10:17:59 DEBUG ThreadLocalRandom: -Dio.netty.initialSeedUniquifier: 0xc37f7b0acb58454e (took 1 ms)
15/08/11 10:17:59 DEBUG ByteBufUtil: -Dio.netty.allocator.type: unpooled
15/08/11 10:17:59 DEBUG ByteBufUtil: -Dio.netty.threadLocalDirectBufferSize: 65536
15/08/11 10:17:59 DEBUG NetUtil: Loopback interface: lo (lo, 0:0:0:0:0:0:0:1%1)
15/08/11 10:17:59 DEBUG NetUtil: /proc/sys/net/core/somaxconn: 128
15/08/11 10:17:59 DEBUG TransportServer: Shuffle server started on port :57830
15/08/11 10:17:59 INFO NettyBlockTransferService: Server created on 57830
15/08/11 10:17:59 INFO BlockManagerMaster: Trying to register BlockManager
15/08/11 10:17:59 DEBUG BlockManagerMasterActor: [actor] received message RegisterBlockManager(BlockManagerId(<driver>, 192.168.130.131, 57830),278302556,Actor[akka://sparkDriver/user/BlockManagerActor1#1247837586]) from Actor[akka://sparkDriver/temp/$a]
15/08/11 10:17:59 INFO BlockManagerMasterActor: Registering block manager 192.168.130.131:57830 with 265.4 MB RAM, BlockManagerId(<driver>, 192.168.130.131, 57830)
15/08/11 10:17:59 INFO BlockManagerMaster: Registered BlockManager
15/08/11 10:17:59 DEBUG BlockManagerMasterActor: [actor] handled message (14.54463 ms) RegisterBlockManager(BlockManagerId(<driver>, 192.168.130.131, 57830),278302556,Actor[akka://sparkDriver/user/BlockManagerActor1#1247837586]) from Actor[akka://sparkDriver/temp/$a]
15/08/11 10:17:59 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:17:59 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.250306 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:17:59 DEBUG ServletHandler: filterNameMap={}
15/08/11 10:17:59 DEBUG ServletHandler: pathFilters=null
15/08/11 10:17:59 DEBUG ServletHandler: servletFilterMap=null
15/08/11 10:17:59 DEBUG ServletHandler: servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$1-6eecdcff}
15/08/11 10:17:59 DEBUG ServletHandler: servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-6eecdcff=org.apache.spark.ui.JettyUtils$$anon$1-6eecdcff}
15/08/11 10:17:59 DEBUG Container: Container org.spark-project.jetty.server.handler.ContextHandlerCollection@42c08a7e + o.s.j.s.ServletContextHandler{/metrics/json,null} as handler
15/08/11 10:17:59 DEBUG AbstractLifeCycle: starting o.s.j.s.ServletContextHandler{/metrics/json,null}
15/08/11 10:17:59 DEBUG Container: Container org.spark-project.jetty.servlet.ServletHandler@5ce11915 + org.apache.spark.ui.JettyUtils$$anon$1-6eecdcff as servlet
15/08/11 10:17:59 DEBUG Container: Container org.spark-project.jetty.servlet.ServletHandler@5ce11915 + [/]=>org.apache.spark.ui.JettyUtils$$anon$1-6eecdcff as servletMapping
15/08/11 10:17:59 DEBUG Container: Container o.s.j.s.ServletContextHandler{/metrics/json,null} + org.spark-project.jetty.servlet.ServletHandler@5ce11915 as handler
15/08/11 10:17:59 DEBUG AbstractLifeCycle: starting org.spark-project.jetty.servlet.ServletHandler@5ce11915
15/08/11 10:17:59 DEBUG ServletHandler: filterNameMap={}
15/08/11 10:17:59 DEBUG ServletHandler: pathFilters=null
15/08/11 10:17:59 DEBUG ServletHandler: servletFilterMap=null
15/08/11 10:17:59 DEBUG ServletHandler: servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$1-6eecdcff}
15/08/11 10:17:59 DEBUG ServletHandler: servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-6eecdcff=org.apache.spark.ui.JettyUtils$$anon$1-6eecdcff}
15/08/11 10:17:59 DEBUG AbstractHandler: starting org.spark-project.jetty.servlet.ServletHandler@5ce11915
15/08/11 10:17:59 DEBUG AbstractLifeCycle: STARTED org.spark-project.jetty.servlet.ServletHandler@5ce11915
15/08/11 10:17:59 DEBUG AbstractHandler: starting o.s.j.s.ServletContextHandler{/metrics/json,null}
15/08/11 10:17:59 DEBUG AbstractLifeCycle: starting org.apache.spark.ui.JettyUtils$$anon$1-6eecdcff
15/08/11 10:17:59 DEBUG AbstractLifeCycle: STARTED org.apache.spark.ui.JettyUtils$$anon$1-6eecdcff
15/08/11 10:17:59 DEBUG AbstractLifeCycle: STARTED o.s.j.s.ServletContextHandler{/metrics/json,null}
15/08/11 10:17:59 INFO SparkDeploySchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
15/08/11 10:18:00 INFO MemoryStore: ensureFreeSpace(153304) called with curMem=0, maxMem=278302556
15/08/11 10:18:00 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 149.7 KB, free 265.3 MB)
15/08/11 10:18:00 DEBUG BlockManager: Put block broadcast_0 locally took  228 ms
15/08/11 10:18:00 DEBUG BlockManager: Putting block broadcast_0 without replication took  229 ms
15/08/11 10:18:00 INFO MemoryStore: ensureFreeSpace(15252) called with curMem=153304, maxMem=278302556
15/08/11 10:18:00 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.9 KB, free 265.2 MB)
15/08/11 10:18:00 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_0_piece0,StorageLevel(false, true, false, false, 1),15252,0,0) from Actor[akka://sparkDriver/temp/$b]
15/08/11 10:18:00 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.130.131:57830 (size: 14.9 KB, free: 265.4 MB)
15/08/11 10:18:00 DEBUG BlockManagerMasterActor: [actor] handled message (1.541632 ms) UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_0_piece0,StorageLevel(false, true, false, false, 1),15252,0,0) from Actor[akka://sparkDriver/temp/$b]
15/08/11 10:18:00 INFO BlockManagerMaster: Updated info of block broadcast_0_piece0
15/08/11 10:18:00 DEBUG BlockManager: Told master about block broadcast_0_piece0
15/08/11 10:18:00 DEBUG BlockManager: Put block broadcast_0_piece0 locally took  23 ms
15/08/11 10:18:00 DEBUG BlockManager: Putting block broadcast_0_piece0 without replication took  24 ms
15/08/11 10:18:00 INFO SparkContext: Created broadcast 0 from textFile at KMeansTest.scala:49
15/08/11 10:18:00 DEBUG BlockManager: Getting local block broadcast_0
15/08/11 10:18:00 DEBUG BlockManager: Level for block broadcast_0 is StorageLevel(true, true, false, true, 1)
15/08/11 10:18:00 DEBUG BlockManager: Getting block broadcast_0 from memory
15/08/11 10:18:00 DEBUG HadoopRDD: SplitLocationInfo and other new Hadoop classes are unavailable. Using the older Hadoop location info code.
java.lang.ClassNotFoundException: org.apache.hadoop.mapred.InputSplitWithLocationInfo
	at java.net.URLClassLoader$1.run(URLClassLoader.java:366)
	at java.net.URLClassLoader$1.run(URLClassLoader.java:355)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.net.URLClassLoader.findClass(URLClassLoader.java:354)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:425)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:308)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:358)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:190)
	at org.apache.spark.rdd.HadoopRDD$SplitInfoReflections.<init>(HadoopRDD.scala:383)
	at org.apache.spark.rdd.HadoopRDD$.liftedTree1$1(HadoopRDD.scala:393)
	at org.apache.spark.rdd.HadoopRDD$.<init>(HadoopRDD.scala:392)
	at org.apache.spark.rdd.HadoopRDD$.<clinit>(HadoopRDD.scala)
	at org.apache.spark.rdd.HadoopRDD.getJobConf(HadoopRDD.scala:161)
	at org.apache.spark.rdd.HadoopRDD.getPartitions(HadoopRDD.scala:196)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:220)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:218)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:218)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:32)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:220)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:218)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:218)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:32)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:220)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:218)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:218)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1511)
	at org.apache.spark.rdd.RDD.count(RDD.scala:1007)
	at org.apache.spark.rdd.RDD.takeSample(RDD.scala:429)
	at org.apache.spark.examples.KMeansTest$.main(KMeansTest.scala:56)
	at org.apache.spark.examples.KMeansTest.main(KMeansTest.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:569)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:166)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:189)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:110)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
15/08/11 10:18:00 DEBUG HadoopRDD: Creating new JobConf and caching it for later re-use
15/08/11 10:18:00 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:00 DEBUG SparkDeploySchedulerBackend: [actor] handled message (2.440731 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:01 DEBUG BlockReaderLocal: dfs.client.use.legacy.blockreader.local = false
15/08/11 10:18:01 DEBUG BlockReaderLocal: dfs.client.read.shortcircuit = false
15/08/11 10:18:01 DEBUG BlockReaderLocal: dfs.client.domain.socket.data.traffic = false
15/08/11 10:18:01 DEBUG BlockReaderLocal: dfs.domain.socket.path = 
15/08/11 10:18:01 DEBUG RetryUtils: multipleLinearRandomRetry = null
15/08/11 10:18:01 DEBUG Server: rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@3b108e32
15/08/11 10:18:01 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:01 DEBUG SparkDeploySchedulerBackend: [actor] handled message (2.16334 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:02 DEBUG BlockReaderLocal: Both short-circuit local reads and UNIX domain socket are disabled.
15/08/11 10:18:04 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:04 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.295189 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:04 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:04 DEBUG SparkDeploySchedulerBackend: [actor] handled message (1.295143 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:04 INFO FileInputFormat: Total input paths to process : 1
15/08/11 10:18:04 DEBUG FileInputFormat: Total # of splits: 3
15/08/11 10:18:04 INFO SparkContext: Starting job: takeSample at KMeansTest.scala:56
15/08/11 10:18:04 INFO DAGScheduler: Got job 0 (takeSample at KMeansTest.scala:56) with 3 output partitions (allowLocal=false)
15/08/11 10:18:04 INFO DAGScheduler: Final stage: Stage 0(takeSample at KMeansTest.scala:56)
15/08/11 10:18:04 INFO DAGScheduler: Parents of final stage: List()
15/08/11 10:18:04 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD KMeans01 MapPartitionsRDD[2] at map at KMeansTest.scala:50
15/08/11 10:18:04 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:18:04 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@32541904) from Actor[akka://sparkDriver/temp/$c]
15/08/11 10:18:04 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:18:04 DEBUG BlockManagerMasterActor: [actor] handled message (9.384879 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@32541904) from Actor[akka://sparkDriver/temp/$c]
15/08/11 10:18:04 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@32541904) from Actor[akka://sparkDriver/temp/$d]
15/08/11 10:18:04 DEBUG BlockManagerMasterActor: [actor] handled message (0.329137 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@32541904) from Actor[akka://sparkDriver/temp/$d]
15/08/11 10:18:04 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:18:04 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:18:04 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster: akka.tcp://sparkMaster@hadoop2:7077/user/Master
15/08/11 10:18:04 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(KMeans01|2|0,rdd_2_0,, KMeans01|2|1,rdd_2_1,, KMeans01|2|2,rdd_2_2,).
15/08/11 10:18:04 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:18:04 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$g]
15/08/11 10:18:04 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:18:04 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:04 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:04 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:04 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:04 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:04 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:04 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:18:04 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:18:04 DEBUG BlockManager: Got multiple block location in  251 ms
15/08/11 10:18:04 DEBUG BlockManagerMasterActor: [actor] handled message (20.76712 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$g]
15/08/11 10:18:04 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD file:/home/hadoop/share/udisk/MyTest/data-Kmeans MapPartitionsRDD[1] at textFile at KMeansTest.scala:49
15/08/11 10:18:04 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:18:04 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@537a712c) from Actor[akka://sparkDriver/temp/$h]
15/08/11 10:18:04 DEBUG BlockManagerMasterActor: [actor] handled message (0.46231 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@537a712c) from Actor[akka://sparkDriver/temp/$h]
15/08/11 10:18:04 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:18:04 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@537a712c) from Actor[akka://sparkDriver/temp/$i]
15/08/11 10:18:04 DEBUG BlockManagerMasterActor: [actor] handled message (0.26166 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@537a712c) from Actor[akka://sparkDriver/temp/$i]
15/08/11 10:18:04 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:18:04 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:18:04 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(file:/home/hadoop/share/udisk/MyTest/data-Kmeans|1|0,rdd_1_0,, file:/home/hadoop/share/udisk/MyTest/data-Kmeans|1|1,rdd_1_1,, file:/home/hadoop/share/udisk/MyTest/data-Kmeans|1|2,rdd_1_2,).
15/08/11 10:18:04 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:18:04 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$k]
15/08/11 10:18:04 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:18:04 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:04 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:04 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:04 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:04 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:04 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:04 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:18:04 DEBUG BlockManagerMasterActor: [actor] handled message (1.835518 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$k]
15/08/11 10:18:04 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:18:04 DEBUG BlockManager: Got multiple block location in  20 ms
15/08/11 10:18:04 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD file:/home/hadoop/share/udisk/MyTest/data-Kmeans HadoopRDD[0] at textFile at KMeansTest.scala:49
15/08/11 10:18:04 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:18:04 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@3eda0bed) from Actor[akka://sparkDriver/temp/$l]
15/08/11 10:18:04 DEBUG BlockManagerMasterActor: [actor] handled message (0.357137 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@3eda0bed) from Actor[akka://sparkDriver/temp/$l]
15/08/11 10:18:04 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:18:04 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@3eda0bed) from Actor[akka://sparkDriver/temp/$m]
15/08/11 10:18:04 DEBUG BlockManagerMasterActor: [actor] handled message (0.612729 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@3eda0bed) from Actor[akka://sparkDriver/temp/$m]
15/08/11 10:18:04 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:18:04 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:18:04 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(file:/home/hadoop/share/udisk/MyTest/data-Kmeans|0|0,rdd_0_0,, file:/home/hadoop/share/udisk/MyTest/data-Kmeans|0|1,rdd_0_1,, file:/home/hadoop/share/udisk/MyTest/data-Kmeans|0|2,rdd_0_2,).
15/08/11 10:18:04 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:18:04 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$o]
15/08/11 10:18:04 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:18:04 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:04 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:04 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:04 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:04 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:04 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:04 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:18:04 DEBUG BlockManagerMasterActor: [actor] handled message (1.995851 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$o]
15/08/11 10:18:04 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:18:04 DEBUG BlockManager: Got multiple block location in  31 ms
15/08/11 10:18:04 INFO DAGScheduler: [SMSpark v1]Missing parents: List()
15/08/11 10:18:04 DEBUG DAGScheduler: submitStage(Stage 0)
15/08/11 10:18:04 DEBUG DAGScheduler: missing: List()
15/08/11 10:18:04 INFO DAGScheduler: Submitting Stage 0 (KMeans01 MapPartitionsRDD[2] at map at KMeansTest.scala:50), which has no missing parents
15/08/11 10:18:04 DEBUG DAGScheduler: submitMissingTasks(Stage 0)
15/08/11 10:18:04 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:04 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.270454 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:04 INFO MemoryStore: ensureFreeSpace(2872) called with curMem=168556, maxMem=278302556
15/08/11 10:18:04 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 2.8 KB, free 265.2 MB)
15/08/11 10:18:04 DEBUG BlockManager: Put block broadcast_1 locally took  4 ms
15/08/11 10:18:04 DEBUG BlockManager: Putting block broadcast_1 without replication took  5 ms
15/08/11 10:18:04 INFO MemoryStore: ensureFreeSpace(1792) called with curMem=171428, maxMem=278302556
15/08/11 10:18:04 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 1792.0 B, free 265.2 MB)
15/08/11 10:18:04 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_1_piece0,StorageLevel(false, true, false, false, 1),1792,0,0) from Actor[akka://sparkDriver/temp/$p]
15/08/11 10:18:04 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.130.131:57830 (size: 1792.0 B, free: 265.4 MB)
15/08/11 10:18:04 INFO BlockManagerMaster: Updated info of block broadcast_1_piece0
15/08/11 10:18:04 DEBUG BlockManager: Told master about block broadcast_1_piece0
15/08/11 10:18:04 DEBUG BlockManagerMasterActor: [actor] handled message (1.610836 ms) UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_1_piece0,StorageLevel(false, true, false, false, 1),1792,0,0) from Actor[akka://sparkDriver/temp/$p]
15/08/11 10:18:04 DEBUG BlockManager: Put block broadcast_1_piece0 locally took  7 ms
15/08/11 10:18:04 DEBUG BlockManager: Putting block broadcast_1_piece0 without replication took  8 ms
15/08/11 10:18:04 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:852
15/08/11 10:18:04 INFO DAGScheduler: Submitting 3 missing tasks from Stage 0 (KMeans01 MapPartitionsRDD[2] at map at KMeansTest.scala:50)
15/08/11 10:18:04 DEBUG DAGScheduler: New pending tasks: Set(ResultTask(0, 2), ResultTask(0, 1), ResultTask(0, 0))
15/08/11 10:18:04 INFO TaskSchedulerImpl: Adding task set 0.0 with 3 tasks
15/08/11 10:18:04 DEBUG TaskSetManager: Epoch for TaskSet 0.0: 0
15/08/11 10:18:04 DEBUG TaskSetManager: Valid locality levels for TaskSet 0.0: NO_PREF, ANY
15/08/11 10:18:04 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/deadLetters]
15/08/11 10:18:04 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_0, runningTasks: 0
15/08/11 10:18:04 DEBUG SparkDeploySchedulerBackend: [actor] handled message (6.199452 ms) ReviveOffers from Actor[akka://sparkDriver/deadLetters]
15/08/11 10:18:05 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:05 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_0, runningTasks: 0
15/08/11 10:18:05 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.844037 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:06 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:06 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_0, runningTasks: 0
15/08/11 10:18:06 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.846819 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:06 DEBUG SparkDeploySchedulerBackend: [actor] received message RetrieveSparkProps from Actor[akka.tcp://driverPropsFetcher@192.168.130.131:52820/temp/$a]
15/08/11 10:18:06 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.084536 ms) RetrieveSparkProps from Actor[akka.tcp://driverPropsFetcher@192.168.130.131:52820/temp/$a]
15/08/11 10:18:07 DEBUG SparkDeploySchedulerBackend: [actor] received message Disassociated [akka.tcp://sparkDriver@192.168.130.131:57038] <- [akka.tcp://driverPropsFetcher@192.168.130.131:52820] from Actor[akka://sparkDriver/deadLetters]
15/08/11 10:18:07 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.588811 ms) Disassociated [akka.tcp://sparkDriver@192.168.130.131:57038] <- [akka.tcp://driverPropsFetcher@192.168.130.131:52820] from Actor[akka://sparkDriver/deadLetters]
15/08/11 10:18:07 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:07 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_0, runningTasks: 0
15/08/11 10:18:07 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.619653 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:08 DEBUG SparkDeploySchedulerBackend: [actor] received message RegisterExecutor(0,192.168.130.131:49489,4,Map(stdout -> http://192.168.130.131:8081/logPage/?appId=app-20150811101759-0000&executorId=0&logType=stdout, stderr -> http://192.168.130.131:8081/logPage/?appId=app-20150811101759-0000&executorId=0&logType=stderr)) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:08 INFO SparkDeploySchedulerBackend: Registered executor: Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250] with ID 0
15/08/11 10:18:08 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_0, runningTasks: 0
15/08/11 10:18:08 DEBUG TaskSetManager: Valid locality levels for TaskSet 0.0: NO_PREF, ANY
15/08/11 10:18:08 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, 192.168.130.131, PROCESS_LOCAL, 1372 bytes)
15/08/11 10:18:08 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, 192.168.130.131, PROCESS_LOCAL, 1372 bytes)
15/08/11 10:18:08 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, 192.168.130.131, PROCESS_LOCAL, 1372 bytes)
15/08/11 10:18:08 DEBUG TaskSetManager: No tasks for locality level NO_PREF, so moving to locality level ANY
15/08/11 10:18:08 DEBUG SparkDeploySchedulerBackend: [actor] handled message (153.646614 ms) RegisterExecutor(0,192.168.130.131:49489,4,Map(stdout -> http://192.168.130.131:8081/logPage/?appId=app-20150811101759-0000&executorId=0&logType=stdout, stderr -> http://192.168.130.131:8081/logPage/?appId=app-20150811101759-0000&executorId=0&logType=stderr)) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:08 DEBUG BlockManagerMasterActor: [actor] received message RegisterBlockManager(BlockManagerId(0, 192.168.130.131, 47921),257635123,Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/BlockManagerActor1#-943319114]) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$e]
15/08/11 10:18:08 INFO BlockManagerMasterActor: Registering block manager 192.168.130.131:47921 with 245.7 MB RAM, BlockManagerId(0, 192.168.130.131, 47921)
15/08/11 10:18:08 DEBUG BlockManagerMasterActor: [actor] handled message (0.96704 ms) RegisterBlockManager(BlockManagerId(0, 192.168.130.131, 47921),257635123,Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/BlockManagerActor1#-943319114]) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$e]
15/08/11 10:18:08 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,0,RUNNING,org.apache.spark.util.SerializableBuffer@2f9552c6) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:08 DEBUG SparkDeploySchedulerBackend: [actor] handled message (4.599178 ms) StatusUpdate(0,0,RUNNING,org.apache.spark.util.SerializableBuffer@2f9552c6) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:08 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,1,RUNNING,org.apache.spark.util.SerializableBuffer@4631d3aa) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:08 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.071317 ms) StatusUpdate(0,1,RUNNING,org.apache.spark.util.SerializableBuffer@4631d3aa) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:08 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,2,RUNNING,org.apache.spark.util.SerializableBuffer@713f61e6) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:08 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.079532 ms) StatusUpdate(0,2,RUNNING,org.apache.spark.util.SerializableBuffer@713f61e6) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:08 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:08 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_0, runningTasks: 3
15/08/11 10:18:08 DEBUG HttpParser: filled 181/181
15/08/11 10:18:08 DEBUG SparkDeploySchedulerBackend: [actor] handled message (2.37859 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:08 DEBUG Server: REQUEST /jars/SparkExample.jar on BlockingHttpConnection@1d0f118f,g=HttpGenerator{s=0,h=-1,b=-1,c=-1},p=HttpParser{s=-5,l=10,c=0},r=1
15/08/11 10:18:08 DEBUG Server: RESPONSE /jars/SparkExample.jar  200 handled=true
15/08/11 10:18:09 DEBUG BlockManagerMasterActor: [actor] received message GetLocations(broadcast_1_piece0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$h]
15/08/11 10:18:09 DEBUG BlockManagerMasterActor: [actor] handled message (0.284402 ms) GetLocations(broadcast_1_piece0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$h]
15/08/11 10:18:09 DEBUG ResourceLeakDetector: -Dio.netty.leakDetectionLevel: simple
15/08/11 10:18:09 DEBUG Recycler: -Dio.netty.recycler.maxCapacity.default: 262144
15/08/11 10:18:09 DEBUG BlockManager: Level for block broadcast_1_piece0 is StorageLevel(true, true, false, false, 1)
15/08/11 10:18:09 DEBUG BlockManager: Getting block broadcast_1_piece0 from memory
15/08/11 10:18:09 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:09 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_0, runningTasks: 3
15/08/11 10:18:09 DEBUG SparkDeploySchedulerBackend: [actor] handled message (1.894212 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:10 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_1_piece0,StorageLevel(false, true, false, false, 1),1792,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$i]
15/08/11 10:18:10 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.130.131:47921 (size: 1792.0 B, free: 245.7 MB)
15/08/11 10:18:10 DEBUG BlockManagerMasterActor: [actor] handled message (1.437793 ms) UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_1_piece0,StorageLevel(false, true, false, false, 1),1792,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$i]
15/08/11 10:18:10 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:10 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_0, runningTasks: 3
15/08/11 10:18:10 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.985291 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:10 DEBUG BlockManagerMasterActor: [actor] received message GetLocations(rdd_2_1) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$m]
15/08/11 10:18:10 DEBUG BlockManagerMasterActor: [actor] handled message (0.122478 ms) GetLocations(rdd_2_1) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$m]
15/08/11 10:18:10 DEBUG BlockManagerMasterActor: [actor] received message GetLocations(rdd_2_0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$n]
15/08/11 10:18:10 DEBUG BlockManagerMasterActor: [actor] handled message (0.039203 ms) GetLocations(rdd_2_0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$n]
15/08/11 10:18:10 DEBUG BlockManagerMasterActor: [actor] received message GetLocations(rdd_2_2) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$o]
15/08/11 10:18:10 DEBUG BlockManagerMasterActor: [actor] handled message (0.056103 ms) GetLocations(rdd_2_2) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$o]
15/08/11 10:18:11 DEBUG BlockManagerMasterActor: [actor] received message GetLocations(broadcast_0_piece0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$p]
15/08/11 10:18:11 DEBUG BlockManagerMasterActor: [actor] handled message (0.236056 ms) GetLocations(broadcast_0_piece0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$p]
15/08/11 10:18:11 DEBUG BlockManager: Level for block broadcast_0_piece0 is StorageLevel(true, true, false, false, 1)
15/08/11 10:18:11 DEBUG BlockManager: Getting block broadcast_0_piece0 from memory
15/08/11 10:18:11 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_0_piece0,StorageLevel(false, true, false, false, 1),15252,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$q]
15/08/11 10:18:11 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.130.131:47921 (size: 14.9 KB, free: 245.7 MB)
15/08/11 10:18:11 DEBUG BlockManagerMasterActor: [actor] handled message (0.840896 ms) UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_0_piece0,StorageLevel(false, true, false, false, 1),15252,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$q]
15/08/11 10:18:11 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:11 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_0, runningTasks: 3
15/08/11 10:18:11 DEBUG SparkDeploySchedulerBackend: [actor] handled message (1.251372 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:12 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:12 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_0, runningTasks: 3
15/08/11 10:18:12 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.8204 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:13 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:13 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_0, runningTasks: 3
15/08/11 10:18:13 DEBUG SparkDeploySchedulerBackend: [actor] handled message (1.35405 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:13 DEBUG HttpParser: filled -1/0
15/08/11 10:18:13 DEBUG AbstractHttpConnection: closed BlockingHttpConnection@1d0f118f,g=HttpGenerator{s=0,h=-1,b=-1,c=-1},p=HttpParser{s=0,l=0,c=-3},r=1
15/08/11 10:18:14 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:14 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_0, runningTasks: 3
15/08/11 10:18:14 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.638987 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:15 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:15 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_0, runningTasks: 3
15/08/11 10:18:15 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.712366 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:16 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:16 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_0, runningTasks: 3
15/08/11 10:18:16 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.726584 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:17 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),rdd_2_2,StorageLevel(false, false, true, false, 1),0,0,7974286) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$t]
15/08/11 10:18:17 INFO BlockManagerInfo: Added rdd_2_2 on tachyon on 192.168.130.131:47921 (size: 7.6 MB)
15/08/11 10:18:17 DEBUG BlockManagerMasterActor: [actor] handled message (11.377553 ms) UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),rdd_2_2,StorageLevel(false, false, true, false, 1),0,0,7974286) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$t]
15/08/11 10:18:17 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:17 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_0, runningTasks: 3
15/08/11 10:18:17 DEBUG SparkDeploySchedulerBackend: [actor] handled message (3.782443 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:18 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:18 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_0, runningTasks: 3
15/08/11 10:18:18 DEBUG SparkDeploySchedulerBackend: [actor] handled message (1.151128 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:19 DEBUG HeartbeatReceiver: [actor] received message Heartbeat(0,[Lscala.Tuple2;@377b9411,BlockManagerId(0, 192.168.130.131, 47921)) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$u]
15/08/11 10:18:19 DEBUG BlockManagerMasterActor: [actor] received message BlockManagerHeartbeat(BlockManagerId(0, 192.168.130.131, 47921)) from Actor[akka://sparkDriver/temp/$q]
15/08/11 10:18:19 DEBUG BlockManagerMasterActor: [actor] handled message (0.130999 ms) BlockManagerHeartbeat(BlockManagerId(0, 192.168.130.131, 47921)) from Actor[akka://sparkDriver/temp/$q]
15/08/11 10:18:19 DEBUG HeartbeatReceiver: [actor] handled message (25.197479 ms) Heartbeat(0,[Lscala.Tuple2;@377b9411,BlockManagerId(0, 192.168.130.131, 47921)) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$u]
15/08/11 10:18:19 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:19 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_0, runningTasks: 3
15/08/11 10:18:19 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.806918 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:20 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,2,FINISHED,org.apache.spark.util.SerializableBuffer@359abca) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:20 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_0, runningTasks: 2
15/08/11 10:18:20 DEBUG SparkDeploySchedulerBackend: [actor] handled message (20.953178 ms) StatusUpdate(0,2,FINISHED,org.apache.spark.util.SerializableBuffer@359abca) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:20 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 12232 ms on 192.168.130.131 (1/3)
15/08/11 10:18:20 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:20 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_0, runningTasks: 2
15/08/11 10:18:20 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.832499 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:21 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:21 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_0, runningTasks: 2
15/08/11 10:18:21 DEBUG SparkDeploySchedulerBackend: [actor] handled message (1.015274 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:22 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:22 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_0, runningTasks: 2
15/08/11 10:18:22 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.986727 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:23 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:23 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_0, runningTasks: 2
15/08/11 10:18:23 DEBUG SparkDeploySchedulerBackend: [actor] handled message (1.508297 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:24 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),rdd_2_1,StorageLevel(false, false, true, false, 1),0,0,44804988) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$x]
15/08/11 10:18:24 INFO BlockManagerInfo: Added rdd_2_1 on tachyon on 192.168.130.131:47921 (size: 42.7 MB)
15/08/11 10:18:24 DEBUG BlockManagerMasterActor: [actor] handled message (0.553786 ms) UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),rdd_2_1,StorageLevel(false, false, true, false, 1),0,0,44804988) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$x]
15/08/11 10:18:24 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:24 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_0, runningTasks: 2
15/08/11 10:18:24 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.998533 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:25 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),rdd_2_0,StorageLevel(false, false, true, false, 1),0,0,44820726) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$A]
15/08/11 10:18:25 INFO BlockManagerInfo: Added rdd_2_0 on tachyon on 192.168.130.131:47921 (size: 42.7 MB)
15/08/11 10:18:25 DEBUG BlockManagerMasterActor: [actor] handled message (0.583691 ms) UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),rdd_2_0,StorageLevel(false, false, true, false, 1),0,0,44820726) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$A]
15/08/11 10:18:25 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:25 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_0, runningTasks: 2
15/08/11 10:18:25 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.905013 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:25 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,1,FINISHED,org.apache.spark.util.SerializableBuffer@244072d2) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:25 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_0, runningTasks: 1
15/08/11 10:18:25 DEBUG SparkDeploySchedulerBackend: [actor] handled message (2.272461 ms) StatusUpdate(0,1,FINISHED,org.apache.spark.util.SerializableBuffer@244072d2) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:25 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 17769 ms on 192.168.130.131 (2/3)
15/08/11 10:18:26 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,0,FINISHED,org.apache.spark.util.SerializableBuffer@7748c737) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:26 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_0, runningTasks: 0
15/08/11 10:18:26 DEBUG SparkDeploySchedulerBackend: [actor] handled message (1.19828 ms) StatusUpdate(0,0,FINISHED,org.apache.spark.util.SerializableBuffer@7748c737) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:26 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 17951 ms on 192.168.130.131 (3/3)
15/08/11 10:18:26 INFO DAGScheduler: Stage 0 (takeSample at KMeansTest.scala:56) finished in 21.039 s
15/08/11 10:18:26 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
15/08/11 10:18:26 DEBUG DAGScheduler: After removal of stage 0, remaining stages = 0
15/08/11 10:18:26 INFO DAGScheduler: Job 0 finished: takeSample at KMeansTest.scala:56, took 21.775425 s
15/08/11 10:18:26 INFO SparkContext: Starting job: takeSample at KMeansTest.scala:56
15/08/11 10:18:26 INFO DAGScheduler: Got job 1 (takeSample at KMeansTest.scala:56) with 3 output partitions (allowLocal=false)
15/08/11 10:18:26 INFO DAGScheduler: Final stage: Stage 1(takeSample at KMeansTest.scala:56)
15/08/11 10:18:26 INFO DAGScheduler: Parents of final stage: List()
15/08/11 10:18:26 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD PartitionwiseSampledRDD[3] at takeSample at KMeansTest.scala:56
15/08/11 10:18:26 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:18:26 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@f1f930c) from Actor[akka://sparkDriver/temp/$r]
15/08/11 10:18:26 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:18:26 DEBUG BlockManagerMasterActor: [actor] handled message (0.265207 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@f1f930c) from Actor[akka://sparkDriver/temp/$r]
15/08/11 10:18:26 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@f1f930c) from Actor[akka://sparkDriver/temp/$s]
15/08/11 10:18:26 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:18:26 DEBUG BlockManagerMasterActor: [actor] handled message (0.192696 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@f1f930c) from Actor[akka://sparkDriver/temp/$s]
15/08/11 10:18:26 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:18:26 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|3|0,rdd_3_0,, null|3|1,rdd_3_1,, null|3|2,rdd_3_2,).
15/08/11 10:18:26 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:18:26 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$u]
15/08/11 10:18:26 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:18:26 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:26 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:26 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:26 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:26 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:26 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:26 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:26 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:26 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:26 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:18:26 DEBUG BlockManagerMasterActor: [actor] handled message (1.34258 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$u]
15/08/11 10:18:26 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:18:26 DEBUG BlockManager: Got multiple block location in  14 ms
15/08/11 10:18:26 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD KMeans01 MapPartitionsRDD[2] at map at KMeansTest.scala:50
15/08/11 10:18:26 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:18:26 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@459d9885) from Actor[akka://sparkDriver/temp/$v]
15/08/11 10:18:26 DEBUG BlockManagerMasterActor: [actor] handled message (0.310319 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@459d9885) from Actor[akka://sparkDriver/temp/$v]
15/08/11 10:18:26 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(ArrayBuffer(BlockManagerId(0, 192.168.130.131, 47921)), ArrayBuffer(BlockManagerId(0, 192.168.130.131, 47921)), ArrayBuffer(BlockManagerId(0, 192.168.130.131, 47921)))
15/08/11 10:18:26 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@459d9885) from Actor[akka://sparkDriver/temp/$w]
15/08/11 10:18:26 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:18:26 DEBUG BlockManagerMasterActor: [actor] handled message (0.349224 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@459d9885) from Actor[akka://sparkDriver/temp/$w]
15/08/11 10:18:26 INFO DAGScheduler: [SMSpark v1]Missing parents: List()
15/08/11 10:18:26 DEBUG DAGScheduler: submitStage(Stage 1)
15/08/11 10:18:26 DEBUG DAGScheduler: missing: List()
15/08/11 10:18:26 INFO DAGScheduler: Submitting Stage 1 (PartitionwiseSampledRDD[3] at takeSample at KMeansTest.scala:56), which has no missing parents
15/08/11 10:18:26 DEBUG DAGScheduler: submitMissingTasks(Stage 1)
15/08/11 10:18:26 INFO MemoryStore: ensureFreeSpace(3464) called with curMem=173220, maxMem=278302556
15/08/11 10:18:26 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 3.4 KB, free 265.2 MB)
15/08/11 10:18:26 DEBUG BlockManager: Put block broadcast_2 locally took  3 ms
15/08/11 10:18:26 DEBUG BlockManager: Putting block broadcast_2 without replication took  3 ms
15/08/11 10:18:26 INFO MemoryStore: ensureFreeSpace(2081) called with curMem=176684, maxMem=278302556
15/08/11 10:18:26 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.0 KB, free 265.2 MB)
15/08/11 10:18:26 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_2_piece0,StorageLevel(false, true, false, false, 1),2081,0,0) from Actor[akka://sparkDriver/temp/$x]
15/08/11 10:18:26 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 192.168.130.131:57830 (size: 2.0 KB, free: 265.4 MB)
15/08/11 10:18:26 INFO BlockManagerMaster: Updated info of block broadcast_2_piece0
15/08/11 10:18:26 DEBUG BlockManager: Told master about block broadcast_2_piece0
15/08/11 10:18:26 DEBUG BlockManagerMasterActor: [actor] handled message (1.957746 ms) UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_2_piece0,StorageLevel(false, true, false, false, 1),2081,0,0) from Actor[akka://sparkDriver/temp/$x]
15/08/11 10:18:26 DEBUG BlockManager: Put block broadcast_2_piece0 locally took  6 ms
15/08/11 10:18:26 DEBUG BlockManager: Putting block broadcast_2_piece0 without replication took  7 ms
15/08/11 10:18:26 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:852
15/08/11 10:18:26 INFO DAGScheduler: Submitting 3 missing tasks from Stage 1 (PartitionwiseSampledRDD[3] at takeSample at KMeansTest.scala:56)
15/08/11 10:18:26 DEBUG DAGScheduler: New pending tasks: Set(ResultTask(1, 0), ResultTask(1, 2), ResultTask(1, 1))
15/08/11 10:18:26 INFO TaskSchedulerImpl: Adding task set 1.0 with 3 tasks
15/08/11 10:18:26 DEBUG TaskSetManager: Epoch for TaskSet 1.0: 0
15/08/11 10:18:26 DEBUG TaskSetManager: Valid locality levels for TaskSet 1.0: PROCESS_LOCAL, NODE_LOCAL, ANY
15/08/11 10:18:26 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/deadLetters]
15/08/11 10:18:26 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_1, runningTasks: 0
15/08/11 10:18:26 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 3, 192.168.130.131, PROCESS_LOCAL, 1481 bytes)
15/08/11 10:18:26 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 4, 192.168.130.131, PROCESS_LOCAL, 1481 bytes)
15/08/11 10:18:26 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 5, 192.168.130.131, PROCESS_LOCAL, 1481 bytes)
15/08/11 10:18:26 DEBUG TaskSetManager: No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
15/08/11 10:18:26 DEBUG TaskSetManager: No tasks for locality level NODE_LOCAL, so moving to locality level ANY
15/08/11 10:18:26 DEBUG SparkDeploySchedulerBackend: [actor] handled message (11.28934 ms) ReviveOffers from Actor[akka://sparkDriver/deadLetters]
15/08/11 10:18:26 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,3,RUNNING,org.apache.spark.util.SerializableBuffer@3e13bdf5) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:26 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.125983 ms) StatusUpdate(0,3,RUNNING,org.apache.spark.util.SerializableBuffer@3e13bdf5) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:26 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,4,RUNNING,org.apache.spark.util.SerializableBuffer@21c3faa) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:26 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.077931 ms) StatusUpdate(0,4,RUNNING,org.apache.spark.util.SerializableBuffer@21c3faa) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:26 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,5,RUNNING,org.apache.spark.util.SerializableBuffer@c97b2fb) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:26 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.079143 ms) StatusUpdate(0,5,RUNNING,org.apache.spark.util.SerializableBuffer@c97b2fb) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:26 DEBUG BlockManagerMasterActor: [actor] received message GetLocations(broadcast_2_piece0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$B]
15/08/11 10:18:26 DEBUG BlockManagerMasterActor: [actor] handled message (0.149568 ms) GetLocations(broadcast_2_piece0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$B]
15/08/11 10:18:26 DEBUG BlockManager: Level for block broadcast_2_piece0 is StorageLevel(true, true, false, false, 1)
15/08/11 10:18:26 DEBUG BlockManager: Getting block broadcast_2_piece0 from memory
15/08/11 10:18:26 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_2_piece0,StorageLevel(false, true, false, false, 1),2081,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$C]
15/08/11 10:18:26 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 192.168.130.131:47921 (size: 2.0 KB, free: 245.7 MB)
15/08/11 10:18:26 DEBUG BlockManagerMasterActor: [actor] handled message (0.721433 ms) UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_2_piece0,StorageLevel(false, true, false, false, 1),2081,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$C]
15/08/11 10:18:26 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:26 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_1, runningTasks: 3
15/08/11 10:18:26 DEBUG SparkDeploySchedulerBackend: [actor] handled message (3.321146 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:26 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,5,FINISHED,org.apache.spark.util.SerializableBuffer@26c4e626) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:26 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_1, runningTasks: 2
15/08/11 10:18:26 DEBUG SparkDeploySchedulerBackend: [actor] handled message (1.671229 ms) StatusUpdate(0,5,FINISHED,org.apache.spark.util.SerializableBuffer@26c4e626) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:27 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 5) in 753 ms on 192.168.130.131 (1/3)
15/08/11 10:18:27 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,3,FINISHED,org.apache.spark.util.SerializableBuffer@7f61879e) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:27 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_1, runningTasks: 1
15/08/11 10:18:27 DEBUG SparkDeploySchedulerBackend: [actor] handled message (1.60013 ms) StatusUpdate(0,3,FINISHED,org.apache.spark.util.SerializableBuffer@7f61879e) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:27 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 3) in 1506 ms on 192.168.130.131 (2/3)
15/08/11 10:18:27 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,4,FINISHED,org.apache.spark.util.SerializableBuffer@73982ba1) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:27 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_1, runningTasks: 0
15/08/11 10:18:27 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.960482 ms) StatusUpdate(0,4,FINISHED,org.apache.spark.util.SerializableBuffer@73982ba1) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:27 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 4) in 1593 ms on 192.168.130.131 (3/3)
15/08/11 10:18:27 INFO DAGScheduler: Stage 1 (takeSample at KMeansTest.scala:56) finished in 1.616 s
15/08/11 10:18:27 DEBUG DAGScheduler: After removal of stage 1, remaining stages = 0
15/08/11 10:18:27 INFO DAGScheduler: Job 1 finished: takeSample at KMeansTest.scala:56, took 1.672536 s
15/08/11 10:18:27 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
15/08/11 10:18:27 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:27 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.294387 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:27 INFO SparkContext: Starting job: collectAsMap at KMeansTest.scala:67
15/08/11 10:18:27 INFO DAGScheduler: Registering RDD 4 (map at KMeansTest.scala:61)
15/08/11 10:18:27 INFO DAGScheduler: Got job 2 (collectAsMap at KMeansTest.scala:67) with 3 output partitions (allowLocal=false)
15/08/11 10:18:27 INFO DAGScheduler: Final stage: Stage 3(collectAsMap at KMeansTest.scala:67)
15/08/11 10:18:27 INFO DAGScheduler: Parents of final stage: List(Stage 2)
15/08/11 10:18:27 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD MapPartitionsRDD[6] at map at KMeansTest.scala:65
15/08/11 10:18:27 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:18:27 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@3267f991) from Actor[akka://sparkDriver/temp/$y]
15/08/11 10:18:27 DEBUG BlockManagerMasterActor: [actor] handled message (0.153556 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@3267f991) from Actor[akka://sparkDriver/temp/$y]
15/08/11 10:18:27 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:18:27 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@3267f991) from Actor[akka://sparkDriver/temp/$z]
15/08/11 10:18:27 DEBUG BlockManagerMasterActor: [actor] handled message (0.245931 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@3267f991) from Actor[akka://sparkDriver/temp/$z]
15/08/11 10:18:27 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:18:27 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:18:27 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|6|0,rdd_6_0,, null|6|1,rdd_6_1,, null|6|2,rdd_6_2,).
15/08/11 10:18:27 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:18:27 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$B]
15/08/11 10:18:27 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:18:27 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:27 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:27 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:27 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:27 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:27 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:27 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:27 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:27 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:27 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:18:27 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:18:27 DEBUG BlockManager: Got multiple block location in  21 ms
15/08/11 10:18:27 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD ShuffledRDD[5] at reduceByKey at KMeansTest.scala:63
15/08/11 10:18:27 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:18:27 DEBUG BlockManagerMasterActor: [actor] handled message (10.555902 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$B]
15/08/11 10:18:27 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@796e624f) from Actor[akka://sparkDriver/temp/$C]
15/08/11 10:18:27 DEBUG BlockManagerMasterActor: [actor] handled message (0.231558 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@796e624f) from Actor[akka://sparkDriver/temp/$C]
15/08/11 10:18:27 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:18:27 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@796e624f) from Actor[akka://sparkDriver/temp/$D]
15/08/11 10:18:27 DEBUG BlockManagerMasterActor: [actor] handled message (0.239115 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@796e624f) from Actor[akka://sparkDriver/temp/$D]
15/08/11 10:18:27 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:18:27 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:18:27 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|5|0,rdd_5_0,, null|5|1,rdd_5_1,, null|5|2,rdd_5_2,).
15/08/11 10:18:27 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:18:27 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$F]
15/08/11 10:18:27 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:18:27 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:27 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:27 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:27 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:27 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:27 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:27 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:27 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:27 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:27 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:18:27 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:18:27 DEBUG BlockManager: Got multiple block location in  19 ms
15/08/11 10:18:27 INFO DAGScheduler: [SMSpark v1]Missing parents: List(Stage 2)
15/08/11 10:18:27 DEBUG DAGScheduler: submitStage(Stage 3)
15/08/11 10:18:27 DEBUG DAGScheduler: missing: List(Stage 2)
15/08/11 10:18:27 DEBUG DAGScheduler: submitStage(Stage 2)
15/08/11 10:18:27 DEBUG BlockManagerMasterActor: [actor] handled message (3.987669 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$F]
15/08/11 10:18:27 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD MapPartitionsRDD[4] at map at KMeansTest.scala:61
15/08/11 10:18:27 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:18:27 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@b51b399) from Actor[akka://sparkDriver/temp/$G]
15/08/11 10:18:27 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:18:27 DEBUG BlockManagerMasterActor: [actor] handled message (6.424103 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@b51b399) from Actor[akka://sparkDriver/temp/$G]
15/08/11 10:18:27 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@b51b399) from Actor[akka://sparkDriver/temp/$H]
15/08/11 10:18:27 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:18:27 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:18:27 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|4|0,rdd_4_0,, null|4|1,rdd_4_1,, null|4|2,rdd_4_2,).
15/08/11 10:18:27 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:18:27 DEBUG BlockManagerMasterActor: [actor] handled message (12.419233 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@b51b399) from Actor[akka://sparkDriver/temp/$H]
15/08/11 10:18:27 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$J]
15/08/11 10:18:27 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:18:27 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:27 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:27 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:27 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:27 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:27 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:27 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:27 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:27 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:27 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:18:27 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:18:27 DEBUG BlockManager: Got multiple block location in  22 ms
15/08/11 10:18:27 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD KMeans01 MapPartitionsRDD[2] at map at KMeansTest.scala:50
15/08/11 10:18:27 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:18:27 DEBUG BlockManagerMasterActor: [actor] handled message (3.903146 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$J]
15/08/11 10:18:27 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@5e359ae3) from Actor[akka://sparkDriver/temp/$K]
15/08/11 10:18:27 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(ArrayBuffer(BlockManagerId(0, 192.168.130.131, 47921)), ArrayBuffer(BlockManagerId(0, 192.168.130.131, 47921)), ArrayBuffer(BlockManagerId(0, 192.168.130.131, 47921)))
15/08/11 10:18:27 DEBUG BlockManagerMasterActor: [actor] handled message (0.664537 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@5e359ae3) from Actor[akka://sparkDriver/temp/$K]
15/08/11 10:18:27 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@5e359ae3) from Actor[akka://sparkDriver/temp/$L]
15/08/11 10:18:27 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:18:27 DEBUG DAGScheduler: missing: List()
15/08/11 10:18:27 INFO DAGScheduler: Submitting Stage 2 (MapPartitionsRDD[4] at map at KMeansTest.scala:61), which has no missing parents
15/08/11 10:18:27 DEBUG DAGScheduler: submitMissingTasks(Stage 2)
15/08/11 10:18:27 DEBUG BlockManagerMasterActor: [actor] handled message (4.931895 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@5e359ae3) from Actor[akka://sparkDriver/temp/$L]
15/08/11 10:18:28 INFO MemoryStore: ensureFreeSpace(4768) called with curMem=178765, maxMem=278302556
15/08/11 10:18:28 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 4.7 KB, free 265.2 MB)
15/08/11 10:18:28 DEBUG BlockManager: Put block broadcast_3 locally took  5 ms
15/08/11 10:18:28 DEBUG BlockManager: Putting block broadcast_3 without replication took  5 ms
15/08/11 10:18:28 INFO MemoryStore: ensureFreeSpace(3202) called with curMem=183533, maxMem=278302556
15/08/11 10:18:28 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.1 KB, free 265.2 MB)
15/08/11 10:18:28 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_3_piece0,StorageLevel(false, true, false, false, 1),3202,0,0) from Actor[akka://sparkDriver/temp/$M]
15/08/11 10:18:28 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 192.168.130.131:57830 (size: 3.1 KB, free: 265.4 MB)
15/08/11 10:18:28 INFO BlockManagerMaster: Updated info of block broadcast_3_piece0
15/08/11 10:18:28 DEBUG BlockManager: Told master about block broadcast_3_piece0
15/08/11 10:18:28 DEBUG BlockManagerMasterActor: [actor] handled message (0.635161 ms) UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_3_piece0,StorageLevel(false, true, false, false, 1),3202,0,0) from Actor[akka://sparkDriver/temp/$M]
15/08/11 10:18:28 DEBUG BlockManager: Put block broadcast_3_piece0 locally took  3 ms
15/08/11 10:18:28 DEBUG BlockManager: Putting block broadcast_3_piece0 without replication took  3 ms
15/08/11 10:18:28 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:852
15/08/11 10:18:28 INFO DAGScheduler: Submitting 3 missing tasks from Stage 2 (MapPartitionsRDD[4] at map at KMeansTest.scala:61)
15/08/11 10:18:28 DEBUG DAGScheduler: New pending tasks: Set(ShuffleMapTask(2, 0), ShuffleMapTask(2, 1), ShuffleMapTask(2, 2))
15/08/11 10:18:28 INFO TaskSchedulerImpl: Adding task set 2.0 with 3 tasks
15/08/11 10:18:28 DEBUG TaskSetManager: Epoch for TaskSet 2.0: 0
15/08/11 10:18:28 DEBUG TaskSetManager: Valid locality levels for TaskSet 2.0: PROCESS_LOCAL, NODE_LOCAL, ANY
15/08/11 10:18:28 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/deadLetters]
15/08/11 10:18:28 DEBUG DAGScheduler: submitStage(Stage 3)
15/08/11 10:18:28 DEBUG DAGScheduler: missing: List(Stage 2)
15/08/11 10:18:28 DEBUG DAGScheduler: submitStage(Stage 2)
15/08/11 10:18:28 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_2, runningTasks: 0
15/08/11 10:18:28 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 6, 192.168.130.131, PROCESS_LOCAL, 1361 bytes)
15/08/11 10:18:28 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 7, 192.168.130.131, PROCESS_LOCAL, 1361 bytes)
15/08/11 10:18:28 DEBUG DAGScheduler: submitStage(Stage 3)
15/08/11 10:18:28 INFO TaskSetManager: Starting task 2.0 in stage 2.0 (TID 8, 192.168.130.131, PROCESS_LOCAL, 1361 bytes)
15/08/11 10:18:28 DEBUG DAGScheduler: missing: List(Stage 2)
15/08/11 10:18:28 DEBUG TaskSetManager: No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
15/08/11 10:18:28 DEBUG DAGScheduler: submitStage(Stage 2)
15/08/11 10:18:28 DEBUG DAGScheduler: submitStage(Stage 3)
15/08/11 10:18:28 DEBUG DAGScheduler: missing: List(Stage 2)
15/08/11 10:18:28 DEBUG DAGScheduler: submitStage(Stage 2)
15/08/11 10:18:28 DEBUG TaskSetManager: No tasks for locality level NODE_LOCAL, so moving to locality level ANY
15/08/11 10:18:28 DEBUG DAGScheduler: submitStage(Stage 3)
15/08/11 10:18:28 DEBUG DAGScheduler: missing: List(Stage 2)
15/08/11 10:18:28 DEBUG DAGScheduler: submitStage(Stage 2)
15/08/11 10:18:28 DEBUG SparkDeploySchedulerBackend: [actor] handled message (16.621766 ms) ReviveOffers from Actor[akka://sparkDriver/deadLetters]
15/08/11 10:18:28 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,6,RUNNING,org.apache.spark.util.SerializableBuffer@449ecfdd) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:28 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.091028 ms) StatusUpdate(0,6,RUNNING,org.apache.spark.util.SerializableBuffer@449ecfdd) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:28 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,7,RUNNING,org.apache.spark.util.SerializableBuffer@1660d95d) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:28 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.197692 ms) StatusUpdate(0,7,RUNNING,org.apache.spark.util.SerializableBuffer@1660d95d) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:28 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,8,RUNNING,org.apache.spark.util.SerializableBuffer@305e7425) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:28 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.187288 ms) StatusUpdate(0,8,RUNNING,org.apache.spark.util.SerializableBuffer@305e7425) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:28 DEBUG BlockManagerMasterActor: [actor] received message GetLocations(broadcast_3_piece0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$D]
15/08/11 10:18:28 DEBUG BlockManagerMasterActor: [actor] handled message (0.401396 ms) GetLocations(broadcast_3_piece0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$D]
15/08/11 10:18:28 DEBUG BlockManager: Level for block broadcast_3_piece0 is StorageLevel(true, true, false, false, 1)
15/08/11 10:18:28 DEBUG BlockManager: Getting block broadcast_3_piece0 from memory
15/08/11 10:18:28 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_3_piece0,StorageLevel(false, true, false, false, 1),3202,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$E]
15/08/11 10:18:28 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 192.168.130.131:47921 (size: 3.1 KB, free: 245.7 MB)
15/08/11 10:18:28 DEBUG BlockManagerMasterActor: [actor] handled message (1.360507 ms) UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_3_piece0,StorageLevel(false, true, false, false, 1),3202,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$E]
15/08/11 10:18:28 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:28 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_2, runningTasks: 3
15/08/11 10:18:28 DEBUG SparkDeploySchedulerBackend: [actor] handled message (1.334556 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:29 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:29 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_2, runningTasks: 3
15/08/11 10:18:29 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.95475 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:29 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,8,FINISHED,org.apache.spark.util.SerializableBuffer@4e058be4) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:29 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_2, runningTasks: 2
15/08/11 10:18:29 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.90495 ms) StatusUpdate(0,8,FINISHED,org.apache.spark.util.SerializableBuffer@4e058be4) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:29 INFO TaskSetManager: Finished task 2.0 in stage 2.0 (TID 8) in 1835 ms on 192.168.130.131 (1/3)
15/08/11 10:18:29 DEBUG DAGScheduler: ShuffleMapTask finished on 0
15/08/11 10:18:29 DEBUG DAGScheduler: submitStage(Stage 3)
15/08/11 10:18:29 DEBUG DAGScheduler: missing: List(Stage 2)
15/08/11 10:18:29 DEBUG DAGScheduler: submitStage(Stage 2)
15/08/11 10:18:29 DEBUG HeartbeatReceiver: [actor] received message Heartbeat(0,[Lscala.Tuple2;@2990554a,BlockManagerId(0, 192.168.130.131, 47921)) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$F]
15/08/11 10:18:29 DEBUG BlockManagerMasterActor: [actor] received message BlockManagerHeartbeat(BlockManagerId(0, 192.168.130.131, 47921)) from Actor[akka://sparkDriver/temp/$N]
15/08/11 10:18:29 DEBUG BlockManagerMasterActor: [actor] handled message (0.169139 ms) BlockManagerHeartbeat(BlockManagerId(0, 192.168.130.131, 47921)) from Actor[akka://sparkDriver/temp/$N]
15/08/11 10:18:29 DEBUG HeartbeatReceiver: [actor] handled message (1.113353 ms) Heartbeat(0,[Lscala.Tuple2;@2990554a,BlockManagerId(0, 192.168.130.131, 47921)) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$F]
15/08/11 10:18:30 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:30 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_2, runningTasks: 2
15/08/11 10:18:30 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.759063 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:31 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,7,FINISHED,org.apache.spark.util.SerializableBuffer@bf3e82c) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:31 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_2, runningTasks: 1
15/08/11 10:18:31 DEBUG SparkDeploySchedulerBackend: [actor] handled message (1.069724 ms) StatusUpdate(0,7,FINISHED,org.apache.spark.util.SerializableBuffer@bf3e82c) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:31 DEBUG DAGScheduler: ShuffleMapTask finished on 0
15/08/11 10:18:31 DEBUG DAGScheduler: submitStage(Stage 3)
15/08/11 10:18:31 DEBUG DAGScheduler: missing: List(Stage 2)
15/08/11 10:18:31 DEBUG DAGScheduler: submitStage(Stage 2)
15/08/11 10:18:31 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 7) in 3495 ms on 192.168.130.131 (2/3)
15/08/11 10:18:31 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,6,FINISHED,org.apache.spark.util.SerializableBuffer@3a0fa6d5) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:31 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_2, runningTasks: 0
15/08/11 10:18:31 DEBUG SparkDeploySchedulerBackend: [actor] handled message (2.210818 ms) StatusUpdate(0,6,FINISHED,org.apache.spark.util.SerializableBuffer@3a0fa6d5) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:31 DEBUG DAGScheduler: ShuffleMapTask finished on 0
15/08/11 10:18:31 INFO DAGScheduler: Stage 2 (map at KMeansTest.scala:61) finished in 3.623 s
15/08/11 10:18:31 INFO DAGScheduler: looking for newly runnable stages
15/08/11 10:18:31 INFO DAGScheduler: running: Set()
15/08/11 10:18:31 INFO DAGScheduler: waiting: Set(Stage 3)
15/08/11 10:18:31 INFO DAGScheduler: failed: Set()
15/08/11 10:18:31 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 6) in 3609 ms on 192.168.130.131 (3/3)
15/08/11 10:18:31 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
15/08/11 10:18:31 DEBUG MapOutputTrackerMaster: Increasing epoch to 1
15/08/11 10:18:31 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD MapPartitionsRDD[6] at map at KMeansTest.scala:65
15/08/11 10:18:31 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:18:31 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@1599a9f4) from Actor[akka://sparkDriver/temp/$O]
15/08/11 10:18:31 DEBUG BlockManagerMasterActor: [actor] handled message (0.526115 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@1599a9f4) from Actor[akka://sparkDriver/temp/$O]
15/08/11 10:18:31 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:18:31 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@1599a9f4) from Actor[akka://sparkDriver/temp/$P]
15/08/11 10:18:31 DEBUG BlockManagerMasterActor: [actor] handled message (0.220026 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@1599a9f4) from Actor[akka://sparkDriver/temp/$P]
15/08/11 10:18:31 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:18:31 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:18:31 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|6|0,rdd_6_0,, null|6|1,rdd_6_1,, null|6|2,rdd_6_2,).
15/08/11 10:18:31 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:18:31 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$R]
15/08/11 10:18:31 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:18:31 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:31 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:31 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:31 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:31 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:31 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:31 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:31 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:31 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:31 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:18:31 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:18:31 DEBUG BlockManager: Got multiple block location in  79 ms
15/08/11 10:18:31 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD ShuffledRDD[5] at reduceByKey at KMeansTest.scala:63
15/08/11 10:18:31 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:18:31 DEBUG BlockManagerMasterActor: [actor] handled message (7.961228 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$R]
15/08/11 10:18:31 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@7542d0b0) from Actor[akka://sparkDriver/temp/$S]
15/08/11 10:18:31 DEBUG BlockManagerMasterActor: [actor] handled message (0.260528 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@7542d0b0) from Actor[akka://sparkDriver/temp/$S]
15/08/11 10:18:31 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:18:31 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@7542d0b0) from Actor[akka://sparkDriver/temp/$T]
15/08/11 10:18:31 DEBUG BlockManagerMasterActor: [actor] handled message (0.218374 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@7542d0b0) from Actor[akka://sparkDriver/temp/$T]
15/08/11 10:18:31 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:18:31 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:18:31 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|5|0,rdd_5_0,, null|5|1,rdd_5_1,, null|5|2,rdd_5_2,).
15/08/11 10:18:31 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:18:31 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$V]
15/08/11 10:18:31 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:18:31 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:31 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:31 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:31 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:31 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:31 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:31 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:31 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:31 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:31 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:18:31 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:18:31 DEBUG BlockManager: Got multiple block location in  30 ms
15/08/11 10:18:31 INFO DAGScheduler: Missing parents for Stage 3: List()
15/08/11 10:18:31 INFO DAGScheduler: Submitting Stage 3 (MapPartitionsRDD[6] at map at KMeansTest.scala:65), which is now runnable
15/08/11 10:18:31 DEBUG DAGScheduler: submitMissingTasks(Stage 3)
15/08/11 10:18:31 DEBUG BlockManagerMasterActor: [actor] handled message (12.661717 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$V]
15/08/11 10:18:31 INFO MemoryStore: ensureFreeSpace(2560) called with curMem=186735, maxMem=278302556
15/08/11 10:18:31 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 2.5 KB, free 265.2 MB)
15/08/11 10:18:31 DEBUG BlockManager: Put block broadcast_4 locally took  7 ms
15/08/11 10:18:31 DEBUG BlockManager: Putting block broadcast_4 without replication took  8 ms
15/08/11 10:18:31 INFO MemoryStore: ensureFreeSpace(1537) called with curMem=189295, maxMem=278302556
15/08/11 10:18:31 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 1537.0 B, free 265.2 MB)
15/08/11 10:18:31 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_4_piece0,StorageLevel(false, true, false, false, 1),1537,0,0) from Actor[akka://sparkDriver/temp/$W]
15/08/11 10:18:31 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 192.168.130.131:57830 (size: 1537.0 B, free: 265.4 MB)
15/08/11 10:18:31 DEBUG BlockManagerMasterActor: [actor] handled message (1.183604 ms) UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_4_piece0,StorageLevel(false, true, false, false, 1),1537,0,0) from Actor[akka://sparkDriver/temp/$W]
15/08/11 10:18:31 INFO BlockManagerMaster: Updated info of block broadcast_4_piece0
15/08/11 10:18:31 DEBUG BlockManager: Told master about block broadcast_4_piece0
15/08/11 10:18:31 DEBUG BlockManager: Put block broadcast_4_piece0 locally took  9 ms
15/08/11 10:18:31 DEBUG BlockManager: Putting block broadcast_4_piece0 without replication took  9 ms
15/08/11 10:18:31 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:852
15/08/11 10:18:31 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:31 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.28421 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:31 INFO DAGScheduler: Submitting 3 missing tasks from Stage 3 (MapPartitionsRDD[6] at map at KMeansTest.scala:65)
15/08/11 10:18:31 DEBUG DAGScheduler: New pending tasks: Set(ResultTask(3, 1), ResultTask(3, 0), ResultTask(3, 2))
15/08/11 10:18:31 INFO TaskSchedulerImpl: Adding task set 3.0 with 3 tasks
15/08/11 10:18:31 DEBUG TaskSetManager: Epoch for TaskSet 3.0: 1
15/08/11 10:18:31 DEBUG TaskSetManager: Valid locality levels for TaskSet 3.0: NO_PREF, ANY
15/08/11 10:18:31 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/deadLetters]
15/08/11 10:18:31 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_3, runningTasks: 0
15/08/11 10:18:31 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 9, 192.168.130.131, PROCESS_LOCAL, 1116 bytes)
15/08/11 10:18:31 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 10, 192.168.130.131, PROCESS_LOCAL, 1116 bytes)
15/08/11 10:18:31 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 11, 192.168.130.131, PROCESS_LOCAL, 1116 bytes)
15/08/11 10:18:31 DEBUG TaskSetManager: No tasks for locality level NO_PREF, so moving to locality level ANY
15/08/11 10:18:31 DEBUG SparkDeploySchedulerBackend: [actor] handled message (26.652036 ms) ReviveOffers from Actor[akka://sparkDriver/deadLetters]
15/08/11 10:18:31 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,9,RUNNING,org.apache.spark.util.SerializableBuffer@18b8e08e) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:31 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.129678 ms) StatusUpdate(0,9,RUNNING,org.apache.spark.util.SerializableBuffer@18b8e08e) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:31 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,10,RUNNING,org.apache.spark.util.SerializableBuffer@119e9750) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:31 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.057885 ms) StatusUpdate(0,10,RUNNING,org.apache.spark.util.SerializableBuffer@119e9750) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:31 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,11,RUNNING,org.apache.spark.util.SerializableBuffer@42e00e39) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:31 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.056656 ms) StatusUpdate(0,11,RUNNING,org.apache.spark.util.SerializableBuffer@42e00e39) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:31 DEBUG BlockManagerMasterActor: [actor] received message GetLocations(broadcast_4_piece0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$G]
15/08/11 10:18:31 DEBUG BlockManagerMasterActor: [actor] handled message (0.343421 ms) GetLocations(broadcast_4_piece0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$G]
15/08/11 10:18:31 DEBUG BlockManager: Level for block broadcast_4_piece0 is StorageLevel(true, true, false, false, 1)
15/08/11 10:18:31 DEBUG BlockManager: Getting block broadcast_4_piece0 from memory
15/08/11 10:18:31 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_4_piece0,StorageLevel(false, true, false, false, 1),1537,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$H]
15/08/11 10:18:31 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 192.168.130.131:47921 (size: 1537.0 B, free: 245.7 MB)
15/08/11 10:18:31 DEBUG BlockManagerMasterActor: [actor] handled message (1.371872 ms) UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_4_piece0,StorageLevel(false, true, false, false, 1),1537,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$H]
15/08/11 10:18:31 DEBUG MapOutputTrackerMasterActor: [actor] received message GetMapOutputStatuses(0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$I]
15/08/11 10:18:31 INFO MapOutputTrackerMasterActor: Asked to send map output locations for shuffle 0 to sparkExecutor@192.168.130.131:49489
15/08/11 10:18:31 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 162 bytes
15/08/11 10:18:31 DEBUG MapOutputTrackerMasterActor: [actor] handled message (12.513373 ms) GetMapOutputStatuses(0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$I]
15/08/11 10:18:32 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,11,FINISHED,org.apache.spark.util.SerializableBuffer@1cea97ad) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:32 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_3, runningTasks: 2
15/08/11 10:18:32 DEBUG SparkDeploySchedulerBackend: [actor] handled message (3.682755 ms) StatusUpdate(0,11,FINISHED,org.apache.spark.util.SerializableBuffer@1cea97ad) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:32 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,9,FINISHED,org.apache.spark.util.SerializableBuffer@3a2d3196) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:32 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 11) in 279 ms on 192.168.130.131 (1/3)
15/08/11 10:18:32 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_3, runningTasks: 1
15/08/11 10:18:32 DEBUG SparkDeploySchedulerBackend: [actor] handled message (22.457197 ms) StatusUpdate(0,9,FINISHED,org.apache.spark.util.SerializableBuffer@3a2d3196) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:32 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,10,FINISHED,org.apache.spark.util.SerializableBuffer@dc97997) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:32 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_3, runningTasks: 0
15/08/11 10:18:32 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.546648 ms) StatusUpdate(0,10,FINISHED,org.apache.spark.util.SerializableBuffer@dc97997) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:32 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 10) in 305 ms on 192.168.130.131 (2/3)
15/08/11 10:18:32 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 9) in 337 ms on 192.168.130.131 (3/3)
15/08/11 10:18:32 INFO DAGScheduler: Stage 3 (collectAsMap at KMeansTest.scala:67) finished in 0.344 s
15/08/11 10:18:32 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
15/08/11 10:18:32 DEBUG DAGScheduler: After removal of stage 2, remaining stages = 1
15/08/11 10:18:32 DEBUG DAGScheduler: After removal of stage 3, remaining stages = 0
15/08/11 10:18:32 INFO DAGScheduler: Job 2 finished: collectAsMap at KMeansTest.scala:67, took 4.279886 s
Finished iteration (num = 0)
15/08/11 10:18:32 INFO SparkContext: Starting job: collectAsMap at KMeansTest.scala:67
15/08/11 10:18:32 INFO DAGScheduler: Registering RDD 7 (map at KMeansTest.scala:61)
15/08/11 10:18:32 INFO DAGScheduler: Got job 3 (collectAsMap at KMeansTest.scala:67) with 3 output partitions (allowLocal=false)
15/08/11 10:18:32 INFO DAGScheduler: Final stage: Stage 5(collectAsMap at KMeansTest.scala:67)
15/08/11 10:18:32 INFO DAGScheduler: Parents of final stage: List(Stage 4)
15/08/11 10:18:32 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD MapPartitionsRDD[9] at map at KMeansTest.scala:65
15/08/11 10:18:32 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:18:32 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@341123a2) from Actor[akka://sparkDriver/temp/$X]
15/08/11 10:18:32 DEBUG BlockManagerMasterActor: [actor] handled message (2.34019 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@341123a2) from Actor[akka://sparkDriver/temp/$X]
15/08/11 10:18:32 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:18:32 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@341123a2) from Actor[akka://sparkDriver/temp/$Y]
15/08/11 10:18:32 DEBUG BlockManagerMasterActor: [actor] handled message (0.330036 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@341123a2) from Actor[akka://sparkDriver/temp/$Y]
15/08/11 10:18:32 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:18:32 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:18:32 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|9|0,rdd_9_0,, null|9|1,rdd_9_1,, null|9|2,rdd_9_2,).
15/08/11 10:18:32 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:18:32 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$0]
15/08/11 10:18:32 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:18:32 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:32 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:32 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:32 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:32 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:32 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:32 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:32 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:32 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:32 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:18:32 DEBUG BlockManagerMasterActor: [actor] handled message (4.501298 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$0]
15/08/11 10:18:32 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:18:32 DEBUG BlockManager: Got multiple block location in  23 ms
15/08/11 10:18:32 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD ShuffledRDD[8] at reduceByKey at KMeansTest.scala:63
15/08/11 10:18:32 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:18:32 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@6f8e2c4e) from Actor[akka://sparkDriver/temp/$1]
15/08/11 10:18:32 DEBUG BlockManagerMasterActor: [actor] handled message (0.198474 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@6f8e2c4e) from Actor[akka://sparkDriver/temp/$1]
15/08/11 10:18:32 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:18:32 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@6f8e2c4e) from Actor[akka://sparkDriver/temp/$2]
15/08/11 10:18:32 DEBUG BlockManagerMasterActor: [actor] handled message (0.182614 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@6f8e2c4e) from Actor[akka://sparkDriver/temp/$2]
15/08/11 10:18:32 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:18:32 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:18:32 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|8|0,rdd_8_0,, null|8|1,rdd_8_1,, null|8|2,rdd_8_2,).
15/08/11 10:18:32 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:18:32 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$4]
15/08/11 10:18:32 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:18:32 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:32 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:32 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:32 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:32 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:32 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:32 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:32 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:32 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:32 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:18:32 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:18:32 DEBUG BlockManager: Got multiple block location in  22 ms
15/08/11 10:18:32 INFO DAGScheduler: [SMSpark v1]Missing parents: List(Stage 4)
15/08/11 10:18:32 DEBUG BlockManagerMasterActor: [actor] handled message (12.594855 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$4]
15/08/11 10:18:32 DEBUG DAGScheduler: submitStage(Stage 5)
15/08/11 10:18:32 DEBUG DAGScheduler: missing: List(Stage 4)
15/08/11 10:18:32 DEBUG DAGScheduler: submitStage(Stage 4)
15/08/11 10:18:32 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD MapPartitionsRDD[7] at map at KMeansTest.scala:61
15/08/11 10:18:32 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:18:32 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@41e690cf) from Actor[akka://sparkDriver/temp/$5]
15/08/11 10:18:32 DEBUG BlockManagerMasterActor: [actor] handled message (0.220163 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@41e690cf) from Actor[akka://sparkDriver/temp/$5]
15/08/11 10:18:32 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:18:32 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@41e690cf) from Actor[akka://sparkDriver/temp/$6]
15/08/11 10:18:32 DEBUG BlockManagerMasterActor: [actor] handled message (0.624905 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@41e690cf) from Actor[akka://sparkDriver/temp/$6]
15/08/11 10:18:32 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:18:32 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:18:32 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|7|0,rdd_7_0,, null|7|1,rdd_7_1,, null|7|2,rdd_7_2,).
15/08/11 10:18:32 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:18:32 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$8]
15/08/11 10:18:32 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:18:32 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:32 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:32 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:32 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:32 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:32 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:32 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:32 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:32 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:32 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:18:32 DEBUG BlockManagerMasterActor: [actor] handled message (2.906657 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$8]
15/08/11 10:18:32 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:18:32 DEBUG BlockManager: Got multiple block location in  20 ms
15/08/11 10:18:32 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD KMeans01 MapPartitionsRDD[2] at map at KMeansTest.scala:50
15/08/11 10:18:32 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:18:32 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@ffd71d2) from Actor[akka://sparkDriver/temp/$9]
15/08/11 10:18:32 DEBUG BlockManagerMasterActor: [actor] handled message (0.522027 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@ffd71d2) from Actor[akka://sparkDriver/temp/$9]
15/08/11 10:18:32 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(ArrayBuffer(BlockManagerId(0, 192.168.130.131, 47921)), ArrayBuffer(BlockManagerId(0, 192.168.130.131, 47921)), ArrayBuffer(BlockManagerId(0, 192.168.130.131, 47921)))
15/08/11 10:18:32 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@ffd71d2) from Actor[akka://sparkDriver/temp/$+]
15/08/11 10:18:32 DEBUG BlockManagerMasterActor: [actor] handled message (0.357176 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@ffd71d2) from Actor[akka://sparkDriver/temp/$+]
15/08/11 10:18:32 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:18:32 DEBUG DAGScheduler: missing: List()
15/08/11 10:18:32 INFO DAGScheduler: Submitting Stage 4 (MapPartitionsRDD[7] at map at KMeansTest.scala:61), which has no missing parents
15/08/11 10:18:32 DEBUG DAGScheduler: submitMissingTasks(Stage 4)
15/08/11 10:18:32 INFO MemoryStore: ensureFreeSpace(4768) called with curMem=190832, maxMem=278302556
15/08/11 10:18:32 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 4.7 KB, free 265.2 MB)
15/08/11 10:18:32 DEBUG BlockManager: Put block broadcast_5 locally took  2 ms
15/08/11 10:18:32 DEBUG BlockManager: Putting block broadcast_5 without replication took  3 ms
15/08/11 10:18:32 INFO MemoryStore: ensureFreeSpace(3198) called with curMem=195600, maxMem=278302556
15/08/11 10:18:32 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 3.1 KB, free 265.2 MB)
15/08/11 10:18:32 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_5_piece0,StorageLevel(false, true, false, false, 1),3198,0,0) from Actor[akka://sparkDriver/temp/$~]
15/08/11 10:18:32 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 192.168.130.131:57830 (size: 3.1 KB, free: 265.4 MB)
15/08/11 10:18:32 INFO BlockManagerMaster: Updated info of block broadcast_5_piece0
15/08/11 10:18:32 DEBUG BlockManager: Told master about block broadcast_5_piece0
15/08/11 10:18:32 DEBUG BlockManagerMasterActor: [actor] handled message (0.921039 ms) UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_5_piece0,StorageLevel(false, true, false, false, 1),3198,0,0) from Actor[akka://sparkDriver/temp/$~]
15/08/11 10:18:32 DEBUG BlockManager: Put block broadcast_5_piece0 locally took  3 ms
15/08/11 10:18:32 DEBUG BlockManager: Putting block broadcast_5_piece0 without replication took  10 ms
15/08/11 10:18:32 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:852
15/08/11 10:18:32 INFO DAGScheduler: Submitting 3 missing tasks from Stage 4 (MapPartitionsRDD[7] at map at KMeansTest.scala:61)
15/08/11 10:18:32 DEBUG DAGScheduler: New pending tasks: Set(ShuffleMapTask(4, 1), ShuffleMapTask(4, 2), ShuffleMapTask(4, 0))
15/08/11 10:18:32 INFO TaskSchedulerImpl: Adding task set 4.0 with 3 tasks
15/08/11 10:18:32 DEBUG TaskSetManager: Epoch for TaskSet 4.0: 1
15/08/11 10:18:32 DEBUG TaskSetManager: Valid locality levels for TaskSet 4.0: PROCESS_LOCAL, NODE_LOCAL, ANY
15/08/11 10:18:32 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/deadLetters]
15/08/11 10:18:32 DEBUG DAGScheduler: submitStage(Stage 5)
15/08/11 10:18:32 DEBUG DAGScheduler: missing: List(Stage 4)
15/08/11 10:18:32 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_4, runningTasks: 0
15/08/11 10:18:32 DEBUG DAGScheduler: submitStage(Stage 4)
15/08/11 10:18:32 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 12, 192.168.130.131, PROCESS_LOCAL, 1361 bytes)
15/08/11 10:18:32 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 13, 192.168.130.131, PROCESS_LOCAL, 1361 bytes)
15/08/11 10:18:32 INFO TaskSetManager: Starting task 2.0 in stage 4.0 (TID 14, 192.168.130.131, PROCESS_LOCAL, 1361 bytes)
15/08/11 10:18:32 DEBUG TaskSetManager: No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
15/08/11 10:18:32 DEBUG TaskSetManager: No tasks for locality level NODE_LOCAL, so moving to locality level ANY
15/08/11 10:18:32 DEBUG DAGScheduler: submitStage(Stage 5)
15/08/11 10:18:32 DEBUG SparkDeploySchedulerBackend: [actor] handled message (18.942125 ms) ReviveOffers from Actor[akka://sparkDriver/deadLetters]
15/08/11 10:18:32 DEBUG DAGScheduler: missing: List(Stage 4)
15/08/11 10:18:32 DEBUG BlockManagerMasterActor: [actor] received message GetLocations(broadcast_5_piece0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$J]
15/08/11 10:18:32 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,12,RUNNING,org.apache.spark.util.SerializableBuffer@5b3a35a5) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:32 DEBUG BlockManagerMasterActor: [actor] handled message (0.183343 ms) GetLocations(broadcast_5_piece0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$J]
15/08/11 10:18:32 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.101003 ms) StatusUpdate(0,12,RUNNING,org.apache.spark.util.SerializableBuffer@5b3a35a5) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:32 DEBUG DAGScheduler: submitStage(Stage 4)
15/08/11 10:18:32 DEBUG DAGScheduler: submitStage(Stage 5)
15/08/11 10:18:32 DEBUG DAGScheduler: missing: List(Stage 4)
15/08/11 10:18:32 DEBUG DAGScheduler: submitStage(Stage 4)
15/08/11 10:18:32 DEBUG DAGScheduler: submitStage(Stage 5)
15/08/11 10:18:32 DEBUG DAGScheduler: missing: List(Stage 4)
15/08/11 10:18:32 DEBUG DAGScheduler: submitStage(Stage 4)
15/08/11 10:18:32 DEBUG BlockManager: Level for block broadcast_5_piece0 is StorageLevel(true, true, false, false, 1)
15/08/11 10:18:32 DEBUG BlockManager: Getting block broadcast_5_piece0 from memory
15/08/11 10:18:32 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,13,RUNNING,org.apache.spark.util.SerializableBuffer@39178c5c) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:32 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.072183 ms) StatusUpdate(0,13,RUNNING,org.apache.spark.util.SerializableBuffer@39178c5c) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:32 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,14,RUNNING,org.apache.spark.util.SerializableBuffer@3900094c) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:32 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.072626 ms) StatusUpdate(0,14,RUNNING,org.apache.spark.util.SerializableBuffer@3900094c) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:32 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_5_piece0,StorageLevel(false, true, false, false, 1),3198,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$K]
15/08/11 10:18:32 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 192.168.130.131:47921 (size: 3.1 KB, free: 245.7 MB)
15/08/11 10:18:32 DEBUG BlockManagerMasterActor: [actor] handled message (2.804099 ms) UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_5_piece0,StorageLevel(false, true, false, false, 1),3198,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$K]
15/08/11 10:18:32 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:32 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_4, runningTasks: 3
15/08/11 10:18:32 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.936031 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:33 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:33 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_4, runningTasks: 3
15/08/11 10:18:33 DEBUG SparkDeploySchedulerBackend: [actor] handled message (1.031914 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:34 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,14,FINISHED,org.apache.spark.util.SerializableBuffer@382b6004) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:34 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_4, runningTasks: 2
15/08/11 10:18:34 DEBUG SparkDeploySchedulerBackend: [actor] handled message (1.284319 ms) StatusUpdate(0,14,FINISHED,org.apache.spark.util.SerializableBuffer@382b6004) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:34 DEBUG DAGScheduler: ShuffleMapTask finished on 0
15/08/11 10:18:34 DEBUG DAGScheduler: submitStage(Stage 5)
15/08/11 10:18:34 DEBUG DAGScheduler: missing: List(Stage 4)
15/08/11 10:18:34 DEBUG DAGScheduler: submitStage(Stage 4)
15/08/11 10:18:34 INFO TaskSetManager: Finished task 2.0 in stage 4.0 (TID 14) in 1749 ms on 192.168.130.131 (1/3)
15/08/11 10:18:34 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:34 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_4, runningTasks: 2
15/08/11 10:18:34 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.895068 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:35 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:35 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_4, runningTasks: 2
15/08/11 10:18:35 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.783197 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:35 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,13,FINISHED,org.apache.spark.util.SerializableBuffer@27acc36b) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:35 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_4, runningTasks: 1
15/08/11 10:18:35 DEBUG SparkDeploySchedulerBackend: [actor] handled message (1.010203 ms) StatusUpdate(0,13,FINISHED,org.apache.spark.util.SerializableBuffer@27acc36b) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:35 DEBUG DAGScheduler: ShuffleMapTask finished on 0
15/08/11 10:18:35 DEBUG DAGScheduler: submitStage(Stage 5)
15/08/11 10:18:35 DEBUG DAGScheduler: missing: List(Stage 4)
15/08/11 10:18:35 DEBUG DAGScheduler: submitStage(Stage 4)
15/08/11 10:18:35 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 13) in 3607 ms on 192.168.130.131 (2/3)
15/08/11 10:18:36 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,12,FINISHED,org.apache.spark.util.SerializableBuffer@3f51ba26) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:36 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_4, runningTasks: 0
15/08/11 10:18:36 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.990593 ms) StatusUpdate(0,12,FINISHED,org.apache.spark.util.SerializableBuffer@3f51ba26) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:36 DEBUG DAGScheduler: ShuffleMapTask finished on 0
15/08/11 10:18:36 INFO DAGScheduler: Stage 4 (map at KMeansTest.scala:61) finished in 3.791 s
15/08/11 10:18:36 INFO DAGScheduler: looking for newly runnable stages
15/08/11 10:18:36 INFO DAGScheduler: running: Set()
15/08/11 10:18:36 INFO DAGScheduler: waiting: Set(Stage 5)
15/08/11 10:18:36 INFO DAGScheduler: failed: Set()
15/08/11 10:18:36 DEBUG MapOutputTrackerMaster: Increasing epoch to 2
15/08/11 10:18:36 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD MapPartitionsRDD[9] at map at KMeansTest.scala:65
15/08/11 10:18:36 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@e943544) from Actor[akka://sparkDriver/temp/$ab]
15/08/11 10:18:36 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 12) in 3743 ms on 192.168.130.131 (3/3)
15/08/11 10:18:36 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: [actor] handled message (0.301653 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@e943544) from Actor[akka://sparkDriver/temp/$ab]
15/08/11 10:18:36 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@e943544) from Actor[akka://sparkDriver/temp/$bb]
15/08/11 10:18:36 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: [actor] handled message (0.263905 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@e943544) from Actor[akka://sparkDriver/temp/$bb]
15/08/11 10:18:36 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:18:36 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|9|0,rdd_9_0,, null|9|1,rdd_9_1,, null|9|2,rdd_9_2,).
15/08/11 10:18:36 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$db]
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:18:36 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: [actor] handled message (1.495876 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$db]
15/08/11 10:18:36 DEBUG BlockManager: Got multiple block location in  17 ms
15/08/11 10:18:36 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD ShuffledRDD[8] at reduceByKey at KMeansTest.scala:63
15/08/11 10:18:36 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@7034317d) from Actor[akka://sparkDriver/temp/$eb]
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: [actor] handled message (0.401693 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@7034317d) from Actor[akka://sparkDriver/temp/$eb]
15/08/11 10:18:36 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@7034317d) from Actor[akka://sparkDriver/temp/$fb]
15/08/11 10:18:36 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: [actor] handled message (0.317804 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@7034317d) from Actor[akka://sparkDriver/temp/$fb]
15/08/11 10:18:36 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:18:36 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|8|0,rdd_8_0,, null|8|1,rdd_8_1,, null|8|2,rdd_8_2,).
15/08/11 10:18:36 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$hb]
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: [actor] handled message (1.494297 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$hb]
15/08/11 10:18:36 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:18:36 DEBUG BlockManager: Got multiple block location in  17 ms
15/08/11 10:18:36 INFO DAGScheduler: Missing parents for Stage 5: List()
15/08/11 10:18:36 INFO DAGScheduler: Submitting Stage 5 (MapPartitionsRDD[9] at map at KMeansTest.scala:65), which is now runnable
15/08/11 10:18:36 DEBUG DAGScheduler: submitMissingTasks(Stage 5)
15/08/11 10:18:36 INFO MemoryStore: ensureFreeSpace(2560) called with curMem=198798, maxMem=278302556
15/08/11 10:18:36 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 2.5 KB, free 265.2 MB)
15/08/11 10:18:36 DEBUG BlockManager: Put block broadcast_6 locally took  2 ms
15/08/11 10:18:36 DEBUG BlockManager: Putting block broadcast_6 without replication took  2 ms
15/08/11 10:18:36 INFO MemoryStore: ensureFreeSpace(1520) called with curMem=201358, maxMem=278302556
15/08/11 10:18:36 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 1520.0 B, free 265.2 MB)
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_6_piece0,StorageLevel(false, true, false, false, 1),1520,0,0) from Actor[akka://sparkDriver/temp/$ib]
15/08/11 10:18:36 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 192.168.130.131:57830 (size: 1520.0 B, free: 265.4 MB)
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: [actor] handled message (0.982497 ms) UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_6_piece0,StorageLevel(false, true, false, false, 1),1520,0,0) from Actor[akka://sparkDriver/temp/$ib]
15/08/11 10:18:36 INFO BlockManagerMaster: Updated info of block broadcast_6_piece0
15/08/11 10:18:36 DEBUG BlockManager: Told master about block broadcast_6_piece0
15/08/11 10:18:36 DEBUG BlockManager: Put block broadcast_6_piece0 locally took  5 ms
15/08/11 10:18:36 DEBUG BlockManager: Putting block broadcast_6_piece0 without replication took  5 ms
15/08/11 10:18:36 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:852
15/08/11 10:18:36 INFO DAGScheduler: Submitting 3 missing tasks from Stage 5 (MapPartitionsRDD[9] at map at KMeansTest.scala:65)
15/08/11 10:18:36 DEBUG DAGScheduler: New pending tasks: Set(ResultTask(5, 1), ResultTask(5, 2), ResultTask(5, 0))
15/08/11 10:18:36 INFO TaskSchedulerImpl: Adding task set 5.0 with 3 tasks
15/08/11 10:18:36 DEBUG TaskSetManager: Epoch for TaskSet 5.0: 2
15/08/11 10:18:36 DEBUG TaskSetManager: Valid locality levels for TaskSet 5.0: NO_PREF, ANY
15/08/11 10:18:36 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/deadLetters]
15/08/11 10:18:36 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5, runningTasks: 0
15/08/11 10:18:36 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 15, 192.168.130.131, PROCESS_LOCAL, 1116 bytes)
15/08/11 10:18:36 INFO TaskSetManager: Starting task 1.0 in stage 5.0 (TID 16, 192.168.130.131, PROCESS_LOCAL, 1116 bytes)
15/08/11 10:18:36 INFO TaskSetManager: Starting task 2.0 in stage 5.0 (TID 17, 192.168.130.131, PROCESS_LOCAL, 1116 bytes)
15/08/11 10:18:36 DEBUG TaskSetManager: No tasks for locality level NO_PREF, so moving to locality level ANY
15/08/11 10:18:36 DEBUG SparkDeploySchedulerBackend: [actor] handled message (3.862468 ms) ReviveOffers from Actor[akka://sparkDriver/deadLetters]
15/08/11 10:18:36 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,16,RUNNING,org.apache.spark.util.SerializableBuffer@33e44042) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:36 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.091 ms) StatusUpdate(0,16,RUNNING,org.apache.spark.util.SerializableBuffer@33e44042) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:36 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,15,RUNNING,org.apache.spark.util.SerializableBuffer@4e36c7ab) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:36 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.073192 ms) StatusUpdate(0,15,RUNNING,org.apache.spark.util.SerializableBuffer@4e36c7ab) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:36 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,17,RUNNING,org.apache.spark.util.SerializableBuffer@6e6ed3aa) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:36 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.050305 ms) StatusUpdate(0,17,RUNNING,org.apache.spark.util.SerializableBuffer@6e6ed3aa) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: [actor] received message GetLocations(broadcast_6_piece0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$L]
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: [actor] handled message (0.166974 ms) GetLocations(broadcast_6_piece0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$L]
15/08/11 10:18:36 DEBUG BlockManager: Level for block broadcast_6_piece0 is StorageLevel(true, true, false, false, 1)
15/08/11 10:18:36 DEBUG BlockManager: Getting block broadcast_6_piece0 from memory
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_6_piece0,StorageLevel(false, true, false, false, 1),1520,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$M]
15/08/11 10:18:36 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 192.168.130.131:47921 (size: 1520.0 B, free: 245.7 MB)
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: [actor] handled message (7.233576 ms) UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_6_piece0,StorageLevel(false, true, false, false, 1),1520,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$M]
15/08/11 10:18:36 DEBUG MapOutputTrackerMasterActor: [actor] received message GetMapOutputStatuses(1) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$N]
15/08/11 10:18:36 INFO MapOutputTrackerMasterActor: Asked to send map output locations for shuffle 1 to sparkExecutor@192.168.130.131:49489
15/08/11 10:18:36 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 162 bytes
15/08/11 10:18:36 DEBUG MapOutputTrackerMasterActor: [actor] handled message (11.292661 ms) GetMapOutputStatuses(1) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$N]
15/08/11 10:18:36 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,17,FINISHED,org.apache.spark.util.SerializableBuffer@78c4dc9f) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:36 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5, runningTasks: 2
15/08/11 10:18:36 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.902891 ms) StatusUpdate(0,17,FINISHED,org.apache.spark.util.SerializableBuffer@78c4dc9f) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:36 INFO TaskSetManager: Finished task 2.0 in stage 5.0 (TID 17) in 160 ms on 192.168.130.131 (1/3)
15/08/11 10:18:36 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,15,FINISHED,org.apache.spark.util.SerializableBuffer@44742f73) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:36 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5, runningTasks: 1
15/08/11 10:18:36 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.92661 ms) StatusUpdate(0,15,FINISHED,org.apache.spark.util.SerializableBuffer@44742f73) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:36 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,16,FINISHED,org.apache.spark.util.SerializableBuffer@27d74a21) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:36 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_5, runningTasks: 0
15/08/11 10:18:36 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.472118 ms) StatusUpdate(0,16,FINISHED,org.apache.spark.util.SerializableBuffer@27d74a21) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:36 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 15) in 204 ms on 192.168.130.131 (2/3)
15/08/11 10:18:36 INFO DAGScheduler: Stage 5 (collectAsMap at KMeansTest.scala:67) finished in 0.220 s
15/08/11 10:18:36 DEBUG DAGScheduler: After removal of stage 5, remaining stages = 1
15/08/11 10:18:36 INFO TaskSetManager: Finished task 1.0 in stage 5.0 (TID 16) in 213 ms on 192.168.130.131 (3/3)
15/08/11 10:18:36 DEBUG DAGScheduler: After removal of stage 4, remaining stages = 0
15/08/11 10:18:36 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
15/08/11 10:18:36 INFO DAGScheduler: Job 3 finished: collectAsMap at KMeansTest.scala:67, took 4.215562 s
Finished iteration (num = 1)
15/08/11 10:18:36 INFO SparkContext: Starting job: collectAsMap at KMeansTest.scala:67
15/08/11 10:18:36 INFO DAGScheduler: Registering RDD 10 (map at KMeansTest.scala:61)
15/08/11 10:18:36 INFO DAGScheduler: Got job 4 (collectAsMap at KMeansTest.scala:67) with 3 output partitions (allowLocal=false)
15/08/11 10:18:36 INFO DAGScheduler: Final stage: Stage 7(collectAsMap at KMeansTest.scala:67)
15/08/11 10:18:36 INFO DAGScheduler: Parents of final stage: List(Stage 6)
15/08/11 10:18:36 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD MapPartitionsRDD[12] at map at KMeansTest.scala:65
15/08/11 10:18:36 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@735ca68) from Actor[akka://sparkDriver/temp/$jb]
15/08/11 10:18:36 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: [actor] handled message (0.371562 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@735ca68) from Actor[akka://sparkDriver/temp/$jb]
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@735ca68) from Actor[akka://sparkDriver/temp/$kb]
15/08/11 10:18:36 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: [actor] handled message (0.219838 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@735ca68) from Actor[akka://sparkDriver/temp/$kb]
15/08/11 10:18:36 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:18:36 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|12|0,rdd_12_0,, null|12|1,rdd_12_1,, null|12|2,rdd_12_2,).
15/08/11 10:18:36 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$mb]
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: [actor] handled message (2.006995 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$mb]
15/08/11 10:18:36 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:18:36 DEBUG BlockManager: Got multiple block location in  17 ms
15/08/11 10:18:36 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD ShuffledRDD[11] at reduceByKey at KMeansTest.scala:63
15/08/11 10:18:36 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@5e6b5067) from Actor[akka://sparkDriver/temp/$nb]
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: [actor] handled message (0.261442 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@5e6b5067) from Actor[akka://sparkDriver/temp/$nb]
15/08/11 10:18:36 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@5e6b5067) from Actor[akka://sparkDriver/temp/$ob]
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: [actor] handled message (0.253412 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@5e6b5067) from Actor[akka://sparkDriver/temp/$ob]
15/08/11 10:18:36 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:18:36 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:18:36 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|11|0,rdd_11_0,, null|11|1,rdd_11_1,, null|11|2,rdd_11_2,).
15/08/11 10:18:36 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$qb]
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:18:36 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:18:36 DEBUG BlockManager: Got multiple block location in  26 ms
15/08/11 10:18:36 INFO DAGScheduler: [SMSpark v1]Missing parents: List(Stage 6)
15/08/11 10:18:36 DEBUG DAGScheduler: submitStage(Stage 7)
15/08/11 10:18:36 DEBUG DAGScheduler: missing: List(Stage 6)
15/08/11 10:18:36 DEBUG DAGScheduler: submitStage(Stage 6)
15/08/11 10:18:36 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD MapPartitionsRDD[10] at map at KMeansTest.scala:61
15/08/11 10:18:36 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: [actor] handled message (10.039066 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$qb]
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@592bc0f0) from Actor[akka://sparkDriver/temp/$rb]
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: [actor] handled message (0.213549 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@592bc0f0) from Actor[akka://sparkDriver/temp/$rb]
15/08/11 10:18:36 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@592bc0f0) from Actor[akka://sparkDriver/temp/$sb]
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: [actor] handled message (0.208751 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@592bc0f0) from Actor[akka://sparkDriver/temp/$sb]
15/08/11 10:18:36 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:18:36 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:18:36 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|10|0,rdd_10_0,, null|10|1,rdd_10_1,, null|10|2,rdd_10_2,).
15/08/11 10:18:36 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$ub]
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:18:36 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:18:36 DEBUG BlockManager: Got multiple block location in  23 ms
15/08/11 10:18:36 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD KMeans01 MapPartitionsRDD[2] at map at KMeansTest.scala:50
15/08/11 10:18:36 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: [actor] handled message (5.637971 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$ub]
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@5f506b96) from Actor[akka://sparkDriver/temp/$vb]
15/08/11 10:18:36 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(ArrayBuffer(BlockManagerId(0, 192.168.130.131, 47921)), ArrayBuffer(BlockManagerId(0, 192.168.130.131, 47921)), ArrayBuffer(BlockManagerId(0, 192.168.130.131, 47921)))
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: [actor] handled message (2.787892 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@5f506b96) from Actor[akka://sparkDriver/temp/$vb]
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@5f506b96) from Actor[akka://sparkDriver/temp/$wb]
15/08/11 10:18:36 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:18:36 DEBUG DAGScheduler: missing: List()
15/08/11 10:18:36 INFO DAGScheduler: Submitting Stage 6 (MapPartitionsRDD[10] at map at KMeansTest.scala:61), which has no missing parents
15/08/11 10:18:36 DEBUG DAGScheduler: submitMissingTasks(Stage 6)
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: [actor] handled message (4.246624 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@5f506b96) from Actor[akka://sparkDriver/temp/$wb]
15/08/11 10:18:36 INFO MemoryStore: ensureFreeSpace(4768) called with curMem=202878, maxMem=278302556
15/08/11 10:18:36 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 4.7 KB, free 265.2 MB)
15/08/11 10:18:36 DEBUG BlockManager: Put block broadcast_7 locally took  2 ms
15/08/11 10:18:36 DEBUG BlockManager: Putting block broadcast_7 without replication took  2 ms
15/08/11 10:18:36 INFO MemoryStore: ensureFreeSpace(3205) called with curMem=207646, maxMem=278302556
15/08/11 10:18:36 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 3.1 KB, free 265.2 MB)
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_7_piece0,StorageLevel(false, true, false, false, 1),3205,0,0) from Actor[akka://sparkDriver/temp/$xb]
15/08/11 10:18:36 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 192.168.130.131:57830 (size: 3.1 KB, free: 265.4 MB)
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: [actor] handled message (0.640911 ms) UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_7_piece0,StorageLevel(false, true, false, false, 1),3205,0,0) from Actor[akka://sparkDriver/temp/$xb]
15/08/11 10:18:36 INFO BlockManagerMaster: Updated info of block broadcast_7_piece0
15/08/11 10:18:36 DEBUG BlockManager: Told master about block broadcast_7_piece0
15/08/11 10:18:36 DEBUG BlockManager: Put block broadcast_7_piece0 locally took  3 ms
15/08/11 10:18:36 DEBUG BlockManager: Putting block broadcast_7_piece0 without replication took  4 ms
15/08/11 10:18:36 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:852
15/08/11 10:18:36 INFO DAGScheduler: Submitting 3 missing tasks from Stage 6 (MapPartitionsRDD[10] at map at KMeansTest.scala:61)
15/08/11 10:18:36 DEBUG DAGScheduler: New pending tasks: Set(ShuffleMapTask(6, 0), ShuffleMapTask(6, 1), ShuffleMapTask(6, 2))
15/08/11 10:18:36 INFO TaskSchedulerImpl: Adding task set 6.0 with 3 tasks
15/08/11 10:18:36 DEBUG TaskSetManager: Epoch for TaskSet 6.0: 2
15/08/11 10:18:36 DEBUG TaskSetManager: Valid locality levels for TaskSet 6.0: PROCESS_LOCAL, NODE_LOCAL, ANY
15/08/11 10:18:36 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/deadLetters]
15/08/11 10:18:36 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_6, runningTasks: 0
15/08/11 10:18:36 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 18, 192.168.130.131, PROCESS_LOCAL, 1361 bytes)
15/08/11 10:18:36 DEBUG DAGScheduler: submitStage(Stage 7)
15/08/11 10:18:36 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 19, 192.168.130.131, PROCESS_LOCAL, 1361 bytes)
15/08/11 10:18:36 DEBUG DAGScheduler: missing: List(Stage 6)
15/08/11 10:18:36 DEBUG DAGScheduler: submitStage(Stage 6)
15/08/11 10:18:36 DEBUG DAGScheduler: submitStage(Stage 7)
15/08/11 10:18:36 DEBUG DAGScheduler: missing: List(Stage 6)
15/08/11 10:18:36 DEBUG DAGScheduler: submitStage(Stage 6)
15/08/11 10:18:36 DEBUG DAGScheduler: submitStage(Stage 7)
15/08/11 10:18:36 DEBUG DAGScheduler: missing: List(Stage 6)
15/08/11 10:18:36 DEBUG DAGScheduler: submitStage(Stage 6)
15/08/11 10:18:36 INFO TaskSetManager: Starting task 2.0 in stage 6.0 (TID 20, 192.168.130.131, PROCESS_LOCAL, 1361 bytes)
15/08/11 10:18:36 DEBUG TaskSetManager: No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
15/08/11 10:18:36 DEBUG TaskSetManager: No tasks for locality level NODE_LOCAL, so moving to locality level ANY
15/08/11 10:18:36 DEBUG DAGScheduler: submitStage(Stage 7)
15/08/11 10:18:36 DEBUG DAGScheduler: missing: List(Stage 6)
15/08/11 10:18:36 DEBUG DAGScheduler: submitStage(Stage 6)
15/08/11 10:18:36 DEBUG SparkDeploySchedulerBackend: [actor] handled message (17.569492 ms) ReviveOffers from Actor[akka://sparkDriver/deadLetters]
15/08/11 10:18:36 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,18,RUNNING,org.apache.spark.util.SerializableBuffer@25ca1a0c) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:36 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.278735 ms) StatusUpdate(0,18,RUNNING,org.apache.spark.util.SerializableBuffer@25ca1a0c) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:36 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,19,RUNNING,org.apache.spark.util.SerializableBuffer@77741d35) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:36 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.146987 ms) StatusUpdate(0,19,RUNNING,org.apache.spark.util.SerializableBuffer@77741d35) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: [actor] received message GetLocations(broadcast_7_piece0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$O]
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: [actor] handled message (0.160306 ms) GetLocations(broadcast_7_piece0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$O]
15/08/11 10:18:36 DEBUG BlockManager: Level for block broadcast_7_piece0 is StorageLevel(true, true, false, false, 1)
15/08/11 10:18:36 DEBUG BlockManager: Getting block broadcast_7_piece0 from memory
15/08/11 10:18:36 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,20,RUNNING,org.apache.spark.util.SerializableBuffer@48fbbf69) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:36 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.636068 ms) StatusUpdate(0,20,RUNNING,org.apache.spark.util.SerializableBuffer@48fbbf69) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_7_piece0,StorageLevel(false, true, false, false, 1),3205,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$P]
15/08/11 10:18:36 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 192.168.130.131:47921 (size: 3.1 KB, free: 245.7 MB)
15/08/11 10:18:36 DEBUG BlockManagerMasterActor: [actor] handled message (0.761503 ms) UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_7_piece0,StorageLevel(false, true, false, false, 1),3205,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$P]
15/08/11 10:18:36 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:36 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_6, runningTasks: 3
15/08/11 10:18:36 DEBUG SparkDeploySchedulerBackend: [actor] handled message (3.113747 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:37 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:37 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_6, runningTasks: 3
15/08/11 10:18:37 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.54506 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:38 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,20,FINISHED,org.apache.spark.util.SerializableBuffer@59bc9a45) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:38 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_6, runningTasks: 2
15/08/11 10:18:38 DEBUG SparkDeploySchedulerBackend: [actor] handled message (2.678809 ms) StatusUpdate(0,20,FINISHED,org.apache.spark.util.SerializableBuffer@59bc9a45) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:38 DEBUG DAGScheduler: ShuffleMapTask finished on 0
15/08/11 10:18:38 DEBUG DAGScheduler: submitStage(Stage 7)
15/08/11 10:18:38 DEBUG DAGScheduler: missing: List(Stage 6)
15/08/11 10:18:38 DEBUG DAGScheduler: submitStage(Stage 6)
15/08/11 10:18:38 INFO TaskSetManager: Finished task 2.0 in stage 6.0 (TID 20) in 1503 ms on 192.168.130.131 (1/3)
15/08/11 10:18:38 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:38 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_6, runningTasks: 2
15/08/11 10:18:38 DEBUG SparkDeploySchedulerBackend: [actor] handled message (18.303629 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:39 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:39 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_6, runningTasks: 2
15/08/11 10:18:39 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.800251 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:39 DEBUG HeartbeatReceiver: [actor] received message Heartbeat(0,[Lscala.Tuple2;@6fca0e2,BlockManagerId(0, 192.168.130.131, 47921)) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$Q]
15/08/11 10:18:39 DEBUG BlockManagerMasterActor: [actor] received message BlockManagerHeartbeat(BlockManagerId(0, 192.168.130.131, 47921)) from Actor[akka://sparkDriver/temp/$yb]
15/08/11 10:18:39 DEBUG BlockManagerMasterActor: [actor] handled message (0.181338 ms) BlockManagerHeartbeat(BlockManagerId(0, 192.168.130.131, 47921)) from Actor[akka://sparkDriver/temp/$yb]
15/08/11 10:18:39 DEBUG HeartbeatReceiver: [actor] handled message (1.148935 ms) Heartbeat(0,[Lscala.Tuple2;@6fca0e2,BlockManagerId(0, 192.168.130.131, 47921)) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$Q]
15/08/11 10:18:40 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,19,FINISHED,org.apache.spark.util.SerializableBuffer@6e1dee72) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:40 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_6, runningTasks: 1
15/08/11 10:18:40 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.973909 ms) StatusUpdate(0,19,FINISHED,org.apache.spark.util.SerializableBuffer@6e1dee72) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:40 DEBUG DAGScheduler: ShuffleMapTask finished on 0
15/08/11 10:18:40 DEBUG DAGScheduler: submitStage(Stage 7)
15/08/11 10:18:40 DEBUG DAGScheduler: missing: List(Stage 6)
15/08/11 10:18:40 DEBUG DAGScheduler: submitStage(Stage 6)
15/08/11 10:18:40 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 19) in 4078 ms on 192.168.130.131 (2/3)
15/08/11 10:18:40 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,18,FINISHED,org.apache.spark.util.SerializableBuffer@6f11b6d8) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:40 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_6, runningTasks: 0
15/08/11 10:18:40 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.887278 ms) StatusUpdate(0,18,FINISHED,org.apache.spark.util.SerializableBuffer@6f11b6d8) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:40 DEBUG DAGScheduler: ShuffleMapTask finished on 0
15/08/11 10:18:40 INFO DAGScheduler: Stage 6 (map at KMeansTest.scala:61) finished in 4.139 s
15/08/11 10:18:40 INFO DAGScheduler: looking for newly runnable stages
15/08/11 10:18:40 INFO DAGScheduler: running: Set()
15/08/11 10:18:40 INFO DAGScheduler: waiting: Set(Stage 7)
15/08/11 10:18:40 INFO DAGScheduler: failed: Set()
15/08/11 10:18:40 DEBUG MapOutputTrackerMaster: Increasing epoch to 3
15/08/11 10:18:40 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD MapPartitionsRDD[12] at map at KMeansTest.scala:65
15/08/11 10:18:40 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:18:40 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@73fb57df) from Actor[akka://sparkDriver/temp/$zb]
15/08/11 10:18:40 DEBUG BlockManagerMasterActor: [actor] handled message (0.150534 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@73fb57df) from Actor[akka://sparkDriver/temp/$zb]
15/08/11 10:18:40 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:18:40 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@73fb57df) from Actor[akka://sparkDriver/temp/$Ab]
15/08/11 10:18:40 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 18) in 4126 ms on 192.168.130.131 (3/3)
15/08/11 10:18:40 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
15/08/11 10:18:40 DEBUG BlockManagerMasterActor: [actor] handled message (0.150278 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@73fb57df) from Actor[akka://sparkDriver/temp/$Ab]
15/08/11 10:18:40 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:18:40 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:18:40 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|12|0,rdd_12_0,, null|12|1,rdd_12_1,, null|12|2,rdd_12_2,).
15/08/11 10:18:40 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:18:40 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$Cb]
15/08/11 10:18:40 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:18:40 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:40 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:40 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:40 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:40 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:40 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:40 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:40 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:40 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:40 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:18:40 DEBUG BlockManagerMasterActor: [actor] handled message (1.300607 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$Cb]
15/08/11 10:18:40 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:18:40 DEBUG BlockManager: Got multiple block location in  12 ms
15/08/11 10:18:40 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD ShuffledRDD[11] at reduceByKey at KMeansTest.scala:63
15/08/11 10:18:40 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:18:40 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@354e9c82) from Actor[akka://sparkDriver/temp/$Db]
15/08/11 10:18:40 DEBUG BlockManagerMasterActor: [actor] handled message (0.122036 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@354e9c82) from Actor[akka://sparkDriver/temp/$Db]
15/08/11 10:18:40 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:18:40 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@354e9c82) from Actor[akka://sparkDriver/temp/$Eb]
15/08/11 10:18:40 DEBUG BlockManagerMasterActor: [actor] handled message (0.111703 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@354e9c82) from Actor[akka://sparkDriver/temp/$Eb]
15/08/11 10:18:40 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:18:40 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:18:40 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|11|0,rdd_11_0,, null|11|1,rdd_11_1,, null|11|2,rdd_11_2,).
15/08/11 10:18:40 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:18:40 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$Gb]
15/08/11 10:18:40 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:18:40 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:40 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:40 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:40 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:40 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:40 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:40 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:40 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:40 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:40 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:18:40 DEBUG BlockManagerMasterActor: [actor] handled message (1.171049 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$Gb]
15/08/11 10:18:40 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:18:40 DEBUG BlockManager: Got multiple block location in  13 ms
15/08/11 10:18:40 INFO DAGScheduler: Missing parents for Stage 7: List()
15/08/11 10:18:40 INFO DAGScheduler: Submitting Stage 7 (MapPartitionsRDD[12] at map at KMeansTest.scala:65), which is now runnable
15/08/11 10:18:40 DEBUG DAGScheduler: submitMissingTasks(Stage 7)
15/08/11 10:18:40 INFO MemoryStore: ensureFreeSpace(2560) called with curMem=210851, maxMem=278302556
15/08/11 10:18:40 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 2.5 KB, free 265.2 MB)
15/08/11 10:18:40 DEBUG BlockManager: Put block broadcast_8 locally took  2 ms
15/08/11 10:18:40 DEBUG BlockManager: Putting block broadcast_8 without replication took  2 ms
15/08/11 10:18:40 INFO MemoryStore: ensureFreeSpace(1521) called with curMem=213411, maxMem=278302556
15/08/11 10:18:40 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 1521.0 B, free 265.2 MB)
15/08/11 10:18:40 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_8_piece0,StorageLevel(false, true, false, false, 1),1521,0,0) from Actor[akka://sparkDriver/temp/$Hb]
15/08/11 10:18:40 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 192.168.130.131:57830 (size: 1521.0 B, free: 265.4 MB)
15/08/11 10:18:40 DEBUG BlockManagerMasterActor: [actor] handled message (0.770684 ms) UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_8_piece0,StorageLevel(false, true, false, false, 1),1521,0,0) from Actor[akka://sparkDriver/temp/$Hb]
15/08/11 10:18:40 INFO BlockManagerMaster: Updated info of block broadcast_8_piece0
15/08/11 10:18:40 DEBUG BlockManager: Told master about block broadcast_8_piece0
15/08/11 10:18:40 DEBUG BlockManager: Put block broadcast_8_piece0 locally took  3 ms
15/08/11 10:18:40 DEBUG BlockManager: Putting block broadcast_8_piece0 without replication took  3 ms
15/08/11 10:18:40 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:852
15/08/11 10:18:40 INFO DAGScheduler: Submitting 3 missing tasks from Stage 7 (MapPartitionsRDD[12] at map at KMeansTest.scala:65)
15/08/11 10:18:40 DEBUG DAGScheduler: New pending tasks: Set(ResultTask(7, 2), ResultTask(7, 0), ResultTask(7, 1))
15/08/11 10:18:40 INFO TaskSchedulerImpl: Adding task set 7.0 with 3 tasks
15/08/11 10:18:40 DEBUG TaskSetManager: Epoch for TaskSet 7.0: 3
15/08/11 10:18:40 DEBUG TaskSetManager: Valid locality levels for TaskSet 7.0: NO_PREF, ANY
15/08/11 10:18:40 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/deadLetters]
15/08/11 10:18:40 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7, runningTasks: 0
15/08/11 10:18:40 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 21, 192.168.130.131, PROCESS_LOCAL, 1116 bytes)
15/08/11 10:18:40 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 22, 192.168.130.131, PROCESS_LOCAL, 1116 bytes)
15/08/11 10:18:40 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 23, 192.168.130.131, PROCESS_LOCAL, 1116 bytes)
15/08/11 10:18:40 DEBUG TaskSetManager: No tasks for locality level NO_PREF, so moving to locality level ANY
15/08/11 10:18:40 DEBUG SparkDeploySchedulerBackend: [actor] handled message (14.046098 ms) ReviveOffers from Actor[akka://sparkDriver/deadLetters]
15/08/11 10:18:40 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,21,RUNNING,org.apache.spark.util.SerializableBuffer@983c533) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:40 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.056951 ms) StatusUpdate(0,21,RUNNING,org.apache.spark.util.SerializableBuffer@983c533) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:40 DEBUG BlockManagerMasterActor: [actor] received message GetLocations(broadcast_8_piece0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$R]
15/08/11 10:18:40 DEBUG BlockManagerMasterActor: [actor] handled message (0.34921 ms) GetLocations(broadcast_8_piece0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$R]
15/08/11 10:18:40 DEBUG BlockManager: Level for block broadcast_8_piece0 is StorageLevel(true, true, false, false, 1)
15/08/11 10:18:40 DEBUG BlockManager: Getting block broadcast_8_piece0 from memory
15/08/11 10:18:40 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,22,RUNNING,org.apache.spark.util.SerializableBuffer@5a26d36b) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:40 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.237833 ms) StatusUpdate(0,22,RUNNING,org.apache.spark.util.SerializableBuffer@5a26d36b) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:40 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,23,RUNNING,org.apache.spark.util.SerializableBuffer@2b02440a) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:40 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.066973 ms) StatusUpdate(0,23,RUNNING,org.apache.spark.util.SerializableBuffer@2b02440a) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:40 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_8_piece0,StorageLevel(false, true, false, false, 1),1521,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$S]
15/08/11 10:18:40 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 192.168.130.131:47921 (size: 1521.0 B, free: 245.7 MB)
15/08/11 10:18:40 DEBUG BlockManagerMasterActor: [actor] handled message (0.718153 ms) UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_8_piece0,StorageLevel(false, true, false, false, 1),1521,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$S]
15/08/11 10:18:40 DEBUG MapOutputTrackerMasterActor: [actor] received message GetMapOutputStatuses(2) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$T]
15/08/11 10:18:40 INFO MapOutputTrackerMasterActor: Asked to send map output locations for shuffle 2 to sparkExecutor@192.168.130.131:49489
15/08/11 10:18:40 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 162 bytes
15/08/11 10:18:40 DEBUG MapOutputTrackerMasterActor: [actor] handled message (0.694679 ms) GetMapOutputStatuses(2) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$T]
15/08/11 10:18:40 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:40 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7, runningTasks: 3
15/08/11 10:18:40 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.717824 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:40 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,23,FINISHED,org.apache.spark.util.SerializableBuffer@415c7850) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:40 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7, runningTasks: 2
15/08/11 10:18:40 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.874539 ms) StatusUpdate(0,23,FINISHED,org.apache.spark.util.SerializableBuffer@415c7850) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:40 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,21,FINISHED,org.apache.spark.util.SerializableBuffer@1ddeedb6) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:40 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 23) in 131 ms on 192.168.130.131 (1/3)
15/08/11 10:18:40 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7, runningTasks: 1
15/08/11 10:18:40 DEBUG SparkDeploySchedulerBackend: [actor] handled message (7.849551 ms) StatusUpdate(0,21,FINISHED,org.apache.spark.util.SerializableBuffer@1ddeedb6) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:40 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,22,FINISHED,org.apache.spark.util.SerializableBuffer@5d59d69c) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:40 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_7, runningTasks: 0
15/08/11 10:18:40 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.774823 ms) StatusUpdate(0,22,FINISHED,org.apache.spark.util.SerializableBuffer@5d59d69c) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:40 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 22) in 155 ms on 192.168.130.131 (2/3)
15/08/11 10:18:40 INFO DAGScheduler: Stage 7 (collectAsMap at KMeansTest.scala:67) finished in 0.191 s
15/08/11 10:18:40 DEBUG DAGScheduler: After removal of stage 7, remaining stages = 1
15/08/11 10:18:40 DEBUG DAGScheduler: After removal of stage 6, remaining stages = 0
15/08/11 10:18:40 INFO DAGScheduler: Job 4 finished: collectAsMap at KMeansTest.scala:67, took 4.517529 s
Finished iteration (num = 2)
15/08/11 10:18:40 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 21) in 187 ms on 192.168.130.131 (3/3)
15/08/11 10:18:40 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
15/08/11 10:18:41 INFO SparkContext: Starting job: collectAsMap at KMeansTest.scala:67
15/08/11 10:18:41 INFO DAGScheduler: Registering RDD 13 (map at KMeansTest.scala:61)
15/08/11 10:18:41 INFO DAGScheduler: Got job 5 (collectAsMap at KMeansTest.scala:67) with 3 output partitions (allowLocal=false)
15/08/11 10:18:41 INFO DAGScheduler: Final stage: Stage 9(collectAsMap at KMeansTest.scala:67)
15/08/11 10:18:41 INFO DAGScheduler: Parents of final stage: List(Stage 8)
15/08/11 10:18:41 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD MapPartitionsRDD[15] at map at KMeansTest.scala:65
15/08/11 10:18:41 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:18:41 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@4aa0f695) from Actor[akka://sparkDriver/temp/$Ib]
15/08/11 10:18:41 DEBUG BlockManagerMasterActor: [actor] handled message (0.152439 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@4aa0f695) from Actor[akka://sparkDriver/temp/$Ib]
15/08/11 10:18:41 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:18:41 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@4aa0f695) from Actor[akka://sparkDriver/temp/$Jb]
15/08/11 10:18:41 DEBUG BlockManagerMasterActor: [actor] handled message (0.114342 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@4aa0f695) from Actor[akka://sparkDriver/temp/$Jb]
15/08/11 10:18:41 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:18:41 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:18:41 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|15|0,rdd_15_0,, null|15|1,rdd_15_1,, null|15|2,rdd_15_2,).
15/08/11 10:18:41 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:18:41 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$Lb]
15/08/11 10:18:41 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:18:41 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:41 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:41 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:41 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:41 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:41 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:41 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:41 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:41 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:41 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:18:41 DEBUG BlockManagerMasterActor: [actor] handled message (1.042533 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$Lb]
15/08/11 10:18:41 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:18:41 DEBUG BlockManager: Got multiple block location in  15 ms
15/08/11 10:18:41 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD ShuffledRDD[14] at reduceByKey at KMeansTest.scala:63
15/08/11 10:18:41 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:18:41 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@22c39ba) from Actor[akka://sparkDriver/temp/$Mb]
15/08/11 10:18:41 DEBUG BlockManagerMasterActor: [actor] handled message (0.216596 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@22c39ba) from Actor[akka://sparkDriver/temp/$Mb]
15/08/11 10:18:41 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:18:41 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@22c39ba) from Actor[akka://sparkDriver/temp/$Nb]
15/08/11 10:18:41 DEBUG BlockManagerMasterActor: [actor] handled message (0.146025 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@22c39ba) from Actor[akka://sparkDriver/temp/$Nb]
15/08/11 10:18:41 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:18:41 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:18:41 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|14|0,rdd_14_0,, null|14|1,rdd_14_1,, null|14|2,rdd_14_2,).
15/08/11 10:18:41 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:18:41 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$Pb]
15/08/11 10:18:41 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:18:41 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:41 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:41 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:41 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:41 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:41 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:41 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:41 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:41 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:41 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:18:41 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:18:41 DEBUG BlockManager: Got multiple block location in  14 ms
15/08/11 10:18:41 INFO DAGScheduler: [SMSpark v1]Missing parents: List(Stage 8)
15/08/11 10:18:41 DEBUG DAGScheduler: submitStage(Stage 9)
15/08/11 10:18:41 DEBUG DAGScheduler: missing: List(Stage 8)
15/08/11 10:18:41 DEBUG DAGScheduler: submitStage(Stage 8)
15/08/11 10:18:41 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD MapPartitionsRDD[13] at map at KMeansTest.scala:61
15/08/11 10:18:41 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:18:41 DEBUG BlockManagerMasterActor: [actor] handled message (5.713086 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$Pb]
15/08/11 10:18:41 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@4a9ed9f8) from Actor[akka://sparkDriver/temp/$Qb]
15/08/11 10:18:41 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:18:41 DEBUG BlockManagerMasterActor: [actor] handled message (0.190736 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@4a9ed9f8) from Actor[akka://sparkDriver/temp/$Qb]
15/08/11 10:18:41 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@4a9ed9f8) from Actor[akka://sparkDriver/temp/$Rb]
15/08/11 10:18:41 DEBUG BlockManagerMasterActor: [actor] handled message (0.247855 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@4a9ed9f8) from Actor[akka://sparkDriver/temp/$Rb]
15/08/11 10:18:41 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:18:41 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:18:41 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|13|0,rdd_13_0,, null|13|1,rdd_13_1,, null|13|2,rdd_13_2,).
15/08/11 10:18:41 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:18:41 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$Tb]
15/08/11 10:18:41 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:18:41 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:41 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:41 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:41 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:41 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:41 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:41 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:41 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:41 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:41 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:18:41 DEBUG BlockManagerMasterActor: [actor] handled message (1.026656 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$Tb]
15/08/11 10:18:41 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:18:41 DEBUG BlockManager: Got multiple block location in  16 ms
15/08/11 10:18:41 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD KMeans01 MapPartitionsRDD[2] at map at KMeansTest.scala:50
15/08/11 10:18:41 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:18:41 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@2cb6d4cb) from Actor[akka://sparkDriver/temp/$Ub]
15/08/11 10:18:41 DEBUG BlockManagerMasterActor: [actor] handled message (0.286675 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@2cb6d4cb) from Actor[akka://sparkDriver/temp/$Ub]
15/08/11 10:18:41 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(ArrayBuffer(BlockManagerId(0, 192.168.130.131, 47921)), ArrayBuffer(BlockManagerId(0, 192.168.130.131, 47921)), ArrayBuffer(BlockManagerId(0, 192.168.130.131, 47921)))
15/08/11 10:18:41 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@2cb6d4cb) from Actor[akka://sparkDriver/temp/$Vb]
15/08/11 10:18:41 DEBUG BlockManagerMasterActor: [actor] handled message (0.229922 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@2cb6d4cb) from Actor[akka://sparkDriver/temp/$Vb]
15/08/11 10:18:41 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:18:41 DEBUG DAGScheduler: missing: List()
15/08/11 10:18:41 INFO DAGScheduler: Submitting Stage 8 (MapPartitionsRDD[13] at map at KMeansTest.scala:61), which has no missing parents
15/08/11 10:18:41 DEBUG DAGScheduler: submitMissingTasks(Stage 8)
15/08/11 10:18:41 INFO MemoryStore: ensureFreeSpace(4768) called with curMem=214932, maxMem=278302556
15/08/11 10:18:41 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 4.7 KB, free 265.2 MB)
15/08/11 10:18:41 DEBUG BlockManager: Put block broadcast_9 locally took  2 ms
15/08/11 10:18:41 DEBUG BlockManager: Putting block broadcast_9 without replication took  3 ms
15/08/11 10:18:41 INFO MemoryStore: ensureFreeSpace(3205) called with curMem=219700, maxMem=278302556
15/08/11 10:18:41 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 3.1 KB, free 265.2 MB)
15/08/11 10:18:41 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_9_piece0,StorageLevel(false, true, false, false, 1),3205,0,0) from Actor[akka://sparkDriver/temp/$Wb]
15/08/11 10:18:41 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 192.168.130.131:57830 (size: 3.1 KB, free: 265.4 MB)
15/08/11 10:18:41 DEBUG BlockManagerMasterActor: [actor] handled message (0.657253 ms) UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_9_piece0,StorageLevel(false, true, false, false, 1),3205,0,0) from Actor[akka://sparkDriver/temp/$Wb]
15/08/11 10:18:41 INFO BlockManagerMaster: Updated info of block broadcast_9_piece0
15/08/11 10:18:41 DEBUG BlockManager: Told master about block broadcast_9_piece0
15/08/11 10:18:41 DEBUG BlockManager: Put block broadcast_9_piece0 locally took  3 ms
15/08/11 10:18:41 DEBUG BlockManager: Putting block broadcast_9_piece0 without replication took  4 ms
15/08/11 10:18:41 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:852
15/08/11 10:18:41 INFO DAGScheduler: Submitting 3 missing tasks from Stage 8 (MapPartitionsRDD[13] at map at KMeansTest.scala:61)
15/08/11 10:18:41 DEBUG DAGScheduler: New pending tasks: Set(ShuffleMapTask(8, 1), ShuffleMapTask(8, 2), ShuffleMapTask(8, 0))
15/08/11 10:18:41 INFO TaskSchedulerImpl: Adding task set 8.0 with 3 tasks
15/08/11 10:18:41 DEBUG TaskSetManager: Epoch for TaskSet 8.0: 3
15/08/11 10:18:41 DEBUG TaskSetManager: Valid locality levels for TaskSet 8.0: PROCESS_LOCAL, NODE_LOCAL, ANY
15/08/11 10:18:41 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/deadLetters]
15/08/11 10:18:41 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8, runningTasks: 0
15/08/11 10:18:41 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 24, 192.168.130.131, PROCESS_LOCAL, 1361 bytes)
15/08/11 10:18:41 INFO TaskSetManager: Starting task 1.0 in stage 8.0 (TID 25, 192.168.130.131, PROCESS_LOCAL, 1361 bytes)
15/08/11 10:18:41 INFO TaskSetManager: Starting task 2.0 in stage 8.0 (TID 26, 192.168.130.131, PROCESS_LOCAL, 1361 bytes)
15/08/11 10:18:41 DEBUG TaskSetManager: No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
15/08/11 10:18:41 DEBUG TaskSetManager: No tasks for locality level NODE_LOCAL, so moving to locality level ANY
15/08/11 10:18:41 DEBUG DAGScheduler: submitStage(Stage 9)
15/08/11 10:18:41 DEBUG DAGScheduler: missing: List(Stage 8)
15/08/11 10:18:41 DEBUG DAGScheduler: submitStage(Stage 8)
15/08/11 10:18:41 DEBUG DAGScheduler: submitStage(Stage 9)
15/08/11 10:18:41 DEBUG DAGScheduler: missing: List(Stage 8)
15/08/11 10:18:41 DEBUG DAGScheduler: submitStage(Stage 8)
15/08/11 10:18:41 DEBUG BlockManagerMasterActor: [actor] received message GetLocations(broadcast_9_piece0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$U]
15/08/11 10:18:41 DEBUG BlockManagerMasterActor: [actor] handled message (0.066715 ms) GetLocations(broadcast_9_piece0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$U]
15/08/11 10:18:41 DEBUG DAGScheduler: submitStage(Stage 9)
15/08/11 10:18:41 DEBUG DAGScheduler: missing: List(Stage 8)
15/08/11 10:18:41 DEBUG DAGScheduler: submitStage(Stage 8)
15/08/11 10:18:41 DEBUG SparkDeploySchedulerBackend: [actor] handled message (30.3609 ms) ReviveOffers from Actor[akka://sparkDriver/deadLetters]
15/08/11 10:18:41 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,24,RUNNING,org.apache.spark.util.SerializableBuffer@7d94d0e7) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:41 DEBUG BlockManager: Level for block broadcast_9_piece0 is StorageLevel(true, true, false, false, 1)
15/08/11 10:18:41 DEBUG BlockManager: Getting block broadcast_9_piece0 from memory
15/08/11 10:18:41 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.116021 ms) StatusUpdate(0,24,RUNNING,org.apache.spark.util.SerializableBuffer@7d94d0e7) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:41 DEBUG DAGScheduler: submitStage(Stage 9)
15/08/11 10:18:41 DEBUG DAGScheduler: missing: List(Stage 8)
15/08/11 10:18:41 DEBUG DAGScheduler: submitStage(Stage 8)
15/08/11 10:18:41 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_9_piece0,StorageLevel(false, true, false, false, 1),3205,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$V]
15/08/11 10:18:41 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 192.168.130.131:47921 (size: 3.1 KB, free: 245.7 MB)
15/08/11 10:18:41 DEBUG BlockManagerMasterActor: [actor] handled message (0.608669 ms) UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_9_piece0,StorageLevel(false, true, false, false, 1),3205,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$V]
15/08/11 10:18:41 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,25,RUNNING,org.apache.spark.util.SerializableBuffer@120bc835) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:41 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.066932 ms) StatusUpdate(0,25,RUNNING,org.apache.spark.util.SerializableBuffer@120bc835) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:41 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,26,RUNNING,org.apache.spark.util.SerializableBuffer@438518d4) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:41 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.052108 ms) StatusUpdate(0,26,RUNNING,org.apache.spark.util.SerializableBuffer@438518d4) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:41 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,26,FINISHED,org.apache.spark.util.SerializableBuffer@572128ed) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:41 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8, runningTasks: 2
15/08/11 10:18:41 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.854498 ms) StatusUpdate(0,26,FINISHED,org.apache.spark.util.SerializableBuffer@572128ed) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:41 DEBUG DAGScheduler: ShuffleMapTask finished on 0
15/08/11 10:18:41 DEBUG DAGScheduler: submitStage(Stage 9)
15/08/11 10:18:41 DEBUG DAGScheduler: missing: List(Stage 8)
15/08/11 10:18:41 DEBUG DAGScheduler: submitStage(Stage 8)
15/08/11 10:18:41 INFO TaskSetManager: Finished task 2.0 in stage 8.0 (TID 26) in 720 ms on 192.168.130.131 (1/3)
15/08/11 10:18:41 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:41 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8, runningTasks: 2
15/08/11 10:18:41 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.707455 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:42 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:42 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8, runningTasks: 2
15/08/11 10:18:42 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.672529 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:43 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,24,FINISHED,org.apache.spark.util.SerializableBuffer@1b1131ca) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:43 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8, runningTasks: 1
15/08/11 10:18:43 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.664064 ms) StatusUpdate(0,24,FINISHED,org.apache.spark.util.SerializableBuffer@1b1131ca) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:43 DEBUG DAGScheduler: ShuffleMapTask finished on 0
15/08/11 10:18:43 DEBUG DAGScheduler: submitStage(Stage 9)
15/08/11 10:18:43 DEBUG DAGScheduler: missing: List(Stage 8)
15/08/11 10:18:43 DEBUG DAGScheduler: submitStage(Stage 8)
15/08/11 10:18:43 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 24) in 2619 ms on 192.168.130.131 (2/3)
15/08/11 10:18:43 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:43 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8, runningTasks: 1
15/08/11 10:18:43 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.593609 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:43 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,25,FINISHED,org.apache.spark.util.SerializableBuffer@5dbd2a8) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:43 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_8, runningTasks: 0
15/08/11 10:18:43 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.675883 ms) StatusUpdate(0,25,FINISHED,org.apache.spark.util.SerializableBuffer@5dbd2a8) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:43 DEBUG DAGScheduler: ShuffleMapTask finished on 0
15/08/11 10:18:43 INFO DAGScheduler: Stage 8 (map at KMeansTest.scala:61) finished in 2.761 s
15/08/11 10:18:43 INFO DAGScheduler: looking for newly runnable stages
15/08/11 10:18:43 INFO DAGScheduler: running: Set()
15/08/11 10:18:43 INFO DAGScheduler: waiting: Set(Stage 9)
15/08/11 10:18:43 INFO DAGScheduler: failed: Set()
15/08/11 10:18:43 DEBUG MapOutputTrackerMaster: Increasing epoch to 4
15/08/11 10:18:43 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD MapPartitionsRDD[15] at map at KMeansTest.scala:65
15/08/11 10:18:43 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:18:43 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@22e31699) from Actor[akka://sparkDriver/temp/$Xb]
15/08/11 10:18:43 DEBUG BlockManagerMasterActor: [actor] handled message (0.216343 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@22e31699) from Actor[akka://sparkDriver/temp/$Xb]
15/08/11 10:18:43 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:18:43 INFO TaskSetManager: Finished task 1.0 in stage 8.0 (TID 25) in 2755 ms on 192.168.130.131 (3/3)
15/08/11 10:18:43 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@22e31699) from Actor[akka://sparkDriver/temp/$Yb]
15/08/11 10:18:43 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
15/08/11 10:18:43 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:18:43 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:18:43 DEBUG BlockManagerMasterActor: [actor] handled message (0.37145 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@22e31699) from Actor[akka://sparkDriver/temp/$Yb]
15/08/11 10:18:43 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|15|0,rdd_15_0,, null|15|1,rdd_15_1,, null|15|2,rdd_15_2,).
15/08/11 10:18:43 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:18:43 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$0b]
15/08/11 10:18:43 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:18:43 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:43 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:43 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:43 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:43 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:43 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:43 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:43 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:43 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:43 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:18:43 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:18:43 DEBUG BlockManager: Got multiple block location in  19 ms
15/08/11 10:18:43 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD ShuffledRDD[14] at reduceByKey at KMeansTest.scala:63
15/08/11 10:18:43 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:18:43 DEBUG BlockManagerMasterActor: [actor] handled message (3.077448 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$0b]
15/08/11 10:18:43 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@44ed50e3) from Actor[akka://sparkDriver/temp/$1b]
15/08/11 10:18:43 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:18:43 DEBUG BlockManagerMasterActor: [actor] handled message (0.501335 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@44ed50e3) from Actor[akka://sparkDriver/temp/$1b]
15/08/11 10:18:43 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@44ed50e3) from Actor[akka://sparkDriver/temp/$2b]
15/08/11 10:18:43 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:18:43 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:18:43 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|14|0,rdd_14_0,, null|14|1,rdd_14_1,, null|14|2,rdd_14_2,).
15/08/11 10:18:43 DEBUG BlockManagerMasterActor: [actor] handled message (1.467406 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@44ed50e3) from Actor[akka://sparkDriver/temp/$2b]
15/08/11 10:18:43 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:18:43 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$4b]
15/08/11 10:18:43 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:18:43 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:43 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:43 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:43 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:43 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:43 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:43 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:43 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:43 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:43 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:18:43 DEBUG BlockManagerMasterActor: [actor] handled message (0.981522 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$4b]
15/08/11 10:18:43 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:18:43 DEBUG BlockManager: Got multiple block location in  13 ms
15/08/11 10:18:43 INFO DAGScheduler: Missing parents for Stage 9: List()
15/08/11 10:18:43 INFO DAGScheduler: Submitting Stage 9 (MapPartitionsRDD[15] at map at KMeansTest.scala:65), which is now runnable
15/08/11 10:18:43 DEBUG DAGScheduler: submitMissingTasks(Stage 9)
15/08/11 10:18:43 INFO MemoryStore: ensureFreeSpace(2560) called with curMem=222905, maxMem=278302556
15/08/11 10:18:43 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 2.5 KB, free 265.2 MB)
15/08/11 10:18:43 DEBUG BlockManager: Put block broadcast_10 locally took  1 ms
15/08/11 10:18:43 DEBUG BlockManager: Putting block broadcast_10 without replication took  1 ms
15/08/11 10:18:43 INFO MemoryStore: ensureFreeSpace(1517) called with curMem=225465, maxMem=278302556
15/08/11 10:18:43 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 1517.0 B, free 265.2 MB)
15/08/11 10:18:43 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_10_piece0,StorageLevel(false, true, false, false, 1),1517,0,0) from Actor[akka://sparkDriver/temp/$5b]
15/08/11 10:18:43 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 192.168.130.131:57830 (size: 1517.0 B, free: 265.4 MB)
15/08/11 10:18:43 INFO BlockManagerMaster: Updated info of block broadcast_10_piece0
15/08/11 10:18:43 DEBUG BlockManager: Told master about block broadcast_10_piece0
15/08/11 10:18:43 DEBUG BlockManager: Put block broadcast_10_piece0 locally took  5 ms
15/08/11 10:18:43 DEBUG BlockManager: Putting block broadcast_10_piece0 without replication took  5 ms
15/08/11 10:18:43 DEBUG BlockManagerMasterActor: [actor] handled message (0.950873 ms) UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_10_piece0,StorageLevel(false, true, false, false, 1),1517,0,0) from Actor[akka://sparkDriver/temp/$5b]
15/08/11 10:18:43 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:852
15/08/11 10:18:43 INFO DAGScheduler: Submitting 3 missing tasks from Stage 9 (MapPartitionsRDD[15] at map at KMeansTest.scala:65)
15/08/11 10:18:43 DEBUG DAGScheduler: New pending tasks: Set(ResultTask(9, 2), ResultTask(9, 0), ResultTask(9, 1))
15/08/11 10:18:43 INFO TaskSchedulerImpl: Adding task set 9.0 with 3 tasks
15/08/11 10:18:43 DEBUG TaskSetManager: Epoch for TaskSet 9.0: 4
15/08/11 10:18:43 DEBUG TaskSetManager: Valid locality levels for TaskSet 9.0: NO_PREF, ANY
15/08/11 10:18:43 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/deadLetters]
15/08/11 10:18:43 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9, runningTasks: 0
15/08/11 10:18:43 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 27, 192.168.130.131, PROCESS_LOCAL, 1116 bytes)
15/08/11 10:18:43 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 28, 192.168.130.131, PROCESS_LOCAL, 1116 bytes)
15/08/11 10:18:43 INFO TaskSetManager: Starting task 2.0 in stage 9.0 (TID 29, 192.168.130.131, PROCESS_LOCAL, 1116 bytes)
15/08/11 10:18:43 DEBUG TaskSetManager: No tasks for locality level NO_PREF, so moving to locality level ANY
15/08/11 10:18:43 DEBUG SparkDeploySchedulerBackend: [actor] handled message (3.667803 ms) ReviveOffers from Actor[akka://sparkDriver/deadLetters]
15/08/11 10:18:43 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,27,RUNNING,org.apache.spark.util.SerializableBuffer@301e4154) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:43 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.056697 ms) StatusUpdate(0,27,RUNNING,org.apache.spark.util.SerializableBuffer@301e4154) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:43 DEBUG BlockManagerMasterActor: [actor] received message GetLocations(broadcast_10_piece0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$W]
15/08/11 10:18:43 DEBUG BlockManagerMasterActor: [actor] handled message (0.249741 ms) GetLocations(broadcast_10_piece0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$W]
15/08/11 10:18:43 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,28,RUNNING,org.apache.spark.util.SerializableBuffer@12530a7a) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:43 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.13746 ms) StatusUpdate(0,28,RUNNING,org.apache.spark.util.SerializableBuffer@12530a7a) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:43 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,29,RUNNING,org.apache.spark.util.SerializableBuffer@1e7c6cbd) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:43 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.119969 ms) StatusUpdate(0,29,RUNNING,org.apache.spark.util.SerializableBuffer@1e7c6cbd) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:43 DEBUG BlockManager: Level for block broadcast_10_piece0 is StorageLevel(true, true, false, false, 1)
15/08/11 10:18:43 DEBUG BlockManager: Getting block broadcast_10_piece0 from memory
15/08/11 10:18:43 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_10_piece0,StorageLevel(false, true, false, false, 1),1517,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$X]
15/08/11 10:18:43 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 192.168.130.131:47921 (size: 1517.0 B, free: 245.7 MB)
15/08/11 10:18:43 DEBUG BlockManagerMasterActor: [actor] handled message (0.631516 ms) UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_10_piece0,StorageLevel(false, true, false, false, 1),1517,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$X]
15/08/11 10:18:43 DEBUG MapOutputTrackerMasterActor: [actor] received message GetMapOutputStatuses(3) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$Y]
15/08/11 10:18:43 INFO MapOutputTrackerMasterActor: Asked to send map output locations for shuffle 3 to sparkExecutor@192.168.130.131:49489
15/08/11 10:18:43 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 3 is 162 bytes
15/08/11 10:18:43 DEBUG MapOutputTrackerMasterActor: [actor] handled message (0.666994 ms) GetMapOutputStatuses(3) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$Y]
15/08/11 10:18:43 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,29,FINISHED,org.apache.spark.util.SerializableBuffer@4c6cbd72) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:43 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9, runningTasks: 2
15/08/11 10:18:43 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.824461 ms) StatusUpdate(0,29,FINISHED,org.apache.spark.util.SerializableBuffer@4c6cbd72) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:43 INFO TaskSetManager: Finished task 2.0 in stage 9.0 (TID 29) in 91 ms on 192.168.130.131 (1/3)
15/08/11 10:18:44 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,27,FINISHED,org.apache.spark.util.SerializableBuffer@3db26662) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:44 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9, runningTasks: 1
15/08/11 10:18:44 DEBUG SparkDeploySchedulerBackend: [actor] handled message (1.209455 ms) StatusUpdate(0,27,FINISHED,org.apache.spark.util.SerializableBuffer@3db26662) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:44 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 27) in 125 ms on 192.168.130.131 (2/3)
15/08/11 10:18:44 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,28,FINISHED,org.apache.spark.util.SerializableBuffer@47aef63a) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:44 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_9, runningTasks: 0
15/08/11 10:18:44 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.58941 ms) StatusUpdate(0,28,FINISHED,org.apache.spark.util.SerializableBuffer@47aef63a) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:44 INFO DAGScheduler: Stage 9 (collectAsMap at KMeansTest.scala:67) finished in 0.146 s
15/08/11 10:18:44 DEBUG DAGScheduler: After removal of stage 8, remaining stages = 1
15/08/11 10:18:44 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 28) in 137 ms on 192.168.130.131 (3/3)
15/08/11 10:18:44 DEBUG DAGScheduler: After removal of stage 9, remaining stages = 0
15/08/11 10:18:44 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
15/08/11 10:18:44 INFO DAGScheduler: Job 5 finished: collectAsMap at KMeansTest.scala:67, took 3.038702 s
Finished iteration (num = 3)
15/08/11 10:18:44 INFO SparkContext: Starting job: collectAsMap at KMeansTest.scala:67
15/08/11 10:18:44 INFO DAGScheduler: Registering RDD 16 (map at KMeansTest.scala:61)
15/08/11 10:18:44 INFO DAGScheduler: Got job 6 (collectAsMap at KMeansTest.scala:67) with 3 output partitions (allowLocal=false)
15/08/11 10:18:44 INFO DAGScheduler: Final stage: Stage 11(collectAsMap at KMeansTest.scala:67)
15/08/11 10:18:44 INFO DAGScheduler: Parents of final stage: List(Stage 10)
15/08/11 10:18:44 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD MapPartitionsRDD[18] at map at KMeansTest.scala:65
15/08/11 10:18:44 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:18:44 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@2d1f342f) from Actor[akka://sparkDriver/temp/$6b]
15/08/11 10:18:44 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:18:44 DEBUG BlockManagerMasterActor: [actor] handled message (0.343235 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@2d1f342f) from Actor[akka://sparkDriver/temp/$6b]
15/08/11 10:18:44 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@2d1f342f) from Actor[akka://sparkDriver/temp/$7b]
15/08/11 10:18:44 DEBUG BlockManagerMasterActor: [actor] handled message (0.26228 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@2d1f342f) from Actor[akka://sparkDriver/temp/$7b]
15/08/11 10:18:44 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:18:44 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:18:44 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|18|0,rdd_18_0,, null|18|1,rdd_18_1,, null|18|2,rdd_18_2,).
15/08/11 10:18:44 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:18:44 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$9b]
15/08/11 10:18:44 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:18:44 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:44 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:44 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:44 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:44 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:44 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:44 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:44 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:44 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:44 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:18:44 DEBUG BlockManagerMasterActor: [actor] handled message (1.315928 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$9b]
15/08/11 10:18:44 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:18:44 DEBUG BlockManager: Got multiple block location in  22 ms
15/08/11 10:18:44 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD ShuffledRDD[17] at reduceByKey at KMeansTest.scala:63
15/08/11 10:18:44 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:18:44 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@47cb3a02) from Actor[akka://sparkDriver/temp/$+b]
15/08/11 10:18:44 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:18:44 DEBUG BlockManagerMasterActor: [actor] handled message (0.235235 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@47cb3a02) from Actor[akka://sparkDriver/temp/$+b]
15/08/11 10:18:44 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@47cb3a02) from Actor[akka://sparkDriver/temp/$~b]
15/08/11 10:18:44 DEBUG BlockManagerMasterActor: [actor] handled message (0.390327 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@47cb3a02) from Actor[akka://sparkDriver/temp/$~b]
15/08/11 10:18:44 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:18:44 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:18:44 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|17|0,rdd_17_0,, null|17|1,rdd_17_1,, null|17|2,rdd_17_2,).
15/08/11 10:18:44 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:18:44 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$bc]
15/08/11 10:18:44 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:18:44 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:44 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:44 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:44 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:44 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:44 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:44 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:44 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:44 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:44 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:18:44 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:18:44 DEBUG BlockManagerMasterActor: [actor] handled message (1.826354 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$bc]
15/08/11 10:18:44 DEBUG BlockManager: Got multiple block location in  15 ms
15/08/11 10:18:44 INFO DAGScheduler: [SMSpark v1]Missing parents: List(Stage 10)
15/08/11 10:18:44 DEBUG DAGScheduler: submitStage(Stage 11)
15/08/11 10:18:44 DEBUG DAGScheduler: missing: List(Stage 10)
15/08/11 10:18:44 DEBUG DAGScheduler: submitStage(Stage 10)
15/08/11 10:18:44 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD MapPartitionsRDD[16] at map at KMeansTest.scala:61
15/08/11 10:18:44 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:18:44 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@3f5c5461) from Actor[akka://sparkDriver/temp/$cc]
15/08/11 10:18:44 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:18:44 DEBUG BlockManagerMasterActor: [actor] handled message (0.323747 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@3f5c5461) from Actor[akka://sparkDriver/temp/$cc]
15/08/11 10:18:44 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@3f5c5461) from Actor[akka://sparkDriver/temp/$dc]
15/08/11 10:18:44 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:18:44 DEBUG BlockManagerMasterActor: [actor] handled message (0.224261 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@3f5c5461) from Actor[akka://sparkDriver/temp/$dc]
15/08/11 10:18:44 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:18:44 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|16|0,rdd_16_0,, null|16|1,rdd_16_1,, null|16|2,rdd_16_2,).
15/08/11 10:18:44 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:18:44 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$fc]
15/08/11 10:18:44 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:18:44 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:44 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:44 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:44 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:44 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:44 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:44 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:44 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:44 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:44 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:18:44 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:18:44 DEBUG BlockManagerMasterActor: [actor] handled message (0.973564 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$fc]
15/08/11 10:18:44 DEBUG BlockManager: Got multiple block location in  17 ms
15/08/11 10:18:44 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD KMeans01 MapPartitionsRDD[2] at map at KMeansTest.scala:50
15/08/11 10:18:44 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:18:44 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@2f53db06) from Actor[akka://sparkDriver/temp/$gc]
15/08/11 10:18:44 DEBUG BlockManagerMasterActor: [actor] handled message (0.319493 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@2f53db06) from Actor[akka://sparkDriver/temp/$gc]
15/08/11 10:18:44 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(ArrayBuffer(BlockManagerId(0, 192.168.130.131, 47921)), ArrayBuffer(BlockManagerId(0, 192.168.130.131, 47921)), ArrayBuffer(BlockManagerId(0, 192.168.130.131, 47921)))
15/08/11 10:18:44 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@2f53db06) from Actor[akka://sparkDriver/temp/$hc]
15/08/11 10:18:44 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:18:44 DEBUG BlockManagerMasterActor: [actor] handled message (0.225722 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@2f53db06) from Actor[akka://sparkDriver/temp/$hc]
15/08/11 10:18:44 DEBUG DAGScheduler: missing: List()
15/08/11 10:18:44 INFO DAGScheduler: Submitting Stage 10 (MapPartitionsRDD[16] at map at KMeansTest.scala:61), which has no missing parents
15/08/11 10:18:44 DEBUG DAGScheduler: submitMissingTasks(Stage 10)
15/08/11 10:18:44 INFO MemoryStore: ensureFreeSpace(4768) called with curMem=226982, maxMem=278302556
15/08/11 10:18:44 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 4.7 KB, free 265.2 MB)
15/08/11 10:18:44 DEBUG BlockManager: Put block broadcast_11 locally took  3 ms
15/08/11 10:18:44 DEBUG BlockManager: Putting block broadcast_11 without replication took  3 ms
15/08/11 10:18:44 INFO MemoryStore: ensureFreeSpace(3202) called with curMem=231750, maxMem=278302556
15/08/11 10:18:44 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 3.1 KB, free 265.2 MB)
15/08/11 10:18:44 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_11_piece0,StorageLevel(false, true, false, false, 1),3202,0,0) from Actor[akka://sparkDriver/temp/$ic]
15/08/11 10:18:44 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 192.168.130.131:57830 (size: 3.1 KB, free: 265.4 MB)
15/08/11 10:18:44 DEBUG BlockManagerMasterActor: [actor] handled message (0.978434 ms) UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_11_piece0,StorageLevel(false, true, false, false, 1),3202,0,0) from Actor[akka://sparkDriver/temp/$ic]
15/08/11 10:18:44 INFO BlockManagerMaster: Updated info of block broadcast_11_piece0
15/08/11 10:18:44 DEBUG BlockManager: Told master about block broadcast_11_piece0
15/08/11 10:18:44 DEBUG BlockManager: Put block broadcast_11_piece0 locally took  5 ms
15/08/11 10:18:44 DEBUG BlockManager: Putting block broadcast_11_piece0 without replication took  5 ms
15/08/11 10:18:44 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:852
15/08/11 10:18:44 INFO DAGScheduler: Submitting 3 missing tasks from Stage 10 (MapPartitionsRDD[16] at map at KMeansTest.scala:61)
15/08/11 10:18:44 DEBUG DAGScheduler: New pending tasks: Set(ShuffleMapTask(10, 1), ShuffleMapTask(10, 0), ShuffleMapTask(10, 2))
15/08/11 10:18:44 INFO TaskSchedulerImpl: Adding task set 10.0 with 3 tasks
15/08/11 10:18:44 DEBUG TaskSetManager: Epoch for TaskSet 10.0: 4
15/08/11 10:18:44 DEBUG TaskSetManager: Valid locality levels for TaskSet 10.0: PROCESS_LOCAL, NODE_LOCAL, ANY
15/08/11 10:18:44 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/deadLetters]
15/08/11 10:18:44 DEBUG DAGScheduler: submitStage(Stage 11)
15/08/11 10:18:44 DEBUG DAGScheduler: missing: List(Stage 10)
15/08/11 10:18:44 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_10, runningTasks: 0
15/08/11 10:18:44 DEBUG DAGScheduler: submitStage(Stage 10)
15/08/11 10:18:44 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 30, 192.168.130.131, PROCESS_LOCAL, 1361 bytes)
15/08/11 10:18:44 DEBUG DAGScheduler: submitStage(Stage 11)
15/08/11 10:18:44 DEBUG DAGScheduler: missing: List(Stage 10)
15/08/11 10:18:44 DEBUG DAGScheduler: submitStage(Stage 10)
15/08/11 10:18:44 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 31, 192.168.130.131, PROCESS_LOCAL, 1361 bytes)
15/08/11 10:18:44 DEBUG DAGScheduler: submitStage(Stage 11)
15/08/11 10:18:44 DEBUG DAGScheduler: missing: List(Stage 10)
15/08/11 10:18:44 DEBUG DAGScheduler: submitStage(Stage 10)
15/08/11 10:18:44 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 32, 192.168.130.131, PROCESS_LOCAL, 1361 bytes)
15/08/11 10:18:44 DEBUG TaskSetManager: No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
15/08/11 10:18:44 DEBUG DAGScheduler: submitStage(Stage 11)
15/08/11 10:18:44 DEBUG TaskSetManager: No tasks for locality level NODE_LOCAL, so moving to locality level ANY
15/08/11 10:18:44 DEBUG DAGScheduler: missing: List(Stage 10)
15/08/11 10:18:44 DEBUG DAGScheduler: submitStage(Stage 10)
15/08/11 10:18:44 DEBUG SparkDeploySchedulerBackend: [actor] handled message (4.268648 ms) ReviveOffers from Actor[akka://sparkDriver/deadLetters]
15/08/11 10:18:44 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,30,RUNNING,org.apache.spark.util.SerializableBuffer@6ee37fcd) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:44 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.05485 ms) StatusUpdate(0,30,RUNNING,org.apache.spark.util.SerializableBuffer@6ee37fcd) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:44 DEBUG BlockManagerMasterActor: [actor] received message GetLocations(broadcast_11_piece0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$Z]
15/08/11 10:18:44 DEBUG BlockManagerMasterActor: [actor] handled message (2.343177 ms) GetLocations(broadcast_11_piece0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$Z]
15/08/11 10:18:44 DEBUG BlockManager: Level for block broadcast_11_piece0 is StorageLevel(true, true, false, false, 1)
15/08/11 10:18:44 DEBUG BlockManager: Getting block broadcast_11_piece0 from memory
15/08/11 10:18:44 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,31,RUNNING,org.apache.spark.util.SerializableBuffer@13100598) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:44 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.07817 ms) StatusUpdate(0,31,RUNNING,org.apache.spark.util.SerializableBuffer@13100598) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:44 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_11_piece0,StorageLevel(false, true, false, false, 1),3202,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$0]
15/08/11 10:18:44 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 192.168.130.131:47921 (size: 3.1 KB, free: 245.7 MB)
15/08/11 10:18:44 DEBUG BlockManagerMasterActor: [actor] handled message (0.678687 ms) UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_11_piece0,StorageLevel(false, true, false, false, 1),3202,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$0]
15/08/11 10:18:44 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,32,RUNNING,org.apache.spark.util.SerializableBuffer@df47ef) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:44 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.137085 ms) StatusUpdate(0,32,RUNNING,org.apache.spark.util.SerializableBuffer@df47ef) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:44 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:44 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_10, runningTasks: 3
15/08/11 10:18:44 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.825464 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:45 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,32,FINISHED,org.apache.spark.util.SerializableBuffer@7a663caf) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:45 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_10, runningTasks: 2
15/08/11 10:18:45 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.781813 ms) StatusUpdate(0,32,FINISHED,org.apache.spark.util.SerializableBuffer@7a663caf) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:45 DEBUG DAGScheduler: ShuffleMapTask finished on 0
15/08/11 10:18:45 DEBUG DAGScheduler: submitStage(Stage 11)
15/08/11 10:18:45 DEBUG DAGScheduler: missing: List(Stage 10)
15/08/11 10:18:45 DEBUG DAGScheduler: submitStage(Stage 10)
15/08/11 10:18:45 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 32) in 1163 ms on 192.168.130.131 (1/3)
15/08/11 10:18:45 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:45 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_10, runningTasks: 2
15/08/11 10:18:45 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.620139 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:46 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,30,FINISHED,org.apache.spark.util.SerializableBuffer@1e62699f) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:46 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_10, runningTasks: 1
15/08/11 10:18:46 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.696384 ms) StatusUpdate(0,30,FINISHED,org.apache.spark.util.SerializableBuffer@1e62699f) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:46 DEBUG DAGScheduler: ShuffleMapTask finished on 0
15/08/11 10:18:46 DEBUG DAGScheduler: submitStage(Stage 11)
15/08/11 10:18:46 DEBUG DAGScheduler: missing: List(Stage 10)
15/08/11 10:18:46 DEBUG DAGScheduler: submitStage(Stage 10)
15/08/11 10:18:46 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 30) in 2661 ms on 192.168.130.131 (2/3)
15/08/11 10:18:46 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:46 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_10, runningTasks: 1
15/08/11 10:18:46 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.973372 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:46 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,31,FINISHED,org.apache.spark.util.SerializableBuffer@4f04554e) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:46 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_10, runningTasks: 0
15/08/11 10:18:46 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.810946 ms) StatusUpdate(0,31,FINISHED,org.apache.spark.util.SerializableBuffer@4f04554e) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:46 DEBUG DAGScheduler: ShuffleMapTask finished on 0
15/08/11 10:18:46 INFO DAGScheduler: Stage 10 (map at KMeansTest.scala:61) finished in 2.722 s
15/08/11 10:18:46 INFO DAGScheduler: looking for newly runnable stages
15/08/11 10:18:46 INFO DAGScheduler: running: Set()
15/08/11 10:18:46 INFO DAGScheduler: waiting: Set(Stage 11)
15/08/11 10:18:46 INFO DAGScheduler: failed: Set()
15/08/11 10:18:46 DEBUG MapOutputTrackerMaster: Increasing epoch to 5
15/08/11 10:18:46 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD MapPartitionsRDD[18] at map at KMeansTest.scala:65
15/08/11 10:18:46 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:18:46 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@257c9c69) from Actor[akka://sparkDriver/temp/$jc]
15/08/11 10:18:46 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:18:46 DEBUG BlockManagerMasterActor: [actor] handled message (0.213108 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@257c9c69) from Actor[akka://sparkDriver/temp/$jc]
15/08/11 10:18:46 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@257c9c69) from Actor[akka://sparkDriver/temp/$kc]
15/08/11 10:18:46 DEBUG BlockManagerMasterActor: [actor] handled message (0.191418 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@257c9c69) from Actor[akka://sparkDriver/temp/$kc]
15/08/11 10:18:46 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:18:46 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:18:46 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|18|0,rdd_18_0,, null|18|1,rdd_18_1,, null|18|2,rdd_18_2,).
15/08/11 10:18:46 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 31) in 2711 ms on 192.168.130.131 (3/3)
15/08/11 10:18:46 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
15/08/11 10:18:46 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:18:46 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$mc]
15/08/11 10:18:46 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:18:46 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:46 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:46 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:46 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:46 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:46 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:46 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:46 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:46 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:46 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:18:46 DEBUG BlockManagerMasterActor: [actor] handled message (1.295419 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$mc]
15/08/11 10:18:46 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:18:46 DEBUG BlockManager: Got multiple block location in  16 ms
15/08/11 10:18:46 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD ShuffledRDD[17] at reduceByKey at KMeansTest.scala:63
15/08/11 10:18:46 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:18:46 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@f5d2de6) from Actor[akka://sparkDriver/temp/$nc]
15/08/11 10:18:46 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:18:46 DEBUG BlockManagerMasterActor: [actor] handled message (0.276244 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@f5d2de6) from Actor[akka://sparkDriver/temp/$nc]
15/08/11 10:18:46 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@f5d2de6) from Actor[akka://sparkDriver/temp/$oc]
15/08/11 10:18:46 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:18:46 DEBUG BlockManagerMasterActor: [actor] handled message (0.147699 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@f5d2de6) from Actor[akka://sparkDriver/temp/$oc]
15/08/11 10:18:46 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:18:46 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|17|0,rdd_17_0,, null|17|1,rdd_17_1,, null|17|2,rdd_17_2,).
15/08/11 10:18:46 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:18:46 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$qc]
15/08/11 10:18:46 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:18:46 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:46 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:46 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:46 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:46 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:46 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:46 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:46 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:46 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:46 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:18:46 DEBUG BlockManagerMasterActor: [actor] handled message (0.888264 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$qc]
15/08/11 10:18:46 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:18:46 DEBUG BlockManager: Got multiple block location in  13 ms
15/08/11 10:18:46 INFO DAGScheduler: Missing parents for Stage 11: List()
15/08/11 10:18:46 INFO DAGScheduler: Submitting Stage 11 (MapPartitionsRDD[18] at map at KMeansTest.scala:65), which is now runnable
15/08/11 10:18:46 DEBUG DAGScheduler: submitMissingTasks(Stage 11)
15/08/11 10:18:46 INFO MemoryStore: ensureFreeSpace(2560) called with curMem=234952, maxMem=278302556
15/08/11 10:18:46 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 2.5 KB, free 265.2 MB)
15/08/11 10:18:46 DEBUG BlockManager: Put block broadcast_12 locally took  2 ms
15/08/11 10:18:46 DEBUG BlockManager: Putting block broadcast_12 without replication took  2 ms
15/08/11 10:18:46 INFO MemoryStore: ensureFreeSpace(1521) called with curMem=237512, maxMem=278302556
15/08/11 10:18:46 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 1521.0 B, free 265.2 MB)
15/08/11 10:18:46 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_12_piece0,StorageLevel(false, true, false, false, 1),1521,0,0) from Actor[akka://sparkDriver/temp/$rc]
15/08/11 10:18:46 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 192.168.130.131:57830 (size: 1521.0 B, free: 265.4 MB)
15/08/11 10:18:46 INFO BlockManagerMaster: Updated info of block broadcast_12_piece0
15/08/11 10:18:46 DEBUG BlockManager: Told master about block broadcast_12_piece0
15/08/11 10:18:46 DEBUG BlockManagerMasterActor: [actor] handled message (0.665588 ms) UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_12_piece0,StorageLevel(false, true, false, false, 1),1521,0,0) from Actor[akka://sparkDriver/temp/$rc]
15/08/11 10:18:46 DEBUG BlockManager: Put block broadcast_12_piece0 locally took  3 ms
15/08/11 10:18:46 DEBUG BlockManager: Putting block broadcast_12_piece0 without replication took  3 ms
15/08/11 10:18:46 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:852
15/08/11 10:18:46 INFO DAGScheduler: Submitting 3 missing tasks from Stage 11 (MapPartitionsRDD[18] at map at KMeansTest.scala:65)
15/08/11 10:18:46 DEBUG DAGScheduler: New pending tasks: Set(ResultTask(11, 2), ResultTask(11, 1), ResultTask(11, 0))
15/08/11 10:18:46 INFO TaskSchedulerImpl: Adding task set 11.0 with 3 tasks
15/08/11 10:18:46 DEBUG TaskSetManager: Epoch for TaskSet 11.0: 5
15/08/11 10:18:46 DEBUG TaskSetManager: Valid locality levels for TaskSet 11.0: NO_PREF, ANY
15/08/11 10:18:46 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/deadLetters]
15/08/11 10:18:46 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_11, runningTasks: 0
15/08/11 10:18:46 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 33, 192.168.130.131, PROCESS_LOCAL, 1116 bytes)
15/08/11 10:18:46 INFO TaskSetManager: Starting task 1.0 in stage 11.0 (TID 34, 192.168.130.131, PROCESS_LOCAL, 1116 bytes)
15/08/11 10:18:46 INFO TaskSetManager: Starting task 2.0 in stage 11.0 (TID 35, 192.168.130.131, PROCESS_LOCAL, 1116 bytes)
15/08/11 10:18:46 DEBUG TaskSetManager: No tasks for locality level NO_PREF, so moving to locality level ANY
15/08/11 10:18:46 DEBUG SparkDeploySchedulerBackend: [actor] handled message (4.791324 ms) ReviveOffers from Actor[akka://sparkDriver/deadLetters]
15/08/11 10:18:46 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,33,RUNNING,org.apache.spark.util.SerializableBuffer@33b4cfcc) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:46 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.190202 ms) StatusUpdate(0,33,RUNNING,org.apache.spark.util.SerializableBuffer@33b4cfcc) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:46 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,34,RUNNING,org.apache.spark.util.SerializableBuffer@23b67499) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:46 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.10993 ms) StatusUpdate(0,34,RUNNING,org.apache.spark.util.SerializableBuffer@23b67499) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:46 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,35,RUNNING,org.apache.spark.util.SerializableBuffer@1fa0fb20) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:46 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.123922 ms) StatusUpdate(0,35,RUNNING,org.apache.spark.util.SerializableBuffer@1fa0fb20) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:46 DEBUG BlockManagerMasterActor: [actor] received message GetLocations(broadcast_12_piece0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$1]
15/08/11 10:18:46 DEBUG BlockManagerMasterActor: [actor] handled message (0.120976 ms) GetLocations(broadcast_12_piece0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$1]
15/08/11 10:18:46 DEBUG BlockManager: Level for block broadcast_12_piece0 is StorageLevel(true, true, false, false, 1)
15/08/11 10:18:46 DEBUG BlockManager: Getting block broadcast_12_piece0 from memory
15/08/11 10:18:46 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_12_piece0,StorageLevel(false, true, false, false, 1),1521,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$2]
15/08/11 10:18:46 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 192.168.130.131:47921 (size: 1521.0 B, free: 245.7 MB)
15/08/11 10:18:46 DEBUG BlockManagerMasterActor: [actor] handled message (0.631089 ms) UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_12_piece0,StorageLevel(false, true, false, false, 1),1521,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$2]
15/08/11 10:18:46 DEBUG MapOutputTrackerMasterActor: [actor] received message GetMapOutputStatuses(4) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$3]
15/08/11 10:18:46 INFO MapOutputTrackerMasterActor: Asked to send map output locations for shuffle 4 to sparkExecutor@192.168.130.131:49489
15/08/11 10:18:46 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 4 is 162 bytes
15/08/11 10:18:46 DEBUG MapOutputTrackerMasterActor: [actor] handled message (0.614636 ms) GetMapOutputStatuses(4) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$3]
15/08/11 10:18:47 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,35,FINISHED,org.apache.spark.util.SerializableBuffer@1d915082) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:47 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_11, runningTasks: 2
15/08/11 10:18:47 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.748724 ms) StatusUpdate(0,35,FINISHED,org.apache.spark.util.SerializableBuffer@1d915082) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:47 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,33,FINISHED,org.apache.spark.util.SerializableBuffer@2f3c95f8) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:47 INFO TaskSetManager: Finished task 2.0 in stage 11.0 (TID 35) in 97 ms on 192.168.130.131 (1/3)
15/08/11 10:18:47 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_11, runningTasks: 1
15/08/11 10:18:47 DEBUG SparkDeploySchedulerBackend: [actor] handled message (10.339705 ms) StatusUpdate(0,33,FINISHED,org.apache.spark.util.SerializableBuffer@2f3c95f8) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:47 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,34,FINISHED,org.apache.spark.util.SerializableBuffer@799af885) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:47 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 33) in 126 ms on 192.168.130.131 (2/3)
15/08/11 10:18:47 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_11, runningTasks: 0
15/08/11 10:18:47 DEBUG SparkDeploySchedulerBackend: [actor] handled message (8.152528 ms) StatusUpdate(0,34,FINISHED,org.apache.spark.util.SerializableBuffer@799af885) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:47 INFO DAGScheduler: Stage 11 (collectAsMap at KMeansTest.scala:67) finished in 0.140 s
15/08/11 10:18:47 DEBUG DAGScheduler: After removal of stage 11, remaining stages = 1
15/08/11 10:18:47 INFO TaskSetManager: Finished task 1.0 in stage 11.0 (TID 34) in 135 ms on 192.168.130.131 (3/3)
15/08/11 10:18:47 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
15/08/11 10:18:47 DEBUG DAGScheduler: After removal of stage 10, remaining stages = 0
15/08/11 10:18:47 INFO DAGScheduler: Job 6 finished: collectAsMap at KMeansTest.scala:67, took 3.000546 s
Finished iteration (num = 4)
15/08/11 10:18:47 INFO SparkContext: Starting job: collectAsMap at KMeansTest.scala:67
15/08/11 10:18:47 INFO DAGScheduler: Registering RDD 19 (map at KMeansTest.scala:61)
15/08/11 10:18:47 INFO DAGScheduler: Got job 7 (collectAsMap at KMeansTest.scala:67) with 3 output partitions (allowLocal=false)
15/08/11 10:18:47 INFO DAGScheduler: Final stage: Stage 13(collectAsMap at KMeansTest.scala:67)
15/08/11 10:18:47 INFO DAGScheduler: Parents of final stage: List(Stage 12)
15/08/11 10:18:47 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD MapPartitionsRDD[21] at map at KMeansTest.scala:65
15/08/11 10:18:47 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:18:47 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@5ef4c3a) from Actor[akka://sparkDriver/temp/$sc]
15/08/11 10:18:47 DEBUG BlockManagerMasterActor: [actor] handled message (0.167993 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@5ef4c3a) from Actor[akka://sparkDriver/temp/$sc]
15/08/11 10:18:47 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:18:47 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@5ef4c3a) from Actor[akka://sparkDriver/temp/$tc]
15/08/11 10:18:47 DEBUG BlockManagerMasterActor: [actor] handled message (0.122633 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@5ef4c3a) from Actor[akka://sparkDriver/temp/$tc]
15/08/11 10:18:47 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:18:47 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:18:47 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|21|0,rdd_21_0,, null|21|1,rdd_21_1,, null|21|2,rdd_21_2,).
15/08/11 10:18:47 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:18:47 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$vc]
15/08/11 10:18:47 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:18:47 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:47 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:47 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:47 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:47 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:47 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:47 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:47 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:47 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:47 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:18:47 DEBUG BlockManagerMasterActor: [actor] handled message (0.946725 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$vc]
15/08/11 10:18:47 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:18:47 DEBUG BlockManager: Got multiple block location in  11 ms
15/08/11 10:18:47 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD ShuffledRDD[20] at reduceByKey at KMeansTest.scala:63
15/08/11 10:18:47 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:18:47 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@717f0d2d) from Actor[akka://sparkDriver/temp/$wc]
15/08/11 10:18:47 DEBUG BlockManagerMasterActor: [actor] handled message (0.54904 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@717f0d2d) from Actor[akka://sparkDriver/temp/$wc]
15/08/11 10:18:47 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:18:47 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@717f0d2d) from Actor[akka://sparkDriver/temp/$xc]
15/08/11 10:18:47 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:18:47 DEBUG BlockManagerMasterActor: [actor] handled message (0.18128 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@717f0d2d) from Actor[akka://sparkDriver/temp/$xc]
15/08/11 10:18:47 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:18:47 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|20|0,rdd_20_0,, null|20|1,rdd_20_1,, null|20|2,rdd_20_2,).
15/08/11 10:18:47 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:18:47 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$zc]
15/08/11 10:18:47 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:18:47 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:47 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:47 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:47 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:47 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:47 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:47 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:47 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:47 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:47 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:18:47 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:18:47 DEBUG BlockManagerMasterActor: [actor] handled message (1.100031 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$zc]
15/08/11 10:18:47 DEBUG BlockManager: Got multiple block location in  11 ms
15/08/11 10:18:47 INFO DAGScheduler: [SMSpark v1]Missing parents: List(Stage 12)
15/08/11 10:18:47 DEBUG DAGScheduler: submitStage(Stage 13)
15/08/11 10:18:47 DEBUG DAGScheduler: missing: List(Stage 12)
15/08/11 10:18:47 DEBUG DAGScheduler: submitStage(Stage 12)
15/08/11 10:18:47 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD MapPartitionsRDD[19] at map at KMeansTest.scala:61
15/08/11 10:18:47 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:18:47 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@4a111c47) from Actor[akka://sparkDriver/temp/$Ac]
15/08/11 10:18:47 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:18:47 DEBUG BlockManagerMasterActor: [actor] handled message (0.171162 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@4a111c47) from Actor[akka://sparkDriver/temp/$Ac]
15/08/11 10:18:47 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@4a111c47) from Actor[akka://sparkDriver/temp/$Bc]
15/08/11 10:18:47 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:18:47 DEBUG BlockManagerMasterActor: [actor] handled message (0.144454 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@4a111c47) from Actor[akka://sparkDriver/temp/$Bc]
15/08/11 10:18:47 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:18:47 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|19|0,rdd_19_0,, null|19|1,rdd_19_1,, null|19|2,rdd_19_2,).
15/08/11 10:18:47 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:18:47 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$Dc]
15/08/11 10:18:47 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:18:47 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:47 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:47 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:47 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:47 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:47 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:47 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:47 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:47 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:47 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:18:47 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:18:47 DEBUG BlockManagerMasterActor: [actor] handled message (1.025848 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$Dc]
15/08/11 10:18:47 DEBUG BlockManager: Got multiple block location in  9 ms
15/08/11 10:18:47 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD KMeans01 MapPartitionsRDD[2] at map at KMeansTest.scala:50
15/08/11 10:18:47 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:18:47 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@412bbda4) from Actor[akka://sparkDriver/temp/$Ec]
15/08/11 10:18:47 DEBUG BlockManagerMasterActor: [actor] handled message (0.210281 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@412bbda4) from Actor[akka://sparkDriver/temp/$Ec]
15/08/11 10:18:47 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(ArrayBuffer(BlockManagerId(0, 192.168.130.131, 47921)), ArrayBuffer(BlockManagerId(0, 192.168.130.131, 47921)), ArrayBuffer(BlockManagerId(0, 192.168.130.131, 47921)))
15/08/11 10:18:47 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@412bbda4) from Actor[akka://sparkDriver/temp/$Fc]
15/08/11 10:18:47 DEBUG BlockManagerMasterActor: [actor] handled message (0.305891 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@412bbda4) from Actor[akka://sparkDriver/temp/$Fc]
15/08/11 10:18:47 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:18:47 DEBUG DAGScheduler: missing: List()
15/08/11 10:18:47 INFO DAGScheduler: Submitting Stage 12 (MapPartitionsRDD[19] at map at KMeansTest.scala:61), which has no missing parents
15/08/11 10:18:47 DEBUG DAGScheduler: submitMissingTasks(Stage 12)
15/08/11 10:18:47 INFO MemoryStore: ensureFreeSpace(4768) called with curMem=239033, maxMem=278302556
15/08/11 10:18:47 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 4.7 KB, free 265.2 MB)
15/08/11 10:18:47 DEBUG BlockManager: Put block broadcast_13 locally took  2 ms
15/08/11 10:18:47 DEBUG BlockManager: Putting block broadcast_13 without replication took  2 ms
15/08/11 10:18:47 INFO MemoryStore: ensureFreeSpace(3201) called with curMem=243801, maxMem=278302556
15/08/11 10:18:47 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 3.1 KB, free 265.2 MB)
15/08/11 10:18:47 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_13_piece0,StorageLevel(false, true, false, false, 1),3201,0,0) from Actor[akka://sparkDriver/temp/$Gc]
15/08/11 10:18:47 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 192.168.130.131:57830 (size: 3.1 KB, free: 265.4 MB)
15/08/11 10:18:47 INFO BlockManagerMaster: Updated info of block broadcast_13_piece0
15/08/11 10:18:47 DEBUG BlockManagerMasterActor: [actor] handled message (0.603821 ms) UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_13_piece0,StorageLevel(false, true, false, false, 1),3201,0,0) from Actor[akka://sparkDriver/temp/$Gc]
15/08/11 10:18:47 DEBUG BlockManager: Told master about block broadcast_13_piece0
15/08/11 10:18:47 DEBUG BlockManager: Put block broadcast_13_piece0 locally took  3 ms
15/08/11 10:18:47 DEBUG BlockManager: Putting block broadcast_13_piece0 without replication took  3 ms
15/08/11 10:18:47 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:852
15/08/11 10:18:47 INFO DAGScheduler: Submitting 3 missing tasks from Stage 12 (MapPartitionsRDD[19] at map at KMeansTest.scala:61)
15/08/11 10:18:47 DEBUG DAGScheduler: New pending tasks: Set(ShuffleMapTask(12, 1), ShuffleMapTask(12, 2), ShuffleMapTask(12, 0))
15/08/11 10:18:47 INFO TaskSchedulerImpl: Adding task set 12.0 with 3 tasks
15/08/11 10:18:47 DEBUG TaskSetManager: Epoch for TaskSet 12.0: 5
15/08/11 10:18:47 DEBUG TaskSetManager: Valid locality levels for TaskSet 12.0: PROCESS_LOCAL, NODE_LOCAL, ANY
15/08/11 10:18:47 DEBUG DAGScheduler: submitStage(Stage 13)
15/08/11 10:18:47 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/deadLetters]
15/08/11 10:18:47 DEBUG DAGScheduler: missing: List(Stage 12)
15/08/11 10:18:47 DEBUG DAGScheduler: submitStage(Stage 12)
15/08/11 10:18:47 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_12, runningTasks: 0
15/08/11 10:18:47 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 36, 192.168.130.131, PROCESS_LOCAL, 1361 bytes)
15/08/11 10:18:47 DEBUG DAGScheduler: submitStage(Stage 13)
15/08/11 10:18:47 DEBUG DAGScheduler: missing: List(Stage 12)
15/08/11 10:18:47 DEBUG DAGScheduler: submitStage(Stage 12)
15/08/11 10:18:47 INFO TaskSetManager: Starting task 1.0 in stage 12.0 (TID 37, 192.168.130.131, PROCESS_LOCAL, 1361 bytes)
15/08/11 10:18:47 DEBUG DAGScheduler: submitStage(Stage 13)
15/08/11 10:18:47 DEBUG DAGScheduler: missing: List(Stage 12)
15/08/11 10:18:47 DEBUG DAGScheduler: submitStage(Stage 12)
15/08/11 10:18:47 INFO TaskSetManager: Starting task 2.0 in stage 12.0 (TID 38, 192.168.130.131, PROCESS_LOCAL, 1361 bytes)
15/08/11 10:18:47 DEBUG DAGScheduler: submitStage(Stage 13)
15/08/11 10:18:47 DEBUG TaskSetManager: No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
15/08/11 10:18:47 DEBUG DAGScheduler: missing: List(Stage 12)
15/08/11 10:18:47 DEBUG TaskSetManager: No tasks for locality level NODE_LOCAL, so moving to locality level ANY
15/08/11 10:18:47 DEBUG DAGScheduler: submitStage(Stage 12)
15/08/11 10:18:47 DEBUG SparkDeploySchedulerBackend: [actor] handled message (4.189571 ms) ReviveOffers from Actor[akka://sparkDriver/deadLetters]
15/08/11 10:18:47 DEBUG BlockManagerMasterActor: [actor] received message GetLocations(broadcast_13_piece0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$4]
15/08/11 10:18:47 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,36,RUNNING,org.apache.spark.util.SerializableBuffer@7c458b57) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:47 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.073551 ms) StatusUpdate(0,36,RUNNING,org.apache.spark.util.SerializableBuffer@7c458b57) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:47 DEBUG BlockManagerMasterActor: [actor] handled message (0.116728 ms) GetLocations(broadcast_13_piece0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$4]
15/08/11 10:18:47 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,38,RUNNING,org.apache.spark.util.SerializableBuffer@29a90c7e) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:47 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.085686 ms) StatusUpdate(0,38,RUNNING,org.apache.spark.util.SerializableBuffer@29a90c7e) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:47 DEBUG BlockManager: Level for block broadcast_13_piece0 is StorageLevel(true, true, false, false, 1)
15/08/11 10:18:47 DEBUG BlockManager: Getting block broadcast_13_piece0 from memory
15/08/11 10:18:47 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,37,RUNNING,org.apache.spark.util.SerializableBuffer@323cd01e) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:47 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.052117 ms) StatusUpdate(0,37,RUNNING,org.apache.spark.util.SerializableBuffer@323cd01e) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:47 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_13_piece0,StorageLevel(false, true, false, false, 1),3201,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$5]
15/08/11 10:18:47 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 192.168.130.131:47921 (size: 3.1 KB, free: 245.7 MB)
15/08/11 10:18:47 DEBUG BlockManagerMasterActor: [actor] handled message (0.833069 ms) UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_13_piece0,StorageLevel(false, true, false, false, 1),3201,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$5]
15/08/11 10:18:47 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,38,FINISHED,org.apache.spark.util.SerializableBuffer@7216670f) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:47 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_12, runningTasks: 2
15/08/11 10:18:47 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.974538 ms) StatusUpdate(0,38,FINISHED,org.apache.spark.util.SerializableBuffer@7216670f) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:47 DEBUG DAGScheduler: ShuffleMapTask finished on 0
15/08/11 10:18:47 DEBUG DAGScheduler: submitStage(Stage 13)
15/08/11 10:18:47 DEBUG DAGScheduler: missing: List(Stage 12)
15/08/11 10:18:47 DEBUG DAGScheduler: submitStage(Stage 12)
15/08/11 10:18:47 INFO TaskSetManager: Finished task 2.0 in stage 12.0 (TID 38) in 621 ms on 192.168.130.131 (1/3)
15/08/11 10:18:47 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:47 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_12, runningTasks: 2
15/08/11 10:18:47 DEBUG SparkDeploySchedulerBackend: [actor] handled message (1.447819 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:48 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:48 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_12, runningTasks: 2
15/08/11 10:18:48 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.672474 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:49 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,36,FINISHED,org.apache.spark.util.SerializableBuffer@65b34581) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:49 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_12, runningTasks: 1
15/08/11 10:18:49 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.542345 ms) StatusUpdate(0,36,FINISHED,org.apache.spark.util.SerializableBuffer@65b34581) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:49 DEBUG DAGScheduler: ShuffleMapTask finished on 0
15/08/11 10:18:49 DEBUG DAGScheduler: submitStage(Stage 13)
15/08/11 10:18:49 DEBUG DAGScheduler: missing: List(Stage 12)
15/08/11 10:18:49 DEBUG DAGScheduler: submitStage(Stage 12)
15/08/11 10:18:49 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 36) in 2336 ms on 192.168.130.131 (2/3)
15/08/11 10:18:49 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,37,FINISHED,org.apache.spark.util.SerializableBuffer@5c984c50) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:49 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_12, runningTasks: 0
15/08/11 10:18:49 DEBUG SparkDeploySchedulerBackend: [actor] handled message (1.170806 ms) StatusUpdate(0,37,FINISHED,org.apache.spark.util.SerializableBuffer@5c984c50) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:49 DEBUG DAGScheduler: ShuffleMapTask finished on 0
15/08/11 10:18:49 INFO TaskSetManager: Finished task 1.0 in stage 12.0 (TID 37) in 2554 ms on 192.168.130.131 (3/3)
15/08/11 10:18:49 INFO DAGScheduler: Stage 12 (map at KMeansTest.scala:61) finished in 2.570 s
15/08/11 10:18:49 INFO DAGScheduler: looking for newly runnable stages
15/08/11 10:18:49 INFO DAGScheduler: running: Set()
15/08/11 10:18:49 INFO DAGScheduler: waiting: Set(Stage 13)
15/08/11 10:18:49 INFO DAGScheduler: failed: Set()
15/08/11 10:18:49 DEBUG MapOutputTrackerMaster: Increasing epoch to 6
15/08/11 10:18:49 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD MapPartitionsRDD[21] at map at KMeansTest.scala:65
15/08/11 10:18:49 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:18:49 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
15/08/11 10:18:49 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@12ba47ae) from Actor[akka://sparkDriver/temp/$Hc]
15/08/11 10:18:49 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:18:49 DEBUG BlockManagerMasterActor: [actor] handled message (0.279906 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@12ba47ae) from Actor[akka://sparkDriver/temp/$Hc]
15/08/11 10:18:49 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@12ba47ae) from Actor[akka://sparkDriver/temp/$Ic]
15/08/11 10:18:49 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:18:49 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:18:49 DEBUG BlockManagerMasterActor: [actor] handled message (0.335232 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@12ba47ae) from Actor[akka://sparkDriver/temp/$Ic]
15/08/11 10:18:49 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|21|0,rdd_21_0,, null|21|1,rdd_21_1,, null|21|2,rdd_21_2,).
15/08/11 10:18:49 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:18:49 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$Kc]
15/08/11 10:18:49 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:18:49 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:49 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:49 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:49 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:49 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:49 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:49 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:49 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:49 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:49 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:18:49 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:18:49 DEBUG BlockManagerMasterActor: [actor] handled message (1.021846 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$Kc]
15/08/11 10:18:49 DEBUG BlockManager: Got multiple block location in  17 ms
15/08/11 10:18:49 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD ShuffledRDD[20] at reduceByKey at KMeansTest.scala:63
15/08/11 10:18:49 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:18:49 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@7ea8cf04) from Actor[akka://sparkDriver/temp/$Lc]
15/08/11 10:18:49 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:18:49 DEBUG BlockManagerMasterActor: [actor] handled message (0.328381 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@7ea8cf04) from Actor[akka://sparkDriver/temp/$Lc]
15/08/11 10:18:49 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@7ea8cf04) from Actor[akka://sparkDriver/temp/$Mc]
15/08/11 10:18:49 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:18:49 DEBUG BlockManagerMasterActor: [actor] handled message (0.263283 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@7ea8cf04) from Actor[akka://sparkDriver/temp/$Mc]
15/08/11 10:18:49 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:18:49 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|20|0,rdd_20_0,, null|20|1,rdd_20_1,, null|20|2,rdd_20_2,).
15/08/11 10:18:49 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:18:49 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$Oc]
15/08/11 10:18:49 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:18:49 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:49 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:49 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:49 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:49 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:49 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:49 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:49 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:49 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:49 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:18:49 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:18:49 DEBUG BlockManagerMasterActor: [actor] handled message (4.773964 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$Oc]
15/08/11 10:18:49 DEBUG BlockManager: Got multiple block location in  20 ms
15/08/11 10:18:49 INFO DAGScheduler: Missing parents for Stage 13: List()
15/08/11 10:18:49 INFO DAGScheduler: Submitting Stage 13 (MapPartitionsRDD[21] at map at KMeansTest.scala:65), which is now runnable
15/08/11 10:18:49 DEBUG DAGScheduler: submitMissingTasks(Stage 13)
15/08/11 10:18:49 INFO MemoryStore: ensureFreeSpace(2560) called with curMem=247002, maxMem=278302556
15/08/11 10:18:49 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 2.5 KB, free 265.2 MB)
15/08/11 10:18:49 DEBUG BlockManager: Put block broadcast_14 locally took  2 ms
15/08/11 10:18:49 DEBUG BlockManager: Putting block broadcast_14 without replication took  3 ms
15/08/11 10:18:49 INFO MemoryStore: ensureFreeSpace(1519) called with curMem=249562, maxMem=278302556
15/08/11 10:18:49 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 1519.0 B, free 265.2 MB)
15/08/11 10:18:49 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_14_piece0,StorageLevel(false, true, false, false, 1),1519,0,0) from Actor[akka://sparkDriver/temp/$Pc]
15/08/11 10:18:49 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 192.168.130.131:57830 (size: 1519.0 B, free: 265.4 MB)
15/08/11 10:18:49 DEBUG BlockManagerMasterActor: [actor] handled message (0.77528 ms) UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_14_piece0,StorageLevel(false, true, false, false, 1),1519,0,0) from Actor[akka://sparkDriver/temp/$Pc]
15/08/11 10:18:49 INFO BlockManagerMaster: Updated info of block broadcast_14_piece0
15/08/11 10:18:49 DEBUG BlockManager: Told master about block broadcast_14_piece0
15/08/11 10:18:49 DEBUG BlockManager: Put block broadcast_14_piece0 locally took  3 ms
15/08/11 10:18:49 DEBUG BlockManager: Putting block broadcast_14_piece0 without replication took  4 ms
15/08/11 10:18:49 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:852
15/08/11 10:18:49 INFO DAGScheduler: Submitting 3 missing tasks from Stage 13 (MapPartitionsRDD[21] at map at KMeansTest.scala:65)
15/08/11 10:18:49 DEBUG DAGScheduler: New pending tasks: Set(ResultTask(13, 0), ResultTask(13, 1), ResultTask(13, 2))
15/08/11 10:18:49 INFO TaskSchedulerImpl: Adding task set 13.0 with 3 tasks
15/08/11 10:18:49 DEBUG TaskSetManager: Epoch for TaskSet 13.0: 6
15/08/11 10:18:49 DEBUG TaskSetManager: Valid locality levels for TaskSet 13.0: NO_PREF, ANY
15/08/11 10:18:49 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/deadLetters]
15/08/11 10:18:49 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13, runningTasks: 0
15/08/11 10:18:49 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 39, 192.168.130.131, PROCESS_LOCAL, 1116 bytes)
15/08/11 10:18:49 INFO TaskSetManager: Starting task 1.0 in stage 13.0 (TID 40, 192.168.130.131, PROCESS_LOCAL, 1116 bytes)
15/08/11 10:18:49 INFO TaskSetManager: Starting task 2.0 in stage 13.0 (TID 41, 192.168.130.131, PROCESS_LOCAL, 1116 bytes)
15/08/11 10:18:49 DEBUG TaskSetManager: No tasks for locality level NO_PREF, so moving to locality level ANY
15/08/11 10:18:49 DEBUG SparkDeploySchedulerBackend: [actor] handled message (17.309135 ms) ReviveOffers from Actor[akka://sparkDriver/deadLetters]
15/08/11 10:18:49 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,39,RUNNING,org.apache.spark.util.SerializableBuffer@1796ba3f) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:49 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.109055 ms) StatusUpdate(0,39,RUNNING,org.apache.spark.util.SerializableBuffer@1796ba3f) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:49 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,40,RUNNING,org.apache.spark.util.SerializableBuffer@289d8a32) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:49 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.120467 ms) StatusUpdate(0,40,RUNNING,org.apache.spark.util.SerializableBuffer@289d8a32) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:49 DEBUG BlockManagerMasterActor: [actor] received message GetLocations(broadcast_14_piece0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$6]
15/08/11 10:18:49 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,41,RUNNING,org.apache.spark.util.SerializableBuffer@7edbed72) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:49 DEBUG BlockManagerMasterActor: [actor] handled message (0.109592 ms) GetLocations(broadcast_14_piece0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$6]
15/08/11 10:18:49 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.050145 ms) StatusUpdate(0,41,RUNNING,org.apache.spark.util.SerializableBuffer@7edbed72) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:49 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:49 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13, runningTasks: 3
15/08/11 10:18:49 DEBUG SparkDeploySchedulerBackend: [actor] handled message (1.09575 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:49 DEBUG BlockManager: Level for block broadcast_14_piece0 is StorageLevel(true, true, false, false, 1)
15/08/11 10:18:49 DEBUG BlockManager: Getting block broadcast_14_piece0 from memory
15/08/11 10:18:49 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_14_piece0,StorageLevel(false, true, false, false, 1),1519,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$7]
15/08/11 10:18:49 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 192.168.130.131:47921 (size: 1519.0 B, free: 245.7 MB)
15/08/11 10:18:49 DEBUG BlockManagerMasterActor: [actor] handled message (4.41921 ms) UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_14_piece0,StorageLevel(false, true, false, false, 1),1519,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$7]
15/08/11 10:18:49 DEBUG MapOutputTrackerMasterActor: [actor] received message GetMapOutputStatuses(5) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$8]
15/08/11 10:18:49 INFO MapOutputTrackerMasterActor: Asked to send map output locations for shuffle 5 to sparkExecutor@192.168.130.131:49489
15/08/11 10:18:49 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 5 is 162 bytes
15/08/11 10:18:49 DEBUG MapOutputTrackerMasterActor: [actor] handled message (4.534225 ms) GetMapOutputStatuses(5) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$8]
15/08/11 10:18:49 DEBUG HeartbeatReceiver: [actor] received message Heartbeat(0,[Lscala.Tuple2;@1ac2e78c,BlockManagerId(0, 192.168.130.131, 47921)) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$9]
15/08/11 10:18:49 DEBUG BlockManagerMasterActor: [actor] received message BlockManagerHeartbeat(BlockManagerId(0, 192.168.130.131, 47921)) from Actor[akka://sparkDriver/temp/$Qc]
15/08/11 10:18:49 DEBUG BlockManagerMasterActor: [actor] handled message (0.288345 ms) BlockManagerHeartbeat(BlockManagerId(0, 192.168.130.131, 47921)) from Actor[akka://sparkDriver/temp/$Qc]
15/08/11 10:18:50 DEBUG HeartbeatReceiver: [actor] handled message (1.659327 ms) Heartbeat(0,[Lscala.Tuple2;@1ac2e78c,BlockManagerId(0, 192.168.130.131, 47921)) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$9]
15/08/11 10:18:50 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,39,FINISHED,org.apache.spark.util.SerializableBuffer@2c7ed9eb) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:50 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13, runningTasks: 2
15/08/11 10:18:50 DEBUG SparkDeploySchedulerBackend: [actor] handled message (1.336754 ms) StatusUpdate(0,39,FINISHED,org.apache.spark.util.SerializableBuffer@2c7ed9eb) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:50 DEBUG ContextCleaner: Got cleaning task CleanBroadcast(5)
15/08/11 10:18:50 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,41,FINISHED,org.apache.spark.util.SerializableBuffer@6d5c16d) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:50 DEBUG ContextCleaner: Cleaning broadcast 5
15/08/11 10:18:50 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 39) in 311 ms on 192.168.130.131 (1/3)
15/08/11 10:18:50 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13, runningTasks: 1
15/08/11 10:18:50 DEBUG SparkDeploySchedulerBackend: [actor] handled message (4.624006 ms) StatusUpdate(0,41,FINISHED,org.apache.spark.util.SerializableBuffer@6d5c16d) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:50 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,40,FINISHED,org.apache.spark.util.SerializableBuffer@3b8dde9c) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:50 DEBUG TorrentBroadcast: Unpersisting TorrentBroadcast 5
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] received message RemoveBroadcast(5,true) from Actor[akka://sparkDriver/temp/$Rc]
15/08/11 10:18:50 INFO TaskSetManager: Finished task 2.0 in stage 13.0 (TID 41) in 433 ms on 192.168.130.131 (2/3)
15/08/11 10:18:50 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_13, runningTasks: 0
15/08/11 10:18:50 DEBUG SparkDeploySchedulerBackend: [actor] handled message (17.693215 ms) StatusUpdate(0,40,FINISHED,org.apache.spark.util.SerializableBuffer@3b8dde9c) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:50 DEBUG BlockManagerSlaveActor: [actor] received message RemoveBroadcast(5,true) from Actor[akka://sparkDriver/temp/$Sc]
15/08/11 10:18:50 DEBUG BlockManagerSlaveActor: removing broadcast 5
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] handled message (9.188422 ms) RemoveBroadcast(5,true) from Actor[akka://sparkDriver/temp/$Rc]
15/08/11 10:18:50 INFO BlockManager: Removing broadcast 5
15/08/11 10:18:50 DEBUG BlockManagerSlaveActor: [actor] handled message (19.07638 ms) RemoveBroadcast(5,true) from Actor[akka://sparkDriver/temp/$Sc]
15/08/11 10:18:50 INFO BlockManager: Removing block broadcast_5_piece0
15/08/11 10:18:50 INFO MemoryStore: Block broadcast_5_piece0 of size 3198 dropped from memory (free 278054673)
15/08/11 10:18:50 INFO DAGScheduler: Stage 13 (collectAsMap at KMeansTest.scala:67) finished in 0.512 s
15/08/11 10:18:50 DEBUG DAGScheduler: After removal of stage 13, remaining stages = 1
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_5_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka://sparkDriver/temp/$Uc]
15/08/11 10:18:50 DEBUG DAGScheduler: After removal of stage 12, remaining stages = 0
15/08/11 10:18:50 INFO DAGScheduler: Job 7 finished: collectAsMap at KMeansTest.scala:67, took 3.201797 s
Finished iteration (num = 5)
15/08/11 10:18:50 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 192.168.130.131:57830 in memory (size: 3.1 KB, free: 265.4 MB)
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] handled message (1.689492 ms) UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_5_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka://sparkDriver/temp/$Uc]
15/08/11 10:18:50 INFO BlockManagerMaster: Updated info of block broadcast_5_piece0
15/08/11 10:18:50 DEBUG BlockManager: Told master about block broadcast_5_piece0
15/08/11 10:18:50 INFO BlockManager: Removing block broadcast_5
15/08/11 10:18:50 INFO MemoryStore: Block broadcast_5 of size 4768 dropped from memory (free 278059441)
15/08/11 10:18:50 INFO TaskSetManager: Finished task 1.0 in stage 13.0 (TID 40) in 456 ms on 192.168.130.131 (3/3)
15/08/11 10:18:50 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_5_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$+]
15/08/11 10:18:50 DEBUG BlockManagerSlaveActor: Done removing broadcast 5, response is 2
15/08/11 10:18:50 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 192.168.130.131:47921 in memory (size: 3.1 KB, free: 245.7 MB)
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] handled message (0.828122 ms) UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_5_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$+]
15/08/11 10:18:50 DEBUG BlockManagerSlaveActor: Sent response: 2 to Actor[akka://sparkDriver/temp/$Sc]
15/08/11 10:18:50 INFO ContextCleaner: Cleaned broadcast 5
15/08/11 10:18:50 DEBUG ContextCleaner: Got cleaning task CleanShuffle(1)
15/08/11 10:18:50 DEBUG ContextCleaner: Cleaning shuffle 1
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] received message RemoveShuffle(1) from Actor[akka://sparkDriver/temp/$Vc]
15/08/11 10:18:50 DEBUG BlockManagerSlaveActor: [actor] received message RemoveShuffle(1) from Actor[akka://sparkDriver/temp/$Wc]
15/08/11 10:18:50 DEBUG BlockManagerSlaveActor: [actor] handled message (4.414267 ms) RemoveShuffle(1) from Actor[akka://sparkDriver/temp/$Wc]
15/08/11 10:18:50 DEBUG BlockManagerSlaveActor: removing shuffle 1
15/08/11 10:18:50 DEBUG BlockManagerSlaveActor: Done removing shuffle 1, response is true
15/08/11 10:18:50 DEBUG BlockManagerSlaveActor: Sent response: true to Actor[akka://sparkDriver/temp/$Wc]
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] handled message (33.298187 ms) RemoveShuffle(1) from Actor[akka://sparkDriver/temp/$Vc]
15/08/11 10:18:50 INFO ContextCleaner: Cleaned shuffle 1
15/08/11 10:18:50 DEBUG ContextCleaner: Got cleaning task CleanBroadcast(4)
15/08/11 10:18:50 DEBUG ContextCleaner: Cleaning broadcast 4
15/08/11 10:18:50 DEBUG TorrentBroadcast: Unpersisting TorrentBroadcast 4
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] received message RemoveBroadcast(4,true) from Actor[akka://sparkDriver/temp/$Yc]
15/08/11 10:18:50 DEBUG BlockManagerSlaveActor: [actor] received message RemoveBroadcast(4,true) from Actor[akka://sparkDriver/temp/$Zc]
15/08/11 10:18:50 DEBUG BlockManagerSlaveActor: [actor] handled message (0.05409 ms) RemoveBroadcast(4,true) from Actor[akka://sparkDriver/temp/$Zc]
15/08/11 10:18:50 DEBUG BlockManagerSlaveActor: removing broadcast 4
15/08/11 10:18:50 INFO BlockManager: Removing broadcast 4
15/08/11 10:18:50 INFO BlockManager: Removing block broadcast_4
15/08/11 10:18:50 INFO MemoryStore: Block broadcast_4 of size 2560 dropped from memory (free 278062001)
15/08/11 10:18:50 INFO BlockManager: Removing block broadcast_4_piece0
15/08/11 10:18:50 INFO MemoryStore: Block broadcast_4_piece0 of size 1537 dropped from memory (free 278063538)
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] handled message (11.813117 ms) RemoveBroadcast(4,true) from Actor[akka://sparkDriver/temp/$Yc]
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_4_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka://sparkDriver/temp/$1c]
15/08/11 10:18:50 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 192.168.130.131:57830 in memory (size: 1537.0 B, free: 265.4 MB)
15/08/11 10:18:50 INFO SparkContext: Starting job: collectAsMap at KMeansTest.scala:67
15/08/11 10:18:50 INFO DAGScheduler: Registering RDD 22 (map at KMeansTest.scala:61)
15/08/11 10:18:50 INFO BlockManagerMaster: Updated info of block broadcast_4_piece0
15/08/11 10:18:50 DEBUG BlockManager: Told master about block broadcast_4_piece0
15/08/11 10:18:50 DEBUG BlockManagerSlaveActor: Done removing broadcast 4, response is 2
15/08/11 10:18:50 DEBUG BlockManagerSlaveActor: Sent response: 2 to Actor[akka://sparkDriver/temp/$Zc]
15/08/11 10:18:50 INFO DAGScheduler: Got job 8 (collectAsMap at KMeansTest.scala:67) with 3 output partitions (allowLocal=false)
15/08/11 10:18:50 INFO DAGScheduler: Final stage: Stage 15(collectAsMap at KMeansTest.scala:67)
15/08/11 10:18:50 INFO DAGScheduler: Parents of final stage: List(Stage 14)
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] handled message (21.79864 ms) UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_4_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka://sparkDriver/temp/$1c]
15/08/11 10:18:50 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD MapPartitionsRDD[24] at map at KMeansTest.scala:65
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_4_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$~]
15/08/11 10:18:50 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:18:50 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 192.168.130.131:47921 in memory (size: 1537.0 B, free: 245.7 MB)
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] handled message (5.640217 ms) UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_4_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$~]
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@77d0bf3e) from Actor[akka://sparkDriver/temp/$2c]
15/08/11 10:18:50 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] handled message (1.002 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@77d0bf3e) from Actor[akka://sparkDriver/temp/$2c]
15/08/11 10:18:50 INFO ContextCleaner: Cleaned broadcast 4
15/08/11 10:18:50 DEBUG ContextCleaner: Got cleaning task CleanBroadcast(3)
15/08/11 10:18:50 DEBUG ContextCleaner: Cleaning broadcast 3
15/08/11 10:18:50 DEBUG TorrentBroadcast: Unpersisting TorrentBroadcast 3
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@77d0bf3e) from Actor[akka://sparkDriver/temp/$3c]
15/08/11 10:18:50 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:18:50 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:18:50 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|24|0,rdd_24_0,, null|24|1,rdd_24_1,, null|24|2,rdd_24_2,).
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] handled message (6.612026 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@77d0bf3e) from Actor[akka://sparkDriver/temp/$3c]
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] received message RemoveBroadcast(3,true) from Actor[akka://sparkDriver/temp/$5c]
15/08/11 10:18:50 DEBUG BlockManagerSlaveActor: [actor] received message RemoveBroadcast(3,true) from Actor[akka://sparkDriver/temp/$6c]
15/08/11 10:18:50 DEBUG BlockManagerSlaveActor: [actor] handled message (0.07527 ms) RemoveBroadcast(3,true) from Actor[akka://sparkDriver/temp/$6c]
15/08/11 10:18:50 DEBUG BlockManagerSlaveActor: removing broadcast 3
15/08/11 10:18:50 INFO BlockManager: Removing broadcast 3
15/08/11 10:18:50 INFO BlockManager: Removing block broadcast_3_piece0
15/08/11 10:18:50 INFO MemoryStore: Block broadcast_3_piece0 of size 3202 dropped from memory (free 278066740)
15/08/11 10:18:50 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] handled message (2.706258 ms) RemoveBroadcast(3,true) from Actor[akka://sparkDriver/temp/$5c]
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$8c]
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:18:50 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:18:50 DEBUG BlockManager: Got multiple block location in  53 ms
15/08/11 10:18:50 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD ShuffledRDD[23] at reduceByKey at KMeansTest.scala:63
15/08/11 10:18:50 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] handled message (13.356791 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$8c]
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_3_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka://sparkDriver/temp/$9c]
15/08/11 10:18:50 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 192.168.130.131:57830 in memory (size: 3.1 KB, free: 265.4 MB)
15/08/11 10:18:50 INFO BlockManagerMaster: Updated info of block broadcast_3_piece0
15/08/11 10:18:50 DEBUG BlockManager: Told master about block broadcast_3_piece0
15/08/11 10:18:50 INFO BlockManager: Removing block broadcast_3
15/08/11 10:18:50 INFO MemoryStore: Block broadcast_3 of size 4768 dropped from memory (free 278071508)
15/08/11 10:18:50 DEBUG BlockManagerSlaveActor: Done removing broadcast 3, response is 2
15/08/11 10:18:50 DEBUG BlockManagerSlaveActor: Sent response: 2 to Actor[akka://sparkDriver/temp/$6c]
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] handled message (2.865034 ms) UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_3_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka://sparkDriver/temp/$9c]
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_3_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$ab]
15/08/11 10:18:50 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 192.168.130.131:47921 in memory (size: 3.1 KB, free: 245.7 MB)
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] handled message (3.833764 ms) UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_3_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$ab]
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@42f4aaa) from Actor[akka://sparkDriver/temp/$+c]
15/08/11 10:18:50 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] handled message (0.630935 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@42f4aaa) from Actor[akka://sparkDriver/temp/$+c]
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@42f4aaa) from Actor[akka://sparkDriver/temp/$~c]
15/08/11 10:18:50 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:18:50 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:18:50 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|23|0,rdd_23_0,, null|23|1,rdd_23_1,, null|23|2,rdd_23_2,).
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] handled message (2.126445 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@42f4aaa) from Actor[akka://sparkDriver/temp/$~c]
15/08/11 10:18:50 INFO ContextCleaner: Cleaned broadcast 3
15/08/11 10:18:50 DEBUG ContextCleaner: Got cleaning task CleanShuffle(0)
15/08/11 10:18:50 DEBUG ContextCleaner: Cleaning shuffle 0
15/08/11 10:18:50 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] received message RemoveShuffle(0) from Actor[akka://sparkDriver/temp/$bd]
15/08/11 10:18:50 DEBUG BlockManagerSlaveActor: [actor] received message RemoveShuffle(0) from Actor[akka://sparkDriver/temp/$cd]
15/08/11 10:18:50 DEBUG BlockManagerSlaveActor: [actor] handled message (0.046328 ms) RemoveShuffle(0) from Actor[akka://sparkDriver/temp/$cd]
15/08/11 10:18:50 DEBUG BlockManagerSlaveActor: removing shuffle 0
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] handled message (0.574268 ms) RemoveShuffle(0) from Actor[akka://sparkDriver/temp/$bd]
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$dd]
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:50 DEBUG BlockManagerSlaveActor: Done removing shuffle 0, response is true
15/08/11 10:18:50 DEBUG BlockManagerSlaveActor: Sent response: true to Actor[akka://sparkDriver/temp/$cd]
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] handled message (2.500726 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$dd]
15/08/11 10:18:50 INFO ContextCleaner: Cleaned shuffle 0
15/08/11 10:18:50 DEBUG ContextCleaner: Got cleaning task CleanBroadcast(2)
15/08/11 10:18:50 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:18:50 DEBUG BlockManager: Got multiple block location in  43 ms
15/08/11 10:18:50 INFO DAGScheduler: [SMSpark v1]Missing parents: List(Stage 14)
15/08/11 10:18:50 DEBUG DAGScheduler: submitStage(Stage 15)
15/08/11 10:18:50 DEBUG DAGScheduler: missing: List(Stage 14)
15/08/11 10:18:50 DEBUG DAGScheduler: submitStage(Stage 14)
15/08/11 10:18:50 DEBUG ContextCleaner: Cleaning broadcast 2
15/08/11 10:18:50 DEBUG TorrentBroadcast: Unpersisting TorrentBroadcast 2
15/08/11 10:18:50 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD MapPartitionsRDD[22] at map at KMeansTest.scala:61
15/08/11 10:18:50 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] received message RemoveBroadcast(2,true) from Actor[akka://sparkDriver/temp/$fd]
15/08/11 10:18:50 DEBUG BlockManagerSlaveActor: [actor] received message RemoveBroadcast(2,true) from Actor[akka://sparkDriver/temp/$gd]
15/08/11 10:18:50 DEBUG BlockManagerSlaveActor: [actor] handled message (0.088088 ms) RemoveBroadcast(2,true) from Actor[akka://sparkDriver/temp/$gd]
15/08/11 10:18:50 DEBUG BlockManagerSlaveActor: removing broadcast 2
15/08/11 10:18:50 INFO BlockManager: Removing broadcast 2
15/08/11 10:18:50 INFO BlockManager: Removing block broadcast_2
15/08/11 10:18:50 INFO MemoryStore: Block broadcast_2 of size 3464 dropped from memory (free 278074972)
15/08/11 10:18:50 INFO BlockManager: Removing block broadcast_2_piece0
15/08/11 10:18:50 INFO MemoryStore: Block broadcast_2_piece0 of size 2081 dropped from memory (free 278077053)
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] handled message (3.610396 ms) RemoveBroadcast(2,true) from Actor[akka://sparkDriver/temp/$fd]
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@6be8e70) from Actor[akka://sparkDriver/temp/$id]
15/08/11 10:18:50 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] handled message (2.640765 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@6be8e70) from Actor[akka://sparkDriver/temp/$id]
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_2_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka://sparkDriver/temp/$jd]
15/08/11 10:18:50 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 192.168.130.131:57830 in memory (size: 2.0 KB, free: 265.4 MB)
15/08/11 10:18:50 INFO BlockManagerMaster: Updated info of block broadcast_2_piece0
15/08/11 10:18:50 DEBUG BlockManager: Told master about block broadcast_2_piece0
15/08/11 10:18:50 DEBUG BlockManagerSlaveActor: Done removing broadcast 2, response is 2
15/08/11 10:18:50 DEBUG BlockManagerSlaveActor: Sent response: 2 to Actor[akka://sparkDriver/temp/$gd]
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] handled message (10.080181 ms) UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_2_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka://sparkDriver/temp/$jd]
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@6be8e70) from Actor[akka://sparkDriver/temp/$kd]
15/08/11 10:18:50 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:18:50 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:18:50 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|22|0,rdd_22_0,, null|22|1,rdd_22_1,, null|22|2,rdd_22_2,).
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] handled message (0.949804 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@6be8e70) from Actor[akka://sparkDriver/temp/$kd]
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_2_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$bb]
15/08/11 10:18:50 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 192.168.130.131:47921 in memory (size: 2.0 KB, free: 245.7 MB)
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] handled message (1.226639 ms) UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_2_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$bb]
15/08/11 10:18:50 INFO ContextCleaner: Cleaned broadcast 2
15/08/11 10:18:50 DEBUG ContextCleaner: Got cleaning task CleanBroadcast(1)
15/08/11 10:18:50 DEBUG ContextCleaner: Cleaning broadcast 1
15/08/11 10:18:50 DEBUG TorrentBroadcast: Unpersisting TorrentBroadcast 1
15/08/11 10:18:50 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] received message RemoveBroadcast(1,true) from Actor[akka://sparkDriver/temp/$md]
15/08/11 10:18:50 DEBUG BlockManagerSlaveActor: [actor] received message RemoveBroadcast(1,true) from Actor[akka://sparkDriver/temp/$nd]
15/08/11 10:18:50 DEBUG BlockManagerSlaveActor: [actor] handled message (0.647 ms) RemoveBroadcast(1,true) from Actor[akka://sparkDriver/temp/$nd]
15/08/11 10:18:50 DEBUG BlockManagerSlaveActor: removing broadcast 1
15/08/11 10:18:50 INFO BlockManager: Removing broadcast 1
15/08/11 10:18:50 INFO BlockManager: Removing block broadcast_1_piece0
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] handled message (4.606226 ms) RemoveBroadcast(1,true) from Actor[akka://sparkDriver/temp/$md]
15/08/11 10:18:50 INFO MemoryStore: Block broadcast_1_piece0 of size 1792 dropped from memory (free 278078845)
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$pd]
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] handled message (1.836408 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$pd]
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_1_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka://sparkDriver/temp/$qd]
15/08/11 10:18:50 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 192.168.130.131:57830 in memory (size: 1792.0 B, free: 265.4 MB)
15/08/11 10:18:50 INFO BlockManagerMaster: Updated info of block broadcast_1_piece0
15/08/11 10:18:50 DEBUG BlockManager: Told master about block broadcast_1_piece0
15/08/11 10:18:50 INFO BlockManager: Removing block broadcast_1
15/08/11 10:18:50 INFO MemoryStore: Block broadcast_1 of size 2872 dropped from memory (free 278081717)
15/08/11 10:18:50 DEBUG BlockManagerSlaveActor: Done removing broadcast 1, response is 2
15/08/11 10:18:50 DEBUG BlockManagerSlaveActor: Sent response: 2 to Actor[akka://sparkDriver/temp/$nd]
15/08/11 10:18:50 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] handled message (3.301151 ms) UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_1_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka://sparkDriver/temp/$qd]
15/08/11 10:18:50 DEBUG BlockManager: Got multiple block location in  50 ms
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_1_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$cb]
15/08/11 10:18:50 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD KMeans01 MapPartitionsRDD[2] at map at KMeansTest.scala:50
15/08/11 10:18:50 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:18:50 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 192.168.130.131:47921 in memory (size: 1792.0 B, free: 245.7 MB)
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] handled message (1.974485 ms) UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_1_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$cb]
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@4f8f3fb1) from Actor[akka://sparkDriver/temp/$rd]
15/08/11 10:18:50 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(ArrayBuffer(BlockManagerId(0, 192.168.130.131, 47921)), ArrayBuffer(BlockManagerId(0, 192.168.130.131, 47921)), ArrayBuffer(BlockManagerId(0, 192.168.130.131, 47921)))
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] handled message (1.284761 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@4f8f3fb1) from Actor[akka://sparkDriver/temp/$rd]
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@4f8f3fb1) from Actor[akka://sparkDriver/temp/$sd]
15/08/11 10:18:50 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:18:50 DEBUG DAGScheduler: missing: List()
15/08/11 10:18:50 INFO DAGScheduler: Submitting Stage 14 (MapPartitionsRDD[22] at map at KMeansTest.scala:61), which has no missing parents
15/08/11 10:18:50 DEBUG DAGScheduler: submitMissingTasks(Stage 14)
15/08/11 10:18:50 INFO ContextCleaner: Cleaned broadcast 1
15/08/11 10:18:50 DEBUG ContextCleaner: Got cleaning task CleanBroadcast(13)
15/08/11 10:18:50 DEBUG ContextCleaner: Cleaning broadcast 13
15/08/11 10:18:50 DEBUG TorrentBroadcast: Unpersisting TorrentBroadcast 13
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] handled message (7.128477 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@4f8f3fb1) from Actor[akka://sparkDriver/temp/$sd]
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] received message RemoveBroadcast(13,true) from Actor[akka://sparkDriver/temp/$td]
15/08/11 10:18:50 DEBUG BlockManagerSlaveActor: [actor] received message RemoveBroadcast(13,true) from Actor[akka://sparkDriver/temp/$ud]
15/08/11 10:18:50 DEBUG BlockManagerSlaveActor: removing broadcast 13
15/08/11 10:18:50 DEBUG BlockManagerSlaveActor: [actor] handled message (0.10288 ms) RemoveBroadcast(13,true) from Actor[akka://sparkDriver/temp/$ud]
15/08/11 10:18:50 INFO BlockManager: Removing broadcast 13
15/08/11 10:18:50 INFO BlockManager: Removing block broadcast_13_piece0
15/08/11 10:18:50 INFO MemoryStore: Block broadcast_13_piece0 of size 3201 dropped from memory (free 278084918)
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] handled message (5.306073 ms) RemoveBroadcast(13,true) from Actor[akka://sparkDriver/temp/$td]
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_13_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka://sparkDriver/temp/$wd]
15/08/11 10:18:50 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 192.168.130.131:57830 in memory (size: 3.1 KB, free: 265.4 MB)
15/08/11 10:18:50 INFO MemoryStore: ensureFreeSpace(4768) called with curMem=217638, maxMem=278302556
15/08/11 10:18:50 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 4.7 KB, free 265.2 MB)
15/08/11 10:18:50 DEBUG BlockManager: Put block broadcast_15 locally took  17 ms
15/08/11 10:18:50 DEBUG BlockManager: Putting block broadcast_15 without replication took  17 ms
15/08/11 10:18:50 INFO BlockManagerMaster: Updated info of block broadcast_13_piece0
15/08/11 10:18:50 DEBUG BlockManager: Told master about block broadcast_13_piece0
15/08/11 10:18:50 INFO BlockManager: Removing block broadcast_13
15/08/11 10:18:50 INFO MemoryStore: Block broadcast_13 of size 4768 dropped from memory (free 278084918)
15/08/11 10:18:50 DEBUG BlockManagerSlaveActor: Done removing broadcast 13, response is 2
15/08/11 10:18:50 DEBUG BlockManagerSlaveActor: Sent response: 2 to Actor[akka://sparkDriver/temp/$ud]
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] handled message (13.327736 ms) UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_13_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka://sparkDriver/temp/$wd]
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_13_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$db]
15/08/11 10:18:50 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 192.168.130.131:47921 in memory (size: 3.1 KB, free: 245.7 MB)
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] handled message (0.871046 ms) UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_13_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$db]
15/08/11 10:18:50 INFO ContextCleaner: Cleaned broadcast 13
15/08/11 10:18:50 DEBUG ContextCleaner: Got cleaning task CleanBroadcast(12)
15/08/11 10:18:50 DEBUG ContextCleaner: Cleaning broadcast 12
15/08/11 10:18:50 DEBUG TorrentBroadcast: Unpersisting TorrentBroadcast 12
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] received message RemoveBroadcast(12,true) from Actor[akka://sparkDriver/temp/$xd]
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] handled message (0.784789 ms) RemoveBroadcast(12,true) from Actor[akka://sparkDriver/temp/$xd]
15/08/11 10:18:50 DEBUG BlockManagerSlaveActor: [actor] received message RemoveBroadcast(12,true) from Actor[akka://sparkDriver/temp/$zd]
15/08/11 10:18:50 DEBUG BlockManagerSlaveActor: removing broadcast 12
15/08/11 10:18:50 DEBUG BlockManagerSlaveActor: [actor] handled message (0.050973 ms) RemoveBroadcast(12,true) from Actor[akka://sparkDriver/temp/$zd]
15/08/11 10:18:50 INFO BlockManager: Removing broadcast 12
15/08/11 10:18:50 INFO BlockManager: Removing block broadcast_12
15/08/11 10:18:50 INFO MemoryStore: Block broadcast_12 of size 2560 dropped from memory (free 278087478)
15/08/11 10:18:50 INFO BlockManager: Removing block broadcast_12_piece0
15/08/11 10:18:50 INFO MemoryStore: Block broadcast_12_piece0 of size 1521 dropped from memory (free 278088999)
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_12_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka://sparkDriver/temp/$Ad]
15/08/11 10:18:50 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 192.168.130.131:57830 in memory (size: 1521.0 B, free: 265.4 MB)
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] handled message (0.869699 ms) UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_12_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka://sparkDriver/temp/$Ad]
15/08/11 10:18:50 INFO BlockManagerMaster: Updated info of block broadcast_12_piece0
15/08/11 10:18:50 DEBUG BlockManager: Told master about block broadcast_12_piece0
15/08/11 10:18:50 DEBUG BlockManagerSlaveActor: Done removing broadcast 12, response is 2
15/08/11 10:18:50 DEBUG BlockManagerSlaveActor: Sent response: 2 to Actor[akka://sparkDriver/temp/$zd]
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_12_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$eb]
15/08/11 10:18:50 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 192.168.130.131:47921 in memory (size: 1521.0 B, free: 245.7 MB)
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] handled message (6.108039 ms) UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_12_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$eb]
15/08/11 10:18:50 INFO ContextCleaner: Cleaned broadcast 12
15/08/11 10:18:50 DEBUG ContextCleaner: Got cleaning task CleanBroadcast(11)
15/08/11 10:18:50 DEBUG ContextCleaner: Cleaning broadcast 11
15/08/11 10:18:50 DEBUG TorrentBroadcast: Unpersisting TorrentBroadcast 11
15/08/11 10:18:50 INFO MemoryStore: ensureFreeSpace(3201) called with curMem=213557, maxMem=278302556
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] received message RemoveBroadcast(11,true) from Actor[akka://sparkDriver/temp/$Bd]
15/08/11 10:18:50 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 3.1 KB, free 265.2 MB)
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] handled message (0.849495 ms) RemoveBroadcast(11,true) from Actor[akka://sparkDriver/temp/$Bd]
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_15_piece0,StorageLevel(false, true, false, false, 1),3201,0,0) from Actor[akka://sparkDriver/temp/$Ed]
15/08/11 10:18:50 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 192.168.130.131:57830 (size: 3.1 KB, free: 265.4 MB)
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] handled message (0.709751 ms) UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_15_piece0,StorageLevel(false, true, false, false, 1),3201,0,0) from Actor[akka://sparkDriver/temp/$Ed]
15/08/11 10:18:50 DEBUG BlockManagerSlaveActor: [actor] received message RemoveBroadcast(11,true) from Actor[akka://sparkDriver/temp/$Cd]
15/08/11 10:18:50 DEBUG BlockManagerSlaveActor: [actor] handled message (0.067196 ms) RemoveBroadcast(11,true) from Actor[akka://sparkDriver/temp/$Cd]
15/08/11 10:18:50 DEBUG BlockManagerSlaveActor: removing broadcast 11
15/08/11 10:18:50 INFO BlockManager: Removing broadcast 11
15/08/11 10:18:50 INFO BlockManager: Removing block broadcast_11
15/08/11 10:18:50 INFO MemoryStore: Block broadcast_11 of size 4768 dropped from memory (free 278090566)
15/08/11 10:18:50 INFO BlockManager: Removing block broadcast_11_piece0
15/08/11 10:18:50 INFO MemoryStore: Block broadcast_11_piece0 of size 3202 dropped from memory (free 278093768)
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_11_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka://sparkDriver/temp/$Fd]
15/08/11 10:18:50 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 192.168.130.131:57830 in memory (size: 3.1 KB, free: 265.4 MB)
15/08/11 10:18:50 INFO BlockManagerMaster: Updated info of block broadcast_15_piece0
15/08/11 10:18:50 DEBUG BlockManager: Told master about block broadcast_15_piece0
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] handled message (0.78922 ms) UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_11_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka://sparkDriver/temp/$Fd]
15/08/11 10:18:50 DEBUG BlockManager: Put block broadcast_15_piece0 locally took  18 ms
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_11_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$fb]
15/08/11 10:18:50 DEBUG BlockManager: Putting block broadcast_15_piece0 without replication took  18 ms
15/08/11 10:18:50 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 192.168.130.131:47921 in memory (size: 3.1 KB, free: 245.7 MB)
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] handled message (0.601992 ms) UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_11_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$fb]
15/08/11 10:18:50 INFO BlockManagerMaster: Updated info of block broadcast_11_piece0
15/08/11 10:18:50 DEBUG BlockManager: Told master about block broadcast_11_piece0
15/08/11 10:18:50 DEBUG BlockManagerSlaveActor: Done removing broadcast 11, response is 2
15/08/11 10:18:50 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:852
15/08/11 10:18:50 DEBUG BlockManagerSlaveActor: Sent response: 2 to Actor[akka://sparkDriver/temp/$Cd]
15/08/11 10:18:50 INFO ContextCleaner: Cleaned broadcast 11
15/08/11 10:18:50 DEBUG ContextCleaner: Got cleaning task CleanShuffle(4)
15/08/11 10:18:50 DEBUG ContextCleaner: Cleaning shuffle 4
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] received message RemoveShuffle(4) from Actor[akka://sparkDriver/temp/$Gd]
15/08/11 10:18:50 INFO DAGScheduler: Submitting 3 missing tasks from Stage 14 (MapPartitionsRDD[22] at map at KMeansTest.scala:61)
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] handled message (0.829165 ms) RemoveShuffle(4) from Actor[akka://sparkDriver/temp/$Gd]
15/08/11 10:18:50 DEBUG BlockManagerSlaveActor: [actor] received message RemoveShuffle(4) from Actor[akka://sparkDriver/temp/$Id]
15/08/11 10:18:50 DEBUG BlockManagerSlaveActor: removing shuffle 4
15/08/11 10:18:50 DEBUG BlockManagerSlaveActor: [actor] handled message (0.046268 ms) RemoveShuffle(4) from Actor[akka://sparkDriver/temp/$Id]
15/08/11 10:18:50 DEBUG BlockManagerSlaveActor: Done removing shuffle 4, response is true
15/08/11 10:18:50 DEBUG BlockManagerSlaveActor: Sent response: true to Actor[akka://sparkDriver/temp/$Id]
15/08/11 10:18:50 INFO ContextCleaner: Cleaned shuffle 4
15/08/11 10:18:50 DEBUG ContextCleaner: Got cleaning task CleanBroadcast(10)
15/08/11 10:18:50 DEBUG ContextCleaner: Cleaning broadcast 10
15/08/11 10:18:50 DEBUG TorrentBroadcast: Unpersisting TorrentBroadcast 10
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] received message RemoveBroadcast(10,true) from Actor[akka://sparkDriver/temp/$Jd]
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] handled message (0.621749 ms) RemoveBroadcast(10,true) from Actor[akka://sparkDriver/temp/$Jd]
15/08/11 10:18:50 DEBUG BlockManagerSlaveActor: [actor] received message RemoveBroadcast(10,true) from Actor[akka://sparkDriver/temp/$Kd]
15/08/11 10:18:50 DEBUG BlockManagerSlaveActor: [actor] handled message (0.05726 ms) RemoveBroadcast(10,true) from Actor[akka://sparkDriver/temp/$Kd]
15/08/11 10:18:50 DEBUG BlockManagerSlaveActor: removing broadcast 10
15/08/11 10:18:50 INFO BlockManager: Removing broadcast 10
15/08/11 10:18:50 INFO BlockManager: Removing block broadcast_10
15/08/11 10:18:50 INFO MemoryStore: Block broadcast_10 of size 2560 dropped from memory (free 278096328)
15/08/11 10:18:50 INFO BlockManager: Removing block broadcast_10_piece0
15/08/11 10:18:50 INFO MemoryStore: Block broadcast_10_piece0 of size 1517 dropped from memory (free 278097845)
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_10_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka://sparkDriver/temp/$Md]
15/08/11 10:18:50 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 192.168.130.131:57830 in memory (size: 1517.0 B, free: 265.4 MB)
15/08/11 10:18:50 INFO BlockManagerMaster: Updated info of block broadcast_10_piece0
15/08/11 10:18:50 DEBUG BlockManager: Told master about block broadcast_10_piece0
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] handled message (0.737584 ms) UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_10_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka://sparkDriver/temp/$Md]
15/08/11 10:18:50 DEBUG BlockManagerSlaveActor: Done removing broadcast 10, response is 2
15/08/11 10:18:50 DEBUG BlockManagerSlaveActor: Sent response: 2 to Actor[akka://sparkDriver/temp/$Kd]
15/08/11 10:18:50 DEBUG DAGScheduler: New pending tasks: Set(ShuffleMapTask(14, 0), ShuffleMapTask(14, 2), ShuffleMapTask(14, 1))
15/08/11 10:18:50 INFO TaskSchedulerImpl: Adding task set 14.0 with 3 tasks
15/08/11 10:18:50 DEBUG TaskSetManager: Epoch for TaskSet 14.0: 6
15/08/11 10:18:50 DEBUG TaskSetManager: Valid locality levels for TaskSet 14.0: PROCESS_LOCAL, NODE_LOCAL, ANY
15/08/11 10:18:50 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/deadLetters]
15/08/11 10:18:50 DEBUG DAGScheduler: submitStage(Stage 15)
15/08/11 10:18:50 DEBUG DAGScheduler: missing: List(Stage 14)
15/08/11 10:18:50 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_14, runningTasks: 0
15/08/11 10:18:50 DEBUG DAGScheduler: submitStage(Stage 14)
15/08/11 10:18:50 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 42, 192.168.130.131, PROCESS_LOCAL, 1361 bytes)
15/08/11 10:18:50 INFO TaskSetManager: Starting task 1.0 in stage 14.0 (TID 43, 192.168.130.131, PROCESS_LOCAL, 1361 bytes)
15/08/11 10:18:50 DEBUG DAGScheduler: submitStage(Stage 15)
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_10_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$gb]
15/08/11 10:18:50 DEBUG DAGScheduler: missing: List(Stage 14)
15/08/11 10:18:50 DEBUG DAGScheduler: submitStage(Stage 14)
15/08/11 10:18:50 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 192.168.130.131:47921 in memory (size: 1517.0 B, free: 245.7 MB)
15/08/11 10:18:50 DEBUG DAGScheduler: submitStage(Stage 15)
15/08/11 10:18:50 INFO ContextCleaner: Cleaned broadcast 10
15/08/11 10:18:50 DEBUG ContextCleaner: Got cleaning task CleanBroadcast(9)
15/08/11 10:18:50 DEBUG ContextCleaner: Cleaning broadcast 9
15/08/11 10:18:50 DEBUG TorrentBroadcast: Unpersisting TorrentBroadcast 9
15/08/11 10:18:50 INFO TaskSetManager: Starting task 2.0 in stage 14.0 (TID 44, 192.168.130.131, PROCESS_LOCAL, 1361 bytes)
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] handled message (0.799643 ms) UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_10_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$gb]
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] received message RemoveBroadcast(9,true) from Actor[akka://sparkDriver/temp/$Nd]
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] handled message (0.644795 ms) RemoveBroadcast(9,true) from Actor[akka://sparkDriver/temp/$Nd]
15/08/11 10:18:50 DEBUG BlockManagerSlaveActor: [actor] received message RemoveBroadcast(9,true) from Actor[akka://sparkDriver/temp/$Od]
15/08/11 10:18:50 DEBUG BlockManagerSlaveActor: removing broadcast 9
15/08/11 10:18:50 INFO BlockManager: Removing broadcast 9
15/08/11 10:18:50 INFO BlockManager: Removing block broadcast_9
15/08/11 10:18:50 INFO MemoryStore: Block broadcast_9 of size 4768 dropped from memory (free 278102613)
15/08/11 10:18:50 INFO BlockManager: Removing block broadcast_9_piece0
15/08/11 10:18:50 INFO MemoryStore: Block broadcast_9_piece0 of size 3205 dropped from memory (free 278105818)
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_9_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka://sparkDriver/temp/$Qd]
15/08/11 10:18:50 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 192.168.130.131:57830 in memory (size: 3.1 KB, free: 265.4 MB)
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] handled message (0.765023 ms) UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_9_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka://sparkDriver/temp/$Qd]
15/08/11 10:18:50 INFO BlockManagerMaster: Updated info of block broadcast_9_piece0
15/08/11 10:18:50 DEBUG BlockManager: Told master about block broadcast_9_piece0
15/08/11 10:18:50 DEBUG BlockManagerSlaveActor: Done removing broadcast 9, response is 2
15/08/11 10:18:50 DEBUG BlockManagerSlaveActor: Sent response: 2 to Actor[akka://sparkDriver/temp/$Od]
15/08/11 10:18:50 DEBUG BlockManagerSlaveActor: [actor] handled message (0.113848 ms) RemoveBroadcast(9,true) from Actor[akka://sparkDriver/temp/$Od]
15/08/11 10:18:50 DEBUG TaskSetManager: No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_9_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$hb]
15/08/11 10:18:50 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 192.168.130.131:47921 in memory (size: 3.1 KB, free: 245.7 MB)
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] handled message (0.932301 ms) UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_9_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$hb]
15/08/11 10:18:50 DEBUG TaskSetManager: No tasks for locality level NODE_LOCAL, so moving to locality level ANY
15/08/11 10:18:50 INFO ContextCleaner: Cleaned broadcast 9
15/08/11 10:18:50 DEBUG ContextCleaner: Got cleaning task CleanShuffle(3)
15/08/11 10:18:50 DEBUG ContextCleaner: Cleaning shuffle 3
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] received message RemoveShuffle(3) from Actor[akka://sparkDriver/temp/$Rd]
15/08/11 10:18:50 DEBUG BlockManagerSlaveActor: [actor] received message RemoveShuffle(3) from Actor[akka://sparkDriver/temp/$Sd]
15/08/11 10:18:50 DEBUG BlockManagerSlaveActor: [actor] handled message (0.050326 ms) RemoveShuffle(3) from Actor[akka://sparkDriver/temp/$Sd]
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] handled message (0.602257 ms) RemoveShuffle(3) from Actor[akka://sparkDriver/temp/$Rd]
15/08/11 10:18:50 DEBUG BlockManagerSlaveActor: removing shuffle 3
15/08/11 10:18:50 INFO ContextCleaner: Cleaned shuffle 3
15/08/11 10:18:50 DEBUG ContextCleaner: Got cleaning task CleanBroadcast(8)
15/08/11 10:18:50 DEBUG BlockManagerSlaveActor: Done removing shuffle 3, response is true
15/08/11 10:18:50 DEBUG BlockManagerSlaveActor: Sent response: true to Actor[akka://sparkDriver/temp/$Sd]
15/08/11 10:18:50 DEBUG ContextCleaner: Cleaning broadcast 8
15/08/11 10:18:50 DEBUG TorrentBroadcast: Unpersisting TorrentBroadcast 8
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] received message RemoveBroadcast(8,true) from Actor[akka://sparkDriver/temp/$Ud]
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] handled message (0.480083 ms) RemoveBroadcast(8,true) from Actor[akka://sparkDriver/temp/$Ud]
15/08/11 10:18:50 DEBUG BlockManagerSlaveActor: [actor] received message RemoveBroadcast(8,true) from Actor[akka://sparkDriver/temp/$Vd]
15/08/11 10:18:50 DEBUG BlockManagerSlaveActor: removing broadcast 8
15/08/11 10:18:50 INFO BlockManager: Removing broadcast 8
15/08/11 10:18:50 INFO BlockManager: Removing block broadcast_8
15/08/11 10:18:50 INFO MemoryStore: Block broadcast_8 of size 2560 dropped from memory (free 278108378)
15/08/11 10:18:50 INFO BlockManager: Removing block broadcast_8_piece0
15/08/11 10:18:50 INFO MemoryStore: Block broadcast_8_piece0 of size 1521 dropped from memory (free 278109899)
15/08/11 10:18:50 DEBUG BlockManagerSlaveActor: [actor] handled message (1.241441 ms) RemoveBroadcast(8,true) from Actor[akka://sparkDriver/temp/$Vd]
15/08/11 10:18:50 DEBUG DAGScheduler: missing: List(Stage 14)
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_8_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka://sparkDriver/temp/$Wd]
15/08/11 10:18:50 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 192.168.130.131:57830 in memory (size: 1521.0 B, free: 265.4 MB)
15/08/11 10:18:50 INFO BlockManagerMaster: Updated info of block broadcast_8_piece0
15/08/11 10:18:50 DEBUG BlockManager: Told master about block broadcast_8_piece0
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] handled message (2.677215 ms) UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_8_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka://sparkDriver/temp/$Wd]
15/08/11 10:18:50 DEBUG BlockManagerSlaveActor: Done removing broadcast 8, response is 2
15/08/11 10:18:50 DEBUG BlockManagerSlaveActor: Sent response: 2 to Actor[akka://sparkDriver/temp/$Vd]
15/08/11 10:18:50 DEBUG DAGScheduler: submitStage(Stage 14)
15/08/11 10:18:50 DEBUG DAGScheduler: submitStage(Stage 15)
15/08/11 10:18:50 DEBUG SparkDeploySchedulerBackend: [actor] handled message (47.894427 ms) ReviveOffers from Actor[akka://sparkDriver/deadLetters]
15/08/11 10:18:50 DEBUG DAGScheduler: missing: List(Stage 14)
15/08/11 10:18:50 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,42,RUNNING,org.apache.spark.util.SerializableBuffer@4490389) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:50 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.06449 ms) StatusUpdate(0,42,RUNNING,org.apache.spark.util.SerializableBuffer@4490389) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:50 DEBUG DAGScheduler: submitStage(Stage 14)
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] received message GetLocations(broadcast_15_piece0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$ib]
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] handled message (0.130199 ms) GetLocations(broadcast_15_piece0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$ib]
15/08/11 10:18:50 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,43,RUNNING,org.apache.spark.util.SerializableBuffer@2bf925bb) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:50 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.069204 ms) StatusUpdate(0,43,RUNNING,org.apache.spark.util.SerializableBuffer@2bf925bb) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:50 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,44,RUNNING,org.apache.spark.util.SerializableBuffer@721c2e8a) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:50 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.063013 ms) StatusUpdate(0,44,RUNNING,org.apache.spark.util.SerializableBuffer@721c2e8a) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:50 DEBUG BlockManager: Level for block broadcast_15_piece0 is StorageLevel(true, true, false, false, 1)
15/08/11 10:18:50 DEBUG BlockManager: Getting block broadcast_15_piece0 from memory
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_8_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$jb]
15/08/11 10:18:50 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 192.168.130.131:47921 in memory (size: 1521.0 B, free: 245.7 MB)
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] handled message (0.640969 ms) UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_8_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$jb]
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_15_piece0,StorageLevel(false, true, false, false, 1),3201,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$kb]
15/08/11 10:18:50 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 192.168.130.131:47921 (size: 3.1 KB, free: 245.7 MB)
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] handled message (0.65516 ms) UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_15_piece0,StorageLevel(false, true, false, false, 1),3201,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$kb]
15/08/11 10:18:50 INFO ContextCleaner: Cleaned broadcast 8
15/08/11 10:18:50 DEBUG ContextCleaner: Got cleaning task CleanBroadcast(7)
15/08/11 10:18:50 DEBUG ContextCleaner: Cleaning broadcast 7
15/08/11 10:18:50 DEBUG TorrentBroadcast: Unpersisting TorrentBroadcast 7
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] received message RemoveBroadcast(7,true) from Actor[akka://sparkDriver/temp/$Yd]
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] handled message (0.586791 ms) RemoveBroadcast(7,true) from Actor[akka://sparkDriver/temp/$Yd]
15/08/11 10:18:50 DEBUG BlockManagerSlaveActor: [actor] received message RemoveBroadcast(7,true) from Actor[akka://sparkDriver/temp/$Zd]
15/08/11 10:18:50 DEBUG BlockManagerSlaveActor: removing broadcast 7
15/08/11 10:18:50 INFO BlockManager: Removing broadcast 7
15/08/11 10:18:50 INFO BlockManager: Removing block broadcast_7
15/08/11 10:18:50 INFO MemoryStore: Block broadcast_7 of size 4768 dropped from memory (free 278114667)
15/08/11 10:18:50 INFO BlockManager: Removing block broadcast_7_piece0
15/08/11 10:18:50 INFO MemoryStore: Block broadcast_7_piece0 of size 3205 dropped from memory (free 278117872)
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_7_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka://sparkDriver/temp/$0d]
15/08/11 10:18:50 DEBUG BlockManagerSlaveActor: [actor] handled message (1.104097 ms) RemoveBroadcast(7,true) from Actor[akka://sparkDriver/temp/$Zd]
15/08/11 10:18:50 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 192.168.130.131:57830 in memory (size: 3.1 KB, free: 265.4 MB)
15/08/11 10:18:50 INFO BlockManagerMaster: Updated info of block broadcast_7_piece0
15/08/11 10:18:50 DEBUG BlockManager: Told master about block broadcast_7_piece0
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] handled message (6.459969 ms) UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_7_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka://sparkDriver/temp/$0d]
15/08/11 10:18:50 DEBUG BlockManagerSlaveActor: Done removing broadcast 7, response is 2
15/08/11 10:18:50 DEBUG BlockManagerSlaveActor: Sent response: 2 to Actor[akka://sparkDriver/temp/$Zd]
15/08/11 10:18:50 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:50 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_14, runningTasks: 3
15/08/11 10:18:50 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.512257 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_7_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$lb]
15/08/11 10:18:50 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 192.168.130.131:47921 in memory (size: 3.1 KB, free: 245.7 MB)
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] handled message (0.913151 ms) UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_7_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$lb]
15/08/11 10:18:50 INFO ContextCleaner: Cleaned broadcast 7
15/08/11 10:18:50 DEBUG ContextCleaner: Got cleaning task CleanShuffle(2)
15/08/11 10:18:50 DEBUG ContextCleaner: Cleaning shuffle 2
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] received message RemoveShuffle(2) from Actor[akka://sparkDriver/temp/$2d]
15/08/11 10:18:50 DEBUG BlockManagerSlaveActor: [actor] received message RemoveShuffle(2) from Actor[akka://sparkDriver/temp/$3d]
15/08/11 10:18:50 DEBUG BlockManagerSlaveActor: [actor] handled message (0.050966 ms) RemoveShuffle(2) from Actor[akka://sparkDriver/temp/$3d]
15/08/11 10:18:50 DEBUG BlockManagerSlaveActor: removing shuffle 2
15/08/11 10:18:50 INFO ContextCleaner: Cleaned shuffle 2
15/08/11 10:18:50 DEBUG BlockManagerSlaveActor: Done removing shuffle 2, response is true
15/08/11 10:18:50 DEBUG BlockManagerSlaveActor: Sent response: true to Actor[akka://sparkDriver/temp/$3d]
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] handled message (0.86522 ms) RemoveShuffle(2) from Actor[akka://sparkDriver/temp/$2d]
15/08/11 10:18:50 DEBUG ContextCleaner: Got cleaning task CleanBroadcast(6)
15/08/11 10:18:50 DEBUG ContextCleaner: Cleaning broadcast 6
15/08/11 10:18:50 DEBUG TorrentBroadcast: Unpersisting TorrentBroadcast 6
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] received message RemoveBroadcast(6,true) from Actor[akka://sparkDriver/temp/$5d]
15/08/11 10:18:50 DEBUG BlockManagerSlaveActor: [actor] received message RemoveBroadcast(6,true) from Actor[akka://sparkDriver/temp/$6d]
15/08/11 10:18:50 DEBUG BlockManagerSlaveActor: [actor] handled message (0.050182 ms) RemoveBroadcast(6,true) from Actor[akka://sparkDriver/temp/$6d]
15/08/11 10:18:50 DEBUG BlockManagerSlaveActor: removing broadcast 6
15/08/11 10:18:50 INFO BlockManager: Removing broadcast 6
15/08/11 10:18:50 INFO BlockManager: Removing block broadcast_6_piece0
15/08/11 10:18:50 INFO MemoryStore: Block broadcast_6_piece0 of size 1520 dropped from memory (free 278119392)
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] handled message (0.419853 ms) RemoveBroadcast(6,true) from Actor[akka://sparkDriver/temp/$5d]
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_6_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka://sparkDriver/temp/$8d]
15/08/11 10:18:50 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 192.168.130.131:57830 in memory (size: 1520.0 B, free: 265.4 MB)
15/08/11 10:18:50 INFO BlockManagerMaster: Updated info of block broadcast_6_piece0
15/08/11 10:18:50 DEBUG BlockManager: Told master about block broadcast_6_piece0
15/08/11 10:18:50 INFO BlockManager: Removing block broadcast_6
15/08/11 10:18:50 INFO MemoryStore: Block broadcast_6 of size 2560 dropped from memory (free 278121952)
15/08/11 10:18:50 DEBUG BlockManagerSlaveActor: Done removing broadcast 6, response is 2
15/08/11 10:18:50 DEBUG BlockManagerSlaveActor: Sent response: 2 to Actor[akka://sparkDriver/temp/$6d]
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] handled message (7.774674 ms) UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_6_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka://sparkDriver/temp/$8d]
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_6_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$mb]
15/08/11 10:18:50 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 192.168.130.131:47921 in memory (size: 1520.0 B, free: 245.7 MB)
15/08/11 10:18:50 DEBUG BlockManagerMasterActor: [actor] handled message (0.752475 ms) UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_6_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$mb]
15/08/11 10:18:50 INFO ContextCleaner: Cleaned broadcast 6
15/08/11 10:18:51 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:51 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_14, runningTasks: 3
15/08/11 10:18:51 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.793922 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:51 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,44,FINISHED,org.apache.spark.util.SerializableBuffer@822585) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:51 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_14, runningTasks: 2
15/08/11 10:18:51 DEBUG SparkDeploySchedulerBackend: [actor] handled message (1.381703 ms) StatusUpdate(0,44,FINISHED,org.apache.spark.util.SerializableBuffer@822585) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:51 DEBUG DAGScheduler: ShuffleMapTask finished on 0
15/08/11 10:18:51 DEBUG DAGScheduler: submitStage(Stage 15)
15/08/11 10:18:51 DEBUG DAGScheduler: missing: List(Stage 14)
15/08/11 10:18:51 DEBUG DAGScheduler: submitStage(Stage 14)
15/08/11 10:18:51 INFO TaskSetManager: Finished task 2.0 in stage 14.0 (TID 44) in 1134 ms on 192.168.130.131 (1/3)
15/08/11 10:18:52 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:52 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_14, runningTasks: 2
15/08/11 10:18:52 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.999338 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:53 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,43,FINISHED,org.apache.spark.util.SerializableBuffer@606d3f05) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:53 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_14, runningTasks: 1
15/08/11 10:18:53 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.908597 ms) StatusUpdate(0,43,FINISHED,org.apache.spark.util.SerializableBuffer@606d3f05) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:53 DEBUG DAGScheduler: ShuffleMapTask finished on 0
15/08/11 10:18:53 DEBUG DAGScheduler: submitStage(Stage 15)
15/08/11 10:18:53 DEBUG DAGScheduler: missing: List(Stage 14)
15/08/11 10:18:53 DEBUG DAGScheduler: submitStage(Stage 14)
15/08/11 10:18:53 INFO TaskSetManager: Finished task 1.0 in stage 14.0 (TID 43) in 2403 ms on 192.168.130.131 (2/3)
15/08/11 10:18:53 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,42,FINISHED,org.apache.spark.util.SerializableBuffer@244492b8) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:53 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_14, runningTasks: 0
15/08/11 10:18:53 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.684387 ms) StatusUpdate(0,42,FINISHED,org.apache.spark.util.SerializableBuffer@244492b8) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:53 DEBUG DAGScheduler: ShuffleMapTask finished on 0
15/08/11 10:18:53 INFO DAGScheduler: Stage 14 (map at KMeansTest.scala:61) finished in 2.543 s
15/08/11 10:18:53 INFO DAGScheduler: looking for newly runnable stages
15/08/11 10:18:53 INFO DAGScheduler: running: Set()
15/08/11 10:18:53 INFO DAGScheduler: waiting: Set(Stage 15)
15/08/11 10:18:53 INFO DAGScheduler: failed: Set()
15/08/11 10:18:53 DEBUG MapOutputTrackerMaster: Increasing epoch to 7
15/08/11 10:18:53 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD MapPartitionsRDD[24] at map at KMeansTest.scala:65
15/08/11 10:18:53 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:18:53 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 42) in 2537 ms on 192.168.130.131 (3/3)
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@11fc80a2) from Actor[akka://sparkDriver/temp/$9d]
15/08/11 10:18:53 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: [actor] handled message (0.241746 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@11fc80a2) from Actor[akka://sparkDriver/temp/$9d]
15/08/11 10:18:53 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@11fc80a2) from Actor[akka://sparkDriver/temp/$+d]
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: [actor] handled message (0.209173 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@11fc80a2) from Actor[akka://sparkDriver/temp/$+d]
15/08/11 10:18:53 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:18:53 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:18:53 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|24|0,rdd_24_0,, null|24|1,rdd_24_1,, null|24|2,rdd_24_2,).
15/08/11 10:18:53 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$ae]
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: [actor] handled message (0.66661 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$ae]
15/08/11 10:18:53 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:18:53 DEBUG BlockManager: Got multiple block location in  10 ms
15/08/11 10:18:53 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD ShuffledRDD[23] at reduceByKey at KMeansTest.scala:63
15/08/11 10:18:53 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@42cc5534) from Actor[akka://sparkDriver/temp/$be]
15/08/11 10:18:53 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: [actor] handled message (0.199381 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@42cc5534) from Actor[akka://sparkDriver/temp/$be]
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@42cc5534) from Actor[akka://sparkDriver/temp/$ce]
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: [actor] handled message (0.221289 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@42cc5534) from Actor[akka://sparkDriver/temp/$ce]
15/08/11 10:18:53 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:18:53 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:18:53 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|23|0,rdd_23_0,, null|23|1,rdd_23_1,, null|23|2,rdd_23_2,).
15/08/11 10:18:53 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$ee]
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: [actor] handled message (0.776104 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$ee]
15/08/11 10:18:53 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:18:53 DEBUG BlockManager: Got multiple block location in  11 ms
15/08/11 10:18:53 INFO DAGScheduler: Missing parents for Stage 15: List()
15/08/11 10:18:53 INFO DAGScheduler: Submitting Stage 15 (MapPartitionsRDD[24] at map at KMeansTest.scala:65), which is now runnable
15/08/11 10:18:53 DEBUG DAGScheduler: submitMissingTasks(Stage 15)
15/08/11 10:18:53 INFO MemoryStore: ensureFreeSpace(2560) called with curMem=180604, maxMem=278302556
15/08/11 10:18:53 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 2.5 KB, free 265.2 MB)
15/08/11 10:18:53 DEBUG BlockManager: Put block broadcast_16 locally took  2 ms
15/08/11 10:18:53 DEBUG BlockManager: Putting block broadcast_16 without replication took  3 ms
15/08/11 10:18:53 INFO MemoryStore: ensureFreeSpace(1521) called with curMem=183164, maxMem=278302556
15/08/11 10:18:53 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 1521.0 B, free 265.2 MB)
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_16_piece0,StorageLevel(false, true, false, false, 1),1521,0,0) from Actor[akka://sparkDriver/temp/$fe]
15/08/11 10:18:53 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 192.168.130.131:57830 (size: 1521.0 B, free: 265.4 MB)
15/08/11 10:18:53 INFO BlockManagerMaster: Updated info of block broadcast_16_piece0
15/08/11 10:18:53 DEBUG BlockManager: Told master about block broadcast_16_piece0
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: [actor] handled message (0.566946 ms) UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_16_piece0,StorageLevel(false, true, false, false, 1),1521,0,0) from Actor[akka://sparkDriver/temp/$fe]
15/08/11 10:18:53 DEBUG BlockManager: Put block broadcast_16_piece0 locally took  2 ms
15/08/11 10:18:53 DEBUG BlockManager: Putting block broadcast_16_piece0 without replication took  2 ms
15/08/11 10:18:53 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:852
15/08/11 10:18:53 INFO DAGScheduler: Submitting 3 missing tasks from Stage 15 (MapPartitionsRDD[24] at map at KMeansTest.scala:65)
15/08/11 10:18:53 DEBUG DAGScheduler: New pending tasks: Set(ResultTask(15, 0), ResultTask(15, 1), ResultTask(15, 2))
15/08/11 10:18:53 INFO TaskSchedulerImpl: Adding task set 15.0 with 3 tasks
15/08/11 10:18:53 DEBUG TaskSetManager: Epoch for TaskSet 15.0: 7
15/08/11 10:18:53 DEBUG TaskSetManager: Valid locality levels for TaskSet 15.0: NO_PREF, ANY
15/08/11 10:18:53 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/deadLetters]
15/08/11 10:18:53 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_15, runningTasks: 0
15/08/11 10:18:53 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 45, 192.168.130.131, PROCESS_LOCAL, 1116 bytes)
15/08/11 10:18:53 INFO TaskSetManager: Starting task 1.0 in stage 15.0 (TID 46, 192.168.130.131, PROCESS_LOCAL, 1116 bytes)
15/08/11 10:18:53 INFO TaskSetManager: Starting task 2.0 in stage 15.0 (TID 47, 192.168.130.131, PROCESS_LOCAL, 1116 bytes)
15/08/11 10:18:53 DEBUG TaskSetManager: No tasks for locality level NO_PREF, so moving to locality level ANY
15/08/11 10:18:53 DEBUG SparkDeploySchedulerBackend: [actor] handled message (3.635893 ms) ReviveOffers from Actor[akka://sparkDriver/deadLetters]
15/08/11 10:18:53 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,45,RUNNING,org.apache.spark.util.SerializableBuffer@268b038a) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:53 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.054015 ms) StatusUpdate(0,45,RUNNING,org.apache.spark.util.SerializableBuffer@268b038a) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: [actor] received message GetLocations(broadcast_16_piece0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$nb]
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: [actor] handled message (0.83331 ms) GetLocations(broadcast_16_piece0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$nb]
15/08/11 10:18:53 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,46,RUNNING,org.apache.spark.util.SerializableBuffer@2d388e7b) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:53 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.054512 ms) StatusUpdate(0,46,RUNNING,org.apache.spark.util.SerializableBuffer@2d388e7b) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:53 DEBUG BlockManager: Level for block broadcast_16_piece0 is StorageLevel(true, true, false, false, 1)
15/08/11 10:18:53 DEBUG BlockManager: Getting block broadcast_16_piece0 from memory
15/08/11 10:18:53 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,47,RUNNING,org.apache.spark.util.SerializableBuffer@70c3b90b) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:53 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.049547 ms) StatusUpdate(0,47,RUNNING,org.apache.spark.util.SerializableBuffer@70c3b90b) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_16_piece0,StorageLevel(false, true, false, false, 1),1521,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$ob]
15/08/11 10:18:53 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 192.168.130.131:47921 (size: 1521.0 B, free: 245.7 MB)
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: [actor] handled message (0.582678 ms) UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_16_piece0,StorageLevel(false, true, false, false, 1),1521,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$ob]
15/08/11 10:18:53 DEBUG MapOutputTrackerMasterActor: [actor] received message GetMapOutputStatuses(6) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$pb]
15/08/11 10:18:53 INFO MapOutputTrackerMasterActor: Asked to send map output locations for shuffle 6 to sparkExecutor@192.168.130.131:49489
15/08/11 10:18:53 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 6 is 162 bytes
15/08/11 10:18:53 DEBUG MapOutputTrackerMasterActor: [actor] handled message (0.832286 ms) GetMapOutputStatuses(6) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$pb]
15/08/11 10:18:53 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,47,FINISHED,org.apache.spark.util.SerializableBuffer@3fd99b7b) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:53 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_15, runningTasks: 2
15/08/11 10:18:53 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.925442 ms) StatusUpdate(0,47,FINISHED,org.apache.spark.util.SerializableBuffer@3fd99b7b) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:53 INFO TaskSetManager: Finished task 2.0 in stage 15.0 (TID 47) in 72 ms on 192.168.130.131 (1/3)
15/08/11 10:18:53 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,46,FINISHED,org.apache.spark.util.SerializableBuffer@49174334) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:53 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_15, runningTasks: 1
15/08/11 10:18:53 DEBUG SparkDeploySchedulerBackend: [actor] handled message (1.01303 ms) StatusUpdate(0,46,FINISHED,org.apache.spark.util.SerializableBuffer@49174334) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:53 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,45,FINISHED,org.apache.spark.util.SerializableBuffer@163d3069) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:53 INFO TaskSetManager: Finished task 1.0 in stage 15.0 (TID 46) in 103 ms on 192.168.130.131 (2/3)
15/08/11 10:18:53 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_15, runningTasks: 0
15/08/11 10:18:53 DEBUG SparkDeploySchedulerBackend: [actor] handled message (9.59406 ms) StatusUpdate(0,45,FINISHED,org.apache.spark.util.SerializableBuffer@163d3069) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:53 INFO DAGScheduler: Stage 15 (collectAsMap at KMeansTest.scala:67) finished in 0.123 s
15/08/11 10:18:53 DEBUG DAGScheduler: After removal of stage 14, remaining stages = 1
15/08/11 10:18:53 DEBUG DAGScheduler: After removal of stage 15, remaining stages = 0
15/08/11 10:18:53 INFO DAGScheduler: Job 8 finished: collectAsMap at KMeansTest.scala:67, took 3.001944 s
Finished iteration (num = 6)
15/08/11 10:18:53 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 45) in 117 ms on 192.168.130.131 (3/3)
15/08/11 10:18:53 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
15/08/11 10:18:53 INFO SparkContext: Starting job: collectAsMap at KMeansTest.scala:67
15/08/11 10:18:53 INFO DAGScheduler: Registering RDD 25 (map at KMeansTest.scala:61)
15/08/11 10:18:53 INFO DAGScheduler: Got job 9 (collectAsMap at KMeansTest.scala:67) with 3 output partitions (allowLocal=false)
15/08/11 10:18:53 INFO DAGScheduler: Final stage: Stage 17(collectAsMap at KMeansTest.scala:67)
15/08/11 10:18:53 INFO DAGScheduler: Parents of final stage: List(Stage 16)
15/08/11 10:18:53 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD MapPartitionsRDD[27] at map at KMeansTest.scala:65
15/08/11 10:18:53 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@50d2d2b0) from Actor[akka://sparkDriver/temp/$ge]
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: [actor] handled message (0.22056 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@50d2d2b0) from Actor[akka://sparkDriver/temp/$ge]
15/08/11 10:18:53 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@50d2d2b0) from Actor[akka://sparkDriver/temp/$he]
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: [actor] handled message (0.184371 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@50d2d2b0) from Actor[akka://sparkDriver/temp/$he]
15/08/11 10:18:53 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:18:53 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:18:53 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|27|0,rdd_27_0,, null|27|1,rdd_27_1,, null|27|2,rdd_27_2,).
15/08/11 10:18:53 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$je]
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: [actor] handled message (0.903251 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$je]
15/08/11 10:18:53 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:18:53 DEBUG BlockManager: Got multiple block location in  11 ms
15/08/11 10:18:53 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD ShuffledRDD[26] at reduceByKey at KMeansTest.scala:63
15/08/11 10:18:53 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@569c5b67) from Actor[akka://sparkDriver/temp/$ke]
15/08/11 10:18:53 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: [actor] handled message (0.614265 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@569c5b67) from Actor[akka://sparkDriver/temp/$ke]
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@569c5b67) from Actor[akka://sparkDriver/temp/$le]
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: [actor] handled message (0.400334 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@569c5b67) from Actor[akka://sparkDriver/temp/$le]
15/08/11 10:18:53 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:18:53 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:18:53 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|26|0,rdd_26_0,, null|26|1,rdd_26_1,, null|26|2,rdd_26_2,).
15/08/11 10:18:53 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$ne]
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:18:53 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:18:53 DEBUG BlockManager: Got multiple block location in  12 ms
15/08/11 10:18:53 INFO DAGScheduler: [SMSpark v1]Missing parents: List(Stage 16)
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: [actor] handled message (1.13689 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$ne]
15/08/11 10:18:53 DEBUG DAGScheduler: submitStage(Stage 17)
15/08/11 10:18:53 DEBUG DAGScheduler: missing: List(Stage 16)
15/08/11 10:18:53 DEBUG DAGScheduler: submitStage(Stage 16)
15/08/11 10:18:53 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD MapPartitionsRDD[25] at map at KMeansTest.scala:61
15/08/11 10:18:53 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@7e52b02c) from Actor[akka://sparkDriver/temp/$oe]
15/08/11 10:18:53 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: [actor] handled message (0.491828 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@7e52b02c) from Actor[akka://sparkDriver/temp/$oe]
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@7e52b02c) from Actor[akka://sparkDriver/temp/$pe]
15/08/11 10:18:53 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: [actor] handled message (0.174726 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@7e52b02c) from Actor[akka://sparkDriver/temp/$pe]
15/08/11 10:18:53 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:18:53 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|25|0,rdd_25_0,, null|25|1,rdd_25_1,, null|25|2,rdd_25_2,).
15/08/11 10:18:53 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$re]
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: [actor] handled message (1.07567 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$re]
15/08/11 10:18:53 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:18:53 DEBUG BlockManager: Got multiple block location in  11 ms
15/08/11 10:18:53 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD KMeans01 MapPartitionsRDD[2] at map at KMeansTest.scala:50
15/08/11 10:18:53 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@41ac0d18) from Actor[akka://sparkDriver/temp/$se]
15/08/11 10:18:53 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(ArrayBuffer(BlockManagerId(0, 192.168.130.131, 47921)), ArrayBuffer(BlockManagerId(0, 192.168.130.131, 47921)), ArrayBuffer(BlockManagerId(0, 192.168.130.131, 47921)))
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: [actor] handled message (0.306258 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@41ac0d18) from Actor[akka://sparkDriver/temp/$se]
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@41ac0d18) from Actor[akka://sparkDriver/temp/$te]
15/08/11 10:18:53 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: [actor] handled message (0.251608 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@41ac0d18) from Actor[akka://sparkDriver/temp/$te]
15/08/11 10:18:53 DEBUG DAGScheduler: missing: List()
15/08/11 10:18:53 INFO DAGScheduler: Submitting Stage 16 (MapPartitionsRDD[25] at map at KMeansTest.scala:61), which has no missing parents
15/08/11 10:18:53 DEBUG DAGScheduler: submitMissingTasks(Stage 16)
15/08/11 10:18:53 INFO MemoryStore: ensureFreeSpace(4768) called with curMem=184685, maxMem=278302556
15/08/11 10:18:53 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 4.7 KB, free 265.2 MB)
15/08/11 10:18:53 DEBUG BlockManager: Put block broadcast_17 locally took  1 ms
15/08/11 10:18:53 DEBUG BlockManager: Putting block broadcast_17 without replication took  1 ms
15/08/11 10:18:53 INFO MemoryStore: ensureFreeSpace(3200) called with curMem=189453, maxMem=278302556
15/08/11 10:18:53 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 3.1 KB, free 265.2 MB)
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_17_piece0,StorageLevel(false, true, false, false, 1),3200,0,0) from Actor[akka://sparkDriver/temp/$ue]
15/08/11 10:18:53 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 192.168.130.131:57830 (size: 3.1 KB, free: 265.4 MB)
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: [actor] handled message (0.700358 ms) UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_17_piece0,StorageLevel(false, true, false, false, 1),3200,0,0) from Actor[akka://sparkDriver/temp/$ue]
15/08/11 10:18:53 INFO BlockManagerMaster: Updated info of block broadcast_17_piece0
15/08/11 10:18:53 DEBUG BlockManager: Told master about block broadcast_17_piece0
15/08/11 10:18:53 DEBUG BlockManager: Put block broadcast_17_piece0 locally took  3 ms
15/08/11 10:18:53 DEBUG BlockManager: Putting block broadcast_17_piece0 without replication took  3 ms
15/08/11 10:18:53 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:852
15/08/11 10:18:53 INFO DAGScheduler: Submitting 3 missing tasks from Stage 16 (MapPartitionsRDD[25] at map at KMeansTest.scala:61)
15/08/11 10:18:53 DEBUG DAGScheduler: New pending tasks: Set(ShuffleMapTask(16, 1), ShuffleMapTask(16, 2), ShuffleMapTask(16, 0))
15/08/11 10:18:53 INFO TaskSchedulerImpl: Adding task set 16.0 with 3 tasks
15/08/11 10:18:53 DEBUG TaskSetManager: Epoch for TaskSet 16.0: 7
15/08/11 10:18:53 DEBUG TaskSetManager: Valid locality levels for TaskSet 16.0: PROCESS_LOCAL, NODE_LOCAL, ANY
15/08/11 10:18:53 DEBUG DAGScheduler: submitStage(Stage 17)
15/08/11 10:18:53 DEBUG DAGScheduler: missing: List(Stage 16)
15/08/11 10:18:53 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/deadLetters]
15/08/11 10:18:53 DEBUG DAGScheduler: submitStage(Stage 16)
15/08/11 10:18:53 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16, runningTasks: 0
15/08/11 10:18:53 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 48, 192.168.130.131, PROCESS_LOCAL, 1361 bytes)
15/08/11 10:18:53 DEBUG DAGScheduler: submitStage(Stage 17)
15/08/11 10:18:53 INFO TaskSetManager: Starting task 1.0 in stage 16.0 (TID 49, 192.168.130.131, PROCESS_LOCAL, 1361 bytes)
15/08/11 10:18:53 DEBUG DAGScheduler: missing: List(Stage 16)
15/08/11 10:18:53 DEBUG DAGScheduler: submitStage(Stage 16)
15/08/11 10:18:53 DEBUG DAGScheduler: submitStage(Stage 17)
15/08/11 10:18:53 INFO TaskSetManager: Starting task 2.0 in stage 16.0 (TID 50, 192.168.130.131, PROCESS_LOCAL, 1361 bytes)
15/08/11 10:18:53 DEBUG DAGScheduler: missing: List(Stage 16)
15/08/11 10:18:53 DEBUG DAGScheduler: submitStage(Stage 16)
15/08/11 10:18:53 DEBUG TaskSetManager: No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
15/08/11 10:18:53 DEBUG TaskSetManager: No tasks for locality level NODE_LOCAL, so moving to locality level ANY
15/08/11 10:18:53 DEBUG DAGScheduler: submitStage(Stage 17)
15/08/11 10:18:53 DEBUG DAGScheduler: missing: List(Stage 16)
15/08/11 10:18:53 DEBUG DAGScheduler: submitStage(Stage 16)
15/08/11 10:18:53 DEBUG SparkDeploySchedulerBackend: [actor] handled message (5.65169 ms) ReviveOffers from Actor[akka://sparkDriver/deadLetters]
15/08/11 10:18:53 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,48,RUNNING,org.apache.spark.util.SerializableBuffer@3c35705f) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:53 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.055113 ms) StatusUpdate(0,48,RUNNING,org.apache.spark.util.SerializableBuffer@3c35705f) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: [actor] received message GetLocations(broadcast_17_piece0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$qb]
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: [actor] handled message (0.058498 ms) GetLocations(broadcast_17_piece0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$qb]
15/08/11 10:18:53 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,49,RUNNING,org.apache.spark.util.SerializableBuffer@24b9bfb7) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:53 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.074995 ms) StatusUpdate(0,49,RUNNING,org.apache.spark.util.SerializableBuffer@24b9bfb7) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:53 DEBUG BlockManager: Level for block broadcast_17_piece0 is StorageLevel(true, true, false, false, 1)
15/08/11 10:18:53 DEBUG BlockManager: Getting block broadcast_17_piece0 from memory
15/08/11 10:18:53 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,50,RUNNING,org.apache.spark.util.SerializableBuffer@601ba0b3) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:53 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.058865 ms) StatusUpdate(0,50,RUNNING,org.apache.spark.util.SerializableBuffer@601ba0b3) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_17_piece0,StorageLevel(false, true, false, false, 1),3200,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$rb]
15/08/11 10:18:53 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 192.168.130.131:47921 (size: 3.1 KB, free: 245.7 MB)
15/08/11 10:18:53 DEBUG BlockManagerMasterActor: [actor] handled message (1.365592 ms) UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_17_piece0,StorageLevel(false, true, false, false, 1),3200,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$rb]
15/08/11 10:18:53 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:53 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16, runningTasks: 3
15/08/11 10:18:53 DEBUG SparkDeploySchedulerBackend: [actor] handled message (1.225082 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:54 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,50,FINISHED,org.apache.spark.util.SerializableBuffer@4eb1250b) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:54 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16, runningTasks: 2
15/08/11 10:18:54 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.978993 ms) StatusUpdate(0,50,FINISHED,org.apache.spark.util.SerializableBuffer@4eb1250b) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:54 DEBUG DAGScheduler: ShuffleMapTask finished on 0
15/08/11 10:18:54 DEBUG DAGScheduler: submitStage(Stage 17)
15/08/11 10:18:54 DEBUG DAGScheduler: missing: List(Stage 16)
15/08/11 10:18:54 DEBUG DAGScheduler: submitStage(Stage 16)
15/08/11 10:18:54 INFO TaskSetManager: Finished task 2.0 in stage 16.0 (TID 50) in 631 ms on 192.168.130.131 (1/3)
15/08/11 10:18:54 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:54 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16, runningTasks: 2
15/08/11 10:18:54 DEBUG SparkDeploySchedulerBackend: [actor] handled message (1.063934 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:55 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:55 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16, runningTasks: 2
15/08/11 10:18:55 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.694472 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:56 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,48,FINISHED,org.apache.spark.util.SerializableBuffer@4ff71d89) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:56 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16, runningTasks: 1
15/08/11 10:18:56 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.647392 ms) StatusUpdate(0,48,FINISHED,org.apache.spark.util.SerializableBuffer@4ff71d89) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:56 DEBUG DAGScheduler: ShuffleMapTask finished on 0
15/08/11 10:18:56 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 48) in 2916 ms on 192.168.130.131 (2/3)
15/08/11 10:18:56 DEBUG DAGScheduler: submitStage(Stage 17)
15/08/11 10:18:56 DEBUG DAGScheduler: missing: List(Stage 16)
15/08/11 10:18:56 DEBUG DAGScheduler: submitStage(Stage 16)
15/08/11 10:18:56 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,49,FINISHED,org.apache.spark.util.SerializableBuffer@68b43662) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:56 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_16, runningTasks: 0
15/08/11 10:18:56 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.697094 ms) StatusUpdate(0,49,FINISHED,org.apache.spark.util.SerializableBuffer@68b43662) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:56 DEBUG DAGScheduler: ShuffleMapTask finished on 0
15/08/11 10:18:56 INFO DAGScheduler: Stage 16 (map at KMeansTest.scala:61) finished in 2.947 s
15/08/11 10:18:56 INFO TaskSetManager: Finished task 1.0 in stage 16.0 (TID 49) in 2941 ms on 192.168.130.131 (3/3)
15/08/11 10:18:56 INFO DAGScheduler: looking for newly runnable stages
15/08/11 10:18:56 INFO DAGScheduler: running: Set()
15/08/11 10:18:56 INFO DAGScheduler: waiting: Set(Stage 17)
15/08/11 10:18:56 INFO DAGScheduler: failed: Set()
15/08/11 10:18:56 DEBUG MapOutputTrackerMaster: Increasing epoch to 8
15/08/11 10:18:56 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD MapPartitionsRDD[27] at map at KMeansTest.scala:65
15/08/11 10:18:56 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@f5e91a2) from Actor[akka://sparkDriver/temp/$ve]
15/08/11 10:18:56 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: [actor] handled message (0.167807 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@f5e91a2) from Actor[akka://sparkDriver/temp/$ve]
15/08/11 10:18:56 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@f5e91a2) from Actor[akka://sparkDriver/temp/$we]
15/08/11 10:18:56 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: [actor] handled message (0.16429 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@f5e91a2) from Actor[akka://sparkDriver/temp/$we]
15/08/11 10:18:56 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:18:56 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|27|0,rdd_27_0,, null|27|1,rdd_27_1,, null|27|2,rdd_27_2,).
15/08/11 10:18:56 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$ye]
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:18:56 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: [actor] handled message (0.799607 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$ye]
15/08/11 10:18:56 DEBUG BlockManager: Got multiple block location in  10 ms
15/08/11 10:18:56 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD ShuffledRDD[26] at reduceByKey at KMeansTest.scala:63
15/08/11 10:18:56 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@1afc00bd) from Actor[akka://sparkDriver/temp/$ze]
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: [actor] handled message (0.196503 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@1afc00bd) from Actor[akka://sparkDriver/temp/$ze]
15/08/11 10:18:56 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@1afc00bd) from Actor[akka://sparkDriver/temp/$Ae]
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: [actor] handled message (0.188929 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@1afc00bd) from Actor[akka://sparkDriver/temp/$Ae]
15/08/11 10:18:56 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:18:56 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:18:56 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|26|0,rdd_26_0,, null|26|1,rdd_26_1,, null|26|2,rdd_26_2,).
15/08/11 10:18:56 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$Ce]
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: [actor] handled message (1.352244 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$Ce]
15/08/11 10:18:56 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:18:56 DEBUG BlockManager: Got multiple block location in  14 ms
15/08/11 10:18:56 INFO DAGScheduler: Missing parents for Stage 17: List()
15/08/11 10:18:56 INFO DAGScheduler: Submitting Stage 17 (MapPartitionsRDD[27] at map at KMeansTest.scala:65), which is now runnable
15/08/11 10:18:56 DEBUG DAGScheduler: submitMissingTasks(Stage 17)
15/08/11 10:18:56 INFO MemoryStore: ensureFreeSpace(2560) called with curMem=192653, maxMem=278302556
15/08/11 10:18:56 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 2.5 KB, free 265.2 MB)
15/08/11 10:18:56 DEBUG BlockManager: Put block broadcast_18 locally took  1 ms
15/08/11 10:18:56 DEBUG BlockManager: Putting block broadcast_18 without replication took  1 ms
15/08/11 10:18:56 INFO MemoryStore: ensureFreeSpace(1521) called with curMem=195213, maxMem=278302556
15/08/11 10:18:56 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 1521.0 B, free 265.2 MB)
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_18_piece0,StorageLevel(false, true, false, false, 1),1521,0,0) from Actor[akka://sparkDriver/temp/$De]
15/08/11 10:18:56 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 192.168.130.131:57830 (size: 1521.0 B, free: 265.4 MB)
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: [actor] handled message (0.446577 ms) UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_18_piece0,StorageLevel(false, true, false, false, 1),1521,0,0) from Actor[akka://sparkDriver/temp/$De]
15/08/11 10:18:56 INFO BlockManagerMaster: Updated info of block broadcast_18_piece0
15/08/11 10:18:56 DEBUG BlockManager: Told master about block broadcast_18_piece0
15/08/11 10:18:56 DEBUG BlockManager: Put block broadcast_18_piece0 locally took  2 ms
15/08/11 10:18:56 DEBUG BlockManager: Putting block broadcast_18_piece0 without replication took  2 ms
15/08/11 10:18:56 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:852
15/08/11 10:18:56 INFO DAGScheduler: Submitting 3 missing tasks from Stage 17 (MapPartitionsRDD[27] at map at KMeansTest.scala:65)
15/08/11 10:18:56 DEBUG DAGScheduler: New pending tasks: Set(ResultTask(17, 1), ResultTask(17, 0), ResultTask(17, 2))
15/08/11 10:18:56 INFO TaskSchedulerImpl: Adding task set 17.0 with 3 tasks
15/08/11 10:18:56 DEBUG TaskSetManager: Epoch for TaskSet 17.0: 8
15/08/11 10:18:56 DEBUG TaskSetManager: Valid locality levels for TaskSet 17.0: NO_PREF, ANY
15/08/11 10:18:56 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/deadLetters]
15/08/11 10:18:56 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_17, runningTasks: 0
15/08/11 10:18:56 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 51, 192.168.130.131, PROCESS_LOCAL, 1116 bytes)
15/08/11 10:18:56 INFO TaskSetManager: Starting task 1.0 in stage 17.0 (TID 52, 192.168.130.131, PROCESS_LOCAL, 1116 bytes)
15/08/11 10:18:56 INFO TaskSetManager: Starting task 2.0 in stage 17.0 (TID 53, 192.168.130.131, PROCESS_LOCAL, 1116 bytes)
15/08/11 10:18:56 DEBUG TaskSetManager: No tasks for locality level NO_PREF, so moving to locality level ANY
15/08/11 10:18:56 DEBUG SparkDeploySchedulerBackend: [actor] handled message (3.169436 ms) ReviveOffers from Actor[akka://sparkDriver/deadLetters]
15/08/11 10:18:56 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,52,RUNNING,org.apache.spark.util.SerializableBuffer@46894793) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:56 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.099009 ms) StatusUpdate(0,52,RUNNING,org.apache.spark.util.SerializableBuffer@46894793) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:56 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,53,RUNNING,org.apache.spark.util.SerializableBuffer@5eba2812) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:56 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.074041 ms) StatusUpdate(0,53,RUNNING,org.apache.spark.util.SerializableBuffer@5eba2812) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: [actor] received message GetLocations(broadcast_18_piece0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$sb]
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: [actor] handled message (0.087137 ms) GetLocations(broadcast_18_piece0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$sb]
15/08/11 10:18:56 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,51,RUNNING,org.apache.spark.util.SerializableBuffer@5897c159) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:56 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.079551 ms) StatusUpdate(0,51,RUNNING,org.apache.spark.util.SerializableBuffer@5897c159) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:56 DEBUG BlockManager: Level for block broadcast_18_piece0 is StorageLevel(true, true, false, false, 1)
15/08/11 10:18:56 DEBUG BlockManager: Getting block broadcast_18_piece0 from memory
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_18_piece0,StorageLevel(false, true, false, false, 1),1521,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$tb]
15/08/11 10:18:56 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 192.168.130.131:47921 (size: 1521.0 B, free: 245.7 MB)
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: [actor] handled message (0.553417 ms) UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_18_piece0,StorageLevel(false, true, false, false, 1),1521,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$tb]
15/08/11 10:18:56 DEBUG MapOutputTrackerMasterActor: [actor] received message GetMapOutputStatuses(7) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$ub]
15/08/11 10:18:56 INFO MapOutputTrackerMasterActor: Asked to send map output locations for shuffle 7 to sparkExecutor@192.168.130.131:49489
15/08/11 10:18:56 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 7 is 162 bytes
15/08/11 10:18:56 DEBUG MapOutputTrackerMasterActor: [actor] handled message (0.73572 ms) GetMapOutputStatuses(7) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$ub]
15/08/11 10:18:56 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,51,FINISHED,org.apache.spark.util.SerializableBuffer@531f73a0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:56 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_17, runningTasks: 2
15/08/11 10:18:56 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.594929 ms) StatusUpdate(0,51,FINISHED,org.apache.spark.util.SerializableBuffer@531f73a0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:56 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,53,FINISHED,org.apache.spark.util.SerializableBuffer@137d26f0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:56 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 51) in 86 ms on 192.168.130.131 (1/3)
15/08/11 10:18:56 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_17, runningTasks: 1
15/08/11 10:18:56 DEBUG SparkDeploySchedulerBackend: [actor] handled message (20.925789 ms) StatusUpdate(0,53,FINISHED,org.apache.spark.util.SerializableBuffer@137d26f0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:56 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,52,FINISHED,org.apache.spark.util.SerializableBuffer@7f8915e2) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:56 INFO TaskSetManager: Finished task 2.0 in stage 17.0 (TID 53) in 112 ms on 192.168.130.131 (2/3)
15/08/11 10:18:56 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_17, runningTasks: 0
15/08/11 10:18:56 DEBUG SparkDeploySchedulerBackend: [actor] handled message (5.634226 ms) StatusUpdate(0,52,FINISHED,org.apache.spark.util.SerializableBuffer@7f8915e2) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:56 INFO DAGScheduler: Stage 17 (collectAsMap at KMeansTest.scala:67) finished in 0.131 s
15/08/11 10:18:56 DEBUG DAGScheduler: After removal of stage 17, remaining stages = 1
15/08/11 10:18:56 DEBUG DAGScheduler: After removal of stage 16, remaining stages = 0
15/08/11 10:18:56 INFO DAGScheduler: Job 9 finished: collectAsMap at KMeansTest.scala:67, took 3.181121 s
Finished iteration (num = 7)
15/08/11 10:18:56 INFO TaskSetManager: Finished task 1.0 in stage 17.0 (TID 52) in 120 ms on 192.168.130.131 (3/3)
15/08/11 10:18:56 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
15/08/11 10:18:56 INFO SparkContext: Starting job: collectAsMap at KMeansTest.scala:67
15/08/11 10:18:56 INFO DAGScheduler: Registering RDD 28 (map at KMeansTest.scala:61)
15/08/11 10:18:56 INFO DAGScheduler: Got job 10 (collectAsMap at KMeansTest.scala:67) with 3 output partitions (allowLocal=false)
15/08/11 10:18:56 INFO DAGScheduler: Final stage: Stage 19(collectAsMap at KMeansTest.scala:67)
15/08/11 10:18:56 INFO DAGScheduler: Parents of final stage: List(Stage 18)
15/08/11 10:18:56 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD MapPartitionsRDD[30] at map at KMeansTest.scala:65
15/08/11 10:18:56 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@10e2d91b) from Actor[akka://sparkDriver/temp/$Ee]
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: [actor] handled message (0.140989 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@10e2d91b) from Actor[akka://sparkDriver/temp/$Ee]
15/08/11 10:18:56 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@10e2d91b) from Actor[akka://sparkDriver/temp/$Fe]
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: [actor] handled message (0.083483 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@10e2d91b) from Actor[akka://sparkDriver/temp/$Fe]
15/08/11 10:18:56 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:18:56 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:18:56 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|30|0,rdd_30_0,, null|30|1,rdd_30_1,, null|30|2,rdd_30_2,).
15/08/11 10:18:56 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$He]
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: [actor] handled message (0.789602 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$He]
15/08/11 10:18:56 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:18:56 DEBUG BlockManager: Got multiple block location in  9 ms
15/08/11 10:18:56 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD ShuffledRDD[29] at reduceByKey at KMeansTest.scala:63
15/08/11 10:18:56 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@6e0dc5a0) from Actor[akka://sparkDriver/temp/$Ie]
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: [actor] handled message (0.16826 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@6e0dc5a0) from Actor[akka://sparkDriver/temp/$Ie]
15/08/11 10:18:56 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@6e0dc5a0) from Actor[akka://sparkDriver/temp/$Je]
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: [actor] handled message (0.291765 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@6e0dc5a0) from Actor[akka://sparkDriver/temp/$Je]
15/08/11 10:18:56 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:18:56 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:18:56 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|29|0,rdd_29_0,, null|29|1,rdd_29_1,, null|29|2,rdd_29_2,).
15/08/11 10:18:56 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$Le]
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: [actor] handled message (0.722324 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$Le]
15/08/11 10:18:56 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:18:56 DEBUG BlockManager: Got multiple block location in  13 ms
15/08/11 10:18:56 INFO DAGScheduler: [SMSpark v1]Missing parents: List(Stage 18)
15/08/11 10:18:56 DEBUG DAGScheduler: submitStage(Stage 19)
15/08/11 10:18:56 DEBUG DAGScheduler: missing: List(Stage 18)
15/08/11 10:18:56 DEBUG DAGScheduler: submitStage(Stage 18)
15/08/11 10:18:56 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD MapPartitionsRDD[28] at map at KMeansTest.scala:61
15/08/11 10:18:56 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@e00c11d) from Actor[akka://sparkDriver/temp/$Me]
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: [actor] handled message (0.207441 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@e00c11d) from Actor[akka://sparkDriver/temp/$Me]
15/08/11 10:18:56 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@e00c11d) from Actor[akka://sparkDriver/temp/$Ne]
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: [actor] handled message (0.123732 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@e00c11d) from Actor[akka://sparkDriver/temp/$Ne]
15/08/11 10:18:56 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:18:56 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:18:56 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|28|0,rdd_28_0,, null|28|1,rdd_28_1,, null|28|2,rdd_28_2,).
15/08/11 10:18:56 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$Pe]
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:18:56 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: [actor] handled message (0.832029 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$Pe]
15/08/11 10:18:56 DEBUG BlockManager: Got multiple block location in  10 ms
15/08/11 10:18:56 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD KMeans01 MapPartitionsRDD[2] at map at KMeansTest.scala:50
15/08/11 10:18:56 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@5ed4e588) from Actor[akka://sparkDriver/temp/$Qe]
15/08/11 10:18:56 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(ArrayBuffer(BlockManagerId(0, 192.168.130.131, 47921)), ArrayBuffer(BlockManagerId(0, 192.168.130.131, 47921)), ArrayBuffer(BlockManagerId(0, 192.168.130.131, 47921)))
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: [actor] handled message (0.296996 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@5ed4e588) from Actor[akka://sparkDriver/temp/$Qe]
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@5ed4e588) from Actor[akka://sparkDriver/temp/$Re]
15/08/11 10:18:56 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: [actor] handled message (0.200487 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@5ed4e588) from Actor[akka://sparkDriver/temp/$Re]
15/08/11 10:18:56 DEBUG DAGScheduler: missing: List()
15/08/11 10:18:56 INFO DAGScheduler: Submitting Stage 18 (MapPartitionsRDD[28] at map at KMeansTest.scala:61), which has no missing parents
15/08/11 10:18:56 DEBUG DAGScheduler: submitMissingTasks(Stage 18)
15/08/11 10:18:56 INFO MemoryStore: ensureFreeSpace(4768) called with curMem=196734, maxMem=278302556
15/08/11 10:18:56 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 4.7 KB, free 265.2 MB)
15/08/11 10:18:56 DEBUG BlockManager: Put block broadcast_19 locally took  1 ms
15/08/11 10:18:56 DEBUG BlockManager: Putting block broadcast_19 without replication took  1 ms
15/08/11 10:18:56 INFO MemoryStore: ensureFreeSpace(3203) called with curMem=201502, maxMem=278302556
15/08/11 10:18:56 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 3.1 KB, free 265.2 MB)
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_19_piece0,StorageLevel(false, true, false, false, 1),3203,0,0) from Actor[akka://sparkDriver/temp/$Se]
15/08/11 10:18:56 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 192.168.130.131:57830 (size: 3.1 KB, free: 265.4 MB)
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: [actor] handled message (0.832629 ms) UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_19_piece0,StorageLevel(false, true, false, false, 1),3203,0,0) from Actor[akka://sparkDriver/temp/$Se]
15/08/11 10:18:56 INFO BlockManagerMaster: Updated info of block broadcast_19_piece0
15/08/11 10:18:56 DEBUG BlockManager: Told master about block broadcast_19_piece0
15/08/11 10:18:56 DEBUG BlockManager: Put block broadcast_19_piece0 locally took  3 ms
15/08/11 10:18:56 DEBUG BlockManager: Putting block broadcast_19_piece0 without replication took  3 ms
15/08/11 10:18:56 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:852
15/08/11 10:18:56 INFO DAGScheduler: Submitting 3 missing tasks from Stage 18 (MapPartitionsRDD[28] at map at KMeansTest.scala:61)
15/08/11 10:18:56 DEBUG DAGScheduler: New pending tasks: Set(ShuffleMapTask(18, 0), ShuffleMapTask(18, 2), ShuffleMapTask(18, 1))
15/08/11 10:18:56 INFO TaskSchedulerImpl: Adding task set 18.0 with 3 tasks
15/08/11 10:18:56 DEBUG TaskSetManager: Epoch for TaskSet 18.0: 8
15/08/11 10:18:56 DEBUG TaskSetManager: Valid locality levels for TaskSet 18.0: PROCESS_LOCAL, NODE_LOCAL, ANY
15/08/11 10:18:56 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/deadLetters]
15/08/11 10:18:56 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_18, runningTasks: 0
15/08/11 10:18:56 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 54, 192.168.130.131, PROCESS_LOCAL, 1361 bytes)
15/08/11 10:18:56 DEBUG DAGScheduler: submitStage(Stage 19)
15/08/11 10:18:56 INFO TaskSetManager: Starting task 1.0 in stage 18.0 (TID 55, 192.168.130.131, PROCESS_LOCAL, 1361 bytes)
15/08/11 10:18:56 DEBUG DAGScheduler: missing: List(Stage 18)
15/08/11 10:18:56 DEBUG DAGScheduler: submitStage(Stage 18)
15/08/11 10:18:56 DEBUG DAGScheduler: submitStage(Stage 19)
15/08/11 10:18:56 INFO TaskSetManager: Starting task 2.0 in stage 18.0 (TID 56, 192.168.130.131, PROCESS_LOCAL, 1361 bytes)
15/08/11 10:18:56 DEBUG TaskSetManager: No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
15/08/11 10:18:56 DEBUG TaskSetManager: No tasks for locality level NODE_LOCAL, so moving to locality level ANY
15/08/11 10:18:56 DEBUG SparkDeploySchedulerBackend: [actor] handled message (3.721324 ms) ReviveOffers from Actor[akka://sparkDriver/deadLetters]
15/08/11 10:18:56 DEBUG DAGScheduler: missing: List(Stage 18)
15/08/11 10:18:56 DEBUG DAGScheduler: submitStage(Stage 18)
15/08/11 10:18:56 DEBUG DAGScheduler: submitStage(Stage 19)
15/08/11 10:18:56 DEBUG DAGScheduler: missing: List(Stage 18)
15/08/11 10:18:56 DEBUG DAGScheduler: submitStage(Stage 18)
15/08/11 10:18:56 DEBUG DAGScheduler: submitStage(Stage 19)
15/08/11 10:18:56 DEBUG DAGScheduler: missing: List(Stage 18)
15/08/11 10:18:56 DEBUG DAGScheduler: submitStage(Stage 18)
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: [actor] received message GetLocations(broadcast_19_piece0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$vb]
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: [actor] handled message (0.057423 ms) GetLocations(broadcast_19_piece0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$vb]
15/08/11 10:18:56 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,54,RUNNING,org.apache.spark.util.SerializableBuffer@1fa6dc16) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:56 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.082181 ms) StatusUpdate(0,54,RUNNING,org.apache.spark.util.SerializableBuffer@1fa6dc16) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:56 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,56,RUNNING,org.apache.spark.util.SerializableBuffer@3bb3896) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:56 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.095639 ms) StatusUpdate(0,56,RUNNING,org.apache.spark.util.SerializableBuffer@3bb3896) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:56 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,55,RUNNING,org.apache.spark.util.SerializableBuffer@1bf3e703) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:56 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.171752 ms) StatusUpdate(0,55,RUNNING,org.apache.spark.util.SerializableBuffer@1bf3e703) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:56 DEBUG BlockManager: Level for block broadcast_19_piece0 is StorageLevel(true, true, false, false, 1)
15/08/11 10:18:56 DEBUG BlockManager: Getting block broadcast_19_piece0 from memory
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_19_piece0,StorageLevel(false, true, false, false, 1),3203,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$wb]
15/08/11 10:18:56 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 192.168.130.131:47921 (size: 3.1 KB, free: 245.7 MB)
15/08/11 10:18:56 DEBUG BlockManagerMasterActor: [actor] handled message (0.873416 ms) UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_19_piece0,StorageLevel(false, true, false, false, 1),3203,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$wb]
15/08/11 10:18:56 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:56 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_18, runningTasks: 3
15/08/11 10:18:56 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.799757 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:57 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,56,FINISHED,org.apache.spark.util.SerializableBuffer@63226d58) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:57 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_18, runningTasks: 2
15/08/11 10:18:57 DEBUG SparkDeploySchedulerBackend: [actor] handled message (1.477824 ms) StatusUpdate(0,56,FINISHED,org.apache.spark.util.SerializableBuffer@63226d58) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:57 DEBUG DAGScheduler: ShuffleMapTask finished on 0
15/08/11 10:18:57 INFO TaskSetManager: Finished task 2.0 in stage 18.0 (TID 56) in 982 ms on 192.168.130.131 (1/3)
15/08/11 10:18:57 DEBUG DAGScheduler: submitStage(Stage 19)
15/08/11 10:18:57 DEBUG DAGScheduler: missing: List(Stage 18)
15/08/11 10:18:57 DEBUG DAGScheduler: submitStage(Stage 18)
15/08/11 10:18:57 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:57 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_18, runningTasks: 2
15/08/11 10:18:57 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.516462 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:58 DEBUG BlockManagerMasterActor: [actor] received message ExpireDeadHosts from Actor[akka://sparkDriver/user/BlockManagerMaster#1167280481]
15/08/11 10:18:58 DEBUG BlockManagerMasterActor: [actor] handled message (0.090063 ms) ExpireDeadHosts from Actor[akka://sparkDriver/user/BlockManagerMaster#1167280481]
15/08/11 10:18:58 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:58 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_18, runningTasks: 2
15/08/11 10:18:58 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.691134 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:59 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,55,FINISHED,org.apache.spark.util.SerializableBuffer@14c918b8) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:59 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_18, runningTasks: 1
15/08/11 10:18:59 DEBUG SparkDeploySchedulerBackend: [actor] handled message (1.379933 ms) StatusUpdate(0,55,FINISHED,org.apache.spark.util.SerializableBuffer@14c918b8) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:59 DEBUG DAGScheduler: ShuffleMapTask finished on 0
15/08/11 10:18:59 DEBUG DAGScheduler: submitStage(Stage 19)
15/08/11 10:18:59 DEBUG DAGScheduler: missing: List(Stage 18)
15/08/11 10:18:59 DEBUG DAGScheduler: submitStage(Stage 18)
15/08/11 10:18:59 INFO TaskSetManager: Finished task 1.0 in stage 18.0 (TID 55) in 2838 ms on 192.168.130.131 (2/3)
15/08/11 10:18:59 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,54,FINISHED,org.apache.spark.util.SerializableBuffer@1e75e2b1) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:59 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_18, runningTasks: 0
15/08/11 10:18:59 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.87726 ms) StatusUpdate(0,54,FINISHED,org.apache.spark.util.SerializableBuffer@1e75e2b1) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:59 DEBUG DAGScheduler: ShuffleMapTask finished on 0
15/08/11 10:18:59 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 54) in 3034 ms on 192.168.130.131 (3/3)
15/08/11 10:18:59 INFO DAGScheduler: Stage 18 (map at KMeansTest.scala:61) finished in 3.041 s
15/08/11 10:18:59 INFO DAGScheduler: looking for newly runnable stages
15/08/11 10:18:59 INFO DAGScheduler: running: Set()
15/08/11 10:18:59 INFO DAGScheduler: waiting: Set(Stage 19)
15/08/11 10:18:59 INFO DAGScheduler: failed: Set()
15/08/11 10:18:59 DEBUG MapOutputTrackerMaster: Increasing epoch to 9
15/08/11 10:18:59 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD MapPartitionsRDD[30] at map at KMeansTest.scala:65
15/08/11 10:18:59 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:18:59 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
15/08/11 10:18:59 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@4d75e216) from Actor[akka://sparkDriver/temp/$Te]
15/08/11 10:18:59 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:18:59 DEBUG BlockManagerMasterActor: [actor] handled message (0.190785 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@4d75e216) from Actor[akka://sparkDriver/temp/$Te]
15/08/11 10:18:59 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@4d75e216) from Actor[akka://sparkDriver/temp/$Ue]
15/08/11 10:18:59 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:18:59 DEBUG BlockManagerMasterActor: [actor] handled message (0.24523 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@4d75e216) from Actor[akka://sparkDriver/temp/$Ue]
15/08/11 10:18:59 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:18:59 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|30|0,rdd_30_0,, null|30|1,rdd_30_1,, null|30|2,rdd_30_2,).
15/08/11 10:18:59 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:18:59 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$We]
15/08/11 10:18:59 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:18:59 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:59 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:59 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:59 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:59 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:59 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:59 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:59 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:59 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:59 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:18:59 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:18:59 DEBUG BlockManagerMasterActor: [actor] handled message (6.4651 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$We]
15/08/11 10:18:59 DEBUG BlockManager: Got multiple block location in  15 ms
15/08/11 10:18:59 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD ShuffledRDD[29] at reduceByKey at KMeansTest.scala:63
15/08/11 10:18:59 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:18:59 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@30053097) from Actor[akka://sparkDriver/temp/$Xe]
15/08/11 10:18:59 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:18:59 DEBUG BlockManagerMasterActor: [actor] handled message (0.196757 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@30053097) from Actor[akka://sparkDriver/temp/$Xe]
15/08/11 10:18:59 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@30053097) from Actor[akka://sparkDriver/temp/$Ye]
15/08/11 10:18:59 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:18:59 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:18:59 DEBUG BlockManagerMasterActor: [actor] handled message (0.176644 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@30053097) from Actor[akka://sparkDriver/temp/$Ye]
15/08/11 10:18:59 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|29|0,rdd_29_0,, null|29|1,rdd_29_1,, null|29|2,rdd_29_2,).
15/08/11 10:18:59 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:18:59 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$0e]
15/08/11 10:18:59 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:18:59 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:59 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:59 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:59 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:59 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:59 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:59 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:59 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:59 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:59 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:18:59 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:18:59 DEBUG BlockManagerMasterActor: [actor] handled message (0.644498 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$0e]
15/08/11 10:18:59 DEBUG BlockManager: Got multiple block location in  9 ms
15/08/11 10:18:59 INFO DAGScheduler: Missing parents for Stage 19: List()
15/08/11 10:18:59 INFO DAGScheduler: Submitting Stage 19 (MapPartitionsRDD[30] at map at KMeansTest.scala:65), which is now runnable
15/08/11 10:18:59 DEBUG DAGScheduler: submitMissingTasks(Stage 19)
15/08/11 10:18:59 INFO MemoryStore: ensureFreeSpace(2560) called with curMem=204705, maxMem=278302556
15/08/11 10:18:59 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 2.5 KB, free 265.2 MB)
15/08/11 10:18:59 DEBUG BlockManager: Put block broadcast_20 locally took  1 ms
15/08/11 10:18:59 DEBUG BlockManager: Putting block broadcast_20 without replication took  1 ms
15/08/11 10:18:59 INFO MemoryStore: ensureFreeSpace(1519) called with curMem=207265, maxMem=278302556
15/08/11 10:18:59 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 1519.0 B, free 265.2 MB)
15/08/11 10:18:59 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_20_piece0,StorageLevel(false, true, false, false, 1),1519,0,0) from Actor[akka://sparkDriver/temp/$1e]
15/08/11 10:18:59 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 192.168.130.131:57830 (size: 1519.0 B, free: 265.4 MB)
15/08/11 10:18:59 INFO BlockManagerMaster: Updated info of block broadcast_20_piece0
15/08/11 10:18:59 DEBUG BlockManager: Told master about block broadcast_20_piece0
15/08/11 10:18:59 DEBUG BlockManagerMasterActor: [actor] handled message (0.577975 ms) UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_20_piece0,StorageLevel(false, true, false, false, 1),1519,0,0) from Actor[akka://sparkDriver/temp/$1e]
15/08/11 10:18:59 DEBUG BlockManager: Put block broadcast_20_piece0 locally took  2 ms
15/08/11 10:18:59 DEBUG BlockManager: Putting block broadcast_20_piece0 without replication took  2 ms
15/08/11 10:18:59 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:852
15/08/11 10:18:59 INFO DAGScheduler: Submitting 3 missing tasks from Stage 19 (MapPartitionsRDD[30] at map at KMeansTest.scala:65)
15/08/11 10:18:59 DEBUG DAGScheduler: New pending tasks: Set(ResultTask(19, 2), ResultTask(19, 1), ResultTask(19, 0))
15/08/11 10:18:59 INFO TaskSchedulerImpl: Adding task set 19.0 with 3 tasks
15/08/11 10:18:59 DEBUG TaskSetManager: Epoch for TaskSet 19.0: 9
15/08/11 10:18:59 DEBUG TaskSetManager: Valid locality levels for TaskSet 19.0: NO_PREF, ANY
15/08/11 10:18:59 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/deadLetters]
15/08/11 10:18:59 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_19, runningTasks: 0
15/08/11 10:18:59 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 57, 192.168.130.131, PROCESS_LOCAL, 1116 bytes)
15/08/11 10:18:59 INFO TaskSetManager: Starting task 1.0 in stage 19.0 (TID 58, 192.168.130.131, PROCESS_LOCAL, 1116 bytes)
15/08/11 10:18:59 INFO TaskSetManager: Starting task 2.0 in stage 19.0 (TID 59, 192.168.130.131, PROCESS_LOCAL, 1116 bytes)
15/08/11 10:18:59 DEBUG TaskSetManager: No tasks for locality level NO_PREF, so moving to locality level ANY
15/08/11 10:18:59 DEBUG SparkDeploySchedulerBackend: [actor] handled message (3.608712 ms) ReviveOffers from Actor[akka://sparkDriver/deadLetters]
15/08/11 10:18:59 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,57,RUNNING,org.apache.spark.util.SerializableBuffer@148f7ea3) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:59 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.0644 ms) StatusUpdate(0,57,RUNNING,org.apache.spark.util.SerializableBuffer@148f7ea3) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:59 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,58,RUNNING,org.apache.spark.util.SerializableBuffer@58c309e0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:59 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.06861 ms) StatusUpdate(0,58,RUNNING,org.apache.spark.util.SerializableBuffer@58c309e0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:59 DEBUG BlockManagerMasterActor: [actor] received message GetLocations(broadcast_20_piece0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$xb]
15/08/11 10:18:59 DEBUG BlockManagerMasterActor: [actor] handled message (0.074639 ms) GetLocations(broadcast_20_piece0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$xb]
15/08/11 10:18:59 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,59,RUNNING,org.apache.spark.util.SerializableBuffer@188c0b75) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:59 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.063203 ms) StatusUpdate(0,59,RUNNING,org.apache.spark.util.SerializableBuffer@188c0b75) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:59 DEBUG BlockManager: Level for block broadcast_20_piece0 is StorageLevel(true, true, false, false, 1)
15/08/11 10:18:59 DEBUG BlockManager: Getting block broadcast_20_piece0 from memory
15/08/11 10:18:59 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_20_piece0,StorageLevel(false, true, false, false, 1),1519,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$yb]
15/08/11 10:18:59 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 192.168.130.131:47921 (size: 1519.0 B, free: 245.7 MB)
15/08/11 10:18:59 DEBUG BlockManagerMasterActor: [actor] handled message (1.265843 ms) UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_20_piece0,StorageLevel(false, true, false, false, 1),1519,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$yb]
15/08/11 10:18:59 DEBUG MapOutputTrackerMasterActor: [actor] received message GetMapOutputStatuses(8) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$zb]
15/08/11 10:18:59 INFO MapOutputTrackerMasterActor: Asked to send map output locations for shuffle 8 to sparkExecutor@192.168.130.131:49489
15/08/11 10:18:59 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 8 is 162 bytes
15/08/11 10:18:59 DEBUG MapOutputTrackerMasterActor: [actor] handled message (1.310844 ms) GetMapOutputStatuses(8) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$zb]
15/08/11 10:18:59 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:59 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_19, runningTasks: 3
15/08/11 10:18:59 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.807921 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:18:59 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,59,FINISHED,org.apache.spark.util.SerializableBuffer@5cf5321e) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:59 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_19, runningTasks: 2
15/08/11 10:18:59 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.786308 ms) StatusUpdate(0,59,FINISHED,org.apache.spark.util.SerializableBuffer@5cf5321e) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:59 INFO TaskSetManager: Finished task 2.0 in stage 19.0 (TID 59) in 83 ms on 192.168.130.131 (1/3)
15/08/11 10:18:59 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,58,FINISHED,org.apache.spark.util.SerializableBuffer@6332ed19) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:59 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_19, runningTasks: 1
15/08/11 10:18:59 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.561331 ms) StatusUpdate(0,58,FINISHED,org.apache.spark.util.SerializableBuffer@6332ed19) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:59 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,57,FINISHED,org.apache.spark.util.SerializableBuffer@246c3730) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:59 INFO TaskSetManager: Finished task 1.0 in stage 19.0 (TID 58) in 97 ms on 192.168.130.131 (2/3)
15/08/11 10:18:59 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_19, runningTasks: 0
15/08/11 10:18:59 DEBUG SparkDeploySchedulerBackend: [actor] handled message (7.644894 ms) StatusUpdate(0,57,FINISHED,org.apache.spark.util.SerializableBuffer@246c3730) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:18:59 INFO DAGScheduler: Stage 19 (collectAsMap at KMeansTest.scala:67) finished in 0.113 s
15/08/11 10:18:59 DEBUG DAGScheduler: After removal of stage 19, remaining stages = 1
15/08/11 10:18:59 DEBUG DAGScheduler: After removal of stage 18, remaining stages = 0
15/08/11 10:18:59 INFO DAGScheduler: Job 10 finished: collectAsMap at KMeansTest.scala:67, took 3.250516 s
Finished iteration (num = 8)
15/08/11 10:18:59 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 57) in 107 ms on 192.168.130.131 (3/3)
15/08/11 10:18:59 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
15/08/11 10:18:59 INFO SparkContext: Starting job: collectAsMap at KMeansTest.scala:67
15/08/11 10:18:59 INFO DAGScheduler: Registering RDD 31 (map at KMeansTest.scala:61)
15/08/11 10:18:59 INFO DAGScheduler: Got job 11 (collectAsMap at KMeansTest.scala:67) with 3 output partitions (allowLocal=false)
15/08/11 10:18:59 INFO DAGScheduler: Final stage: Stage 21(collectAsMap at KMeansTest.scala:67)
15/08/11 10:18:59 INFO DAGScheduler: Parents of final stage: List(Stage 20)
15/08/11 10:18:59 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD MapPartitionsRDD[33] at map at KMeansTest.scala:65
15/08/11 10:18:59 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:18:59 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@53759ba0) from Actor[akka://sparkDriver/temp/$2e]
15/08/11 10:18:59 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:18:59 DEBUG BlockManagerMasterActor: [actor] handled message (0.226276 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@53759ba0) from Actor[akka://sparkDriver/temp/$2e]
15/08/11 10:18:59 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@53759ba0) from Actor[akka://sparkDriver/temp/$3e]
15/08/11 10:18:59 DEBUG BlockManagerMasterActor: [actor] handled message (0.150901 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@53759ba0) from Actor[akka://sparkDriver/temp/$3e]
15/08/11 10:18:59 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:18:59 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:18:59 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|33|0,rdd_33_0,, null|33|1,rdd_33_1,, null|33|2,rdd_33_2,).
15/08/11 10:18:59 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:18:59 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$5e]
15/08/11 10:18:59 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:18:59 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:59 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:59 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:59 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:59 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:59 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:59 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:59 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:59 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:59 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:18:59 DEBUG BlockManagerMasterActor: [actor] handled message (0.86166 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$5e]
15/08/11 10:18:59 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:18:59 DEBUG BlockManager: Got multiple block location in  23 ms
15/08/11 10:18:59 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD ShuffledRDD[32] at reduceByKey at KMeansTest.scala:63
15/08/11 10:18:59 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:18:59 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@135fd1a4) from Actor[akka://sparkDriver/temp/$6e]
15/08/11 10:18:59 DEBUG BlockManagerMasterActor: [actor] handled message (0.177101 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@135fd1a4) from Actor[akka://sparkDriver/temp/$6e]
15/08/11 10:18:59 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:18:59 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@135fd1a4) from Actor[akka://sparkDriver/temp/$7e]
15/08/11 10:18:59 DEBUG BlockManagerMasterActor: [actor] handled message (0.096212 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@135fd1a4) from Actor[akka://sparkDriver/temp/$7e]
15/08/11 10:18:59 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:18:59 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:18:59 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|32|0,rdd_32_0,, null|32|1,rdd_32_1,, null|32|2,rdd_32_2,).
15/08/11 10:18:59 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:18:59 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$9e]
15/08/11 10:18:59 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:18:59 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:59 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:59 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:59 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:59 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:59 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:59 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:59 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:59 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:59 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:18:59 DEBUG BlockManagerMasterActor: [actor] handled message (1.058366 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$9e]
15/08/11 10:18:59 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:18:59 DEBUG BlockManager: Got multiple block location in  17 ms
15/08/11 10:18:59 INFO DAGScheduler: [SMSpark v1]Missing parents: List(Stage 20)
15/08/11 10:18:59 DEBUG DAGScheduler: submitStage(Stage 21)
15/08/11 10:18:59 DEBUG DAGScheduler: missing: List(Stage 20)
15/08/11 10:18:59 DEBUG DAGScheduler: submitStage(Stage 20)
15/08/11 10:18:59 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD MapPartitionsRDD[31] at map at KMeansTest.scala:61
15/08/11 10:18:59 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:18:59 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@75d19db8) from Actor[akka://sparkDriver/temp/$+e]
15/08/11 10:18:59 DEBUG BlockManagerMasterActor: [actor] handled message (0.130945 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@75d19db8) from Actor[akka://sparkDriver/temp/$+e]
15/08/11 10:18:59 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:18:59 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@75d19db8) from Actor[akka://sparkDriver/temp/$~e]
15/08/11 10:18:59 DEBUG BlockManagerMasterActor: [actor] handled message (0.111689 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@75d19db8) from Actor[akka://sparkDriver/temp/$~e]
15/08/11 10:18:59 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:18:59 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:18:59 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|31|0,rdd_31_0,, null|31|1,rdd_31_1,, null|31|2,rdd_31_2,).
15/08/11 10:18:59 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:18:59 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$bf]
15/08/11 10:18:59 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:18:59 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:59 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:59 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:59 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:59 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:59 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:59 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:18:59 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:59 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:18:59 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:18:59 DEBUG BlockManagerMasterActor: [actor] handled message (1.510825 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$bf]
15/08/11 10:18:59 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:18:59 DEBUG BlockManager: Got multiple block location in  17 ms
15/08/11 10:18:59 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD KMeans01 MapPartitionsRDD[2] at map at KMeansTest.scala:50
15/08/11 10:18:59 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:18:59 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@51e2ee04) from Actor[akka://sparkDriver/temp/$cf]
15/08/11 10:18:59 DEBUG BlockManagerMasterActor: [actor] handled message (0.365504 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@51e2ee04) from Actor[akka://sparkDriver/temp/$cf]
15/08/11 10:18:59 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(ArrayBuffer(BlockManagerId(0, 192.168.130.131, 47921)), ArrayBuffer(BlockManagerId(0, 192.168.130.131, 47921)), ArrayBuffer(BlockManagerId(0, 192.168.130.131, 47921)))
15/08/11 10:18:59 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@51e2ee04) from Actor[akka://sparkDriver/temp/$df]
15/08/11 10:18:59 DEBUG BlockManagerMasterActor: [actor] handled message (0.660457 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@51e2ee04) from Actor[akka://sparkDriver/temp/$df]
15/08/11 10:18:59 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:18:59 DEBUG DAGScheduler: missing: List()
15/08/11 10:18:59 INFO DAGScheduler: Submitting Stage 20 (MapPartitionsRDD[31] at map at KMeansTest.scala:61), which has no missing parents
15/08/11 10:18:59 DEBUG DAGScheduler: submitMissingTasks(Stage 20)
15/08/11 10:18:59 INFO MemoryStore: ensureFreeSpace(4768) called with curMem=208784, maxMem=278302556
15/08/11 10:18:59 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 4.7 KB, free 265.2 MB)
15/08/11 10:18:59 DEBUG BlockManager: Put block broadcast_21 locally took  2 ms
15/08/11 10:18:59 DEBUG BlockManager: Putting block broadcast_21 without replication took  2 ms
15/08/11 10:18:59 INFO MemoryStore: ensureFreeSpace(3202) called with curMem=213552, maxMem=278302556
15/08/11 10:18:59 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 3.1 KB, free 265.2 MB)
15/08/11 10:18:59 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_21_piece0,StorageLevel(false, true, false, false, 1),3202,0,0) from Actor[akka://sparkDriver/temp/$ef]
15/08/11 10:18:59 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 192.168.130.131:57830 (size: 3.1 KB, free: 265.4 MB)
15/08/11 10:18:59 DEBUG BlockManagerMasterActor: [actor] handled message (2.217733 ms) UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_21_piece0,StorageLevel(false, true, false, false, 1),3202,0,0) from Actor[akka://sparkDriver/temp/$ef]
15/08/11 10:18:59 INFO BlockManagerMaster: Updated info of block broadcast_21_piece0
15/08/11 10:18:59 DEBUG BlockManager: Told master about block broadcast_21_piece0
15/08/11 10:18:59 DEBUG BlockManager: Put block broadcast_21_piece0 locally took  10 ms
15/08/11 10:18:59 DEBUG BlockManager: Putting block broadcast_21_piece0 without replication took  10 ms
15/08/11 10:18:59 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:852
15/08/11 10:18:59 INFO DAGScheduler: Submitting 3 missing tasks from Stage 20 (MapPartitionsRDD[31] at map at KMeansTest.scala:61)
15/08/11 10:18:59 DEBUG DAGScheduler: New pending tasks: Set(ShuffleMapTask(20, 1), ShuffleMapTask(20, 2), ShuffleMapTask(20, 0))
15/08/11 10:18:59 INFO TaskSchedulerImpl: Adding task set 20.0 with 3 tasks
15/08/11 10:18:59 DEBUG TaskSetManager: Epoch for TaskSet 20.0: 9
15/08/11 10:18:59 DEBUG TaskSetManager: Valid locality levels for TaskSet 20.0: PROCESS_LOCAL, NODE_LOCAL, ANY
15/08/11 10:18:59 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/deadLetters]
15/08/11 10:18:59 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_20, runningTasks: 0
15/08/11 10:18:59 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 60, 192.168.130.131, PROCESS_LOCAL, 1361 bytes)
15/08/11 10:18:59 INFO TaskSetManager: Starting task 1.0 in stage 20.0 (TID 61, 192.168.130.131, PROCESS_LOCAL, 1361 bytes)
15/08/11 10:18:59 DEBUG DAGScheduler: submitStage(Stage 21)
15/08/11 10:18:59 DEBUG DAGScheduler: missing: List(Stage 20)
15/08/11 10:18:59 DEBUG DAGScheduler: submitStage(Stage 20)
15/08/11 10:18:59 INFO TaskSetManager: Starting task 2.0 in stage 20.0 (TID 62, 192.168.130.131, PROCESS_LOCAL, 1361 bytes)
15/08/11 10:18:59 DEBUG TaskSetManager: No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
15/08/11 10:18:59 DEBUG TaskSetManager: No tasks for locality level NODE_LOCAL, so moving to locality level ANY
15/08/11 10:18:59 DEBUG DAGScheduler: submitStage(Stage 21)
15/08/11 10:18:59 DEBUG DAGScheduler: missing: List(Stage 20)
15/08/11 10:18:59 DEBUG DAGScheduler: submitStage(Stage 20)
15/08/11 10:18:59 DEBUG DAGScheduler: submitStage(Stage 21)
15/08/11 10:19:00 DEBUG DAGScheduler: missing: List(Stage 20)
15/08/11 10:19:00 DEBUG DAGScheduler: submitStage(Stage 20)
15/08/11 10:19:00 DEBUG SparkDeploySchedulerBackend: [actor] handled message (11.014743 ms) ReviveOffers from Actor[akka://sparkDriver/deadLetters]
15/08/11 10:19:00 DEBUG DAGScheduler: submitStage(Stage 21)
15/08/11 10:19:00 DEBUG DAGScheduler: missing: List(Stage 20)
15/08/11 10:19:00 DEBUG DAGScheduler: submitStage(Stage 20)
15/08/11 10:19:00 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,60,RUNNING,org.apache.spark.util.SerializableBuffer@3c71b23a) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:00 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.217975 ms) StatusUpdate(0,60,RUNNING,org.apache.spark.util.SerializableBuffer@3c71b23a) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:00 DEBUG BlockManagerMasterActor: [actor] received message GetLocations(broadcast_21_piece0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$Ab]
15/08/11 10:19:00 DEBUG BlockManagerMasterActor: [actor] handled message (0.162202 ms) GetLocations(broadcast_21_piece0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$Ab]
15/08/11 10:19:00 DEBUG HeartbeatReceiver: [actor] received message Heartbeat(0,[Lscala.Tuple2;@1bcf8cb,BlockManagerId(0, 192.168.130.131, 47921)) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$Bb]
15/08/11 10:19:00 DEBUG BlockManagerMasterActor: [actor] received message BlockManagerHeartbeat(BlockManagerId(0, 192.168.130.131, 47921)) from Actor[akka://sparkDriver/temp/$ff]
15/08/11 10:19:00 DEBUG BlockManagerMasterActor: [actor] handled message (0.265214 ms) BlockManagerHeartbeat(BlockManagerId(0, 192.168.130.131, 47921)) from Actor[akka://sparkDriver/temp/$ff]
15/08/11 10:19:00 DEBUG HeartbeatReceiver: [actor] handled message (2.02913 ms) Heartbeat(0,[Lscala.Tuple2;@1bcf8cb,BlockManagerId(0, 192.168.130.131, 47921)) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$Bb]
15/08/11 10:19:00 DEBUG BlockManager: Level for block broadcast_21_piece0 is StorageLevel(true, true, false, false, 1)
15/08/11 10:19:00 DEBUG BlockManager: Getting block broadcast_21_piece0 from memory
15/08/11 10:19:00 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,61,RUNNING,org.apache.spark.util.SerializableBuffer@3978517) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:00 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.10257 ms) StatusUpdate(0,61,RUNNING,org.apache.spark.util.SerializableBuffer@3978517) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:00 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,62,RUNNING,org.apache.spark.util.SerializableBuffer@50a2aad8) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:00 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.928391 ms) StatusUpdate(0,62,RUNNING,org.apache.spark.util.SerializableBuffer@50a2aad8) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:00 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_21_piece0,StorageLevel(false, true, false, false, 1),3202,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$Cb]
15/08/11 10:19:00 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 192.168.130.131:47921 (size: 3.1 KB, free: 245.7 MB)
15/08/11 10:19:00 DEBUG BlockManagerMasterActor: [actor] handled message (0.471103 ms) UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_21_piece0,StorageLevel(false, true, false, false, 1),3202,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$Cb]
15/08/11 10:19:00 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:19:00 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_20, runningTasks: 3
15/08/11 10:19:00 DEBUG SparkDeploySchedulerBackend: [actor] handled message (1.600704 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:19:01 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,62,FINISHED,org.apache.spark.util.SerializableBuffer@1f030fca) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:01 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_20, runningTasks: 2
15/08/11 10:19:01 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.809395 ms) StatusUpdate(0,62,FINISHED,org.apache.spark.util.SerializableBuffer@1f030fca) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:01 DEBUG DAGScheduler: ShuffleMapTask finished on 0
15/08/11 10:19:01 DEBUG DAGScheduler: submitStage(Stage 21)
15/08/11 10:19:01 DEBUG DAGScheduler: missing: List(Stage 20)
15/08/11 10:19:01 DEBUG DAGScheduler: submitStage(Stage 20)
15/08/11 10:19:01 INFO TaskSetManager: Finished task 2.0 in stage 20.0 (TID 62) in 1104 ms on 192.168.130.131 (1/3)
15/08/11 10:19:01 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:19:01 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_20, runningTasks: 2
15/08/11 10:19:01 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.796712 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:19:02 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:19:02 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_20, runningTasks: 2
15/08/11 10:19:02 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.598259 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:19:02 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,61,FINISHED,org.apache.spark.util.SerializableBuffer@201a6ae) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:02 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_20, runningTasks: 1
15/08/11 10:19:02 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.672068 ms) StatusUpdate(0,61,FINISHED,org.apache.spark.util.SerializableBuffer@201a6ae) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:02 DEBUG DAGScheduler: ShuffleMapTask finished on 0
15/08/11 10:19:02 INFO TaskSetManager: Finished task 1.0 in stage 20.0 (TID 61) in 2876 ms on 192.168.130.131 (2/3)
15/08/11 10:19:02 DEBUG DAGScheduler: submitStage(Stage 21)
15/08/11 10:19:02 DEBUG DAGScheduler: missing: List(Stage 20)
15/08/11 10:19:02 DEBUG DAGScheduler: submitStage(Stage 20)
15/08/11 10:19:02 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,60,FINISHED,org.apache.spark.util.SerializableBuffer@535cae6a) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:02 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_20, runningTasks: 0
15/08/11 10:19:02 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.521328 ms) StatusUpdate(0,60,FINISHED,org.apache.spark.util.SerializableBuffer@535cae6a) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:02 DEBUG DAGScheduler: ShuffleMapTask finished on 0
15/08/11 10:19:02 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 60) in 2893 ms on 192.168.130.131 (3/3)
15/08/11 10:19:02 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
15/08/11 10:19:02 INFO DAGScheduler: Stage 20 (map at KMeansTest.scala:61) finished in 2.896 s
15/08/11 10:19:02 INFO DAGScheduler: looking for newly runnable stages
15/08/11 10:19:02 INFO DAGScheduler: running: Set()
15/08/11 10:19:02 INFO DAGScheduler: waiting: Set(Stage 21)
15/08/11 10:19:02 INFO DAGScheduler: failed: Set()
15/08/11 10:19:02 DEBUG MapOutputTrackerMaster: Increasing epoch to 10
15/08/11 10:19:02 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD MapPartitionsRDD[33] at map at KMeansTest.scala:65
15/08/11 10:19:02 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:19:02 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@69bedbe7) from Actor[akka://sparkDriver/temp/$gf]
15/08/11 10:19:02 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:19:02 DEBUG BlockManagerMasterActor: [actor] handled message (0.181626 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@69bedbe7) from Actor[akka://sparkDriver/temp/$gf]
15/08/11 10:19:02 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@69bedbe7) from Actor[akka://sparkDriver/temp/$hf]
15/08/11 10:19:02 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:19:02 DEBUG BlockManagerMasterActor: [actor] handled message (0.178605 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@69bedbe7) from Actor[akka://sparkDriver/temp/$hf]
15/08/11 10:19:02 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:19:02 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|33|0,rdd_33_0,, null|33|1,rdd_33_1,, null|33|2,rdd_33_2,).
15/08/11 10:19:02 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:19:02 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$jf]
15/08/11 10:19:02 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:19:02 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:02 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:02 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:02 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:02 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:02 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:02 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:02 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:02 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:02 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:19:02 DEBUG BlockManagerMasterActor: [actor] handled message (0.762429 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$jf]
15/08/11 10:19:02 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:19:02 DEBUG BlockManager: Got multiple block location in  8 ms
15/08/11 10:19:02 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD ShuffledRDD[32] at reduceByKey at KMeansTest.scala:63
15/08/11 10:19:02 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:19:02 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@20ba33d3) from Actor[akka://sparkDriver/temp/$kf]
15/08/11 10:19:02 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:19:02 DEBUG BlockManagerMasterActor: [actor] handled message (0.150291 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@20ba33d3) from Actor[akka://sparkDriver/temp/$kf]
15/08/11 10:19:02 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@20ba33d3) from Actor[akka://sparkDriver/temp/$lf]
15/08/11 10:19:02 DEBUG BlockManagerMasterActor: [actor] handled message (0.382531 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@20ba33d3) from Actor[akka://sparkDriver/temp/$lf]
15/08/11 10:19:02 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:19:02 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:19:02 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|32|0,rdd_32_0,, null|32|1,rdd_32_1,, null|32|2,rdd_32_2,).
15/08/11 10:19:02 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:19:02 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$nf]
15/08/11 10:19:02 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:19:02 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:02 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:02 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:02 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:02 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:02 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:02 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:02 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:02 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:02 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:19:02 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:19:02 DEBUG BlockManagerMasterActor: [actor] handled message (1.168489 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$nf]
15/08/11 10:19:02 DEBUG BlockManager: Got multiple block location in  10 ms
15/08/11 10:19:02 INFO DAGScheduler: Missing parents for Stage 21: List()
15/08/11 10:19:02 INFO DAGScheduler: Submitting Stage 21 (MapPartitionsRDD[33] at map at KMeansTest.scala:65), which is now runnable
15/08/11 10:19:02 DEBUG DAGScheduler: submitMissingTasks(Stage 21)
15/08/11 10:19:02 INFO MemoryStore: ensureFreeSpace(2560) called with curMem=216754, maxMem=278302556
15/08/11 10:19:02 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 2.5 KB, free 265.2 MB)
15/08/11 10:19:02 DEBUG BlockManager: Put block broadcast_22 locally took  1 ms
15/08/11 10:19:02 DEBUG BlockManager: Putting block broadcast_22 without replication took  1 ms
15/08/11 10:19:02 INFO MemoryStore: ensureFreeSpace(1517) called with curMem=219314, maxMem=278302556
15/08/11 10:19:02 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 1517.0 B, free 265.2 MB)
15/08/11 10:19:02 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_22_piece0,StorageLevel(false, true, false, false, 1),1517,0,0) from Actor[akka://sparkDriver/temp/$of]
15/08/11 10:19:02 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 192.168.130.131:57830 (size: 1517.0 B, free: 265.4 MB)
15/08/11 10:19:02 INFO BlockManagerMaster: Updated info of block broadcast_22_piece0
15/08/11 10:19:02 DEBUG BlockManager: Told master about block broadcast_22_piece0
15/08/11 10:19:02 DEBUG BlockManagerMasterActor: [actor] handled message (0.613912 ms) UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_22_piece0,StorageLevel(false, true, false, false, 1),1517,0,0) from Actor[akka://sparkDriver/temp/$of]
15/08/11 10:19:02 DEBUG BlockManager: Put block broadcast_22_piece0 locally took  3 ms
15/08/11 10:19:02 DEBUG BlockManager: Putting block broadcast_22_piece0 without replication took  3 ms
15/08/11 10:19:02 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:852
15/08/11 10:19:02 INFO DAGScheduler: Submitting 3 missing tasks from Stage 21 (MapPartitionsRDD[33] at map at KMeansTest.scala:65)
15/08/11 10:19:02 DEBUG DAGScheduler: New pending tasks: Set(ResultTask(21, 0), ResultTask(21, 2), ResultTask(21, 1))
15/08/11 10:19:02 INFO TaskSchedulerImpl: Adding task set 21.0 with 3 tasks
15/08/11 10:19:02 DEBUG TaskSetManager: Epoch for TaskSet 21.0: 10
15/08/11 10:19:02 DEBUG TaskSetManager: Valid locality levels for TaskSet 21.0: NO_PREF, ANY
15/08/11 10:19:02 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/deadLetters]
15/08/11 10:19:02 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_21, runningTasks: 0
15/08/11 10:19:02 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 63, 192.168.130.131, PROCESS_LOCAL, 1116 bytes)
15/08/11 10:19:02 INFO TaskSetManager: Starting task 1.0 in stage 21.0 (TID 64, 192.168.130.131, PROCESS_LOCAL, 1116 bytes)
15/08/11 10:19:02 INFO TaskSetManager: Starting task 2.0 in stage 21.0 (TID 65, 192.168.130.131, PROCESS_LOCAL, 1116 bytes)
15/08/11 10:19:02 DEBUG TaskSetManager: No tasks for locality level NO_PREF, so moving to locality level ANY
15/08/11 10:19:02 DEBUG BlockManagerMasterActor: [actor] received message GetLocations(broadcast_22_piece0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$Db]
15/08/11 10:19:02 DEBUG BlockManagerMasterActor: [actor] handled message (0.057454 ms) GetLocations(broadcast_22_piece0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$Db]
15/08/11 10:19:02 DEBUG SparkDeploySchedulerBackend: [actor] handled message (14.453497 ms) ReviveOffers from Actor[akka://sparkDriver/deadLetters]
15/08/11 10:19:02 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,63,RUNNING,org.apache.spark.util.SerializableBuffer@19e60464) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:02 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.050944 ms) StatusUpdate(0,63,RUNNING,org.apache.spark.util.SerializableBuffer@19e60464) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:02 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,64,RUNNING,org.apache.spark.util.SerializableBuffer@4c2a4e84) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:02 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.057115 ms) StatusUpdate(0,64,RUNNING,org.apache.spark.util.SerializableBuffer@4c2a4e84) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:02 DEBUG BlockManager: Level for block broadcast_22_piece0 is StorageLevel(true, true, false, false, 1)
15/08/11 10:19:02 DEBUG BlockManager: Getting block broadcast_22_piece0 from memory
15/08/11 10:19:02 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_22_piece0,StorageLevel(false, true, false, false, 1),1517,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$Eb]
15/08/11 10:19:02 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 192.168.130.131:47921 (size: 1517.0 B, free: 245.7 MB)
15/08/11 10:19:02 DEBUG BlockManagerMasterActor: [actor] handled message (2.61235 ms) UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_22_piece0,StorageLevel(false, true, false, false, 1),1517,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$Eb]
15/08/11 10:19:02 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,65,RUNNING,org.apache.spark.util.SerializableBuffer@2b744a22) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:02 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.060197 ms) StatusUpdate(0,65,RUNNING,org.apache.spark.util.SerializableBuffer@2b744a22) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:02 DEBUG MapOutputTrackerMasterActor: [actor] received message GetMapOutputStatuses(9) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$Fb]
15/08/11 10:19:02 INFO MapOutputTrackerMasterActor: Asked to send map output locations for shuffle 9 to sparkExecutor@192.168.130.131:49489
15/08/11 10:19:02 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 9 is 162 bytes
15/08/11 10:19:02 DEBUG MapOutputTrackerMasterActor: [actor] handled message (0.720649 ms) GetMapOutputStatuses(9) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$Fb]
15/08/11 10:19:02 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,65,FINISHED,org.apache.spark.util.SerializableBuffer@784aa280) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:02 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_21, runningTasks: 2
15/08/11 10:19:02 DEBUG SparkDeploySchedulerBackend: [actor] handled message (1.055886 ms) StatusUpdate(0,65,FINISHED,org.apache.spark.util.SerializableBuffer@784aa280) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:02 INFO TaskSetManager: Finished task 2.0 in stage 21.0 (TID 65) in 58 ms on 192.168.130.131 (1/3)
15/08/11 10:19:02 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,64,FINISHED,org.apache.spark.util.SerializableBuffer@20d65585) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:02 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_21, runningTasks: 1
15/08/11 10:19:02 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.74024 ms) StatusUpdate(0,64,FINISHED,org.apache.spark.util.SerializableBuffer@20d65585) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:03 INFO TaskSetManager: Finished task 1.0 in stage 21.0 (TID 64) in 73 ms on 192.168.130.131 (2/3)
15/08/11 10:19:03 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,63,FINISHED,org.apache.spark.util.SerializableBuffer@7206b8a6) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:03 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_21, runningTasks: 0
15/08/11 10:19:03 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.52728 ms) StatusUpdate(0,63,FINISHED,org.apache.spark.util.SerializableBuffer@7206b8a6) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:03 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 63) in 82 ms on 192.168.130.131 (3/3)
15/08/11 10:19:03 INFO DAGScheduler: Stage 21 (collectAsMap at KMeansTest.scala:67) finished in 0.087 s
15/08/11 10:19:03 DEBUG DAGScheduler: After removal of stage 20, remaining stages = 1
15/08/11 10:19:03 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
15/08/11 10:19:03 DEBUG DAGScheduler: After removal of stage 21, remaining stages = 0
15/08/11 10:19:03 INFO DAGScheduler: Job 11 finished: collectAsMap at KMeansTest.scala:67, took 3.124160 s
Finished iteration (num = 9)
15/08/11 10:19:03 INFO SparkContext: Starting job: collectAsMap at KMeansTest.scala:67
15/08/11 10:19:03 INFO DAGScheduler: Registering RDD 34 (map at KMeansTest.scala:61)
15/08/11 10:19:03 INFO DAGScheduler: Got job 12 (collectAsMap at KMeansTest.scala:67) with 3 output partitions (allowLocal=false)
15/08/11 10:19:03 INFO DAGScheduler: Final stage: Stage 23(collectAsMap at KMeansTest.scala:67)
15/08/11 10:19:03 INFO DAGScheduler: Parents of final stage: List(Stage 22)
15/08/11 10:19:03 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD MapPartitionsRDD[36] at map at KMeansTest.scala:65
15/08/11 10:19:03 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:19:03 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@4b948258) from Actor[akka://sparkDriver/temp/$pf]
15/08/11 10:19:03 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:19:03 DEBUG BlockManagerMasterActor: [actor] handled message (0.177425 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@4b948258) from Actor[akka://sparkDriver/temp/$pf]
15/08/11 10:19:03 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@4b948258) from Actor[akka://sparkDriver/temp/$qf]
15/08/11 10:19:03 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:19:03 DEBUG BlockManagerMasterActor: [actor] handled message (0.205817 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@4b948258) from Actor[akka://sparkDriver/temp/$qf]
15/08/11 10:19:03 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:19:03 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|36|0,rdd_36_0,, null|36|1,rdd_36_1,, null|36|2,rdd_36_2,).
15/08/11 10:19:03 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:19:03 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$sf]
15/08/11 10:19:03 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:19:03 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:03 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:03 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:03 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:03 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:03 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:03 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:03 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:03 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:03 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:19:03 DEBUG BlockManagerMasterActor: [actor] handled message (0.646889 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$sf]
15/08/11 10:19:03 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:19:03 DEBUG BlockManager: Got multiple block location in  10 ms
15/08/11 10:19:03 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD ShuffledRDD[35] at reduceByKey at KMeansTest.scala:63
15/08/11 10:19:03 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:19:03 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@60bdd5eb) from Actor[akka://sparkDriver/temp/$tf]
15/08/11 10:19:03 DEBUG BlockManagerMasterActor: [actor] handled message (0.1555 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@60bdd5eb) from Actor[akka://sparkDriver/temp/$tf]
15/08/11 10:19:03 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:19:03 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@60bdd5eb) from Actor[akka://sparkDriver/temp/$uf]
15/08/11 10:19:03 DEBUG BlockManagerMasterActor: [actor] handled message (0.149038 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@60bdd5eb) from Actor[akka://sparkDriver/temp/$uf]
15/08/11 10:19:03 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:19:03 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:19:03 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|35|0,rdd_35_0,, null|35|1,rdd_35_1,, null|35|2,rdd_35_2,).
15/08/11 10:19:03 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:19:03 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$wf]
15/08/11 10:19:03 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:19:03 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:03 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:03 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:03 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:03 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:03 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:03 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:03 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:03 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:03 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:19:03 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:19:03 DEBUG BlockManagerMasterActor: [actor] handled message (1.451132 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$wf]
15/08/11 10:19:03 DEBUG BlockManager: Got multiple block location in  13 ms
15/08/11 10:19:03 INFO DAGScheduler: [SMSpark v1]Missing parents: List(Stage 22)
15/08/11 10:19:03 DEBUG DAGScheduler: submitStage(Stage 23)
15/08/11 10:19:03 DEBUG DAGScheduler: missing: List(Stage 22)
15/08/11 10:19:03 DEBUG DAGScheduler: submitStage(Stage 22)
15/08/11 10:19:03 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD MapPartitionsRDD[34] at map at KMeansTest.scala:61
15/08/11 10:19:03 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:19:03 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@159e0f9d) from Actor[akka://sparkDriver/temp/$xf]
15/08/11 10:19:03 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:19:03 DEBUG BlockManagerMasterActor: [actor] handled message (0.248248 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@159e0f9d) from Actor[akka://sparkDriver/temp/$xf]
15/08/11 10:19:03 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@159e0f9d) from Actor[akka://sparkDriver/temp/$yf]
15/08/11 10:19:03 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:19:03 DEBUG BlockManagerMasterActor: [actor] handled message (0.23013 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@159e0f9d) from Actor[akka://sparkDriver/temp/$yf]
15/08/11 10:19:03 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:19:03 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|34|0,rdd_34_0,, null|34|1,rdd_34_1,, null|34|2,rdd_34_2,).
15/08/11 10:19:03 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:19:03 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$Af]
15/08/11 10:19:03 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:19:03 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:03 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:03 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:03 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:03 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:03 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:03 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:03 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:03 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:03 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:19:03 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:19:03 DEBUG BlockManagerMasterActor: [actor] handled message (0.678477 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$Af]
15/08/11 10:19:03 DEBUG BlockManager: Got multiple block location in  9 ms
15/08/11 10:19:03 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD KMeans01 MapPartitionsRDD[2] at map at KMeansTest.scala:50
15/08/11 10:19:03 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:19:03 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@4e6a767d) from Actor[akka://sparkDriver/temp/$Bf]
15/08/11 10:19:03 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(ArrayBuffer(BlockManagerId(0, 192.168.130.131, 47921)), ArrayBuffer(BlockManagerId(0, 192.168.130.131, 47921)), ArrayBuffer(BlockManagerId(0, 192.168.130.131, 47921)))
15/08/11 10:19:03 DEBUG BlockManagerMasterActor: [actor] handled message (0.439845 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@4e6a767d) from Actor[akka://sparkDriver/temp/$Bf]
15/08/11 10:19:03 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@4e6a767d) from Actor[akka://sparkDriver/temp/$Cf]
15/08/11 10:19:03 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:19:03 DEBUG BlockManagerMasterActor: [actor] handled message (0.194313 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@4e6a767d) from Actor[akka://sparkDriver/temp/$Cf]
15/08/11 10:19:03 DEBUG DAGScheduler: missing: List()
15/08/11 10:19:03 INFO DAGScheduler: Submitting Stage 22 (MapPartitionsRDD[34] at map at KMeansTest.scala:61), which has no missing parents
15/08/11 10:19:03 DEBUG DAGScheduler: submitMissingTasks(Stage 22)
15/08/11 10:19:03 INFO MemoryStore: ensureFreeSpace(4768) called with curMem=220831, maxMem=278302556
15/08/11 10:19:03 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 4.7 KB, free 265.2 MB)
15/08/11 10:19:03 DEBUG BlockManager: Put block broadcast_23 locally took  1 ms
15/08/11 10:19:03 DEBUG BlockManager: Putting block broadcast_23 without replication took  1 ms
15/08/11 10:19:03 INFO MemoryStore: ensureFreeSpace(3200) called with curMem=225599, maxMem=278302556
15/08/11 10:19:03 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 3.1 KB, free 265.2 MB)
15/08/11 10:19:03 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_23_piece0,StorageLevel(false, true, false, false, 1),3200,0,0) from Actor[akka://sparkDriver/temp/$Df]
15/08/11 10:19:03 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 192.168.130.131:57830 (size: 3.1 KB, free: 265.4 MB)
15/08/11 10:19:03 INFO BlockManagerMaster: Updated info of block broadcast_23_piece0
15/08/11 10:19:03 DEBUG BlockManager: Told master about block broadcast_23_piece0
15/08/11 10:19:03 DEBUG BlockManagerMasterActor: [actor] handled message (0.539254 ms) UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_23_piece0,StorageLevel(false, true, false, false, 1),3200,0,0) from Actor[akka://sparkDriver/temp/$Df]
15/08/11 10:19:03 DEBUG BlockManager: Put block broadcast_23_piece0 locally took  2 ms
15/08/11 10:19:03 DEBUG BlockManager: Putting block broadcast_23_piece0 without replication took  2 ms
15/08/11 10:19:03 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:852
15/08/11 10:19:03 INFO DAGScheduler: Submitting 3 missing tasks from Stage 22 (MapPartitionsRDD[34] at map at KMeansTest.scala:61)
15/08/11 10:19:03 DEBUG DAGScheduler: New pending tasks: Set(ShuffleMapTask(22, 0), ShuffleMapTask(22, 1), ShuffleMapTask(22, 2))
15/08/11 10:19:03 INFO TaskSchedulerImpl: Adding task set 22.0 with 3 tasks
15/08/11 10:19:03 DEBUG TaskSetManager: Epoch for TaskSet 22.0: 10
15/08/11 10:19:03 DEBUG TaskSetManager: Valid locality levels for TaskSet 22.0: PROCESS_LOCAL, NODE_LOCAL, ANY
15/08/11 10:19:03 DEBUG DAGScheduler: submitStage(Stage 23)
15/08/11 10:19:03 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/deadLetters]
15/08/11 10:19:03 DEBUG DAGScheduler: missing: List(Stage 22)
15/08/11 10:19:03 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_22, runningTasks: 0
15/08/11 10:19:03 DEBUG DAGScheduler: submitStage(Stage 22)
15/08/11 10:19:03 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 66, 192.168.130.131, PROCESS_LOCAL, 1361 bytes)
15/08/11 10:19:03 DEBUG DAGScheduler: submitStage(Stage 23)
15/08/11 10:19:03 DEBUG DAGScheduler: missing: List(Stage 22)
15/08/11 10:19:03 DEBUG DAGScheduler: submitStage(Stage 22)
15/08/11 10:19:03 INFO TaskSetManager: Starting task 1.0 in stage 22.0 (TID 67, 192.168.130.131, PROCESS_LOCAL, 1361 bytes)
15/08/11 10:19:03 DEBUG DAGScheduler: submitStage(Stage 23)
15/08/11 10:19:03 DEBUG DAGScheduler: missing: List(Stage 22)
15/08/11 10:19:03 DEBUG DAGScheduler: submitStage(Stage 22)
15/08/11 10:19:03 INFO TaskSetManager: Starting task 2.0 in stage 22.0 (TID 68, 192.168.130.131, PROCESS_LOCAL, 1361 bytes)
15/08/11 10:19:03 DEBUG TaskSetManager: No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
15/08/11 10:19:03 DEBUG DAGScheduler: submitStage(Stage 23)
15/08/11 10:19:03 DEBUG TaskSetManager: No tasks for locality level NODE_LOCAL, so moving to locality level ANY
15/08/11 10:19:03 DEBUG DAGScheduler: missing: List(Stage 22)
15/08/11 10:19:03 DEBUG DAGScheduler: submitStage(Stage 22)
15/08/11 10:19:03 DEBUG SparkDeploySchedulerBackend: [actor] handled message (5.865886 ms) ReviveOffers from Actor[akka://sparkDriver/deadLetters]
15/08/11 10:19:03 DEBUG BlockManagerMasterActor: [actor] received message GetLocations(broadcast_23_piece0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$Gb]
15/08/11 10:19:03 DEBUG BlockManagerMasterActor: [actor] handled message (0.192403 ms) GetLocations(broadcast_23_piece0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$Gb]
15/08/11 10:19:03 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,66,RUNNING,org.apache.spark.util.SerializableBuffer@1e9d1025) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:03 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.106457 ms) StatusUpdate(0,66,RUNNING,org.apache.spark.util.SerializableBuffer@1e9d1025) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:03 DEBUG BlockManager: Level for block broadcast_23_piece0 is StorageLevel(true, true, false, false, 1)
15/08/11 10:19:03 DEBUG BlockManager: Getting block broadcast_23_piece0 from memory
15/08/11 10:19:03 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,67,RUNNING,org.apache.spark.util.SerializableBuffer@4db0fa61) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:03 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.088838 ms) StatusUpdate(0,67,RUNNING,org.apache.spark.util.SerializableBuffer@4db0fa61) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:03 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,68,RUNNING,org.apache.spark.util.SerializableBuffer@1e061e20) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:03 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.040901 ms) StatusUpdate(0,68,RUNNING,org.apache.spark.util.SerializableBuffer@1e061e20) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:03 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_23_piece0,StorageLevel(false, true, false, false, 1),3200,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$Hb]
15/08/11 10:19:03 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 192.168.130.131:47921 (size: 3.1 KB, free: 245.7 MB)
15/08/11 10:19:03 DEBUG BlockManagerMasterActor: [actor] handled message (6.194012 ms) UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_23_piece0,StorageLevel(false, true, false, false, 1),3200,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$Hb]
15/08/11 10:19:03 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:19:03 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_22, runningTasks: 3
15/08/11 10:19:03 DEBUG SparkDeploySchedulerBackend: [actor] handled message (1.404101 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:19:04 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,68,FINISHED,org.apache.spark.util.SerializableBuffer@23a3d646) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:04 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_22, runningTasks: 2
15/08/11 10:19:04 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.826506 ms) StatusUpdate(0,68,FINISHED,org.apache.spark.util.SerializableBuffer@23a3d646) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:04 DEBUG DAGScheduler: ShuffleMapTask finished on 0
15/08/11 10:19:04 DEBUG DAGScheduler: submitStage(Stage 23)
15/08/11 10:19:04 DEBUG DAGScheduler: missing: List(Stage 22)
15/08/11 10:19:04 DEBUG DAGScheduler: submitStage(Stage 22)
15/08/11 10:19:04 INFO TaskSetManager: Finished task 2.0 in stage 22.0 (TID 68) in 1299 ms on 192.168.130.131 (1/3)
15/08/11 10:19:04 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:19:04 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_22, runningTasks: 2
15/08/11 10:19:04 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.680769 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:19:05 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:19:05 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_22, runningTasks: 2
15/08/11 10:19:05 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.568981 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:19:06 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,66,FINISHED,org.apache.spark.util.SerializableBuffer@59489ff1) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:06 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_22, runningTasks: 1
15/08/11 10:19:06 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.904288 ms) StatusUpdate(0,66,FINISHED,org.apache.spark.util.SerializableBuffer@59489ff1) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:06 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 66) in 3008 ms on 192.168.130.131 (2/3)
15/08/11 10:19:06 DEBUG DAGScheduler: ShuffleMapTask finished on 0
15/08/11 10:19:06 DEBUG DAGScheduler: submitStage(Stage 23)
15/08/11 10:19:06 DEBUG DAGScheduler: missing: List(Stage 22)
15/08/11 10:19:06 DEBUG DAGScheduler: submitStage(Stage 22)
15/08/11 10:19:06 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,67,FINISHED,org.apache.spark.util.SerializableBuffer@72c315a3) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:06 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_22, runningTasks: 0
15/08/11 10:19:06 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.468512 ms) StatusUpdate(0,67,FINISHED,org.apache.spark.util.SerializableBuffer@72c315a3) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:06 DEBUG DAGScheduler: ShuffleMapTask finished on 0
15/08/11 10:19:06 INFO DAGScheduler: Stage 22 (map at KMeansTest.scala:61) finished in 3.082 s
15/08/11 10:19:06 INFO DAGScheduler: looking for newly runnable stages
15/08/11 10:19:06 INFO DAGScheduler: running: Set()
15/08/11 10:19:06 INFO DAGScheduler: waiting: Set(Stage 23)
15/08/11 10:19:06 INFO DAGScheduler: failed: Set()
15/08/11 10:19:06 DEBUG MapOutputTrackerMaster: Increasing epoch to 11
15/08/11 10:19:06 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD MapPartitionsRDD[36] at map at KMeansTest.scala:65
15/08/11 10:19:06 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@65c1bb31) from Actor[akka://sparkDriver/temp/$Ef]
15/08/11 10:19:06 INFO TaskSetManager: Finished task 1.0 in stage 22.0 (TID 67) in 3076 ms on 192.168.130.131 (3/3)
15/08/11 10:19:06 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
15/08/11 10:19:06 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: [actor] handled message (0.206936 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@65c1bb31) from Actor[akka://sparkDriver/temp/$Ef]
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@65c1bb31) from Actor[akka://sparkDriver/temp/$Ff]
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: [actor] handled message (0.185593 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@65c1bb31) from Actor[akka://sparkDriver/temp/$Ff]
15/08/11 10:19:06 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:19:06 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:19:06 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|36|0,rdd_36_0,, null|36|1,rdd_36_1,, null|36|2,rdd_36_2,).
15/08/11 10:19:06 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$Hf]
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:19:06 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: [actor] handled message (0.714625 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$Hf]
15/08/11 10:19:06 DEBUG BlockManager: Got multiple block location in  10 ms
15/08/11 10:19:06 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD ShuffledRDD[35] at reduceByKey at KMeansTest.scala:63
15/08/11 10:19:06 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@33c94b6e) from Actor[akka://sparkDriver/temp/$If]
15/08/11 10:19:06 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: [actor] handled message (0.155509 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@33c94b6e) from Actor[akka://sparkDriver/temp/$If]
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@33c94b6e) from Actor[akka://sparkDriver/temp/$Jf]
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: [actor] handled message (0.132553 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@33c94b6e) from Actor[akka://sparkDriver/temp/$Jf]
15/08/11 10:19:06 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:19:06 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:19:06 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|35|0,rdd_35_0,, null|35|1,rdd_35_1,, null|35|2,rdd_35_2,).
15/08/11 10:19:06 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$Lf]
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: [actor] handled message (0.681108 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$Lf]
15/08/11 10:19:06 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:19:06 DEBUG BlockManager: Got multiple block location in  9 ms
15/08/11 10:19:06 INFO DAGScheduler: Missing parents for Stage 23: List()
15/08/11 10:19:06 INFO DAGScheduler: Submitting Stage 23 (MapPartitionsRDD[36] at map at KMeansTest.scala:65), which is now runnable
15/08/11 10:19:06 DEBUG DAGScheduler: submitMissingTasks(Stage 23)
15/08/11 10:19:06 INFO MemoryStore: ensureFreeSpace(2560) called with curMem=228799, maxMem=278302556
15/08/11 10:19:06 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 2.5 KB, free 265.2 MB)
15/08/11 10:19:06 DEBUG BlockManager: Put block broadcast_24 locally took  1 ms
15/08/11 10:19:06 DEBUG BlockManager: Putting block broadcast_24 without replication took  1 ms
15/08/11 10:19:06 INFO MemoryStore: ensureFreeSpace(1521) called with curMem=231359, maxMem=278302556
15/08/11 10:19:06 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 1521.0 B, free 265.2 MB)
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_24_piece0,StorageLevel(false, true, false, false, 1),1521,0,0) from Actor[akka://sparkDriver/temp/$Mf]
15/08/11 10:19:06 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 192.168.130.131:57830 (size: 1521.0 B, free: 265.4 MB)
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: [actor] handled message (0.485538 ms) UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_24_piece0,StorageLevel(false, true, false, false, 1),1521,0,0) from Actor[akka://sparkDriver/temp/$Mf]
15/08/11 10:19:06 INFO BlockManagerMaster: Updated info of block broadcast_24_piece0
15/08/11 10:19:06 DEBUG BlockManager: Told master about block broadcast_24_piece0
15/08/11 10:19:06 DEBUG BlockManager: Put block broadcast_24_piece0 locally took  2 ms
15/08/11 10:19:06 DEBUG BlockManager: Putting block broadcast_24_piece0 without replication took  2 ms
15/08/11 10:19:06 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:852
15/08/11 10:19:06 INFO DAGScheduler: Submitting 3 missing tasks from Stage 23 (MapPartitionsRDD[36] at map at KMeansTest.scala:65)
15/08/11 10:19:06 DEBUG DAGScheduler: New pending tasks: Set(ResultTask(23, 0), ResultTask(23, 1), ResultTask(23, 2))
15/08/11 10:19:06 INFO TaskSchedulerImpl: Adding task set 23.0 with 3 tasks
15/08/11 10:19:06 DEBUG TaskSetManager: Epoch for TaskSet 23.0: 11
15/08/11 10:19:06 DEBUG TaskSetManager: Valid locality levels for TaskSet 23.0: NO_PREF, ANY
15/08/11 10:19:06 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/deadLetters]
15/08/11 10:19:06 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_23, runningTasks: 0
15/08/11 10:19:06 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 69, 192.168.130.131, PROCESS_LOCAL, 1116 bytes)
15/08/11 10:19:06 INFO TaskSetManager: Starting task 1.0 in stage 23.0 (TID 70, 192.168.130.131, PROCESS_LOCAL, 1116 bytes)
15/08/11 10:19:06 INFO TaskSetManager: Starting task 2.0 in stage 23.0 (TID 71, 192.168.130.131, PROCESS_LOCAL, 1116 bytes)
15/08/11 10:19:06 DEBUG TaskSetManager: No tasks for locality level NO_PREF, so moving to locality level ANY
15/08/11 10:19:06 DEBUG SparkDeploySchedulerBackend: [actor] handled message (3.751094 ms) ReviveOffers from Actor[akka://sparkDriver/deadLetters]
15/08/11 10:19:06 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,69,RUNNING,org.apache.spark.util.SerializableBuffer@2f9df1ef) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:06 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.063387 ms) StatusUpdate(0,69,RUNNING,org.apache.spark.util.SerializableBuffer@2f9df1ef) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:06 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,70,RUNNING,org.apache.spark.util.SerializableBuffer@2a769a55) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:06 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.089544 ms) StatusUpdate(0,70,RUNNING,org.apache.spark.util.SerializableBuffer@2a769a55) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: [actor] received message GetLocations(broadcast_24_piece0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$Ib]
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: [actor] handled message (0.153407 ms) GetLocations(broadcast_24_piece0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$Ib]
15/08/11 10:19:06 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,71,RUNNING,org.apache.spark.util.SerializableBuffer@112d0b5) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:06 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.047282 ms) StatusUpdate(0,71,RUNNING,org.apache.spark.util.SerializableBuffer@112d0b5) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:06 DEBUG BlockManager: Level for block broadcast_24_piece0 is StorageLevel(true, true, false, false, 1)
15/08/11 10:19:06 DEBUG BlockManager: Getting block broadcast_24_piece0 from memory
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_24_piece0,StorageLevel(false, true, false, false, 1),1521,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$Jb]
15/08/11 10:19:06 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 192.168.130.131:47921 (size: 1521.0 B, free: 245.7 MB)
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: [actor] handled message (0.614044 ms) UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_24_piece0,StorageLevel(false, true, false, false, 1),1521,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$Jb]
15/08/11 10:19:06 DEBUG MapOutputTrackerMasterActor: [actor] received message GetMapOutputStatuses(10) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$Kb]
15/08/11 10:19:06 INFO MapOutputTrackerMasterActor: Asked to send map output locations for shuffle 10 to sparkExecutor@192.168.130.131:49489
15/08/11 10:19:06 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 10 is 161 bytes
15/08/11 10:19:06 DEBUG MapOutputTrackerMasterActor: [actor] handled message (0.767826 ms) GetMapOutputStatuses(10) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$Kb]
15/08/11 10:19:06 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,71,FINISHED,org.apache.spark.util.SerializableBuffer@293a6c6f) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:06 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_23, runningTasks: 2
15/08/11 10:19:06 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.594917 ms) StatusUpdate(0,71,FINISHED,org.apache.spark.util.SerializableBuffer@293a6c6f) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:06 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,70,FINISHED,org.apache.spark.util.SerializableBuffer@3aa5008e) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:06 INFO TaskSetManager: Finished task 2.0 in stage 23.0 (TID 71) in 82 ms on 192.168.130.131 (1/3)
15/08/11 10:19:06 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_23, runningTasks: 1
15/08/11 10:19:06 DEBUG SparkDeploySchedulerBackend: [actor] handled message (2.359065 ms) StatusUpdate(0,70,FINISHED,org.apache.spark.util.SerializableBuffer@3aa5008e) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:06 INFO TaskSetManager: Finished task 1.0 in stage 23.0 (TID 70) in 90 ms on 192.168.130.131 (2/3)
15/08/11 10:19:06 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,69,FINISHED,org.apache.spark.util.SerializableBuffer@2d9c39a5) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:06 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_23, runningTasks: 0
15/08/11 10:19:06 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.655549 ms) StatusUpdate(0,69,FINISHED,org.apache.spark.util.SerializableBuffer@2d9c39a5) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:06 INFO DAGScheduler: Stage 23 (collectAsMap at KMeansTest.scala:67) finished in 0.105 s
15/08/11 10:19:06 DEBUG DAGScheduler: After removal of stage 23, remaining stages = 1
15/08/11 10:19:06 DEBUG DAGScheduler: After removal of stage 22, remaining stages = 0
15/08/11 10:19:06 INFO DAGScheduler: Job 12 finished: collectAsMap at KMeansTest.scala:67, took 3.289074 s
Finished iteration (num = 10)
15/08/11 10:19:06 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 69) in 101 ms on 192.168.130.131 (3/3)
15/08/11 10:19:06 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
15/08/11 10:19:06 INFO SparkContext: Starting job: collectAsMap at KMeansTest.scala:67
15/08/11 10:19:06 INFO DAGScheduler: Registering RDD 37 (map at KMeansTest.scala:61)
15/08/11 10:19:06 INFO DAGScheduler: Got job 13 (collectAsMap at KMeansTest.scala:67) with 3 output partitions (allowLocal=false)
15/08/11 10:19:06 INFO DAGScheduler: Final stage: Stage 25(collectAsMap at KMeansTest.scala:67)
15/08/11 10:19:06 INFO DAGScheduler: Parents of final stage: List(Stage 24)
15/08/11 10:19:06 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD MapPartitionsRDD[39] at map at KMeansTest.scala:65
15/08/11 10:19:06 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@68a7d510) from Actor[akka://sparkDriver/temp/$Nf]
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: [actor] handled message (0.162726 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@68a7d510) from Actor[akka://sparkDriver/temp/$Nf]
15/08/11 10:19:06 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@68a7d510) from Actor[akka://sparkDriver/temp/$Of]
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: [actor] handled message (0.09426 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@68a7d510) from Actor[akka://sparkDriver/temp/$Of]
15/08/11 10:19:06 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:19:06 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:19:06 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|39|0,rdd_39_0,, null|39|1,rdd_39_1,, null|39|2,rdd_39_2,).
15/08/11 10:19:06 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$Qf]
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: [actor] handled message (0.654479 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$Qf]
15/08/11 10:19:06 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:19:06 DEBUG BlockManager: Got multiple block location in  11 ms
15/08/11 10:19:06 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD ShuffledRDD[38] at reduceByKey at KMeansTest.scala:63
15/08/11 10:19:06 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@1fc59c17) from Actor[akka://sparkDriver/temp/$Rf]
15/08/11 10:19:06 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: [actor] handled message (0.201668 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@1fc59c17) from Actor[akka://sparkDriver/temp/$Rf]
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@1fc59c17) from Actor[akka://sparkDriver/temp/$Sf]
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: [actor] handled message (0.140822 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@1fc59c17) from Actor[akka://sparkDriver/temp/$Sf]
15/08/11 10:19:06 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:19:06 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:19:06 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|38|0,rdd_38_0,, null|38|1,rdd_38_1,, null|38|2,rdd_38_2,).
15/08/11 10:19:06 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$Uf]
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: [actor] handled message (0.625717 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$Uf]
15/08/11 10:19:06 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:19:06 DEBUG BlockManager: Got multiple block location in  11 ms
15/08/11 10:19:06 INFO DAGScheduler: [SMSpark v1]Missing parents: List(Stage 24)
15/08/11 10:19:06 DEBUG DAGScheduler: submitStage(Stage 25)
15/08/11 10:19:06 DEBUG DAGScheduler: missing: List(Stage 24)
15/08/11 10:19:06 DEBUG DAGScheduler: submitStage(Stage 24)
15/08/11 10:19:06 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD MapPartitionsRDD[37] at map at KMeansTest.scala:61
15/08/11 10:19:06 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@19ccba05) from Actor[akka://sparkDriver/temp/$Vf]
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: [actor] handled message (0.175571 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@19ccba05) from Actor[akka://sparkDriver/temp/$Vf]
15/08/11 10:19:06 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@19ccba05) from Actor[akka://sparkDriver/temp/$Wf]
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: [actor] handled message (0.175325 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@19ccba05) from Actor[akka://sparkDriver/temp/$Wf]
15/08/11 10:19:06 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:19:06 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:19:06 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|37|0,rdd_37_0,, null|37|1,rdd_37_1,, null|37|2,rdd_37_2,).
15/08/11 10:19:06 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$Yf]
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: [actor] handled message (0.736253 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$Yf]
15/08/11 10:19:06 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:19:06 DEBUG BlockManager: Got multiple block location in  15 ms
15/08/11 10:19:06 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD KMeans01 MapPartitionsRDD[2] at map at KMeansTest.scala:50
15/08/11 10:19:06 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@7e658a10) from Actor[akka://sparkDriver/temp/$Zf]
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: [actor] handled message (0.213489 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@7e658a10) from Actor[akka://sparkDriver/temp/$Zf]
15/08/11 10:19:06 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(ArrayBuffer(BlockManagerId(0, 192.168.130.131, 47921)), ArrayBuffer(BlockManagerId(0, 192.168.130.131, 47921)), ArrayBuffer(BlockManagerId(0, 192.168.130.131, 47921)))
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@7e658a10) from Actor[akka://sparkDriver/temp/$0f]
15/08/11 10:19:06 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: [actor] handled message (0.315337 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@7e658a10) from Actor[akka://sparkDriver/temp/$0f]
15/08/11 10:19:06 DEBUG DAGScheduler: missing: List()
15/08/11 10:19:06 INFO DAGScheduler: Submitting Stage 24 (MapPartitionsRDD[37] at map at KMeansTest.scala:61), which has no missing parents
15/08/11 10:19:06 DEBUG DAGScheduler: submitMissingTasks(Stage 24)
15/08/11 10:19:06 INFO MemoryStore: ensureFreeSpace(4768) called with curMem=232880, maxMem=278302556
15/08/11 10:19:06 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 4.7 KB, free 265.2 MB)
15/08/11 10:19:06 DEBUG BlockManager: Put block broadcast_25 locally took  3 ms
15/08/11 10:19:06 DEBUG BlockManager: Putting block broadcast_25 without replication took  3 ms
15/08/11 10:19:06 INFO MemoryStore: ensureFreeSpace(3201) called with curMem=237648, maxMem=278302556
15/08/11 10:19:06 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 3.1 KB, free 265.2 MB)
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_25_piece0,StorageLevel(false, true, false, false, 1),3201,0,0) from Actor[akka://sparkDriver/temp/$1f]
15/08/11 10:19:06 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 192.168.130.131:57830 (size: 3.1 KB, free: 265.4 MB)
15/08/11 10:19:06 INFO BlockManagerMaster: Updated info of block broadcast_25_piece0
15/08/11 10:19:06 DEBUG BlockManager: Told master about block broadcast_25_piece0
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: [actor] handled message (0.539298 ms) UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_25_piece0,StorageLevel(false, true, false, false, 1),3201,0,0) from Actor[akka://sparkDriver/temp/$1f]
15/08/11 10:19:06 DEBUG BlockManager: Put block broadcast_25_piece0 locally took  2 ms
15/08/11 10:19:06 DEBUG BlockManager: Putting block broadcast_25_piece0 without replication took  2 ms
15/08/11 10:19:06 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:852
15/08/11 10:19:06 INFO DAGScheduler: Submitting 3 missing tasks from Stage 24 (MapPartitionsRDD[37] at map at KMeansTest.scala:61)
15/08/11 10:19:06 DEBUG DAGScheduler: New pending tasks: Set(ShuffleMapTask(24, 2), ShuffleMapTask(24, 1), ShuffleMapTask(24, 0))
15/08/11 10:19:06 INFO TaskSchedulerImpl: Adding task set 24.0 with 3 tasks
15/08/11 10:19:06 DEBUG TaskSetManager: Epoch for TaskSet 24.0: 11
15/08/11 10:19:06 DEBUG TaskSetManager: Valid locality levels for TaskSet 24.0: PROCESS_LOCAL, NODE_LOCAL, ANY
15/08/11 10:19:06 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/deadLetters]
15/08/11 10:19:06 DEBUG DAGScheduler: submitStage(Stage 25)
15/08/11 10:19:06 DEBUG DAGScheduler: missing: List(Stage 24)
15/08/11 10:19:06 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_24, runningTasks: 0
15/08/11 10:19:06 DEBUG DAGScheduler: submitStage(Stage 24)
15/08/11 10:19:06 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 72, 192.168.130.131, PROCESS_LOCAL, 1361 bytes)
15/08/11 10:19:06 DEBUG DAGScheduler: submitStage(Stage 25)
15/08/11 10:19:06 DEBUG DAGScheduler: missing: List(Stage 24)
15/08/11 10:19:06 INFO TaskSetManager: Starting task 1.0 in stage 24.0 (TID 73, 192.168.130.131, PROCESS_LOCAL, 1361 bytes)
15/08/11 10:19:06 DEBUG DAGScheduler: submitStage(Stage 24)
15/08/11 10:19:06 INFO TaskSetManager: Starting task 2.0 in stage 24.0 (TID 74, 192.168.130.131, PROCESS_LOCAL, 1361 bytes)
15/08/11 10:19:06 DEBUG TaskSetManager: No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
15/08/11 10:19:06 DEBUG TaskSetManager: No tasks for locality level NODE_LOCAL, so moving to locality level ANY
15/08/11 10:19:06 DEBUG SparkDeploySchedulerBackend: [actor] handled message (20.424294 ms) ReviveOffers from Actor[akka://sparkDriver/deadLetters]
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: [actor] received message GetLocations(broadcast_25_piece0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$Lb]
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: [actor] handled message (0.082216 ms) GetLocations(broadcast_25_piece0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$Lb]
15/08/11 10:19:06 DEBUG DAGScheduler: submitStage(Stage 25)
15/08/11 10:19:06 DEBUG DAGScheduler: missing: List(Stage 24)
15/08/11 10:19:06 DEBUG DAGScheduler: submitStage(Stage 24)
15/08/11 10:19:06 DEBUG DAGScheduler: submitStage(Stage 25)
15/08/11 10:19:06 DEBUG DAGScheduler: missing: List(Stage 24)
15/08/11 10:19:06 DEBUG DAGScheduler: submitStage(Stage 24)
15/08/11 10:19:06 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,72,RUNNING,org.apache.spark.util.SerializableBuffer@20dfdd55) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:06 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.351872 ms) StatusUpdate(0,72,RUNNING,org.apache.spark.util.SerializableBuffer@20dfdd55) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:06 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,73,RUNNING,org.apache.spark.util.SerializableBuffer@493c084f) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:06 DEBUG BlockManager: Level for block broadcast_25_piece0 is StorageLevel(true, true, false, false, 1)
15/08/11 10:19:06 DEBUG BlockManager: Getting block broadcast_25_piece0 from memory
15/08/11 10:19:06 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.89767 ms) StatusUpdate(0,73,RUNNING,org.apache.spark.util.SerializableBuffer@493c084f) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:06 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,74,RUNNING,org.apache.spark.util.SerializableBuffer@31473beb) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:06 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.062628 ms) StatusUpdate(0,74,RUNNING,org.apache.spark.util.SerializableBuffer@31473beb) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_25_piece0,StorageLevel(false, true, false, false, 1),3201,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$Mb]
15/08/11 10:19:06 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 192.168.130.131:47921 (size: 3.1 KB, free: 245.7 MB)
15/08/11 10:19:06 DEBUG BlockManagerMasterActor: [actor] handled message (0.525372 ms) UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_25_piece0,StorageLevel(false, true, false, false, 1),3201,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$Mb]
15/08/11 10:19:06 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:19:06 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_24, runningTasks: 3
15/08/11 10:19:06 DEBUG SparkDeploySchedulerBackend: [actor] handled message (3.9164 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:19:07 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,74,FINISHED,org.apache.spark.util.SerializableBuffer@54900781) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:07 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_24, runningTasks: 2
15/08/11 10:19:07 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.776045 ms) StatusUpdate(0,74,FINISHED,org.apache.spark.util.SerializableBuffer@54900781) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:07 DEBUG DAGScheduler: ShuffleMapTask finished on 0
15/08/11 10:19:07 DEBUG DAGScheduler: submitStage(Stage 25)
15/08/11 10:19:07 DEBUG DAGScheduler: missing: List(Stage 24)
15/08/11 10:19:07 DEBUG DAGScheduler: submitStage(Stage 24)
15/08/11 10:19:07 INFO TaskSetManager: Finished task 2.0 in stage 24.0 (TID 74) in 1122 ms on 192.168.130.131 (1/3)
15/08/11 10:19:07 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:19:07 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_24, runningTasks: 2
15/08/11 10:19:07 DEBUG SparkDeploySchedulerBackend: [actor] handled message (1.044814 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:19:08 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:19:08 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_24, runningTasks: 2
15/08/11 10:19:08 DEBUG SparkDeploySchedulerBackend: [actor] handled message (1.323159 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:19:09 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:19:09 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_24, runningTasks: 2
15/08/11 10:19:09 DEBUG SparkDeploySchedulerBackend: [actor] handled message (24.761203 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:19:10 DEBUG HeartbeatReceiver: [actor] received message Heartbeat(0,[Lscala.Tuple2;@1e3fd31e,BlockManagerId(0, 192.168.130.131, 47921)) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$Nb]
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: [actor] received message BlockManagerHeartbeat(BlockManagerId(0, 192.168.130.131, 47921)) from Actor[akka://sparkDriver/temp/$2f]
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: [actor] handled message (0.150133 ms) BlockManagerHeartbeat(BlockManagerId(0, 192.168.130.131, 47921)) from Actor[akka://sparkDriver/temp/$2f]
15/08/11 10:19:10 DEBUG HeartbeatReceiver: [actor] handled message (9.691274 ms) Heartbeat(0,[Lscala.Tuple2;@1e3fd31e,BlockManagerId(0, 192.168.130.131, 47921)) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$Nb]
15/08/11 10:19:10 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,73,FINISHED,org.apache.spark.util.SerializableBuffer@4ef92644) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:10 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_24, runningTasks: 1
15/08/11 10:19:10 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.784315 ms) StatusUpdate(0,73,FINISHED,org.apache.spark.util.SerializableBuffer@4ef92644) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:10 DEBUG DAGScheduler: ShuffleMapTask finished on 0
15/08/11 10:19:10 INFO TaskSetManager: Finished task 1.0 in stage 24.0 (TID 73) in 3745 ms on 192.168.130.131 (2/3)
15/08/11 10:19:10 DEBUG DAGScheduler: submitStage(Stage 25)
15/08/11 10:19:10 DEBUG DAGScheduler: missing: List(Stage 24)
15/08/11 10:19:10 DEBUG DAGScheduler: submitStage(Stage 24)
15/08/11 10:19:10 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,72,FINISHED,org.apache.spark.util.SerializableBuffer@473f62dd) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:10 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_24, runningTasks: 0
15/08/11 10:19:10 DEBUG SparkDeploySchedulerBackend: [actor] handled message (1.111803 ms) StatusUpdate(0,72,FINISHED,org.apache.spark.util.SerializableBuffer@473f62dd) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:10 DEBUG DAGScheduler: ShuffleMapTask finished on 0
15/08/11 10:19:10 INFO DAGScheduler: Stage 24 (map at KMeansTest.scala:61) finished in 4.116 s
15/08/11 10:19:10 INFO DAGScheduler: looking for newly runnable stages
15/08/11 10:19:10 INFO DAGScheduler: running: Set()
15/08/11 10:19:10 INFO DAGScheduler: waiting: Set(Stage 25)
15/08/11 10:19:10 INFO DAGScheduler: failed: Set()
15/08/11 10:19:10 DEBUG MapOutputTrackerMaster: Increasing epoch to 12
15/08/11 10:19:10 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD MapPartitionsRDD[39] at map at KMeansTest.scala:65
15/08/11 10:19:10 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@1273bfb6) from Actor[akka://sparkDriver/temp/$3f]
15/08/11 10:19:10 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 72) in 4109 ms on 192.168.130.131 (3/3)
15/08/11 10:19:10 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: [actor] handled message (0.526347 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@1273bfb6) from Actor[akka://sparkDriver/temp/$3f]
15/08/11 10:19:10 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@1273bfb6) from Actor[akka://sparkDriver/temp/$4f]
15/08/11 10:19:10 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: [actor] handled message (0.422316 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@1273bfb6) from Actor[akka://sparkDriver/temp/$4f]
15/08/11 10:19:10 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:19:10 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|39|0,rdd_39_0,, null|39|1,rdd_39_1,, null|39|2,rdd_39_2,).
15/08/11 10:19:10 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$6f]
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:19:10 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:19:10 DEBUG BlockManager: Got multiple block location in  19 ms
15/08/11 10:19:10 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD ShuffledRDD[38] at reduceByKey at KMeansTest.scala:63
15/08/11 10:19:10 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: [actor] handled message (8.140199 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$6f]
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@131ae71c) from Actor[akka://sparkDriver/temp/$7f]
15/08/11 10:19:10 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: [actor] handled message (0.573621 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@131ae71c) from Actor[akka://sparkDriver/temp/$7f]
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@131ae71c) from Actor[akka://sparkDriver/temp/$8f]
15/08/11 10:19:10 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:19:10 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:19:10 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|38|0,rdd_38_0,, null|38|1,rdd_38_1,, null|38|2,rdd_38_2,).
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: [actor] handled message (2.540662 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@131ae71c) from Actor[akka://sparkDriver/temp/$8f]
15/08/11 10:19:10 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$+f]
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:19:10 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:19:10 DEBUG BlockManager: Got multiple block location in  20 ms
15/08/11 10:19:10 INFO DAGScheduler: Missing parents for Stage 25: List()
15/08/11 10:19:10 INFO DAGScheduler: Submitting Stage 25 (MapPartitionsRDD[39] at map at KMeansTest.scala:65), which is now runnable
15/08/11 10:19:10 DEBUG DAGScheduler: submitMissingTasks(Stage 25)
15/08/11 10:19:10 INFO MemoryStore: ensureFreeSpace(2560) called with curMem=240849, maxMem=278302556
15/08/11 10:19:10 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 2.5 KB, free 265.2 MB)
15/08/11 10:19:10 DEBUG BlockManager: Put block broadcast_26 locally took  2 ms
15/08/11 10:19:10 DEBUG BlockManager: Putting block broadcast_26 without replication took  2 ms
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: [actor] handled message (7.4255 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$+f]
15/08/11 10:19:10 INFO MemoryStore: ensureFreeSpace(1521) called with curMem=243409, maxMem=278302556
15/08/11 10:19:10 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 1521.0 B, free 265.2 MB)
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_26_piece0,StorageLevel(false, true, false, false, 1),1521,0,0) from Actor[akka://sparkDriver/temp/$~f]
15/08/11 10:19:10 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 192.168.130.131:57830 (size: 1521.0 B, free: 265.4 MB)
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: [actor] handled message (0.447369 ms) UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_26_piece0,StorageLevel(false, true, false, false, 1),1521,0,0) from Actor[akka://sparkDriver/temp/$~f]
15/08/11 10:19:10 INFO BlockManagerMaster: Updated info of block broadcast_26_piece0
15/08/11 10:19:10 DEBUG BlockManager: Told master about block broadcast_26_piece0
15/08/11 10:19:10 DEBUG BlockManager: Put block broadcast_26_piece0 locally took  2 ms
15/08/11 10:19:10 DEBUG BlockManager: Putting block broadcast_26_piece0 without replication took  2 ms
15/08/11 10:19:10 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:852
15/08/11 10:19:10 INFO DAGScheduler: Submitting 3 missing tasks from Stage 25 (MapPartitionsRDD[39] at map at KMeansTest.scala:65)
15/08/11 10:19:10 DEBUG DAGScheduler: New pending tasks: Set(ResultTask(25, 2), ResultTask(25, 0), ResultTask(25, 1))
15/08/11 10:19:10 INFO TaskSchedulerImpl: Adding task set 25.0 with 3 tasks
15/08/11 10:19:10 DEBUG TaskSetManager: Epoch for TaskSet 25.0: 12
15/08/11 10:19:10 DEBUG TaskSetManager: Valid locality levels for TaskSet 25.0: NO_PREF, ANY
15/08/11 10:19:10 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/deadLetters]
15/08/11 10:19:10 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_25, runningTasks: 0
15/08/11 10:19:10 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 75, 192.168.130.131, PROCESS_LOCAL, 1116 bytes)
15/08/11 10:19:10 INFO TaskSetManager: Starting task 1.0 in stage 25.0 (TID 76, 192.168.130.131, PROCESS_LOCAL, 1116 bytes)
15/08/11 10:19:10 INFO TaskSetManager: Starting task 2.0 in stage 25.0 (TID 77, 192.168.130.131, PROCESS_LOCAL, 1116 bytes)
15/08/11 10:19:10 DEBUG TaskSetManager: No tasks for locality level NO_PREF, so moving to locality level ANY
15/08/11 10:19:10 DEBUG SparkDeploySchedulerBackend: [actor] handled message (2.291567 ms) ReviveOffers from Actor[akka://sparkDriver/deadLetters]
15/08/11 10:19:10 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,75,RUNNING,org.apache.spark.util.SerializableBuffer@33860570) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:10 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.06444 ms) StatusUpdate(0,75,RUNNING,org.apache.spark.util.SerializableBuffer@33860570) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: [actor] received message GetLocations(broadcast_26_piece0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$Ob]
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: [actor] handled message (0.057533 ms) GetLocations(broadcast_26_piece0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$Ob]
15/08/11 10:19:10 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,76,RUNNING,org.apache.spark.util.SerializableBuffer@42404f33) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:10 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.070773 ms) StatusUpdate(0,76,RUNNING,org.apache.spark.util.SerializableBuffer@42404f33) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:10 DEBUG BlockManager: Level for block broadcast_26_piece0 is StorageLevel(true, true, false, false, 1)
15/08/11 10:19:10 DEBUG BlockManager: Getting block broadcast_26_piece0 from memory
15/08/11 10:19:10 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,77,RUNNING,org.apache.spark.util.SerializableBuffer@4d3db309) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:10 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.061608 ms) StatusUpdate(0,77,RUNNING,org.apache.spark.util.SerializableBuffer@4d3db309) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_26_piece0,StorageLevel(false, true, false, false, 1),1521,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$Pb]
15/08/11 10:19:10 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 192.168.130.131:47921 (size: 1521.0 B, free: 245.7 MB)
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: [actor] handled message (0.469433 ms) UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_26_piece0,StorageLevel(false, true, false, false, 1),1521,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$Pb]
15/08/11 10:19:10 DEBUG MapOutputTrackerMasterActor: [actor] received message GetMapOutputStatuses(11) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$Qb]
15/08/11 10:19:10 INFO MapOutputTrackerMasterActor: Asked to send map output locations for shuffle 11 to sparkExecutor@192.168.130.131:49489
15/08/11 10:19:10 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 11 is 161 bytes
15/08/11 10:19:10 DEBUG MapOutputTrackerMasterActor: [actor] handled message (0.865411 ms) GetMapOutputStatuses(11) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$Qb]
15/08/11 10:19:10 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,77,FINISHED,org.apache.spark.util.SerializableBuffer@2630210a) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:10 INFO TaskSetManager: Finished task 2.0 in stage 25.0 (TID 77) in 70 ms on 192.168.130.131 (1/3)
15/08/11 10:19:10 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_25, runningTasks: 2
15/08/11 10:19:10 DEBUG SparkDeploySchedulerBackend: [actor] handled message (19.602659 ms) StatusUpdate(0,77,FINISHED,org.apache.spark.util.SerializableBuffer@2630210a) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:10 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,75,FINISHED,org.apache.spark.util.SerializableBuffer@2fff9ea2) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:10 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_25, runningTasks: 1
15/08/11 10:19:10 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.800656 ms) StatusUpdate(0,75,FINISHED,org.apache.spark.util.SerializableBuffer@2fff9ea2) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:10 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 75) in 96 ms on 192.168.130.131 (2/3)
15/08/11 10:19:10 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,76,FINISHED,org.apache.spark.util.SerializableBuffer@3854e691) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:10 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_25, runningTasks: 0
15/08/11 10:19:10 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.487072 ms) StatusUpdate(0,76,FINISHED,org.apache.spark.util.SerializableBuffer@3854e691) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:10 INFO DAGScheduler: Stage 25 (collectAsMap at KMeansTest.scala:67) finished in 0.129 s
15/08/11 10:19:10 DEBUG DAGScheduler: After removal of stage 25, remaining stages = 1
15/08/11 10:19:10 DEBUG DAGScheduler: After removal of stage 24, remaining stages = 0
15/08/11 10:19:10 INFO DAGScheduler: Job 13 finished: collectAsMap at KMeansTest.scala:67, took 4.369033 s
Finished iteration (num = 11)
15/08/11 10:19:10 INFO TaskSetManager: Finished task 1.0 in stage 25.0 (TID 76) in 120 ms on 192.168.130.131 (3/3)
15/08/11 10:19:10 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
15/08/11 10:19:10 INFO SparkContext: Starting job: collectAsMap at KMeansTest.scala:67
15/08/11 10:19:10 INFO DAGScheduler: Registering RDD 40 (map at KMeansTest.scala:61)
15/08/11 10:19:10 INFO DAGScheduler: Got job 14 (collectAsMap at KMeansTest.scala:67) with 3 output partitions (allowLocal=false)
15/08/11 10:19:10 INFO DAGScheduler: Final stage: Stage 27(collectAsMap at KMeansTest.scala:67)
15/08/11 10:19:10 INFO DAGScheduler: Parents of final stage: List(Stage 26)
15/08/11 10:19:10 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD MapPartitionsRDD[42] at map at KMeansTest.scala:65
15/08/11 10:19:10 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@5921727f) from Actor[akka://sparkDriver/temp/$ag]
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: [actor] handled message (0.126043 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@5921727f) from Actor[akka://sparkDriver/temp/$ag]
15/08/11 10:19:10 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@5921727f) from Actor[akka://sparkDriver/temp/$bg]
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: [actor] handled message (0.126545 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@5921727f) from Actor[akka://sparkDriver/temp/$bg]
15/08/11 10:19:10 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:19:10 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:19:10 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|42|0,rdd_42_0,, null|42|1,rdd_42_1,, null|42|2,rdd_42_2,).
15/08/11 10:19:10 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$dg]
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:19:10 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: [actor] handled message (0.864349 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$dg]
15/08/11 10:19:10 DEBUG BlockManager: Got multiple block location in  9 ms
15/08/11 10:19:10 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD ShuffledRDD[41] at reduceByKey at KMeansTest.scala:63
15/08/11 10:19:10 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@50c0899e) from Actor[akka://sparkDriver/temp/$eg]
15/08/11 10:19:10 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: [actor] handled message (0.14768 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@50c0899e) from Actor[akka://sparkDriver/temp/$eg]
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@50c0899e) from Actor[akka://sparkDriver/temp/$fg]
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: [actor] handled message (0.110382 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@50c0899e) from Actor[akka://sparkDriver/temp/$fg]
15/08/11 10:19:10 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:19:10 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:19:10 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|41|0,rdd_41_0,, null|41|1,rdd_41_1,, null|41|2,rdd_41_2,).
15/08/11 10:19:10 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$hg]
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:19:10 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:19:10 DEBUG BlockManager: Got multiple block location in  12 ms
15/08/11 10:19:10 INFO DAGScheduler: [SMSpark v1]Missing parents: List(Stage 26)
15/08/11 10:19:10 DEBUG DAGScheduler: submitStage(Stage 27)
15/08/11 10:19:10 DEBUG DAGScheduler: missing: List(Stage 26)
15/08/11 10:19:10 DEBUG DAGScheduler: submitStage(Stage 26)
15/08/11 10:19:10 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD MapPartitionsRDD[40] at map at KMeansTest.scala:61
15/08/11 10:19:10 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: [actor] handled message (3.905684 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$hg]
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@607887f6) from Actor[akka://sparkDriver/temp/$ig]
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: [actor] handled message (0.190359 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@607887f6) from Actor[akka://sparkDriver/temp/$ig]
15/08/11 10:19:10 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@607887f6) from Actor[akka://sparkDriver/temp/$jg]
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: [actor] handled message (0.197233 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@607887f6) from Actor[akka://sparkDriver/temp/$jg]
15/08/11 10:19:10 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:19:10 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:19:10 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|40|0,rdd_40_0,, null|40|1,rdd_40_1,, null|40|2,rdd_40_2,).
15/08/11 10:19:10 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$lg]
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: [actor] handled message (0.912703 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$lg]
15/08/11 10:19:10 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:19:10 DEBUG BlockManager: Got multiple block location in  13 ms
15/08/11 10:19:10 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD KMeans01 MapPartitionsRDD[2] at map at KMeansTest.scala:50
15/08/11 10:19:10 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@41269505) from Actor[akka://sparkDriver/temp/$mg]
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: [actor] handled message (0.298545 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@41269505) from Actor[akka://sparkDriver/temp/$mg]
15/08/11 10:19:10 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(ArrayBuffer(BlockManagerId(0, 192.168.130.131, 47921)), ArrayBuffer(BlockManagerId(0, 192.168.130.131, 47921)), ArrayBuffer(BlockManagerId(0, 192.168.130.131, 47921)))
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@41269505) from Actor[akka://sparkDriver/temp/$ng]
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: [actor] handled message (0.265159 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@41269505) from Actor[akka://sparkDriver/temp/$ng]
15/08/11 10:19:10 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:19:10 DEBUG DAGScheduler: missing: List()
15/08/11 10:19:10 INFO DAGScheduler: Submitting Stage 26 (MapPartitionsRDD[40] at map at KMeansTest.scala:61), which has no missing parents
15/08/11 10:19:10 DEBUG DAGScheduler: submitMissingTasks(Stage 26)
15/08/11 10:19:10 INFO MemoryStore: ensureFreeSpace(4768) called with curMem=244930, maxMem=278302556
15/08/11 10:19:10 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 4.7 KB, free 265.2 MB)
15/08/11 10:19:10 DEBUG BlockManager: Put block broadcast_27 locally took  2 ms
15/08/11 10:19:10 DEBUG BlockManager: Putting block broadcast_27 without replication took  2 ms
15/08/11 10:19:10 INFO MemoryStore: ensureFreeSpace(3203) called with curMem=249698, maxMem=278302556
15/08/11 10:19:10 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 3.1 KB, free 265.2 MB)
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_27_piece0,StorageLevel(false, true, false, false, 1),3203,0,0) from Actor[akka://sparkDriver/temp/$og]
15/08/11 10:19:10 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 192.168.130.131:57830 (size: 3.1 KB, free: 265.4 MB)
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: [actor] handled message (0.438729 ms) UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_27_piece0,StorageLevel(false, true, false, false, 1),3203,0,0) from Actor[akka://sparkDriver/temp/$og]
15/08/11 10:19:10 INFO BlockManagerMaster: Updated info of block broadcast_27_piece0
15/08/11 10:19:10 DEBUG BlockManager: Told master about block broadcast_27_piece0
15/08/11 10:19:10 DEBUG BlockManager: Put block broadcast_27_piece0 locally took  2 ms
15/08/11 10:19:10 DEBUG BlockManager: Putting block broadcast_27_piece0 without replication took  2 ms
15/08/11 10:19:10 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:852
15/08/11 10:19:10 INFO DAGScheduler: Submitting 3 missing tasks from Stage 26 (MapPartitionsRDD[40] at map at KMeansTest.scala:61)
15/08/11 10:19:10 DEBUG DAGScheduler: New pending tasks: Set(ShuffleMapTask(26, 1), ShuffleMapTask(26, 0), ShuffleMapTask(26, 2))
15/08/11 10:19:10 INFO TaskSchedulerImpl: Adding task set 26.0 with 3 tasks
15/08/11 10:19:10 DEBUG TaskSetManager: Epoch for TaskSet 26.0: 12
15/08/11 10:19:10 DEBUG TaskSetManager: Valid locality levels for TaskSet 26.0: PROCESS_LOCAL, NODE_LOCAL, ANY
15/08/11 10:19:10 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/deadLetters]
15/08/11 10:19:10 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_26, runningTasks: 0
15/08/11 10:19:10 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 78, 192.168.130.131, PROCESS_LOCAL, 1361 bytes)
15/08/11 10:19:10 INFO TaskSetManager: Starting task 1.0 in stage 26.0 (TID 79, 192.168.130.131, PROCESS_LOCAL, 1361 bytes)
15/08/11 10:19:10 INFO TaskSetManager: Starting task 2.0 in stage 26.0 (TID 80, 192.168.130.131, PROCESS_LOCAL, 1361 bytes)
15/08/11 10:19:10 DEBUG TaskSetManager: No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
15/08/11 10:19:10 DEBUG TaskSetManager: No tasks for locality level NODE_LOCAL, so moving to locality level ANY
15/08/11 10:19:10 DEBUG SparkDeploySchedulerBackend: [actor] handled message (9.57691 ms) ReviveOffers from Actor[akka://sparkDriver/deadLetters]
15/08/11 10:19:10 DEBUG DAGScheduler: submitStage(Stage 27)
15/08/11 10:19:10 DEBUG DAGScheduler: missing: List(Stage 26)
15/08/11 10:19:10 DEBUG DAGScheduler: submitStage(Stage 26)
15/08/11 10:19:10 DEBUG DAGScheduler: submitStage(Stage 27)
15/08/11 10:19:10 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,78,RUNNING,org.apache.spark.util.SerializableBuffer@7877616c) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:10 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.051854 ms) StatusUpdate(0,78,RUNNING,org.apache.spark.util.SerializableBuffer@7877616c) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:10 DEBUG DAGScheduler: missing: List(Stage 26)
15/08/11 10:19:10 DEBUG DAGScheduler: submitStage(Stage 26)
15/08/11 10:19:10 DEBUG DAGScheduler: submitStage(Stage 27)
15/08/11 10:19:10 DEBUG DAGScheduler: missing: List(Stage 26)
15/08/11 10:19:10 DEBUG DAGScheduler: submitStage(Stage 26)
15/08/11 10:19:10 DEBUG DAGScheduler: submitStage(Stage 27)
15/08/11 10:19:10 DEBUG DAGScheduler: missing: List(Stage 26)
15/08/11 10:19:10 DEBUG DAGScheduler: submitStage(Stage 26)
15/08/11 10:19:10 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,80,RUNNING,org.apache.spark.util.SerializableBuffer@659d373d) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:10 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.060866 ms) StatusUpdate(0,80,RUNNING,org.apache.spark.util.SerializableBuffer@659d373d) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:10 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,79,RUNNING,org.apache.spark.util.SerializableBuffer@3495b9e9) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:10 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.062191 ms) StatusUpdate(0,79,RUNNING,org.apache.spark.util.SerializableBuffer@3495b9e9) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: [actor] received message GetLocations(broadcast_27_piece0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$Rb]
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: [actor] handled message (0.065289 ms) GetLocations(broadcast_27_piece0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$Rb]
15/08/11 10:19:10 DEBUG BlockManager: Level for block broadcast_27_piece0 is StorageLevel(true, true, false, false, 1)
15/08/11 10:19:10 DEBUG BlockManager: Getting block broadcast_27_piece0 from memory
15/08/11 10:19:10 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:19:10 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_26, runningTasks: 3
15/08/11 10:19:10 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.585724 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_27_piece0,StorageLevel(false, true, false, false, 1),3203,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$Sb]
15/08/11 10:19:10 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 192.168.130.131:47921 (size: 3.1 KB, free: 245.7 MB)
15/08/11 10:19:10 DEBUG BlockManagerMasterActor: [actor] handled message (0.894207 ms) UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_27_piece0,StorageLevel(false, true, false, false, 1),3203,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$Sb]
15/08/11 10:19:11 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,80,FINISHED,org.apache.spark.util.SerializableBuffer@518aeeca) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:11 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_26, runningTasks: 2
15/08/11 10:19:11 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.625716 ms) StatusUpdate(0,80,FINISHED,org.apache.spark.util.SerializableBuffer@518aeeca) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:11 DEBUG DAGScheduler: ShuffleMapTask finished on 0
15/08/11 10:19:11 INFO TaskSetManager: Finished task 2.0 in stage 26.0 (TID 80) in 971 ms on 192.168.130.131 (1/3)
15/08/11 10:19:11 DEBUG DAGScheduler: submitStage(Stage 27)
15/08/11 10:19:11 DEBUG DAGScheduler: missing: List(Stage 26)
15/08/11 10:19:11 DEBUG DAGScheduler: submitStage(Stage 26)
15/08/11 10:19:11 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:19:11 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_26, runningTasks: 2
15/08/11 10:19:11 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.904705 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:19:12 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:19:12 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_26, runningTasks: 2
15/08/11 10:19:12 DEBUG SparkDeploySchedulerBackend: [actor] handled message (36.738822 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:19:13 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,78,FINISHED,org.apache.spark.util.SerializableBuffer@78433998) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:13 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_26, runningTasks: 1
15/08/11 10:19:13 DEBUG SparkDeploySchedulerBackend: [actor] handled message (1.327195 ms) StatusUpdate(0,78,FINISHED,org.apache.spark.util.SerializableBuffer@78433998) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:13 DEBUG DAGScheduler: ShuffleMapTask finished on 0
15/08/11 10:19:13 DEBUG DAGScheduler: submitStage(Stage 27)
15/08/11 10:19:13 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 78) in 3010 ms on 192.168.130.131 (2/3)
15/08/11 10:19:13 DEBUG DAGScheduler: missing: List(Stage 26)
15/08/11 10:19:13 DEBUG DAGScheduler: submitStage(Stage 26)
15/08/11 10:19:13 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:19:13 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_26, runningTasks: 1
15/08/11 10:19:13 DEBUG SparkDeploySchedulerBackend: [actor] handled message (4.383768 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:19:13 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,79,FINISHED,org.apache.spark.util.SerializableBuffer@57a67d7) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:13 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_26, runningTasks: 0
15/08/11 10:19:13 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.821228 ms) StatusUpdate(0,79,FINISHED,org.apache.spark.util.SerializableBuffer@57a67d7) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:13 DEBUG DAGScheduler: ShuffleMapTask finished on 0
15/08/11 10:19:13 INFO DAGScheduler: Stage 26 (map at KMeansTest.scala:61) finished in 3.140 s
15/08/11 10:19:13 INFO DAGScheduler: looking for newly runnable stages
15/08/11 10:19:13 INFO DAGScheduler: running: Set()
15/08/11 10:19:13 INFO DAGScheduler: waiting: Set(Stage 27)
15/08/11 10:19:13 INFO DAGScheduler: failed: Set()
15/08/11 10:19:13 DEBUG MapOutputTrackerMaster: Increasing epoch to 13
15/08/11 10:19:13 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD MapPartitionsRDD[42] at map at KMeansTest.scala:65
15/08/11 10:19:13 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:19:13 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@27375710) from Actor[akka://sparkDriver/temp/$pg]
15/08/11 10:19:13 DEBUG BlockManagerMasterActor: [actor] handled message (0.204424 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@27375710) from Actor[akka://sparkDriver/temp/$pg]
15/08/11 10:19:13 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:19:13 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@27375710) from Actor[akka://sparkDriver/temp/$qg]
15/08/11 10:19:13 DEBUG BlockManagerMasterActor: [actor] handled message (0.245355 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@27375710) from Actor[akka://sparkDriver/temp/$qg]
15/08/11 10:19:13 INFO TaskSetManager: Finished task 1.0 in stage 26.0 (TID 79) in 3149 ms on 192.168.130.131 (3/3)
15/08/11 10:19:13 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:19:13 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:19:13 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
15/08/11 10:19:13 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|42|0,rdd_42_0,, null|42|1,rdd_42_1,, null|42|2,rdd_42_2,).
15/08/11 10:19:13 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:19:13 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$sg]
15/08/11 10:19:13 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:19:13 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:13 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:13 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:13 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:13 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:13 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:13 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:13 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:13 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:13 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:19:13 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:19:13 DEBUG BlockManager: Got multiple block location in  30 ms
15/08/11 10:19:13 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD ShuffledRDD[41] at reduceByKey at KMeansTest.scala:63
15/08/11 10:19:13 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:19:13 DEBUG BlockManagerMasterActor: [actor] handled message (7.241593 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$sg]
15/08/11 10:19:13 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@5de6414c) from Actor[akka://sparkDriver/temp/$tg]
15/08/11 10:19:13 DEBUG BlockManagerMasterActor: [actor] handled message (0.265145 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@5de6414c) from Actor[akka://sparkDriver/temp/$tg]
15/08/11 10:19:13 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:19:13 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@5de6414c) from Actor[akka://sparkDriver/temp/$ug]
15/08/11 10:19:13 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:19:13 DEBUG BlockManagerMasterActor: [actor] handled message (0.355993 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@5de6414c) from Actor[akka://sparkDriver/temp/$ug]
15/08/11 10:19:13 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:19:13 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|41|0,rdd_41_0,, null|41|1,rdd_41_1,, null|41|2,rdd_41_2,).
15/08/11 10:19:13 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:19:13 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$wg]
15/08/11 10:19:13 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:19:13 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:13 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:13 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:13 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:13 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:13 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:13 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:13 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:13 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:13 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:19:13 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:19:13 DEBUG BlockManager: Got multiple block location in  21 ms
15/08/11 10:19:13 INFO DAGScheduler: Missing parents for Stage 27: List()
15/08/11 10:19:13 INFO DAGScheduler: Submitting Stage 27 (MapPartitionsRDD[42] at map at KMeansTest.scala:65), which is now runnable
15/08/11 10:19:13 DEBUG DAGScheduler: submitMissingTasks(Stage 27)
15/08/11 10:19:13 INFO MemoryStore: ensureFreeSpace(2560) called with curMem=252901, maxMem=278302556
15/08/11 10:19:13 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 2.5 KB, free 265.2 MB)
15/08/11 10:19:14 DEBUG BlockManager: Put block broadcast_28 locally took  8 ms
15/08/11 10:19:14 DEBUG BlockManager: Putting block broadcast_28 without replication took  8 ms
15/08/11 10:19:14 DEBUG BlockManagerMasterActor: [actor] handled message (11.153855 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$wg]
15/08/11 10:19:14 INFO MemoryStore: ensureFreeSpace(1521) called with curMem=255461, maxMem=278302556
15/08/11 10:19:14 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 1521.0 B, free 265.2 MB)
15/08/11 10:19:14 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_28_piece0,StorageLevel(false, true, false, false, 1),1521,0,0) from Actor[akka://sparkDriver/temp/$xg]
15/08/11 10:19:14 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 192.168.130.131:57830 (size: 1521.0 B, free: 265.4 MB)
15/08/11 10:19:14 INFO BlockManagerMaster: Updated info of block broadcast_28_piece0
15/08/11 10:19:14 DEBUG BlockManagerMasterActor: [actor] handled message (0.499031 ms) UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_28_piece0,StorageLevel(false, true, false, false, 1),1521,0,0) from Actor[akka://sparkDriver/temp/$xg]
15/08/11 10:19:14 DEBUG BlockManager: Told master about block broadcast_28_piece0
15/08/11 10:19:14 DEBUG BlockManager: Put block broadcast_28_piece0 locally took  2 ms
15/08/11 10:19:14 DEBUG BlockManager: Putting block broadcast_28_piece0 without replication took  2 ms
15/08/11 10:19:14 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:852
15/08/11 10:19:14 INFO DAGScheduler: Submitting 3 missing tasks from Stage 27 (MapPartitionsRDD[42] at map at KMeansTest.scala:65)
15/08/11 10:19:14 DEBUG DAGScheduler: New pending tasks: Set(ResultTask(27, 1), ResultTask(27, 0), ResultTask(27, 2))
15/08/11 10:19:14 INFO TaskSchedulerImpl: Adding task set 27.0 with 3 tasks
15/08/11 10:19:14 DEBUG TaskSetManager: Epoch for TaskSet 27.0: 13
15/08/11 10:19:14 DEBUG TaskSetManager: Valid locality levels for TaskSet 27.0: NO_PREF, ANY
15/08/11 10:19:14 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/deadLetters]
15/08/11 10:19:14 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_27, runningTasks: 0
15/08/11 10:19:14 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 81, 192.168.130.131, PROCESS_LOCAL, 1116 bytes)
15/08/11 10:19:14 INFO TaskSetManager: Starting task 1.0 in stage 27.0 (TID 82, 192.168.130.131, PROCESS_LOCAL, 1116 bytes)
15/08/11 10:19:14 INFO TaskSetManager: Starting task 2.0 in stage 27.0 (TID 83, 192.168.130.131, PROCESS_LOCAL, 1116 bytes)
15/08/11 10:19:14 DEBUG TaskSetManager: No tasks for locality level NO_PREF, so moving to locality level ANY
15/08/11 10:19:14 DEBUG SparkDeploySchedulerBackend: [actor] handled message (8.946148 ms) ReviveOffers from Actor[akka://sparkDriver/deadLetters]
15/08/11 10:19:14 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,81,RUNNING,org.apache.spark.util.SerializableBuffer@7abd275b) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:14 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.074456 ms) StatusUpdate(0,81,RUNNING,org.apache.spark.util.SerializableBuffer@7abd275b) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:14 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,83,RUNNING,org.apache.spark.util.SerializableBuffer@18630651) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:14 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.211923 ms) StatusUpdate(0,83,RUNNING,org.apache.spark.util.SerializableBuffer@18630651) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:14 DEBUG BlockManagerMasterActor: [actor] received message GetLocations(broadcast_28_piece0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$Tb]
15/08/11 10:19:14 DEBUG BlockManagerMasterActor: [actor] handled message (0.076295 ms) GetLocations(broadcast_28_piece0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$Tb]
15/08/11 10:19:14 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,82,RUNNING,org.apache.spark.util.SerializableBuffer@2a8309e7) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:14 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.066921 ms) StatusUpdate(0,82,RUNNING,org.apache.spark.util.SerializableBuffer@2a8309e7) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:14 DEBUG BlockManager: Level for block broadcast_28_piece0 is StorageLevel(true, true, false, false, 1)
15/08/11 10:19:14 DEBUG BlockManager: Getting block broadcast_28_piece0 from memory
15/08/11 10:19:14 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_28_piece0,StorageLevel(false, true, false, false, 1),1521,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$Ub]
15/08/11 10:19:14 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 192.168.130.131:47921 (size: 1521.0 B, free: 245.7 MB)
15/08/11 10:19:14 DEBUG BlockManagerMasterActor: [actor] handled message (0.699922 ms) UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_28_piece0,StorageLevel(false, true, false, false, 1),1521,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$Ub]
15/08/11 10:19:14 DEBUG MapOutputTrackerMasterActor: [actor] received message GetMapOutputStatuses(12) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$Vb]
15/08/11 10:19:14 INFO MapOutputTrackerMasterActor: Asked to send map output locations for shuffle 12 to sparkExecutor@192.168.130.131:49489
15/08/11 10:19:14 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 12 is 161 bytes
15/08/11 10:19:14 DEBUG MapOutputTrackerMasterActor: [actor] handled message (0.823939 ms) GetMapOutputStatuses(12) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$Vb]
15/08/11 10:19:14 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,83,FINISHED,org.apache.spark.util.SerializableBuffer@2b9179ee) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:14 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_27, runningTasks: 2
15/08/11 10:19:14 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.551771 ms) StatusUpdate(0,83,FINISHED,org.apache.spark.util.SerializableBuffer@2b9179ee) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:14 INFO TaskSetManager: Finished task 2.0 in stage 27.0 (TID 83) in 99 ms on 192.168.130.131 (1/3)
15/08/11 10:19:14 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,82,FINISHED,org.apache.spark.util.SerializableBuffer@3649e302) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:14 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_27, runningTasks: 1
15/08/11 10:19:14 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.72288 ms) StatusUpdate(0,82,FINISHED,org.apache.spark.util.SerializableBuffer@3649e302) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:14 INFO TaskSetManager: Finished task 1.0 in stage 27.0 (TID 82) in 120 ms on 192.168.130.131 (2/3)
15/08/11 10:19:14 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,81,FINISHED,org.apache.spark.util.SerializableBuffer@589a15e5) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:14 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_27, runningTasks: 0
15/08/11 10:19:14 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.973481 ms) StatusUpdate(0,81,FINISHED,org.apache.spark.util.SerializableBuffer@589a15e5) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:14 INFO DAGScheduler: Stage 27 (collectAsMap at KMeansTest.scala:67) finished in 0.143 s
15/08/11 10:19:14 DEBUG DAGScheduler: After removal of stage 26, remaining stages = 1
15/08/11 10:19:14 DEBUG DAGScheduler: After removal of stage 27, remaining stages = 0
15/08/11 10:19:14 INFO DAGScheduler: Job 14 finished: collectAsMap at KMeansTest.scala:67, took 3.441325 s
Finished iteration (num = 12)
15/08/11 10:19:14 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 81) in 138 ms on 192.168.130.131 (3/3)
15/08/11 10:19:14 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool 
15/08/11 10:19:14 INFO SparkContext: Starting job: collectAsMap at KMeansTest.scala:67
15/08/11 10:19:14 INFO DAGScheduler: Registering RDD 43 (map at KMeansTest.scala:61)
15/08/11 10:19:14 INFO DAGScheduler: Got job 15 (collectAsMap at KMeansTest.scala:67) with 3 output partitions (allowLocal=false)
15/08/11 10:19:14 INFO DAGScheduler: Final stage: Stage 29(collectAsMap at KMeansTest.scala:67)
15/08/11 10:19:14 INFO DAGScheduler: Parents of final stage: List(Stage 28)
15/08/11 10:19:14 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD MapPartitionsRDD[45] at map at KMeansTest.scala:65
15/08/11 10:19:14 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:19:14 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@984fd2f) from Actor[akka://sparkDriver/temp/$yg]
15/08/11 10:19:14 DEBUG BlockManagerMasterActor: [actor] handled message (2.439932 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@984fd2f) from Actor[akka://sparkDriver/temp/$yg]
15/08/11 10:19:14 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:19:14 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@984fd2f) from Actor[akka://sparkDriver/temp/$zg]
15/08/11 10:19:14 DEBUG BlockManagerMasterActor: [actor] handled message (0.206843 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@984fd2f) from Actor[akka://sparkDriver/temp/$zg]
15/08/11 10:19:14 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:19:14 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:19:14 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|45|0,rdd_45_0,, null|45|1,rdd_45_1,, null|45|2,rdd_45_2,).
15/08/11 10:19:14 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:19:14 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$Bg]
15/08/11 10:19:14 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:19:14 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:14 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:14 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:14 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:14 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:14 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:14 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:14 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:14 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:14 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:19:14 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:19:14 DEBUG BlockManager: Got multiple block location in  16 ms
15/08/11 10:19:14 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD ShuffledRDD[44] at reduceByKey at KMeansTest.scala:63
15/08/11 10:19:14 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:19:14 DEBUG BlockManagerMasterActor: [actor] handled message (4.619162 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$Bg]
15/08/11 10:19:14 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@1a34e479) from Actor[akka://sparkDriver/temp/$Cg]
15/08/11 10:19:14 DEBUG BlockManagerMasterActor: [actor] handled message (0.13487 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@1a34e479) from Actor[akka://sparkDriver/temp/$Cg]
15/08/11 10:19:14 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:19:14 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@1a34e479) from Actor[akka://sparkDriver/temp/$Dg]
15/08/11 10:19:14 DEBUG BlockManagerMasterActor: [actor] handled message (0.095604 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@1a34e479) from Actor[akka://sparkDriver/temp/$Dg]
15/08/11 10:19:14 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:19:14 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:19:14 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|44|0,rdd_44_0,, null|44|1,rdd_44_1,, null|44|2,rdd_44_2,).
15/08/11 10:19:14 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:19:14 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$Fg]
15/08/11 10:19:14 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:19:14 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:14 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:14 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:14 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:14 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:14 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:14 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:14 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:14 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:14 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:19:14 DEBUG BlockManagerMasterActor: [actor] handled message (0.828237 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$Fg]
15/08/11 10:19:14 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:19:14 DEBUG BlockManager: Got multiple block location in  10 ms
15/08/11 10:19:14 INFO DAGScheduler: [SMSpark v1]Missing parents: List(Stage 28)
15/08/11 10:19:14 DEBUG DAGScheduler: submitStage(Stage 29)
15/08/11 10:19:14 DEBUG DAGScheduler: missing: List(Stage 28)
15/08/11 10:19:14 DEBUG DAGScheduler: submitStage(Stage 28)
15/08/11 10:19:14 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD MapPartitionsRDD[43] at map at KMeansTest.scala:61
15/08/11 10:19:14 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:19:14 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@3cb94f9a) from Actor[akka://sparkDriver/temp/$Gg]
15/08/11 10:19:14 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:19:14 DEBUG BlockManagerMasterActor: [actor] handled message (0.19641 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@3cb94f9a) from Actor[akka://sparkDriver/temp/$Gg]
15/08/11 10:19:14 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@3cb94f9a) from Actor[akka://sparkDriver/temp/$Hg]
15/08/11 10:19:14 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:19:14 DEBUG BlockManagerMasterActor: [actor] handled message (0.219896 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@3cb94f9a) from Actor[akka://sparkDriver/temp/$Hg]
15/08/11 10:19:14 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:19:14 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|43|0,rdd_43_0,, null|43|1,rdd_43_1,, null|43|2,rdd_43_2,).
15/08/11 10:19:14 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:19:14 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$Jg]
15/08/11 10:19:14 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:19:14 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:14 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:14 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:14 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:14 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:14 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:14 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:14 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:14 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:14 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:19:14 DEBUG BlockManagerMasterActor: [actor] handled message (1.214571 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$Jg]
15/08/11 10:19:14 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:19:14 DEBUG BlockManager: Got multiple block location in  24 ms
15/08/11 10:19:14 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD KMeans01 MapPartitionsRDD[2] at map at KMeansTest.scala:50
15/08/11 10:19:14 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:19:14 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@7a520351) from Actor[akka://sparkDriver/temp/$Kg]
15/08/11 10:19:14 DEBUG BlockManagerMasterActor: [actor] handled message (0.230297 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@7a520351) from Actor[akka://sparkDriver/temp/$Kg]
15/08/11 10:19:14 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(ArrayBuffer(BlockManagerId(0, 192.168.130.131, 47921)), ArrayBuffer(BlockManagerId(0, 192.168.130.131, 47921)), ArrayBuffer(BlockManagerId(0, 192.168.130.131, 47921)))
15/08/11 10:19:14 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@7a520351) from Actor[akka://sparkDriver/temp/$Lg]
15/08/11 10:19:14 DEBUG BlockManagerMasterActor: [actor] handled message (0.195458 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@7a520351) from Actor[akka://sparkDriver/temp/$Lg]
15/08/11 10:19:14 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:19:14 DEBUG DAGScheduler: missing: List()
15/08/11 10:19:14 INFO DAGScheduler: Submitting Stage 28 (MapPartitionsRDD[43] at map at KMeansTest.scala:61), which has no missing parents
15/08/11 10:19:14 DEBUG DAGScheduler: submitMissingTasks(Stage 28)
15/08/11 10:19:14 INFO MemoryStore: ensureFreeSpace(4768) called with curMem=256982, maxMem=278302556
15/08/11 10:19:14 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 4.7 KB, free 265.2 MB)
15/08/11 10:19:14 DEBUG BlockManager: Put block broadcast_29 locally took  1 ms
15/08/11 10:19:14 DEBUG BlockManager: Putting block broadcast_29 without replication took  2 ms
15/08/11 10:19:14 INFO MemoryStore: ensureFreeSpace(3205) called with curMem=261750, maxMem=278302556
15/08/11 10:19:14 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 3.1 KB, free 265.2 MB)
15/08/11 10:19:14 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_29_piece0,StorageLevel(false, true, false, false, 1),3205,0,0) from Actor[akka://sparkDriver/temp/$Mg]
15/08/11 10:19:14 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 192.168.130.131:57830 (size: 3.1 KB, free: 265.4 MB)
15/08/11 10:19:14 DEBUG BlockManagerMasterActor: [actor] handled message (0.535053 ms) UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_29_piece0,StorageLevel(false, true, false, false, 1),3205,0,0) from Actor[akka://sparkDriver/temp/$Mg]
15/08/11 10:19:14 INFO BlockManagerMaster: Updated info of block broadcast_29_piece0
15/08/11 10:19:14 DEBUG BlockManager: Told master about block broadcast_29_piece0
15/08/11 10:19:14 DEBUG BlockManager: Put block broadcast_29_piece0 locally took  2 ms
15/08/11 10:19:14 DEBUG BlockManager: Putting block broadcast_29_piece0 without replication took  3 ms
15/08/11 10:19:14 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:852
15/08/11 10:19:14 INFO DAGScheduler: Submitting 3 missing tasks from Stage 28 (MapPartitionsRDD[43] at map at KMeansTest.scala:61)
15/08/11 10:19:14 DEBUG DAGScheduler: New pending tasks: Set(ShuffleMapTask(28, 1), ShuffleMapTask(28, 0), ShuffleMapTask(28, 2))
15/08/11 10:19:14 INFO TaskSchedulerImpl: Adding task set 28.0 with 3 tasks
15/08/11 10:19:14 DEBUG TaskSetManager: Epoch for TaskSet 28.0: 13
15/08/11 10:19:14 DEBUG TaskSetManager: Valid locality levels for TaskSet 28.0: PROCESS_LOCAL, NODE_LOCAL, ANY
15/08/11 10:19:14 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/deadLetters]
15/08/11 10:19:14 DEBUG DAGScheduler: submitStage(Stage 29)
15/08/11 10:19:14 DEBUG DAGScheduler: missing: List(Stage 28)
15/08/11 10:19:14 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_28, runningTasks: 0
15/08/11 10:19:14 DEBUG DAGScheduler: submitStage(Stage 28)
15/08/11 10:19:14 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 84, 192.168.130.131, PROCESS_LOCAL, 1361 bytes)
15/08/11 10:19:14 DEBUG DAGScheduler: submitStage(Stage 29)
15/08/11 10:19:14 DEBUG DAGScheduler: missing: List(Stage 28)
15/08/11 10:19:14 DEBUG DAGScheduler: submitStage(Stage 28)
15/08/11 10:19:14 INFO TaskSetManager: Starting task 1.0 in stage 28.0 (TID 85, 192.168.130.131, PROCESS_LOCAL, 1361 bytes)
15/08/11 10:19:14 DEBUG DAGScheduler: submitStage(Stage 29)
15/08/11 10:19:14 DEBUG DAGScheduler: missing: List(Stage 28)
15/08/11 10:19:14 DEBUG DAGScheduler: submitStage(Stage 28)
15/08/11 10:19:14 INFO TaskSetManager: Starting task 2.0 in stage 28.0 (TID 86, 192.168.130.131, PROCESS_LOCAL, 1361 bytes)
15/08/11 10:19:14 DEBUG TaskSetManager: No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
15/08/11 10:19:14 DEBUG DAGScheduler: submitStage(Stage 29)
15/08/11 10:19:14 DEBUG TaskSetManager: No tasks for locality level NODE_LOCAL, so moving to locality level ANY
15/08/11 10:19:14 DEBUG DAGScheduler: missing: List(Stage 28)
15/08/11 10:19:14 DEBUG DAGScheduler: submitStage(Stage 28)
15/08/11 10:19:14 DEBUG SparkDeploySchedulerBackend: [actor] handled message (7.786501 ms) ReviveOffers from Actor[akka://sparkDriver/deadLetters]
15/08/11 10:19:14 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,84,RUNNING,org.apache.spark.util.SerializableBuffer@7a1d1456) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:14 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.094659 ms) StatusUpdate(0,84,RUNNING,org.apache.spark.util.SerializableBuffer@7a1d1456) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:14 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,85,RUNNING,org.apache.spark.util.SerializableBuffer@b2258bc) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:14 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.03994 ms) StatusUpdate(0,85,RUNNING,org.apache.spark.util.SerializableBuffer@b2258bc) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:14 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,86,RUNNING,org.apache.spark.util.SerializableBuffer@7befa459) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:14 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.05102 ms) StatusUpdate(0,86,RUNNING,org.apache.spark.util.SerializableBuffer@7befa459) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:14 DEBUG BlockManagerMasterActor: [actor] received message GetLocations(broadcast_29_piece0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$Wb]
15/08/11 10:19:14 DEBUG BlockManagerMasterActor: [actor] handled message (0.13256 ms) GetLocations(broadcast_29_piece0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$Wb]
15/08/11 10:19:14 DEBUG BlockManager: Level for block broadcast_29_piece0 is StorageLevel(true, true, false, false, 1)
15/08/11 10:19:14 DEBUG BlockManager: Getting block broadcast_29_piece0 from memory
15/08/11 10:19:14 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_29_piece0,StorageLevel(false, true, false, false, 1),3205,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$Xb]
15/08/11 10:19:14 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 192.168.130.131:47921 (size: 3.1 KB, free: 245.6 MB)
15/08/11 10:19:14 DEBUG BlockManagerMasterActor: [actor] handled message (0.692682 ms) UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_29_piece0,StorageLevel(false, true, false, false, 1),3205,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$Xb]
15/08/11 10:19:14 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:19:14 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_28, runningTasks: 3
15/08/11 10:19:14 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.664427 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:19:14 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,86,FINISHED,org.apache.spark.util.SerializableBuffer@193d86ed) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:14 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_28, runningTasks: 2
15/08/11 10:19:14 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.744451 ms) StatusUpdate(0,86,FINISHED,org.apache.spark.util.SerializableBuffer@193d86ed) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:14 DEBUG DAGScheduler: ShuffleMapTask finished on 0
15/08/11 10:19:14 DEBUG DAGScheduler: submitStage(Stage 29)
15/08/11 10:19:14 DEBUG DAGScheduler: missing: List(Stage 28)
15/08/11 10:19:14 DEBUG DAGScheduler: submitStage(Stage 28)
15/08/11 10:19:14 INFO TaskSetManager: Finished task 2.0 in stage 28.0 (TID 86) in 626 ms on 192.168.130.131 (1/3)
15/08/11 10:19:15 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:19:15 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_28, runningTasks: 2
15/08/11 10:19:15 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.601564 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:19:16 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,85,FINISHED,org.apache.spark.util.SerializableBuffer@16653e8d) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:16 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_28, runningTasks: 1
15/08/11 10:19:16 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.729873 ms) StatusUpdate(0,85,FINISHED,org.apache.spark.util.SerializableBuffer@16653e8d) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:16 DEBUG DAGScheduler: ShuffleMapTask finished on 0
15/08/11 10:19:16 DEBUG DAGScheduler: submitStage(Stage 29)
15/08/11 10:19:16 DEBUG DAGScheduler: missing: List(Stage 28)
15/08/11 10:19:16 DEBUG DAGScheduler: submitStage(Stage 28)
15/08/11 10:19:16 INFO TaskSetManager: Finished task 1.0 in stage 28.0 (TID 85) in 2090 ms on 192.168.130.131 (2/3)
15/08/11 10:19:16 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,84,FINISHED,org.apache.spark.util.SerializableBuffer@50eda677) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:16 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_28, runningTasks: 0
15/08/11 10:19:16 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.503018 ms) StatusUpdate(0,84,FINISHED,org.apache.spark.util.SerializableBuffer@50eda677) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:16 DEBUG DAGScheduler: ShuffleMapTask finished on 0
15/08/11 10:19:16 INFO DAGScheduler: Stage 28 (map at KMeansTest.scala:61) finished in 2.132 s
15/08/11 10:19:16 INFO DAGScheduler: looking for newly runnable stages
15/08/11 10:19:16 INFO DAGScheduler: running: Set()
15/08/11 10:19:16 INFO DAGScheduler: waiting: Set(Stage 29)
15/08/11 10:19:16 INFO DAGScheduler: failed: Set()
15/08/11 10:19:16 DEBUG MapOutputTrackerMaster: Increasing epoch to 14
15/08/11 10:19:16 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD MapPartitionsRDD[45] at map at KMeansTest.scala:65
15/08/11 10:19:16 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:19:16 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 84) in 2128 ms on 192.168.130.131 (3/3)
15/08/11 10:19:16 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool 
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@224bf823) from Actor[akka://sparkDriver/temp/$Ng]
15/08/11 10:19:16 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: [actor] handled message (0.229773 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@224bf823) from Actor[akka://sparkDriver/temp/$Ng]
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@224bf823) from Actor[akka://sparkDriver/temp/$Og]
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: [actor] handled message (0.166836 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@224bf823) from Actor[akka://sparkDriver/temp/$Og]
15/08/11 10:19:16 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:19:16 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:19:16 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|45|0,rdd_45_0,, null|45|1,rdd_45_1,, null|45|2,rdd_45_2,).
15/08/11 10:19:16 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$Qg]
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: [actor] handled message (0.868496 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$Qg]
15/08/11 10:19:16 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:19:16 DEBUG BlockManager: Got multiple block location in  16 ms
15/08/11 10:19:16 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD ShuffledRDD[44] at reduceByKey at KMeansTest.scala:63
15/08/11 10:19:16 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@7a260d53) from Actor[akka://sparkDriver/temp/$Rg]
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: [actor] handled message (0.201211 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@7a260d53) from Actor[akka://sparkDriver/temp/$Rg]
15/08/11 10:19:16 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@7a260d53) from Actor[akka://sparkDriver/temp/$Sg]
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: [actor] handled message (0.165318 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@7a260d53) from Actor[akka://sparkDriver/temp/$Sg]
15/08/11 10:19:16 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:19:16 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:19:16 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|44|0,rdd_44_0,, null|44|1,rdd_44_1,, null|44|2,rdd_44_2,).
15/08/11 10:19:16 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$Ug]
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: [actor] handled message (0.629313 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$Ug]
15/08/11 10:19:16 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:19:16 DEBUG BlockManager: Got multiple block location in  10 ms
15/08/11 10:19:16 INFO DAGScheduler: Missing parents for Stage 29: List()
15/08/11 10:19:16 INFO DAGScheduler: Submitting Stage 29 (MapPartitionsRDD[45] at map at KMeansTest.scala:65), which is now runnable
15/08/11 10:19:16 DEBUG DAGScheduler: submitMissingTasks(Stage 29)
15/08/11 10:19:16 INFO MemoryStore: ensureFreeSpace(2560) called with curMem=264955, maxMem=278302556
15/08/11 10:19:16 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 2.5 KB, free 265.2 MB)
15/08/11 10:19:16 DEBUG BlockManager: Put block broadcast_30 locally took  5 ms
15/08/11 10:19:16 DEBUG BlockManager: Putting block broadcast_30 without replication took  5 ms
15/08/11 10:19:16 INFO MemoryStore: ensureFreeSpace(1519) called with curMem=267515, maxMem=278302556
15/08/11 10:19:16 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 1519.0 B, free 265.2 MB)
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_30_piece0,StorageLevel(false, true, false, false, 1),1519,0,0) from Actor[akka://sparkDriver/temp/$Vg]
15/08/11 10:19:16 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 192.168.130.131:57830 (size: 1519.0 B, free: 265.4 MB)
15/08/11 10:19:16 INFO BlockManagerMaster: Updated info of block broadcast_30_piece0
15/08/11 10:19:16 DEBUG BlockManager: Told master about block broadcast_30_piece0
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: [actor] handled message (0.532506 ms) UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_30_piece0,StorageLevel(false, true, false, false, 1),1519,0,0) from Actor[akka://sparkDriver/temp/$Vg]
15/08/11 10:19:16 DEBUG BlockManager: Put block broadcast_30_piece0 locally took  2 ms
15/08/11 10:19:16 DEBUG BlockManager: Putting block broadcast_30_piece0 without replication took  2 ms
15/08/11 10:19:16 INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:852
15/08/11 10:19:16 INFO DAGScheduler: Submitting 3 missing tasks from Stage 29 (MapPartitionsRDD[45] at map at KMeansTest.scala:65)
15/08/11 10:19:16 DEBUG DAGScheduler: New pending tasks: Set(ResultTask(29, 2), ResultTask(29, 0), ResultTask(29, 1))
15/08/11 10:19:16 INFO TaskSchedulerImpl: Adding task set 29.0 with 3 tasks
15/08/11 10:19:16 DEBUG TaskSetManager: Epoch for TaskSet 29.0: 14
15/08/11 10:19:16 DEBUG TaskSetManager: Valid locality levels for TaskSet 29.0: NO_PREF, ANY
15/08/11 10:19:16 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/deadLetters]
15/08/11 10:19:16 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_29, runningTasks: 0
15/08/11 10:19:16 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 87, 192.168.130.131, PROCESS_LOCAL, 1116 bytes)
15/08/11 10:19:16 INFO TaskSetManager: Starting task 1.0 in stage 29.0 (TID 88, 192.168.130.131, PROCESS_LOCAL, 1116 bytes)
15/08/11 10:19:16 INFO TaskSetManager: Starting task 2.0 in stage 29.0 (TID 89, 192.168.130.131, PROCESS_LOCAL, 1116 bytes)
15/08/11 10:19:16 DEBUG TaskSetManager: No tasks for locality level NO_PREF, so moving to locality level ANY
15/08/11 10:19:16 DEBUG SparkDeploySchedulerBackend: [actor] handled message (2.525538 ms) ReviveOffers from Actor[akka://sparkDriver/deadLetters]
15/08/11 10:19:16 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,88,RUNNING,org.apache.spark.util.SerializableBuffer@31688cd5) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:16 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.047373 ms) StatusUpdate(0,88,RUNNING,org.apache.spark.util.SerializableBuffer@31688cd5) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:16 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,87,RUNNING,org.apache.spark.util.SerializableBuffer@46f60d4a) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:16 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.061449 ms) StatusUpdate(0,87,RUNNING,org.apache.spark.util.SerializableBuffer@46f60d4a) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:16 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,89,RUNNING,org.apache.spark.util.SerializableBuffer@43e299ab) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:16 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.052879 ms) StatusUpdate(0,89,RUNNING,org.apache.spark.util.SerializableBuffer@43e299ab) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: [actor] received message GetLocations(broadcast_30_piece0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$Yb]
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: [actor] handled message (0.107941 ms) GetLocations(broadcast_30_piece0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$Yb]
15/08/11 10:19:16 DEBUG BlockManager: Level for block broadcast_30_piece0 is StorageLevel(true, true, false, false, 1)
15/08/11 10:19:16 DEBUG BlockManager: Getting block broadcast_30_piece0 from memory
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_30_piece0,StorageLevel(false, true, false, false, 1),1519,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$Zb]
15/08/11 10:19:16 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 192.168.130.131:47921 (size: 1519.0 B, free: 245.6 MB)
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: [actor] handled message (0.495159 ms) UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_30_piece0,StorageLevel(false, true, false, false, 1),1519,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$Zb]
15/08/11 10:19:16 DEBUG MapOutputTrackerMasterActor: [actor] received message GetMapOutputStatuses(13) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$0b]
15/08/11 10:19:16 INFO MapOutputTrackerMasterActor: Asked to send map output locations for shuffle 13 to sparkExecutor@192.168.130.131:49489
15/08/11 10:19:16 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 13 is 161 bytes
15/08/11 10:19:16 DEBUG MapOutputTrackerMasterActor: [actor] handled message (0.898353 ms) GetMapOutputStatuses(13) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$0b]
15/08/11 10:19:16 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,88,FINISHED,org.apache.spark.util.SerializableBuffer@5bf2d540) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:16 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_29, runningTasks: 2
15/08/11 10:19:16 DEBUG SparkDeploySchedulerBackend: [actor] handled message (7.262385 ms) StatusUpdate(0,88,FINISHED,org.apache.spark.util.SerializableBuffer@5bf2d540) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:16 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,89,FINISHED,org.apache.spark.util.SerializableBuffer@238e8be9) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:16 INFO TaskSetManager: Finished task 1.0 in stage 29.0 (TID 88) in 76 ms on 192.168.130.131 (1/3)
15/08/11 10:19:16 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_29, runningTasks: 1
15/08/11 10:19:16 DEBUG SparkDeploySchedulerBackend: [actor] handled message (9.382085 ms) StatusUpdate(0,89,FINISHED,org.apache.spark.util.SerializableBuffer@238e8be9) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:16 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,87,FINISHED,org.apache.spark.util.SerializableBuffer@6842133f) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:16 INFO TaskSetManager: Finished task 2.0 in stage 29.0 (TID 89) in 82 ms on 192.168.130.131 (2/3)
15/08/11 10:19:16 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_29, runningTasks: 0
15/08/11 10:19:16 DEBUG SparkDeploySchedulerBackend: [actor] handled message (4.418861 ms) StatusUpdate(0,87,FINISHED,org.apache.spark.util.SerializableBuffer@6842133f) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:16 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 87) in 88 ms on 192.168.130.131 (3/3)
15/08/11 10:19:16 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool 
15/08/11 10:19:16 INFO DAGScheduler: Stage 29 (collectAsMap at KMeansTest.scala:67) finished in 0.091 s
15/08/11 10:19:16 DEBUG DAGScheduler: After removal of stage 29, remaining stages = 1
15/08/11 10:19:16 DEBUG DAGScheduler: After removal of stage 28, remaining stages = 0
15/08/11 10:19:16 INFO DAGScheduler: Job 15 finished: collectAsMap at KMeansTest.scala:67, took 2.340852 s
Finished iteration (num = 13)
15/08/11 10:19:16 INFO SparkContext: Starting job: collectAsMap at KMeansTest.scala:67
15/08/11 10:19:16 INFO DAGScheduler: Registering RDD 46 (map at KMeansTest.scala:61)
15/08/11 10:19:16 INFO DAGScheduler: Got job 16 (collectAsMap at KMeansTest.scala:67) with 3 output partitions (allowLocal=false)
15/08/11 10:19:16 INFO DAGScheduler: Final stage: Stage 31(collectAsMap at KMeansTest.scala:67)
15/08/11 10:19:16 INFO DAGScheduler: Parents of final stage: List(Stage 30)
15/08/11 10:19:16 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD MapPartitionsRDD[48] at map at KMeansTest.scala:65
15/08/11 10:19:16 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@43d120eb) from Actor[akka://sparkDriver/temp/$Wg]
15/08/11 10:19:16 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: [actor] handled message (0.165288 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@43d120eb) from Actor[akka://sparkDriver/temp/$Wg]
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@43d120eb) from Actor[akka://sparkDriver/temp/$Xg]
15/08/11 10:19:16 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: [actor] handled message (0.133178 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@43d120eb) from Actor[akka://sparkDriver/temp/$Xg]
15/08/11 10:19:16 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:19:16 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|48|0,rdd_48_0,, null|48|1,rdd_48_1,, null|48|2,rdd_48_2,).
15/08/11 10:19:16 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$Zg]
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: [actor] handled message (0.842728 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$Zg]
15/08/11 10:19:16 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:19:16 DEBUG BlockManager: Got multiple block location in  8 ms
15/08/11 10:19:16 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD ShuffledRDD[47] at reduceByKey at KMeansTest.scala:63
15/08/11 10:19:16 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@3334a98f) from Actor[akka://sparkDriver/temp/$0g]
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: [actor] handled message (0.169942 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@3334a98f) from Actor[akka://sparkDriver/temp/$0g]
15/08/11 10:19:16 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@3334a98f) from Actor[akka://sparkDriver/temp/$1g]
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: [actor] handled message (0.092867 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@3334a98f) from Actor[akka://sparkDriver/temp/$1g]
15/08/11 10:19:16 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:19:16 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:19:16 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|47|0,rdd_47_0,, null|47|1,rdd_47_1,, null|47|2,rdd_47_2,).
15/08/11 10:19:16 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$3g]
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: [actor] handled message (1.177497 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$3g]
15/08/11 10:19:16 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:19:16 DEBUG BlockManager: Got multiple block location in  17 ms
15/08/11 10:19:16 INFO DAGScheduler: [SMSpark v1]Missing parents: List(Stage 30)
15/08/11 10:19:16 DEBUG DAGScheduler: submitStage(Stage 31)
15/08/11 10:19:16 DEBUG DAGScheduler: missing: List(Stage 30)
15/08/11 10:19:16 DEBUG DAGScheduler: submitStage(Stage 30)
15/08/11 10:19:16 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD MapPartitionsRDD[46] at map at KMeansTest.scala:61
15/08/11 10:19:16 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@2e38a04d) from Actor[akka://sparkDriver/temp/$4g]
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: [actor] handled message (0.13796 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@2e38a04d) from Actor[akka://sparkDriver/temp/$4g]
15/08/11 10:19:16 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@2e38a04d) from Actor[akka://sparkDriver/temp/$5g]
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: [actor] handled message (0.074383 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@2e38a04d) from Actor[akka://sparkDriver/temp/$5g]
15/08/11 10:19:16 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:19:16 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:19:16 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|46|0,rdd_46_0,, null|46|1,rdd_46_1,, null|46|2,rdd_46_2,).
15/08/11 10:19:16 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$7g]
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:19:16 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: [actor] handled message (0.634076 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$7g]
15/08/11 10:19:16 DEBUG BlockManager: Got multiple block location in  9 ms
15/08/11 10:19:16 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD KMeans01 MapPartitionsRDD[2] at map at KMeansTest.scala:50
15/08/11 10:19:16 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@35ad54dd) from Actor[akka://sparkDriver/temp/$8g]
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: [actor] handled message (0.189547 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@35ad54dd) from Actor[akka://sparkDriver/temp/$8g]
15/08/11 10:19:16 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(ArrayBuffer(BlockManagerId(0, 192.168.130.131, 47921)), ArrayBuffer(BlockManagerId(0, 192.168.130.131, 47921)), ArrayBuffer(BlockManagerId(0, 192.168.130.131, 47921)))
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@35ad54dd) from Actor[akka://sparkDriver/temp/$9g]
15/08/11 10:19:16 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: [actor] handled message (0.159175 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@35ad54dd) from Actor[akka://sparkDriver/temp/$9g]
15/08/11 10:19:16 DEBUG DAGScheduler: missing: List()
15/08/11 10:19:16 INFO DAGScheduler: Submitting Stage 30 (MapPartitionsRDD[46] at map at KMeansTest.scala:61), which has no missing parents
15/08/11 10:19:16 DEBUG DAGScheduler: submitMissingTasks(Stage 30)
15/08/11 10:19:16 INFO MemoryStore: ensureFreeSpace(4768) called with curMem=269034, maxMem=278302556
15/08/11 10:19:16 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 4.7 KB, free 265.1 MB)
15/08/11 10:19:16 DEBUG BlockManager: Put block broadcast_31 locally took  1 ms
15/08/11 10:19:16 DEBUG BlockManager: Putting block broadcast_31 without replication took  2 ms
15/08/11 10:19:16 INFO MemoryStore: ensureFreeSpace(3205) called with curMem=273802, maxMem=278302556
15/08/11 10:19:16 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 3.1 KB, free 265.1 MB)
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_31_piece0,StorageLevel(false, true, false, false, 1),3205,0,0) from Actor[akka://sparkDriver/temp/$+g]
15/08/11 10:19:16 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 192.168.130.131:57830 (size: 3.1 KB, free: 265.4 MB)
15/08/11 10:19:16 INFO BlockManagerMaster: Updated info of block broadcast_31_piece0
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: [actor] handled message (0.439156 ms) UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_31_piece0,StorageLevel(false, true, false, false, 1),3205,0,0) from Actor[akka://sparkDriver/temp/$+g]
15/08/11 10:19:16 DEBUG BlockManager: Told master about block broadcast_31_piece0
15/08/11 10:19:16 DEBUG BlockManager: Put block broadcast_31_piece0 locally took  2 ms
15/08/11 10:19:16 DEBUG BlockManager: Putting block broadcast_31_piece0 without replication took  2 ms
15/08/11 10:19:16 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:852
15/08/11 10:19:16 INFO DAGScheduler: Submitting 3 missing tasks from Stage 30 (MapPartitionsRDD[46] at map at KMeansTest.scala:61)
15/08/11 10:19:16 DEBUG DAGScheduler: New pending tasks: Set(ShuffleMapTask(30, 0), ShuffleMapTask(30, 2), ShuffleMapTask(30, 1))
15/08/11 10:19:16 INFO TaskSchedulerImpl: Adding task set 30.0 with 3 tasks
15/08/11 10:19:16 DEBUG TaskSetManager: Epoch for TaskSet 30.0: 14
15/08/11 10:19:16 DEBUG TaskSetManager: Valid locality levels for TaskSet 30.0: PROCESS_LOCAL, NODE_LOCAL, ANY
15/08/11 10:19:16 DEBUG DAGScheduler: submitStage(Stage 31)
15/08/11 10:19:16 DEBUG DAGScheduler: missing: List(Stage 30)
15/08/11 10:19:16 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/deadLetters]
15/08/11 10:19:16 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_30, runningTasks: 0
15/08/11 10:19:16 DEBUG DAGScheduler: submitStage(Stage 30)
15/08/11 10:19:16 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 90, 192.168.130.131, PROCESS_LOCAL, 1361 bytes)
15/08/11 10:19:16 DEBUG DAGScheduler: submitStage(Stage 31)
15/08/11 10:19:16 DEBUG DAGScheduler: missing: List(Stage 30)
15/08/11 10:19:16 DEBUG DAGScheduler: submitStage(Stage 30)
15/08/11 10:19:16 INFO TaskSetManager: Starting task 1.0 in stage 30.0 (TID 91, 192.168.130.131, PROCESS_LOCAL, 1361 bytes)
15/08/11 10:19:16 DEBUG DAGScheduler: submitStage(Stage 31)
15/08/11 10:19:16 DEBUG DAGScheduler: missing: List(Stage 30)
15/08/11 10:19:16 DEBUG DAGScheduler: submitStage(Stage 30)
15/08/11 10:19:16 INFO TaskSetManager: Starting task 2.0 in stage 30.0 (TID 92, 192.168.130.131, PROCESS_LOCAL, 1361 bytes)
15/08/11 10:19:16 DEBUG TaskSetManager: No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
15/08/11 10:19:16 DEBUG TaskSetManager: No tasks for locality level NODE_LOCAL, so moving to locality level ANY
15/08/11 10:19:16 DEBUG DAGScheduler: submitStage(Stage 31)
15/08/11 10:19:16 DEBUG DAGScheduler: missing: List(Stage 30)
15/08/11 10:19:16 DEBUG DAGScheduler: submitStage(Stage 30)
15/08/11 10:19:16 DEBUG SparkDeploySchedulerBackend: [actor] handled message (6.251965 ms) ReviveOffers from Actor[akka://sparkDriver/deadLetters]
15/08/11 10:19:16 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,90,RUNNING,org.apache.spark.util.SerializableBuffer@fd642e2) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:16 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.049356 ms) StatusUpdate(0,90,RUNNING,org.apache.spark.util.SerializableBuffer@fd642e2) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: [actor] received message GetLocations(broadcast_31_piece0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$1b]
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: [actor] handled message (0.197094 ms) GetLocations(broadcast_31_piece0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$1b]
15/08/11 10:19:16 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,91,RUNNING,org.apache.spark.util.SerializableBuffer@7d13f571) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:16 DEBUG BlockManager: Level for block broadcast_31_piece0 is StorageLevel(true, true, false, false, 1)
15/08/11 10:19:16 DEBUG BlockManager: Getting block broadcast_31_piece0 from memory
15/08/11 10:19:16 DEBUG SparkDeploySchedulerBackend: [actor] handled message (1.916947 ms) StatusUpdate(0,91,RUNNING,org.apache.spark.util.SerializableBuffer@7d13f571) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:16 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,92,RUNNING,org.apache.spark.util.SerializableBuffer@211c6c4e) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:16 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.073313 ms) StatusUpdate(0,92,RUNNING,org.apache.spark.util.SerializableBuffer@211c6c4e) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_31_piece0,StorageLevel(false, true, false, false, 1),3205,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$2b]
15/08/11 10:19:16 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 192.168.130.131:47921 (size: 3.1 KB, free: 245.6 MB)
15/08/11 10:19:16 DEBUG BlockManagerMasterActor: [actor] handled message (0.577692 ms) UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_31_piece0,StorageLevel(false, true, false, false, 1),3205,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$2b]
15/08/11 10:19:16 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:19:16 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_30, runningTasks: 3
15/08/11 10:19:16 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.801339 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:19:17 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,92,FINISHED,org.apache.spark.util.SerializableBuffer@9da99bc) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:17 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_30, runningTasks: 2
15/08/11 10:19:17 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.505563 ms) StatusUpdate(0,92,FINISHED,org.apache.spark.util.SerializableBuffer@9da99bc) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:17 DEBUG DAGScheduler: ShuffleMapTask finished on 0
15/08/11 10:19:17 DEBUG DAGScheduler: submitStage(Stage 31)
15/08/11 10:19:17 DEBUG DAGScheduler: missing: List(Stage 30)
15/08/11 10:19:17 DEBUG DAGScheduler: submitStage(Stage 30)
15/08/11 10:19:17 INFO TaskSetManager: Finished task 2.0 in stage 30.0 (TID 92) in 996 ms on 192.168.130.131 (1/3)
15/08/11 10:19:17 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:19:17 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_30, runningTasks: 2
15/08/11 10:19:17 DEBUG SparkDeploySchedulerBackend: [actor] handled message (3.13357 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:19:18 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:19:18 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_30, runningTasks: 2
15/08/11 10:19:18 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.97723 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:19:19 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,90,FINISHED,org.apache.spark.util.SerializableBuffer@266cb77f) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:19 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_30, runningTasks: 1
15/08/11 10:19:19 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.816762 ms) StatusUpdate(0,90,FINISHED,org.apache.spark.util.SerializableBuffer@266cb77f) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:19 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,91,FINISHED,org.apache.spark.util.SerializableBuffer@2b83068e) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:19 DEBUG DAGScheduler: ShuffleMapTask finished on 0
15/08/11 10:19:19 DEBUG DAGScheduler: submitStage(Stage 31)
15/08/11 10:19:19 DEBUG DAGScheduler: missing: List(Stage 30)
15/08/11 10:19:19 DEBUG DAGScheduler: submitStage(Stage 30)
15/08/11 10:19:19 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 90) in 2985 ms on 192.168.130.131 (2/3)
15/08/11 10:19:19 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_30, runningTasks: 0
15/08/11 10:19:19 DEBUG SparkDeploySchedulerBackend: [actor] handled message (27.950005 ms) StatusUpdate(0,91,FINISHED,org.apache.spark.util.SerializableBuffer@2b83068e) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:19 DEBUG DAGScheduler: ShuffleMapTask finished on 0
15/08/11 10:19:19 INFO DAGScheduler: Stage 30 (map at KMeansTest.scala:61) finished in 3.052 s
15/08/11 10:19:19 INFO DAGScheduler: looking for newly runnable stages
15/08/11 10:19:19 INFO DAGScheduler: running: Set()
15/08/11 10:19:19 INFO DAGScheduler: waiting: Set(Stage 31)
15/08/11 10:19:19 INFO DAGScheduler: failed: Set()
15/08/11 10:19:19 DEBUG MapOutputTrackerMaster: Increasing epoch to 15
15/08/11 10:19:19 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD MapPartitionsRDD[48] at map at KMeansTest.scala:65
15/08/11 10:19:19 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:19:19 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@27236af3) from Actor[akka://sparkDriver/temp/$~g]
15/08/11 10:19:19 DEBUG BlockManagerMasterActor: [actor] handled message (0.423996 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@27236af3) from Actor[akka://sparkDriver/temp/$~g]
15/08/11 10:19:19 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:19:19 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@27236af3) from Actor[akka://sparkDriver/temp/$ah]
15/08/11 10:19:19 DEBUG BlockManagerMasterActor: [actor] handled message (0.384935 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@27236af3) from Actor[akka://sparkDriver/temp/$ah]
15/08/11 10:19:19 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:19:19 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:19:19 INFO TaskSetManager: Finished task 1.0 in stage 30.0 (TID 91) in 3039 ms on 192.168.130.131 (3/3)
15/08/11 10:19:19 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool 
15/08/11 10:19:19 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|48|0,rdd_48_0,, null|48|1,rdd_48_1,, null|48|2,rdd_48_2,).
15/08/11 10:19:19 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:19:19 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$ch]
15/08/11 10:19:19 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:19:19 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:19 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:19 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:19 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:19 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:19 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:19 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:19 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:19 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:19 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:19:19 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:19:19 DEBUG BlockManager: Got multiple block location in  82 ms
15/08/11 10:19:19 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD ShuffledRDD[47] at reduceByKey at KMeansTest.scala:63
15/08/11 10:19:19 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:19:19 DEBUG BlockManagerMasterActor: [actor] handled message (2.076452 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$ch]
15/08/11 10:19:19 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@53dbb696) from Actor[akka://sparkDriver/temp/$dh]
15/08/11 10:19:19 DEBUG BlockManagerMasterActor: [actor] handled message (0.177966 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@53dbb696) from Actor[akka://sparkDriver/temp/$dh]
15/08/11 10:19:19 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:19:19 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@53dbb696) from Actor[akka://sparkDriver/temp/$eh]
15/08/11 10:19:19 DEBUG BlockManagerMasterActor: [actor] handled message (0.48117 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@53dbb696) from Actor[akka://sparkDriver/temp/$eh]
15/08/11 10:19:19 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:19:19 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:19:19 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|47|0,rdd_47_0,, null|47|1,rdd_47_1,, null|47|2,rdd_47_2,).
15/08/11 10:19:19 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:19:19 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$gh]
15/08/11 10:19:19 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:19:19 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:19 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:19 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:19 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:19 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:19 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:19 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:19 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:19 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:19 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:19:19 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:19:19 DEBUG BlockManagerMasterActor: [actor] handled message (1.39062 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$gh]
15/08/11 10:19:19 DEBUG BlockManager: Got multiple block location in  40 ms
15/08/11 10:19:19 INFO DAGScheduler: Missing parents for Stage 31: List()
15/08/11 10:19:19 INFO DAGScheduler: Submitting Stage 31 (MapPartitionsRDD[48] at map at KMeansTest.scala:65), which is now runnable
15/08/11 10:19:19 DEBUG DAGScheduler: submitMissingTasks(Stage 31)
15/08/11 10:19:19 INFO MemoryStore: ensureFreeSpace(2560) called with curMem=277007, maxMem=278302556
15/08/11 10:19:19 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 2.5 KB, free 265.1 MB)
15/08/11 10:19:19 DEBUG BlockManager: Put block broadcast_32 locally took  7 ms
15/08/11 10:19:19 DEBUG BlockManager: Putting block broadcast_32 without replication took  14 ms
15/08/11 10:19:19 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:19:19 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.375182 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:19:19 INFO MemoryStore: ensureFreeSpace(1519) called with curMem=279567, maxMem=278302556
15/08/11 10:19:19 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 1519.0 B, free 265.1 MB)
15/08/11 10:19:19 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_32_piece0,StorageLevel(false, true, false, false, 1),1519,0,0) from Actor[akka://sparkDriver/temp/$hh]
15/08/11 10:19:19 DEBUG ContextCleaner: Got cleaning task CleanShuffle(8)
15/08/11 10:19:19 DEBUG ContextCleaner: Cleaning shuffle 8
15/08/11 10:19:19 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 192.168.130.131:57830 (size: 1519.0 B, free: 265.4 MB)
15/08/11 10:19:19 INFO BlockManagerMaster: Updated info of block broadcast_32_piece0
15/08/11 10:19:19 DEBUG BlockManager: Told master about block broadcast_32_piece0
15/08/11 10:19:19 DEBUG BlockManager: Put block broadcast_32_piece0 locally took  33 ms
15/08/11 10:19:19 DEBUG BlockManagerMasterActor: [actor] handled message (6.3619 ms) UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_32_piece0,StorageLevel(false, true, false, false, 1),1519,0,0) from Actor[akka://sparkDriver/temp/$hh]
15/08/11 10:19:19 DEBUG BlockManager: Putting block broadcast_32_piece0 without replication took  33 ms
15/08/11 10:19:19 DEBUG BlockManagerMasterActor: [actor] received message RemoveShuffle(8) from Actor[akka://sparkDriver/temp/$ih]
15/08/11 10:19:19 INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:852
15/08/11 10:19:19 DEBUG BlockManagerMasterActor: [actor] handled message (0.599291 ms) RemoveShuffle(8) from Actor[akka://sparkDriver/temp/$ih]
15/08/11 10:19:19 DEBUG BlockManagerSlaveActor: [actor] received message RemoveShuffle(8) from Actor[akka://sparkDriver/temp/$jh]
15/08/11 10:19:19 DEBUG BlockManagerSlaveActor: [actor] handled message (0.042726 ms) RemoveShuffle(8) from Actor[akka://sparkDriver/temp/$jh]
15/08/11 10:19:19 DEBUG BlockManagerSlaveActor: removing shuffle 8
15/08/11 10:19:19 INFO DAGScheduler: Submitting 3 missing tasks from Stage 31 (MapPartitionsRDD[48] at map at KMeansTest.scala:65)
15/08/11 10:19:19 DEBUG DAGScheduler: New pending tasks: Set(ResultTask(31, 2), ResultTask(31, 1), ResultTask(31, 0))
15/08/11 10:19:19 INFO TaskSchedulerImpl: Adding task set 31.0 with 3 tasks
15/08/11 10:19:19 DEBUG BlockManagerSlaveActor: Done removing shuffle 8, response is true
15/08/11 10:19:19 DEBUG TaskSetManager: Epoch for TaskSet 31.0: 15
15/08/11 10:19:19 DEBUG BlockManagerSlaveActor: Sent response: true to Actor[akka://sparkDriver/temp/$jh]
15/08/11 10:19:19 DEBUG TaskSetManager: Valid locality levels for TaskSet 31.0: NO_PREF, ANY
15/08/11 10:19:19 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/deadLetters]
15/08/11 10:19:19 INFO ContextCleaner: Cleaned shuffle 8
15/08/11 10:19:19 DEBUG ContextCleaner: Got cleaning task CleanBroadcast(18)
15/08/11 10:19:19 DEBUG ContextCleaner: Cleaning broadcast 18
15/08/11 10:19:19 DEBUG TorrentBroadcast: Unpersisting TorrentBroadcast 18
15/08/11 10:19:19 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_31, runningTasks: 0
15/08/11 10:19:19 DEBUG BlockManagerMasterActor: [actor] received message RemoveBroadcast(18,true) from Actor[akka://sparkDriver/temp/$lh]
15/08/11 10:19:19 DEBUG BlockManagerSlaveActor: [actor] received message RemoveBroadcast(18,true) from Actor[akka://sparkDriver/temp/$mh]
15/08/11 10:19:19 DEBUG BlockManagerSlaveActor: [actor] handled message (0.049214 ms) RemoveBroadcast(18,true) from Actor[akka://sparkDriver/temp/$mh]
15/08/11 10:19:19 DEBUG BlockManagerSlaveActor: removing broadcast 18
15/08/11 10:19:19 INFO BlockManager: Removing broadcast 18
15/08/11 10:19:19 INFO BlockManager: Removing block broadcast_18_piece0
15/08/11 10:19:19 INFO MemoryStore: Block broadcast_18_piece0 of size 1521 dropped from memory (free 278022991)
15/08/11 10:19:19 DEBUG BlockManagerMasterActor: [actor] handled message (1.74669 ms) RemoveBroadcast(18,true) from Actor[akka://sparkDriver/temp/$lh]
15/08/11 10:19:19 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_18_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka://sparkDriver/temp/$nh]
15/08/11 10:19:19 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 192.168.130.131:57830 in memory (size: 1521.0 B, free: 265.4 MB)
15/08/11 10:19:19 INFO BlockManagerMaster: Updated info of block broadcast_18_piece0
15/08/11 10:19:19 DEBUG BlockManager: Told master about block broadcast_18_piece0
15/08/11 10:19:19 INFO BlockManager: Removing block broadcast_18
15/08/11 10:19:19 INFO MemoryStore: Block broadcast_18 of size 2560 dropped from memory (free 278025551)
15/08/11 10:19:19 DEBUG BlockManagerSlaveActor: Done removing broadcast 18, response is 2
15/08/11 10:19:19 DEBUG BlockManagerSlaveActor: Sent response: 2 to Actor[akka://sparkDriver/temp/$mh]
15/08/11 10:19:19 DEBUG BlockManagerMasterActor: [actor] handled message (1.496481 ms) UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_18_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka://sparkDriver/temp/$nh]
15/08/11 10:19:19 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 93, 192.168.130.131, PROCESS_LOCAL, 1116 bytes)
15/08/11 10:19:19 INFO TaskSetManager: Starting task 1.0 in stage 31.0 (TID 94, 192.168.130.131, PROCESS_LOCAL, 1116 bytes)
15/08/11 10:19:19 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_18_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$3b]
15/08/11 10:19:19 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 192.168.130.131:47921 in memory (size: 1521.0 B, free: 245.6 MB)
15/08/11 10:19:19 DEBUG BlockManagerMasterActor: [actor] handled message (0.646371 ms) UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_18_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$3b]
15/08/11 10:19:19 INFO TaskSetManager: Starting task 2.0 in stage 31.0 (TID 95, 192.168.130.131, PROCESS_LOCAL, 1116 bytes)
15/08/11 10:19:19 DEBUG TaskSetManager: No tasks for locality level NO_PREF, so moving to locality level ANY
15/08/11 10:19:19 DEBUG SparkDeploySchedulerBackend: [actor] handled message (42.793657 ms) ReviveOffers from Actor[akka://sparkDriver/deadLetters]
15/08/11 10:19:19 INFO ContextCleaner: Cleaned broadcast 18
15/08/11 10:19:19 DEBUG ContextCleaner: Got cleaning task CleanBroadcast(17)
15/08/11 10:19:19 DEBUG ContextCleaner: Cleaning broadcast 17
15/08/11 10:19:19 DEBUG TorrentBroadcast: Unpersisting TorrentBroadcast 17
15/08/11 10:19:19 DEBUG BlockManagerMasterActor: [actor] received message RemoveBroadcast(17,true) from Actor[akka://sparkDriver/temp/$ph]
15/08/11 10:19:19 DEBUG BlockManagerSlaveActor: [actor] received message RemoveBroadcast(17,true) from Actor[akka://sparkDriver/temp/$qh]
15/08/11 10:19:19 DEBUG BlockManagerSlaveActor: [actor] handled message (0.054261 ms) RemoveBroadcast(17,true) from Actor[akka://sparkDriver/temp/$qh]
15/08/11 10:19:19 DEBUG BlockManagerSlaveActor: removing broadcast 17
15/08/11 10:19:19 INFO BlockManager: Removing broadcast 17
15/08/11 10:19:19 INFO BlockManager: Removing block broadcast_17_piece0
15/08/11 10:19:19 INFO MemoryStore: Block broadcast_17_piece0 of size 3200 dropped from memory (free 278028751)
15/08/11 10:19:19 DEBUG BlockManagerMasterActor: [actor] handled message (0.587857 ms) RemoveBroadcast(17,true) from Actor[akka://sparkDriver/temp/$ph]
15/08/11 10:19:19 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_17_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka://sparkDriver/temp/$rh]
15/08/11 10:19:19 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 192.168.130.131:57830 in memory (size: 3.1 KB, free: 265.4 MB)
15/08/11 10:19:19 INFO BlockManagerMaster: Updated info of block broadcast_17_piece0
15/08/11 10:19:19 DEBUG BlockManager: Told master about block broadcast_17_piece0
15/08/11 10:19:19 DEBUG BlockManagerMasterActor: [actor] handled message (0.601105 ms) UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_17_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka://sparkDriver/temp/$rh]
15/08/11 10:19:19 INFO BlockManager: Removing block broadcast_17
15/08/11 10:19:19 INFO MemoryStore: Block broadcast_17 of size 4768 dropped from memory (free 278033519)
15/08/11 10:19:19 DEBUG BlockManagerSlaveActor: Done removing broadcast 17, response is 2
15/08/11 10:19:19 DEBUG BlockManagerSlaveActor: Sent response: 2 to Actor[akka://sparkDriver/temp/$qh]
15/08/11 10:19:19 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,93,RUNNING,org.apache.spark.util.SerializableBuffer@57b7e48) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:19 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.138796 ms) StatusUpdate(0,93,RUNNING,org.apache.spark.util.SerializableBuffer@57b7e48) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:19 DEBUG BlockManagerMasterActor: [actor] received message GetLocations(broadcast_32_piece0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$4b]
15/08/11 10:19:19 DEBUG BlockManagerMasterActor: [actor] handled message (0.100959 ms) GetLocations(broadcast_32_piece0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$4b]
15/08/11 10:19:19 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,94,RUNNING,org.apache.spark.util.SerializableBuffer@6822e7b3) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:19 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.07436 ms) StatusUpdate(0,94,RUNNING,org.apache.spark.util.SerializableBuffer@6822e7b3) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:19 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,95,RUNNING,org.apache.spark.util.SerializableBuffer@4b99ce2e) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:19 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.06371 ms) StatusUpdate(0,95,RUNNING,org.apache.spark.util.SerializableBuffer@4b99ce2e) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:19 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_17_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$5b]
15/08/11 10:19:19 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 192.168.130.131:47921 in memory (size: 3.1 KB, free: 245.6 MB)
15/08/11 10:19:19 DEBUG BlockManagerMasterActor: [actor] handled message (2.188463 ms) UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_17_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$5b]
15/08/11 10:19:19 DEBUG BlockManager: Level for block broadcast_32_piece0 is StorageLevel(true, true, false, false, 1)
15/08/11 10:19:19 DEBUG BlockManager: Getting block broadcast_32_piece0 from memory
15/08/11 10:19:20 INFO ContextCleaner: Cleaned broadcast 17
15/08/11 10:19:20 DEBUG ContextCleaner: Got cleaning task CleanShuffle(7)
15/08/11 10:19:20 DEBUG ContextCleaner: Cleaning shuffle 7
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] received message RemoveShuffle(7) from Actor[akka://sparkDriver/temp/$th]
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: [actor] received message RemoveShuffle(7) from Actor[akka://sparkDriver/temp/$uh]
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: removing shuffle 7
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: [actor] handled message (0.154574 ms) RemoveShuffle(7) from Actor[akka://sparkDriver/temp/$uh]
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: Done removing shuffle 7, response is true
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: Sent response: true to Actor[akka://sparkDriver/temp/$uh]
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] handled message (17.221654 ms) RemoveShuffle(7) from Actor[akka://sparkDriver/temp/$th]
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_32_piece0,StorageLevel(false, true, false, false, 1),1519,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$6b]
15/08/11 10:19:20 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 192.168.130.131:47921 (size: 1519.0 B, free: 245.6 MB)
15/08/11 10:19:20 INFO ContextCleaner: Cleaned shuffle 7
15/08/11 10:19:20 DEBUG ContextCleaner: Got cleaning task CleanBroadcast(16)
15/08/11 10:19:20 DEBUG ContextCleaner: Cleaning broadcast 16
15/08/11 10:19:20 DEBUG TorrentBroadcast: Unpersisting TorrentBroadcast 16
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] handled message (4.960413 ms) UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_32_piece0,StorageLevel(false, true, false, false, 1),1519,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$6b]
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] received message RemoveBroadcast(16,true) from Actor[akka://sparkDriver/temp/$wh]
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: [actor] received message RemoveBroadcast(16,true) from Actor[akka://sparkDriver/temp/$xh]
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: [actor] handled message (0.052672 ms) RemoveBroadcast(16,true) from Actor[akka://sparkDriver/temp/$xh]
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: removing broadcast 16
15/08/11 10:19:20 INFO BlockManager: Removing broadcast 16
15/08/11 10:19:20 INFO BlockManager: Removing block broadcast_16_piece0
15/08/11 10:19:20 INFO MemoryStore: Block broadcast_16_piece0 of size 1521 dropped from memory (free 278035040)
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] handled message (2.860405 ms) RemoveBroadcast(16,true) from Actor[akka://sparkDriver/temp/$wh]
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_16_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka://sparkDriver/temp/$zh]
15/08/11 10:19:20 DEBUG MapOutputTrackerMasterActor: [actor] received message GetMapOutputStatuses(14) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$7b]
15/08/11 10:19:20 INFO MapOutputTrackerMasterActor: Asked to send map output locations for shuffle 14 to sparkExecutor@192.168.130.131:49489
15/08/11 10:19:20 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 14 is 161 bytes
15/08/11 10:19:20 DEBUG MapOutputTrackerMasterActor: [actor] handled message (1.071326 ms) GetMapOutputStatuses(14) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$7b]
15/08/11 10:19:20 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 192.168.130.131:57830 in memory (size: 1521.0 B, free: 265.4 MB)
15/08/11 10:19:20 INFO BlockManagerMaster: Updated info of block broadcast_16_piece0
15/08/11 10:19:20 DEBUG BlockManager: Told master about block broadcast_16_piece0
15/08/11 10:19:20 INFO BlockManager: Removing block broadcast_16
15/08/11 10:19:20 INFO MemoryStore: Block broadcast_16 of size 2560 dropped from memory (free 278037600)
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: Done removing broadcast 16, response is 2
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: Sent response: 2 to Actor[akka://sparkDriver/temp/$xh]
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] handled message (18.803697 ms) UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_16_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka://sparkDriver/temp/$zh]
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_16_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$8b]
15/08/11 10:19:20 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 192.168.130.131:47921 in memory (size: 1521.0 B, free: 245.6 MB)
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] handled message (0.951477 ms) UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_16_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$8b]
15/08/11 10:19:20 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,93,FINISHED,org.apache.spark.util.SerializableBuffer@63206078) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:20 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_31, runningTasks: 2
15/08/11 10:19:20 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.634299 ms) StatusUpdate(0,93,FINISHED,org.apache.spark.util.SerializableBuffer@63206078) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:20 DEBUG HeartbeatReceiver: [actor] received message Heartbeat(0,[Lscala.Tuple2;@7f0ec38,BlockManagerId(0, 192.168.130.131, 47921)) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$9b]
15/08/11 10:19:20 INFO ContextCleaner: Cleaned broadcast 16
15/08/11 10:19:20 DEBUG ContextCleaner: Got cleaning task CleanBroadcast(15)
15/08/11 10:19:20 DEBUG ContextCleaner: Cleaning broadcast 15
15/08/11 10:19:20 DEBUG TorrentBroadcast: Unpersisting TorrentBroadcast 15
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] received message RemoveBroadcast(15,true) from Actor[akka://sparkDriver/temp/$Ah]
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: [actor] received message RemoveBroadcast(15,true) from Actor[akka://sparkDriver/temp/$Bh]
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: [actor] handled message (0.092526 ms) RemoveBroadcast(15,true) from Actor[akka://sparkDriver/temp/$Bh]
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: removing broadcast 15
15/08/11 10:19:20 INFO BlockManager: Removing broadcast 15
15/08/11 10:19:20 INFO BlockManager: Removing block broadcast_15_piece0
15/08/11 10:19:20 INFO MemoryStore: Block broadcast_15_piece0 of size 3201 dropped from memory (free 278040801)
15/08/11 10:19:20 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 93) in 219 ms on 192.168.130.131 (1/3)
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] handled message (6.181945 ms) RemoveBroadcast(15,true) from Actor[akka://sparkDriver/temp/$Ah]
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_15_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka://sparkDriver/temp/$Ch]
15/08/11 10:19:20 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 192.168.130.131:57830 in memory (size: 3.1 KB, free: 265.4 MB)
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] handled message (2.979838 ms) UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_15_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka://sparkDriver/temp/$Ch]
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] received message BlockManagerHeartbeat(BlockManagerId(0, 192.168.130.131, 47921)) from Actor[akka://sparkDriver/temp/$Eh]
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] handled message (0.151435 ms) BlockManagerHeartbeat(BlockManagerId(0, 192.168.130.131, 47921)) from Actor[akka://sparkDriver/temp/$Eh]
15/08/11 10:19:20 DEBUG HeartbeatReceiver: [actor] handled message (14.289749 ms) Heartbeat(0,[Lscala.Tuple2;@7f0ec38,BlockManagerId(0, 192.168.130.131, 47921)) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$9b]
15/08/11 10:19:20 INFO BlockManagerMaster: Updated info of block broadcast_15_piece0
15/08/11 10:19:20 DEBUG BlockManager: Told master about block broadcast_15_piece0
15/08/11 10:19:20 INFO BlockManager: Removing block broadcast_15
15/08/11 10:19:20 INFO MemoryStore: Block broadcast_15 of size 4768 dropped from memory (free 278045569)
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: Done removing broadcast 15, response is 2
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: Sent response: 2 to Actor[akka://sparkDriver/temp/$Bh]
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_15_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$+b]
15/08/11 10:19:20 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 192.168.130.131:47921 in memory (size: 3.1 KB, free: 245.7 MB)
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] handled message (6.594632 ms) UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_15_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$+b]
15/08/11 10:19:20 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,95,FINISHED,org.apache.spark.util.SerializableBuffer@7bf5f1cc) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:20 INFO ContextCleaner: Cleaned broadcast 15
15/08/11 10:19:20 DEBUG ContextCleaner: Got cleaning task CleanShuffle(6)
15/08/11 10:19:20 DEBUG ContextCleaner: Cleaning shuffle 6
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] received message RemoveShuffle(6) from Actor[akka://sparkDriver/temp/$Fh]
15/08/11 10:19:20 INFO ContextCleaner: Cleaned shuffle 6
15/08/11 10:19:20 DEBUG ContextCleaner: Got cleaning task CleanBroadcast(14)
15/08/11 10:19:20 DEBUG ContextCleaner: Cleaning broadcast 14
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: [actor] received message RemoveShuffle(6) from Actor[akka://sparkDriver/temp/$Gh]
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: removing shuffle 6
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: [actor] handled message (0.042794 ms) RemoveShuffle(6) from Actor[akka://sparkDriver/temp/$Gh]
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: Done removing shuffle 6, response is true
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: Sent response: true to Actor[akka://sparkDriver/temp/$Gh]
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] handled message (0.561968 ms) RemoveShuffle(6) from Actor[akka://sparkDriver/temp/$Fh]
15/08/11 10:19:20 DEBUG TorrentBroadcast: Unpersisting TorrentBroadcast 14
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] received message RemoveBroadcast(14,true) from Actor[akka://sparkDriver/temp/$Hh]
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] handled message (0.352362 ms) RemoveBroadcast(14,true) from Actor[akka://sparkDriver/temp/$Hh]
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: [actor] received message RemoveBroadcast(14,true) from Actor[akka://sparkDriver/temp/$Ih]
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: removing broadcast 14
15/08/11 10:19:20 INFO BlockManager: Removing broadcast 14
15/08/11 10:19:20 INFO BlockManager: Removing block broadcast_14_piece0
15/08/11 10:19:20 INFO MemoryStore: Block broadcast_14_piece0 of size 1519 dropped from memory (free 278047088)
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: [actor] handled message (0.076817 ms) RemoveBroadcast(14,true) from Actor[akka://sparkDriver/temp/$Ih]
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_14_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka://sparkDriver/temp/$Jh]
15/08/11 10:19:20 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 192.168.130.131:57830 in memory (size: 1519.0 B, free: 265.4 MB)
15/08/11 10:19:20 INFO BlockManagerMaster: Updated info of block broadcast_14_piece0
15/08/11 10:19:20 DEBUG BlockManager: Told master about block broadcast_14_piece0
15/08/11 10:19:20 INFO BlockManager: Removing block broadcast_14
15/08/11 10:19:20 INFO MemoryStore: Block broadcast_14 of size 2560 dropped from memory (free 278049648)
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: Done removing broadcast 14, response is 2
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: Sent response: 2 to Actor[akka://sparkDriver/temp/$Ih]
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] handled message (42.559004 ms) UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_14_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka://sparkDriver/temp/$Jh]
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_14_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$~b]
15/08/11 10:19:20 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 192.168.130.131:47921 in memory (size: 1519.0 B, free: 245.7 MB)
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] handled message (0.739136 ms) UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_14_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$~b]
15/08/11 10:19:20 INFO ContextCleaner: Cleaned broadcast 14
15/08/11 10:19:20 DEBUG ContextCleaner: Got cleaning task CleanBroadcast(30)
15/08/11 10:19:20 DEBUG ContextCleaner: Cleaning broadcast 30
15/08/11 10:19:20 DEBUG TorrentBroadcast: Unpersisting TorrentBroadcast 30
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] received message RemoveBroadcast(30,true) from Actor[akka://sparkDriver/temp/$Mh]
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: [actor] received message RemoveBroadcast(30,true) from Actor[akka://sparkDriver/temp/$Nh]
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: removing broadcast 30
15/08/11 10:19:20 INFO BlockManager: Removing broadcast 30
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] handled message (0.556704 ms) RemoveBroadcast(30,true) from Actor[akka://sparkDriver/temp/$Mh]
15/08/11 10:19:20 INFO BlockManager: Removing block broadcast_30_piece0
15/08/11 10:19:20 INFO MemoryStore: Block broadcast_30_piece0 of size 1519 dropped from memory (free 278051167)
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: [actor] handled message (0.786179 ms) RemoveBroadcast(30,true) from Actor[akka://sparkDriver/temp/$Nh]
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_30_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka://sparkDriver/temp/$Oh]
15/08/11 10:19:20 INFO BlockManagerInfo: Removed broadcast_30_piece0 on 192.168.130.131:57830 in memory (size: 1519.0 B, free: 265.4 MB)
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] handled message (0.555205 ms) UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_30_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka://sparkDriver/temp/$Oh]
15/08/11 10:19:20 INFO BlockManagerMaster: Updated info of block broadcast_30_piece0
15/08/11 10:19:20 DEBUG BlockManager: Told master about block broadcast_30_piece0
15/08/11 10:19:20 INFO BlockManager: Removing block broadcast_30
15/08/11 10:19:20 INFO MemoryStore: Block broadcast_30 of size 2560 dropped from memory (free 278053727)
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: Done removing broadcast 30, response is 2
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: Sent response: 2 to Actor[akka://sparkDriver/temp/$Nh]
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_30_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$ac]
15/08/11 10:19:20 INFO BlockManagerInfo: Removed broadcast_30_piece0 on 192.168.130.131:47921 in memory (size: 1519.0 B, free: 245.7 MB)
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] handled message (0.49275 ms) UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_30_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$ac]
15/08/11 10:19:20 INFO ContextCleaner: Cleaned broadcast 30
15/08/11 10:19:20 DEBUG ContextCleaner: Got cleaning task CleanBroadcast(29)
15/08/11 10:19:20 INFO TaskSetManager: Finished task 2.0 in stage 31.0 (TID 95) in 251 ms on 192.168.130.131 (2/3)
15/08/11 10:19:20 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_31, runningTasks: 1
15/08/11 10:19:20 DEBUG SparkDeploySchedulerBackend: [actor] handled message (101.246857 ms) StatusUpdate(0,95,FINISHED,org.apache.spark.util.SerializableBuffer@7bf5f1cc) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:20 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,94,FINISHED,org.apache.spark.util.SerializableBuffer@5df90fac) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:20 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_31, runningTasks: 0
15/08/11 10:19:20 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.503389 ms) StatusUpdate(0,94,FINISHED,org.apache.spark.util.SerializableBuffer@5df90fac) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:20 DEBUG ContextCleaner: Cleaning broadcast 29
15/08/11 10:19:20 DEBUG TorrentBroadcast: Unpersisting TorrentBroadcast 29
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] received message RemoveBroadcast(29,true) from Actor[akka://sparkDriver/temp/$Qh]
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: [actor] received message RemoveBroadcast(29,true) from Actor[akka://sparkDriver/temp/$Rh]
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: [actor] handled message (0.037803 ms) RemoveBroadcast(29,true) from Actor[akka://sparkDriver/temp/$Rh]
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: removing broadcast 29
15/08/11 10:19:20 INFO BlockManager: Removing broadcast 29
15/08/11 10:19:20 INFO BlockManager: Removing block broadcast_29_piece0
15/08/11 10:19:20 INFO MemoryStore: Block broadcast_29_piece0 of size 3205 dropped from memory (free 278056932)
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] handled message (0.57233 ms) RemoveBroadcast(29,true) from Actor[akka://sparkDriver/temp/$Qh]
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_29_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka://sparkDriver/temp/$Th]
15/08/11 10:19:20 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 192.168.130.131:57830 in memory (size: 3.1 KB, free: 265.4 MB)
15/08/11 10:19:20 INFO BlockManagerMaster: Updated info of block broadcast_29_piece0
15/08/11 10:19:20 DEBUG BlockManager: Told master about block broadcast_29_piece0
15/08/11 10:19:20 INFO BlockManager: Removing block broadcast_29
15/08/11 10:19:20 INFO MemoryStore: Block broadcast_29 of size 4768 dropped from memory (free 278061700)
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: Done removing broadcast 29, response is 2
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: Sent response: 2 to Actor[akka://sparkDriver/temp/$Rh]
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] handled message (1.43475 ms) UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_29_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka://sparkDriver/temp/$Th]
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_29_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$bc]
15/08/11 10:19:20 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 192.168.130.131:47921 in memory (size: 3.1 KB, free: 245.7 MB)
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] handled message (0.65318 ms) UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_29_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$bc]
15/08/11 10:19:20 INFO ContextCleaner: Cleaned broadcast 29
15/08/11 10:19:20 DEBUG ContextCleaner: Got cleaning task CleanShuffle(13)
15/08/11 10:19:20 DEBUG ContextCleaner: Cleaning shuffle 13
15/08/11 10:19:20 INFO DAGScheduler: Stage 31 (collectAsMap at KMeansTest.scala:67) finished in 0.403 s
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] received message RemoveShuffle(13) from Actor[akka://sparkDriver/temp/$Uh]
15/08/11 10:19:20 DEBUG DAGScheduler: After removal of stage 31, remaining stages = 1
15/08/11 10:19:20 DEBUG DAGScheduler: After removal of stage 30, remaining stages = 0
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] handled message (0.560555 ms) RemoveShuffle(13) from Actor[akka://sparkDriver/temp/$Uh]
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: [actor] received message RemoveShuffle(13) from Actor[akka://sparkDriver/temp/$Vh]
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: [actor] handled message (0.037279 ms) RemoveShuffle(13) from Actor[akka://sparkDriver/temp/$Vh]
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: removing shuffle 13
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: Done removing shuffle 13, response is true
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: Sent response: true to Actor[akka://sparkDriver/temp/$Vh]
15/08/11 10:19:20 INFO DAGScheduler: Job 16 finished: collectAsMap at KMeansTest.scala:67, took 3.757192 s
Finished iteration (num = 14)
15/08/11 10:19:20 INFO ContextCleaner: Cleaned shuffle 13
15/08/11 10:19:20 DEBUG ContextCleaner: Got cleaning task CleanBroadcast(28)
15/08/11 10:19:20 DEBUG ContextCleaner: Cleaning broadcast 28
15/08/11 10:19:20 DEBUG TorrentBroadcast: Unpersisting TorrentBroadcast 28
15/08/11 10:19:20 INFO TaskSetManager: Finished task 1.0 in stage 31.0 (TID 94) in 365 ms on 192.168.130.131 (3/3)
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] received message RemoveBroadcast(28,true) from Actor[akka://sparkDriver/temp/$Xh]
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: [actor] received message RemoveBroadcast(28,true) from Actor[akka://sparkDriver/temp/$Yh]
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] handled message (0.536205 ms) RemoveBroadcast(28,true) from Actor[akka://sparkDriver/temp/$Xh]
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: [actor] handled message (0.036018 ms) RemoveBroadcast(28,true) from Actor[akka://sparkDriver/temp/$Yh]
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: removing broadcast 28
15/08/11 10:19:20 INFO BlockManager: Removing broadcast 28
15/08/11 10:19:20 INFO BlockManager: Removing block broadcast_28
15/08/11 10:19:20 INFO MemoryStore: Block broadcast_28 of size 2560 dropped from memory (free 278064260)
15/08/11 10:19:20 INFO BlockManager: Removing block broadcast_28_piece0
15/08/11 10:19:20 INFO MemoryStore: Block broadcast_28_piece0 of size 1521 dropped from memory (free 278065781)
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_28_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka://sparkDriver/temp/$0h]
15/08/11 10:19:20 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 192.168.130.131:57830 in memory (size: 1521.0 B, free: 265.4 MB)
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] handled message (0.487941 ms) UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_28_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka://sparkDriver/temp/$0h]
15/08/11 10:19:20 INFO BlockManagerMaster: Updated info of block broadcast_28_piece0
15/08/11 10:19:20 DEBUG BlockManager: Told master about block broadcast_28_piece0
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: Done removing broadcast 28, response is 2
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: Sent response: 2 to Actor[akka://sparkDriver/temp/$Yh]
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_28_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$cc]
15/08/11 10:19:20 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool 
15/08/11 10:19:20 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 192.168.130.131:47921 in memory (size: 1521.0 B, free: 245.7 MB)
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] handled message (0.43954 ms) UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_28_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$cc]
15/08/11 10:19:20 INFO ContextCleaner: Cleaned broadcast 28
15/08/11 10:19:20 DEBUG ContextCleaner: Got cleaning task CleanBroadcast(27)
15/08/11 10:19:20 DEBUG ContextCleaner: Cleaning broadcast 27
15/08/11 10:19:20 DEBUG TorrentBroadcast: Unpersisting TorrentBroadcast 27
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] received message RemoveBroadcast(27,true) from Actor[akka://sparkDriver/temp/$1h]
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] handled message (0.308333 ms) RemoveBroadcast(27,true) from Actor[akka://sparkDriver/temp/$1h]
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: [actor] received message RemoveBroadcast(27,true) from Actor[akka://sparkDriver/temp/$2h]
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: [actor] handled message (0.028823 ms) RemoveBroadcast(27,true) from Actor[akka://sparkDriver/temp/$2h]
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: removing broadcast 27
15/08/11 10:19:20 INFO BlockManager: Removing broadcast 27
15/08/11 10:19:20 INFO BlockManager: Removing block broadcast_27
15/08/11 10:19:20 INFO MemoryStore: Block broadcast_27 of size 4768 dropped from memory (free 278070549)
15/08/11 10:19:20 INFO BlockManager: Removing block broadcast_27_piece0
15/08/11 10:19:20 INFO MemoryStore: Block broadcast_27_piece0 of size 3203 dropped from memory (free 278073752)
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_27_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka://sparkDriver/temp/$4h]
15/08/11 10:19:20 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 192.168.130.131:57830 in memory (size: 3.1 KB, free: 265.4 MB)
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] handled message (0.4084 ms) UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_27_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka://sparkDriver/temp/$4h]
15/08/11 10:19:20 INFO BlockManagerMaster: Updated info of block broadcast_27_piece0
15/08/11 10:19:20 DEBUG BlockManager: Told master about block broadcast_27_piece0
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: Done removing broadcast 27, response is 2
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: Sent response: 2 to Actor[akka://sparkDriver/temp/$2h]
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_27_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$dc]
15/08/11 10:19:20 INFO SparkContext: Starting job: collectAsMap at KMeansTest.scala:67
15/08/11 10:19:20 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 192.168.130.131:47921 in memory (size: 3.1 KB, free: 245.7 MB)
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] handled message (0.378116 ms) UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_27_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$dc]
15/08/11 10:19:20 INFO DAGScheduler: Registering RDD 49 (map at KMeansTest.scala:61)
15/08/11 10:19:20 INFO DAGScheduler: Got job 17 (collectAsMap at KMeansTest.scala:67) with 3 output partitions (allowLocal=false)
15/08/11 10:19:20 INFO DAGScheduler: Final stage: Stage 33(collectAsMap at KMeansTest.scala:67)
15/08/11 10:19:20 INFO DAGScheduler: Parents of final stage: List(Stage 32)
15/08/11 10:19:20 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD MapPartitionsRDD[51] at map at KMeansTest.scala:65
15/08/11 10:19:20 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@2ded238e) from Actor[akka://sparkDriver/temp/$5h]
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] handled message (0.172321 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@2ded238e) from Actor[akka://sparkDriver/temp/$5h]
15/08/11 10:19:20 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@2ded238e) from Actor[akka://sparkDriver/temp/$6h]
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] handled message (0.198679 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@2ded238e) from Actor[akka://sparkDriver/temp/$6h]
15/08/11 10:19:20 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:19:20 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:19:20 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|51|0,rdd_51_0,, null|51|1,rdd_51_1,, null|51|2,rdd_51_2,).
15/08/11 10:19:20 INFO ContextCleaner: Cleaned broadcast 27
15/08/11 10:19:20 DEBUG ContextCleaner: Got cleaning task CleanShuffle(12)
15/08/11 10:19:20 DEBUG ContextCleaner: Cleaning shuffle 12
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] received message RemoveShuffle(12) from Actor[akka://sparkDriver/temp/$8h]
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: [actor] received message RemoveShuffle(12) from Actor[akka://sparkDriver/temp/$9h]
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: [actor] handled message (0.037813 ms) RemoveShuffle(12) from Actor[akka://sparkDriver/temp/$9h]
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: removing shuffle 12
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: Done removing shuffle 12, response is true
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: Sent response: true to Actor[akka://sparkDriver/temp/$9h]
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] handled message (1.2883 ms) RemoveShuffle(12) from Actor[akka://sparkDriver/temp/$8h]
15/08/11 10:19:20 INFO ContextCleaner: Cleaned shuffle 12
15/08/11 10:19:20 DEBUG ContextCleaner: Got cleaning task CleanBroadcast(26)
15/08/11 10:19:20 DEBUG ContextCleaner: Cleaning broadcast 26
15/08/11 10:19:20 DEBUG TorrentBroadcast: Unpersisting TorrentBroadcast 26
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] received message RemoveBroadcast(26,true) from Actor[akka://sparkDriver/temp/$+h]
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] handled message (0.380969 ms) RemoveBroadcast(26,true) from Actor[akka://sparkDriver/temp/$+h]
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: [actor] received message RemoveBroadcast(26,true) from Actor[akka://sparkDriver/temp/$ai]
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: [actor] handled message (0.028464 ms) RemoveBroadcast(26,true) from Actor[akka://sparkDriver/temp/$ai]
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: removing broadcast 26
15/08/11 10:19:20 INFO BlockManager: Removing broadcast 26
15/08/11 10:19:20 INFO BlockManager: Removing block broadcast_26
15/08/11 10:19:20 INFO MemoryStore: Block broadcast_26 of size 2560 dropped from memory (free 278076312)
15/08/11 10:19:20 INFO BlockManager: Removing block broadcast_26_piece0
15/08/11 10:19:20 INFO MemoryStore: Block broadcast_26_piece0 of size 1521 dropped from memory (free 278077833)
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_26_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka://sparkDriver/temp/$bi]
15/08/11 10:19:20 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 192.168.130.131:57830 in memory (size: 1521.0 B, free: 265.4 MB)
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] handled message (0.560325 ms) UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_26_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka://sparkDriver/temp/$bi]
15/08/11 10:19:20 INFO BlockManagerMaster: Updated info of block broadcast_26_piece0
15/08/11 10:19:20 DEBUG BlockManager: Told master about block broadcast_26_piece0
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: Done removing broadcast 26, response is 2
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: Sent response: 2 to Actor[akka://sparkDriver/temp/$ai]
15/08/11 10:19:20 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$di]
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] handled message (0.743027 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$di]
15/08/11 10:19:20 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:19:20 DEBUG BlockManager: Got multiple block location in  29 ms
15/08/11 10:19:20 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD ShuffledRDD[50] at reduceByKey at KMeansTest.scala:63
15/08/11 10:19:20 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@22425573) from Actor[akka://sparkDriver/temp/$ei]
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] handled message (0.177367 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@22425573) from Actor[akka://sparkDriver/temp/$ei]
15/08/11 10:19:20 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@22425573) from Actor[akka://sparkDriver/temp/$fi]
15/08/11 10:19:20 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] handled message (0.198033 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@22425573) from Actor[akka://sparkDriver/temp/$fi]
15/08/11 10:19:20 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:19:20 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|50|0,rdd_50_0,, null|50|1,rdd_50_1,, null|50|2,rdd_50_2,).
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_26_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$ec]
15/08/11 10:19:20 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 192.168.130.131:47921 in memory (size: 1521.0 B, free: 245.7 MB)
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] handled message (0.64359 ms) UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_26_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$ec]
15/08/11 10:19:20 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$hi]
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:19:20 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] handled message (1.037289 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$hi]
15/08/11 10:19:20 DEBUG BlockManager: Got multiple block location in  16 ms
15/08/11 10:19:20 INFO DAGScheduler: [SMSpark v1]Missing parents: List(Stage 32)
15/08/11 10:19:20 DEBUG DAGScheduler: submitStage(Stage 33)
15/08/11 10:19:20 DEBUG DAGScheduler: missing: List(Stage 32)
15/08/11 10:19:20 DEBUG DAGScheduler: submitStage(Stage 32)
15/08/11 10:19:20 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD MapPartitionsRDD[49] at map at KMeansTest.scala:61
15/08/11 10:19:20 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:19:20 INFO ContextCleaner: Cleaned broadcast 26
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@2b87a8d0) from Actor[akka://sparkDriver/temp/$ii]
15/08/11 10:19:20 DEBUG ContextCleaner: Got cleaning task CleanBroadcast(25)
15/08/11 10:19:20 DEBUG ContextCleaner: Cleaning broadcast 25
15/08/11 10:19:20 DEBUG TorrentBroadcast: Unpersisting TorrentBroadcast 25
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] handled message (0.150755 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@2b87a8d0) from Actor[akka://sparkDriver/temp/$ii]
15/08/11 10:19:20 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] received message RemoveBroadcast(25,true) from Actor[akka://sparkDriver/temp/$ji]
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: [actor] received message RemoveBroadcast(25,true) from Actor[akka://sparkDriver/temp/$ki]
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: removing broadcast 25
15/08/11 10:19:20 INFO BlockManager: Removing broadcast 25
15/08/11 10:19:20 INFO BlockManager: Removing block broadcast_25_piece0
15/08/11 10:19:20 INFO MemoryStore: Block broadcast_25_piece0 of size 3201 dropped from memory (free 278081034)
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: [actor] handled message (0.081233 ms) RemoveBroadcast(25,true) from Actor[akka://sparkDriver/temp/$ki]
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] handled message (1.489751 ms) RemoveBroadcast(25,true) from Actor[akka://sparkDriver/temp/$ji]
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@2b87a8d0) from Actor[akka://sparkDriver/temp/$mi]
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] handled message (0.195482 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@2b87a8d0) from Actor[akka://sparkDriver/temp/$mi]
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_25_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka://sparkDriver/temp/$ni]
15/08/11 10:19:20 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 192.168.130.131:57830 in memory (size: 3.1 KB, free: 265.4 MB)
15/08/11 10:19:20 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:19:20 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:19:20 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|49|0,rdd_49_0,, null|49|1,rdd_49_1,, null|49|2,rdd_49_2,).
15/08/11 10:19:20 INFO BlockManagerMaster: Updated info of block broadcast_25_piece0
15/08/11 10:19:20 DEBUG BlockManager: Told master about block broadcast_25_piece0
15/08/11 10:19:20 INFO BlockManager: Removing block broadcast_25
15/08/11 10:19:20 INFO MemoryStore: Block broadcast_25 of size 4768 dropped from memory (free 278085802)
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: Done removing broadcast 25, response is 2
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: Sent response: 2 to Actor[akka://sparkDriver/temp/$ki]
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] handled message (2.966861 ms) UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_25_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka://sparkDriver/temp/$ni]
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_25_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$fc]
15/08/11 10:19:20 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 192.168.130.131:47921 in memory (size: 3.1 KB, free: 245.7 MB)
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] handled message (0.513334 ms) UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_25_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$fc]
15/08/11 10:19:20 INFO ContextCleaner: Cleaned broadcast 25
15/08/11 10:19:20 DEBUG ContextCleaner: Got cleaning task CleanShuffle(11)
15/08/11 10:19:20 DEBUG ContextCleaner: Cleaning shuffle 11
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] received message RemoveShuffle(11) from Actor[akka://sparkDriver/temp/$pi]
15/08/11 10:19:20 INFO ContextCleaner: Cleaned shuffle 11
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] handled message (0.805108 ms) RemoveShuffle(11) from Actor[akka://sparkDriver/temp/$pi]
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: [actor] received message RemoveShuffle(11) from Actor[akka://sparkDriver/temp/$qi]
15/08/11 10:19:20 DEBUG ContextCleaner: Got cleaning task CleanBroadcast(24)
15/08/11 10:19:20 DEBUG ContextCleaner: Cleaning broadcast 24
15/08/11 10:19:20 DEBUG TorrentBroadcast: Unpersisting TorrentBroadcast 24
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] received message RemoveBroadcast(24,true) from Actor[akka://sparkDriver/temp/$ri]
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: removing shuffle 11
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] handled message (1.672342 ms) RemoveBroadcast(24,true) from Actor[akka://sparkDriver/temp/$ri]
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: Done removing shuffle 11, response is true
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: Sent response: true to Actor[akka://sparkDriver/temp/$qi]
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: [actor] handled message (1.291671 ms) RemoveShuffle(11) from Actor[akka://sparkDriver/temp/$qi]
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: [actor] received message RemoveBroadcast(24,true) from Actor[akka://sparkDriver/temp/$si]
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: removing broadcast 24
15/08/11 10:19:20 INFO BlockManager: Removing broadcast 24
15/08/11 10:19:20 INFO BlockManager: Removing block broadcast_24_piece0
15/08/11 10:19:20 INFO MemoryStore: Block broadcast_24_piece0 of size 1521 dropped from memory (free 278087323)
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: [actor] handled message (1.556677 ms) RemoveBroadcast(24,true) from Actor[akka://sparkDriver/temp/$si]
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_24_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka://sparkDriver/temp/$ti]
15/08/11 10:19:20 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:19:20 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 192.168.130.131:57830 in memory (size: 1521.0 B, free: 265.4 MB)
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] handled message (1.62524 ms) UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_24_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka://sparkDriver/temp/$ti]
15/08/11 10:19:20 INFO BlockManagerMaster: Updated info of block broadcast_24_piece0
15/08/11 10:19:20 DEBUG BlockManager: Told master about block broadcast_24_piece0
15/08/11 10:19:20 INFO BlockManager: Removing block broadcast_24
15/08/11 10:19:20 INFO MemoryStore: Block broadcast_24 of size 2560 dropped from memory (free 278089883)
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: Done removing broadcast 24, response is 2
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: Sent response: 2 to Actor[akka://sparkDriver/temp/$si]
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$ui]
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:19:20 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:19:20 DEBUG BlockManager: Got multiple block location in  29 ms
15/08/11 10:19:20 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD KMeans01 MapPartitionsRDD[2] at map at KMeansTest.scala:50
15/08/11 10:19:20 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] handled message (0.697047 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$ui]
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@70ab0b8c) from Actor[akka://sparkDriver/temp/$wi]
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] handled message (0.961002 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@70ab0b8c) from Actor[akka://sparkDriver/temp/$wi]
15/08/11 10:19:20 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(ArrayBuffer(BlockManagerId(0, 192.168.130.131, 47921)), ArrayBuffer(BlockManagerId(0, 192.168.130.131, 47921)), ArrayBuffer(BlockManagerId(0, 192.168.130.131, 47921)))
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@70ab0b8c) from Actor[akka://sparkDriver/temp/$yi]
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] handled message (0.453708 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@70ab0b8c) from Actor[akka://sparkDriver/temp/$yi]
15/08/11 10:19:20 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:19:20 DEBUG DAGScheduler: missing: List()
15/08/11 10:19:20 INFO DAGScheduler: Submitting Stage 32 (MapPartitionsRDD[49] at map at KMeansTest.scala:61), which has no missing parents
15/08/11 10:19:20 DEBUG DAGScheduler: submitMissingTasks(Stage 32)
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_24_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$gc]
15/08/11 10:19:20 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 192.168.130.131:47921 in memory (size: 1521.0 B, free: 245.7 MB)
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] handled message (0.550999 ms) UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_24_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$gc]
15/08/11 10:19:20 INFO MemoryStore: ensureFreeSpace(4768) called with curMem=212673, maxMem=278302556
15/08/11 10:19:20 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 4.7 KB, free 265.2 MB)
15/08/11 10:19:20 DEBUG BlockManager: Put block broadcast_33 locally took  2 ms
15/08/11 10:19:20 DEBUG BlockManager: Putting block broadcast_33 without replication took  13 ms
15/08/11 10:19:20 INFO ContextCleaner: Cleaned broadcast 24
15/08/11 10:19:20 DEBUG ContextCleaner: Got cleaning task CleanBroadcast(23)
15/08/11 10:19:20 DEBUG ContextCleaner: Cleaning broadcast 23
15/08/11 10:19:20 DEBUG TorrentBroadcast: Unpersisting TorrentBroadcast 23
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] received message RemoveBroadcast(23,true) from Actor[akka://sparkDriver/temp/$zi]
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: [actor] received message RemoveBroadcast(23,true) from Actor[akka://sparkDriver/temp/$Ai]
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: [actor] handled message (0.036725 ms) RemoveBroadcast(23,true) from Actor[akka://sparkDriver/temp/$Ai]
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: removing broadcast 23
15/08/11 10:19:20 INFO BlockManager: Removing broadcast 23
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] handled message (0.608006 ms) RemoveBroadcast(23,true) from Actor[akka://sparkDriver/temp/$zi]
15/08/11 10:19:20 INFO BlockManager: Removing block broadcast_23_piece0
15/08/11 10:19:20 INFO MemoryStore: Block broadcast_23_piece0 of size 3200 dropped from memory (free 278088315)
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_23_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka://sparkDriver/temp/$Bi]
15/08/11 10:19:20 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 192.168.130.131:57830 in memory (size: 3.1 KB, free: 265.4 MB)
15/08/11 10:19:20 INFO BlockManagerMaster: Updated info of block broadcast_23_piece0
15/08/11 10:19:20 DEBUG BlockManager: Told master about block broadcast_23_piece0
15/08/11 10:19:20 INFO BlockManager: Removing block broadcast_23
15/08/11 10:19:20 INFO MemoryStore: Block broadcast_23 of size 4768 dropped from memory (free 278093083)
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: Done removing broadcast 23, response is 2
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: Sent response: 2 to Actor[akka://sparkDriver/temp/$Ai]
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] handled message (0.719626 ms) UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_23_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka://sparkDriver/temp/$Bi]
15/08/11 10:19:20 INFO MemoryStore: ensureFreeSpace(3208) called with curMem=209473, maxMem=278302556
15/08/11 10:19:20 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 3.1 KB, free 265.2 MB)
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_33_piece0,StorageLevel(false, true, false, false, 1),3208,0,0) from Actor[akka://sparkDriver/temp/$Di]
15/08/11 10:19:20 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 192.168.130.131:57830 (size: 3.1 KB, free: 265.4 MB)
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] handled message (0.447715 ms) UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_33_piece0,StorageLevel(false, true, false, false, 1),3208,0,0) from Actor[akka://sparkDriver/temp/$Di]
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_23_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$hc]
15/08/11 10:19:20 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 192.168.130.131:47921 in memory (size: 3.1 KB, free: 245.7 MB)
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] handled message (0.635211 ms) UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_23_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$hc]
15/08/11 10:19:20 INFO BlockManagerMaster: Updated info of block broadcast_33_piece0
15/08/11 10:19:20 DEBUG BlockManager: Told master about block broadcast_33_piece0
15/08/11 10:19:20 DEBUG BlockManager: Put block broadcast_33_piece0 locally took  10 ms
15/08/11 10:19:20 DEBUG BlockManager: Putting block broadcast_33_piece0 without replication took  11 ms
15/08/11 10:19:20 INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:852
15/08/11 10:19:20 INFO DAGScheduler: Submitting 3 missing tasks from Stage 32 (MapPartitionsRDD[49] at map at KMeansTest.scala:61)
15/08/11 10:19:20 DEBUG DAGScheduler: New pending tasks: Set(ShuffleMapTask(32, 0), ShuffleMapTask(32, 1), ShuffleMapTask(32, 2))
15/08/11 10:19:20 INFO TaskSchedulerImpl: Adding task set 32.0 with 3 tasks
15/08/11 10:19:20 DEBUG TaskSetManager: Epoch for TaskSet 32.0: 15
15/08/11 10:19:20 DEBUG TaskSetManager: Valid locality levels for TaskSet 32.0: PROCESS_LOCAL, NODE_LOCAL, ANY
15/08/11 10:19:20 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/deadLetters]
15/08/11 10:19:20 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_32, runningTasks: 0
15/08/11 10:19:20 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 96, 192.168.130.131, PROCESS_LOCAL, 1361 bytes)
15/08/11 10:19:20 INFO TaskSetManager: Starting task 1.0 in stage 32.0 (TID 97, 192.168.130.131, PROCESS_LOCAL, 1361 bytes)
15/08/11 10:19:20 INFO ContextCleaner: Cleaned broadcast 23
15/08/11 10:19:20 DEBUG ContextCleaner: Got cleaning task CleanShuffle(10)
15/08/11 10:19:20 DEBUG ContextCleaner: Cleaning shuffle 10
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] received message RemoveShuffle(10) from Actor[akka://sparkDriver/temp/$Ei]
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: [actor] received message RemoveShuffle(10) from Actor[akka://sparkDriver/temp/$Fi]
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: [actor] handled message (0.040105 ms) RemoveShuffle(10) from Actor[akka://sparkDriver/temp/$Fi]
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: removing shuffle 10
15/08/11 10:19:20 INFO ContextCleaner: Cleaned shuffle 10
15/08/11 10:19:20 DEBUG ContextCleaner: Got cleaning task CleanBroadcast(22)
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: Done removing shuffle 10, response is true
15/08/11 10:19:20 DEBUG ContextCleaner: Cleaning broadcast 22
15/08/11 10:19:20 DEBUG TorrentBroadcast: Unpersisting TorrentBroadcast 22
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: Sent response: true to Actor[akka://sparkDriver/temp/$Fi]
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] handled message (0.522331 ms) RemoveShuffle(10) from Actor[akka://sparkDriver/temp/$Ei]
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] received message RemoveBroadcast(22,true) from Actor[akka://sparkDriver/temp/$Gi]
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: [actor] received message RemoveBroadcast(22,true) from Actor[akka://sparkDriver/temp/$Hi]
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] handled message (0.331095 ms) RemoveBroadcast(22,true) from Actor[akka://sparkDriver/temp/$Gi]
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: removing broadcast 22
15/08/11 10:19:20 INFO BlockManager: Removing broadcast 22
15/08/11 10:19:20 INFO BlockManager: Removing block broadcast_22_piece0
15/08/11 10:19:20 INFO MemoryStore: Block broadcast_22_piece0 of size 1517 dropped from memory (free 278091392)
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: [actor] handled message (0.144502 ms) RemoveBroadcast(22,true) from Actor[akka://sparkDriver/temp/$Hi]
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_22_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka://sparkDriver/temp/$Ji]
15/08/11 10:19:20 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 192.168.130.131:57830 in memory (size: 1517.0 B, free: 265.4 MB)
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] handled message (0.392442 ms) UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_22_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka://sparkDriver/temp/$Ji]
15/08/11 10:19:20 INFO BlockManagerMaster: Updated info of block broadcast_22_piece0
15/08/11 10:19:20 DEBUG BlockManager: Told master about block broadcast_22_piece0
15/08/11 10:19:20 INFO BlockManager: Removing block broadcast_22
15/08/11 10:19:20 INFO MemoryStore: Block broadcast_22 of size 2560 dropped from memory (free 278093952)
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: Done removing broadcast 22, response is 2
15/08/11 10:19:20 DEBUG DAGScheduler: submitStage(Stage 33)
15/08/11 10:19:20 DEBUG DAGScheduler: missing: List(Stage 32)
15/08/11 10:19:20 DEBUG DAGScheduler: submitStage(Stage 32)
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: Sent response: 2 to Actor[akka://sparkDriver/temp/$Hi]
15/08/11 10:19:20 INFO TaskSetManager: Starting task 2.0 in stage 32.0 (TID 98, 192.168.130.131, PROCESS_LOCAL, 1361 bytes)
15/08/11 10:19:20 DEBUG TaskSetManager: No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
15/08/11 10:19:20 DEBUG TaskSetManager: No tasks for locality level NODE_LOCAL, so moving to locality level ANY
15/08/11 10:19:20 DEBUG DAGScheduler: submitStage(Stage 33)
15/08/11 10:19:20 DEBUG DAGScheduler: missing: List(Stage 32)
15/08/11 10:19:20 DEBUG DAGScheduler: submitStage(Stage 32)
15/08/11 10:19:20 DEBUG DAGScheduler: submitStage(Stage 33)
15/08/11 10:19:20 DEBUG DAGScheduler: missing: List(Stage 32)
15/08/11 10:19:20 DEBUG DAGScheduler: submitStage(Stage 32)
15/08/11 10:19:20 DEBUG SparkDeploySchedulerBackend: [actor] handled message (20.377741 ms) ReviveOffers from Actor[akka://sparkDriver/deadLetters]
15/08/11 10:19:20 DEBUG DAGScheduler: submitStage(Stage 33)
15/08/11 10:19:20 DEBUG DAGScheduler: missing: List(Stage 32)
15/08/11 10:19:20 DEBUG DAGScheduler: submitStage(Stage 32)
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_22_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$ic]
15/08/11 10:19:20 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 192.168.130.131:47921 in memory (size: 1517.0 B, free: 245.7 MB)
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] handled message (0.549093 ms) UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_22_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$ic]
15/08/11 10:19:20 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,96,RUNNING,org.apache.spark.util.SerializableBuffer@24aec30d) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:20 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.069499 ms) StatusUpdate(0,96,RUNNING,org.apache.spark.util.SerializableBuffer@24aec30d) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] received message GetLocations(broadcast_33_piece0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$jc]
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] handled message (0.070849 ms) GetLocations(broadcast_33_piece0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$jc]
15/08/11 10:19:20 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,97,RUNNING,org.apache.spark.util.SerializableBuffer@6d32c7b2) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:20 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.130901 ms) StatusUpdate(0,97,RUNNING,org.apache.spark.util.SerializableBuffer@6d32c7b2) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:20 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,98,RUNNING,org.apache.spark.util.SerializableBuffer@20d4af20) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:20 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.077131 ms) StatusUpdate(0,98,RUNNING,org.apache.spark.util.SerializableBuffer@20d4af20) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:20 DEBUG BlockManager: Level for block broadcast_33_piece0 is StorageLevel(true, true, false, false, 1)
15/08/11 10:19:20 DEBUG BlockManager: Getting block broadcast_33_piece0 from memory
15/08/11 10:19:20 INFO ContextCleaner: Cleaned broadcast 22
15/08/11 10:19:20 DEBUG ContextCleaner: Got cleaning task CleanBroadcast(21)
15/08/11 10:19:20 DEBUG ContextCleaner: Cleaning broadcast 21
15/08/11 10:19:20 DEBUG TorrentBroadcast: Unpersisting TorrentBroadcast 21
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] received message RemoveBroadcast(21,true) from Actor[akka://sparkDriver/temp/$Li]
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] handled message (0.509929 ms) RemoveBroadcast(21,true) from Actor[akka://sparkDriver/temp/$Li]
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: [actor] received message RemoveBroadcast(21,true) from Actor[akka://sparkDriver/temp/$Mi]
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: [actor] handled message (0.046379 ms) RemoveBroadcast(21,true) from Actor[akka://sparkDriver/temp/$Mi]
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: removing broadcast 21
15/08/11 10:19:20 INFO BlockManager: Removing broadcast 21
15/08/11 10:19:20 INFO BlockManager: Removing block broadcast_21_piece0
15/08/11 10:19:20 INFO MemoryStore: Block broadcast_21_piece0 of size 3202 dropped from memory (free 278097154)
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_21_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka://sparkDriver/temp/$Ni]
15/08/11 10:19:20 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 192.168.130.131:57830 in memory (size: 3.1 KB, free: 265.4 MB)
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] handled message (0.491698 ms) UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_21_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka://sparkDriver/temp/$Ni]
15/08/11 10:19:20 INFO BlockManagerMaster: Updated info of block broadcast_21_piece0
15/08/11 10:19:20 DEBUG BlockManager: Told master about block broadcast_21_piece0
15/08/11 10:19:20 INFO BlockManager: Removing block broadcast_21
15/08/11 10:19:20 INFO MemoryStore: Block broadcast_21 of size 4768 dropped from memory (free 278101922)
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: Done removing broadcast 21, response is 2
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: Sent response: 2 to Actor[akka://sparkDriver/temp/$Mi]
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_21_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$kc]
15/08/11 10:19:20 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 192.168.130.131:47921 in memory (size: 3.1 KB, free: 245.7 MB)
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] handled message (0.467641 ms) UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_21_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$kc]
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_33_piece0,StorageLevel(false, true, false, false, 1),3208,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$lc]
15/08/11 10:19:20 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 192.168.130.131:47921 (size: 3.1 KB, free: 245.7 MB)
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] handled message (7.309701 ms) UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_33_piece0,StorageLevel(false, true, false, false, 1),3208,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$lc]
15/08/11 10:19:20 INFO ContextCleaner: Cleaned broadcast 21
15/08/11 10:19:20 DEBUG ContextCleaner: Got cleaning task CleanShuffle(9)
15/08/11 10:19:20 DEBUG ContextCleaner: Cleaning shuffle 9
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] received message RemoveShuffle(9) from Actor[akka://sparkDriver/temp/$Pi]
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: [actor] received message RemoveShuffle(9) from Actor[akka://sparkDriver/temp/$Qi]
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: [actor] handled message (0.113857 ms) RemoveShuffle(9) from Actor[akka://sparkDriver/temp/$Qi]
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: removing shuffle 9
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: Done removing shuffle 9, response is true
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: Sent response: true to Actor[akka://sparkDriver/temp/$Qi]
15/08/11 10:19:20 INFO ContextCleaner: Cleaned shuffle 9
15/08/11 10:19:20 DEBUG ContextCleaner: Got cleaning task CleanBroadcast(20)
15/08/11 10:19:20 DEBUG ContextCleaner: Cleaning broadcast 20
15/08/11 10:19:20 DEBUG TorrentBroadcast: Unpersisting TorrentBroadcast 20
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] handled message (4.040669 ms) RemoveShuffle(9) from Actor[akka://sparkDriver/temp/$Pi]
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] received message RemoveBroadcast(20,true) from Actor[akka://sparkDriver/temp/$Si]
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: [actor] received message RemoveBroadcast(20,true) from Actor[akka://sparkDriver/temp/$Ti]
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: [actor] handled message (0.035092 ms) RemoveBroadcast(20,true) from Actor[akka://sparkDriver/temp/$Ti]
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: removing broadcast 20
15/08/11 10:19:20 INFO BlockManager: Removing broadcast 20
15/08/11 10:19:20 INFO BlockManager: Removing block broadcast_20
15/08/11 10:19:20 INFO MemoryStore: Block broadcast_20 of size 2560 dropped from memory (free 278104482)
15/08/11 10:19:20 INFO BlockManager: Removing block broadcast_20_piece0
15/08/11 10:19:20 INFO MemoryStore: Block broadcast_20_piece0 of size 1519 dropped from memory (free 278106001)
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] handled message (9.286188 ms) RemoveBroadcast(20,true) from Actor[akka://sparkDriver/temp/$Si]
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_20_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka://sparkDriver/temp/$Vi]
15/08/11 10:19:20 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 192.168.130.131:57830 in memory (size: 1519.0 B, free: 265.4 MB)
15/08/11 10:19:20 INFO BlockManagerMaster: Updated info of block broadcast_20_piece0
15/08/11 10:19:20 DEBUG BlockManager: Told master about block broadcast_20_piece0
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: Done removing broadcast 20, response is 2
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: Sent response: 2 to Actor[akka://sparkDriver/temp/$Ti]
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] handled message (9.518483 ms) UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_20_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka://sparkDriver/temp/$Vi]
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_20_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$mc]
15/08/11 10:19:20 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 192.168.130.131:47921 in memory (size: 1519.0 B, free: 245.7 MB)
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] handled message (0.427295 ms) UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_20_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$mc]
15/08/11 10:19:20 INFO ContextCleaner: Cleaned broadcast 20
15/08/11 10:19:20 DEBUG ContextCleaner: Got cleaning task CleanBroadcast(19)
15/08/11 10:19:20 DEBUG ContextCleaner: Cleaning broadcast 19
15/08/11 10:19:20 DEBUG TorrentBroadcast: Unpersisting TorrentBroadcast 19
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] received message RemoveBroadcast(19,true) from Actor[akka://sparkDriver/temp/$Wi]
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: [actor] received message RemoveBroadcast(19,true) from Actor[akka://sparkDriver/temp/$Xi]
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: [actor] handled message (0.094501 ms) RemoveBroadcast(19,true) from Actor[akka://sparkDriver/temp/$Xi]
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: removing broadcast 19
15/08/11 10:19:20 INFO BlockManager: Removing broadcast 19
15/08/11 10:19:20 INFO BlockManager: Removing block broadcast_19
15/08/11 10:19:20 INFO MemoryStore: Block broadcast_19 of size 4768 dropped from memory (free 278110769)
15/08/11 10:19:20 INFO BlockManager: Removing block broadcast_19_piece0
15/08/11 10:19:20 INFO MemoryStore: Block broadcast_19_piece0 of size 3203 dropped from memory (free 278113972)
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] handled message (0.659719 ms) RemoveBroadcast(19,true) from Actor[akka://sparkDriver/temp/$Wi]
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_19_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka://sparkDriver/temp/$Zi]
15/08/11 10:19:20 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 192.168.130.131:57830 in memory (size: 3.1 KB, free: 265.4 MB)
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] handled message (0.515164 ms) UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_19_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka://sparkDriver/temp/$Zi]
15/08/11 10:19:20 INFO BlockManagerMaster: Updated info of block broadcast_19_piece0
15/08/11 10:19:20 DEBUG BlockManager: Told master about block broadcast_19_piece0
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: Done removing broadcast 19, response is 2
15/08/11 10:19:20 DEBUG BlockManagerSlaveActor: Sent response: 2 to Actor[akka://sparkDriver/temp/$Xi]
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_19_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$nc]
15/08/11 10:19:20 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 192.168.130.131:47921 in memory (size: 3.1 KB, free: 245.7 MB)
15/08/11 10:19:20 DEBUG BlockManagerMasterActor: [actor] handled message (0.706935 ms) UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_19_piece0,StorageLevel(false, false, false, false, 1),0,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$nc]
15/08/11 10:19:20 INFO ContextCleaner: Cleaned broadcast 19
15/08/11 10:19:20 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:19:20 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_32, runningTasks: 3
15/08/11 10:19:20 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.797858 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:19:21 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,98,FINISHED,org.apache.spark.util.SerializableBuffer@b17867b) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:21 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_32, runningTasks: 2
15/08/11 10:19:21 DEBUG SparkDeploySchedulerBackend: [actor] handled message (1.073854 ms) StatusUpdate(0,98,FINISHED,org.apache.spark.util.SerializableBuffer@b17867b) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:21 DEBUG DAGScheduler: ShuffleMapTask finished on 0
15/08/11 10:19:21 DEBUG DAGScheduler: submitStage(Stage 33)
15/08/11 10:19:21 DEBUG DAGScheduler: missing: List(Stage 32)
15/08/11 10:19:21 DEBUG DAGScheduler: submitStage(Stage 32)
15/08/11 10:19:21 INFO TaskSetManager: Finished task 2.0 in stage 32.0 (TID 98) in 806 ms on 192.168.130.131 (1/3)
15/08/11 10:19:21 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:19:21 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_32, runningTasks: 2
15/08/11 10:19:21 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.672198 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:19:22 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:19:22 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_32, runningTasks: 2
15/08/11 10:19:22 DEBUG SparkDeploySchedulerBackend: [actor] handled message (3.703754 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:19:23 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,96,FINISHED,org.apache.spark.util.SerializableBuffer@357dfaed) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:23 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_32, runningTasks: 1
15/08/11 10:19:23 DEBUG SparkDeploySchedulerBackend: [actor] handled message (7.217753 ms) StatusUpdate(0,96,FINISHED,org.apache.spark.util.SerializableBuffer@357dfaed) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:23 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 96) in 3082 ms on 192.168.130.131 (2/3)
15/08/11 10:19:23 DEBUG DAGScheduler: ShuffleMapTask finished on 0
15/08/11 10:19:23 DEBUG DAGScheduler: submitStage(Stage 33)
15/08/11 10:19:23 DEBUG DAGScheduler: missing: List(Stage 32)
15/08/11 10:19:23 DEBUG DAGScheduler: submitStage(Stage 32)
15/08/11 10:19:23 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:19:23 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_32, runningTasks: 1
15/08/11 10:19:23 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.78052 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:19:23 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,97,FINISHED,org.apache.spark.util.SerializableBuffer@61e4f90a) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:23 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_32, runningTasks: 0
15/08/11 10:19:23 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.882827 ms) StatusUpdate(0,97,FINISHED,org.apache.spark.util.SerializableBuffer@61e4f90a) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:23 INFO TaskSetManager: Finished task 1.0 in stage 32.0 (TID 97) in 3388 ms on 192.168.130.131 (3/3)
15/08/11 10:19:23 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool 
15/08/11 10:19:23 DEBUG DAGScheduler: ShuffleMapTask finished on 0
15/08/11 10:19:23 INFO DAGScheduler: Stage 32 (map at KMeansTest.scala:61) finished in 3.391 s
15/08/11 10:19:23 INFO DAGScheduler: looking for newly runnable stages
15/08/11 10:19:23 INFO DAGScheduler: running: Set()
15/08/11 10:19:23 INFO DAGScheduler: waiting: Set(Stage 33)
15/08/11 10:19:23 INFO DAGScheduler: failed: Set()
15/08/11 10:19:23 DEBUG MapOutputTrackerMaster: Increasing epoch to 16
15/08/11 10:19:23 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD MapPartitionsRDD[51] at map at KMeansTest.scala:65
15/08/11 10:19:23 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:19:23 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@7f9a31bb) from Actor[akka://sparkDriver/temp/$0i]
15/08/11 10:19:23 DEBUG BlockManagerMasterActor: [actor] handled message (1.325836 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@7f9a31bb) from Actor[akka://sparkDriver/temp/$0i]
15/08/11 10:19:23 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:19:23 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@7f9a31bb) from Actor[akka://sparkDriver/temp/$1i]
15/08/11 10:19:23 DEBUG BlockManagerMasterActor: [actor] handled message (0.347332 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@7f9a31bb) from Actor[akka://sparkDriver/temp/$1i]
15/08/11 10:19:23 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:19:23 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:19:23 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|51|0,rdd_51_0,, null|51|1,rdd_51_1,, null|51|2,rdd_51_2,).
15/08/11 10:19:23 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:19:23 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$3i]
15/08/11 10:19:23 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:19:23 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:23 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:23 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:23 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:23 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:23 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:23 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:23 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:23 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:23 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:19:23 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:19:23 DEBUG BlockManagerMasterActor: [actor] handled message (1.455131 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$3i]
15/08/11 10:19:23 DEBUG BlockManager: Got multiple block location in  23 ms
15/08/11 10:19:23 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD ShuffledRDD[50] at reduceByKey at KMeansTest.scala:63
15/08/11 10:19:23 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:19:23 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@10b5b241) from Actor[akka://sparkDriver/temp/$4i]
15/08/11 10:19:23 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:19:23 DEBUG BlockManagerMasterActor: [actor] handled message (0.312871 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@10b5b241) from Actor[akka://sparkDriver/temp/$4i]
15/08/11 10:19:23 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@10b5b241) from Actor[akka://sparkDriver/temp/$5i]
15/08/11 10:19:23 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:19:23 DEBUG BlockManagerMasterActor: [actor] handled message (0.245171 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@10b5b241) from Actor[akka://sparkDriver/temp/$5i]
15/08/11 10:19:23 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:19:23 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|50|0,rdd_50_0,, null|50|1,rdd_50_1,, null|50|2,rdd_50_2,).
15/08/11 10:19:23 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:19:23 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$7i]
15/08/11 10:19:23 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:19:23 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:23 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:23 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:23 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:23 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:23 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:23 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:23 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:23 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:23 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:19:23 DEBUG BlockManagerMasterActor: [actor] handled message (2.248816 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$7i]
15/08/11 10:19:23 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:19:23 DEBUG BlockManager: Got multiple block location in  28 ms
15/08/11 10:19:23 INFO DAGScheduler: Missing parents for Stage 33: List()
15/08/11 10:19:23 INFO DAGScheduler: Submitting Stage 33 (MapPartitionsRDD[51] at map at KMeansTest.scala:65), which is now runnable
15/08/11 10:19:23 DEBUG DAGScheduler: submitMissingTasks(Stage 33)
15/08/11 10:19:23 INFO MemoryStore: ensureFreeSpace(2560) called with curMem=188584, maxMem=278302556
15/08/11 10:19:23 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 2.5 KB, free 265.2 MB)
15/08/11 10:19:23 DEBUG BlockManager: Put block broadcast_34 locally took  2 ms
15/08/11 10:19:23 DEBUG BlockManager: Putting block broadcast_34 without replication took  2 ms
15/08/11 10:19:23 INFO MemoryStore: ensureFreeSpace(1517) called with curMem=191144, maxMem=278302556
15/08/11 10:19:23 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 1517.0 B, free 265.2 MB)
15/08/11 10:19:23 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_34_piece0,StorageLevel(false, true, false, false, 1),1517,0,0) from Actor[akka://sparkDriver/temp/$8i]
15/08/11 10:19:23 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 192.168.130.131:57830 (size: 1517.0 B, free: 265.4 MB)
15/08/11 10:19:23 DEBUG BlockManagerMasterActor: [actor] handled message (3.377734 ms) UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_34_piece0,StorageLevel(false, true, false, false, 1),1517,0,0) from Actor[akka://sparkDriver/temp/$8i]
15/08/11 10:19:23 INFO BlockManagerMaster: Updated info of block broadcast_34_piece0
15/08/11 10:19:23 DEBUG BlockManager: Told master about block broadcast_34_piece0
15/08/11 10:19:23 DEBUG BlockManager: Put block broadcast_34_piece0 locally took  14 ms
15/08/11 10:19:23 DEBUG BlockManager: Putting block broadcast_34_piece0 without replication took  15 ms
15/08/11 10:19:23 INFO SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:852
15/08/11 10:19:23 INFO DAGScheduler: Submitting 3 missing tasks from Stage 33 (MapPartitionsRDD[51] at map at KMeansTest.scala:65)
15/08/11 10:19:23 DEBUG DAGScheduler: New pending tasks: Set(ResultTask(33, 2), ResultTask(33, 1), ResultTask(33, 0))
15/08/11 10:19:23 INFO TaskSchedulerImpl: Adding task set 33.0 with 3 tasks
15/08/11 10:19:23 DEBUG TaskSetManager: Epoch for TaskSet 33.0: 16
15/08/11 10:19:23 DEBUG TaskSetManager: Valid locality levels for TaskSet 33.0: NO_PREF, ANY
15/08/11 10:19:23 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/deadLetters]
15/08/11 10:19:23 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_33, runningTasks: 0
15/08/11 10:19:23 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 99, 192.168.130.131, PROCESS_LOCAL, 1116 bytes)
15/08/11 10:19:23 INFO TaskSetManager: Starting task 1.0 in stage 33.0 (TID 100, 192.168.130.131, PROCESS_LOCAL, 1116 bytes)
15/08/11 10:19:23 INFO TaskSetManager: Starting task 2.0 in stage 33.0 (TID 101, 192.168.130.131, PROCESS_LOCAL, 1116 bytes)
15/08/11 10:19:23 DEBUG TaskSetManager: No tasks for locality level NO_PREF, so moving to locality level ANY
15/08/11 10:19:23 DEBUG SparkDeploySchedulerBackend: [actor] handled message (28.208465 ms) ReviveOffers from Actor[akka://sparkDriver/deadLetters]
15/08/11 10:19:23 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,99,RUNNING,org.apache.spark.util.SerializableBuffer@38611032) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:24 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.712717 ms) StatusUpdate(0,99,RUNNING,org.apache.spark.util.SerializableBuffer@38611032) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:24 DEBUG BlockManagerMasterActor: [actor] received message GetLocations(broadcast_34_piece0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$oc]
15/08/11 10:19:24 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,100,RUNNING,org.apache.spark.util.SerializableBuffer@6c6e5f88) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:24 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.09821 ms) StatusUpdate(0,100,RUNNING,org.apache.spark.util.SerializableBuffer@6c6e5f88) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:24 DEBUG BlockManagerMasterActor: [actor] handled message (2.44 ms) GetLocations(broadcast_34_piece0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$oc]
15/08/11 10:19:24 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,101,RUNNING,org.apache.spark.util.SerializableBuffer@2de4ba27) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:24 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.139319 ms) StatusUpdate(0,101,RUNNING,org.apache.spark.util.SerializableBuffer@2de4ba27) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:24 DEBUG BlockManager: Level for block broadcast_34_piece0 is StorageLevel(true, true, false, false, 1)
15/08/11 10:19:24 DEBUG BlockManager: Getting block broadcast_34_piece0 from memory
15/08/11 10:19:24 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_34_piece0,StorageLevel(false, true, false, false, 1),1517,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$pc]
15/08/11 10:19:24 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 192.168.130.131:47921 (size: 1517.0 B, free: 245.7 MB)
15/08/11 10:19:24 DEBUG BlockManagerMasterActor: [actor] handled message (0.836151 ms) UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_34_piece0,StorageLevel(false, true, false, false, 1),1517,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$pc]
15/08/11 10:19:24 DEBUG MapOutputTrackerMasterActor: [actor] received message GetMapOutputStatuses(15) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$qc]
15/08/11 10:19:24 INFO MapOutputTrackerMasterActor: Asked to send map output locations for shuffle 15 to sparkExecutor@192.168.130.131:49489
15/08/11 10:19:24 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 15 is 162 bytes
15/08/11 10:19:24 DEBUG MapOutputTrackerMasterActor: [actor] handled message (1.062138 ms) GetMapOutputStatuses(15) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$qc]
15/08/11 10:19:24 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,101,FINISHED,org.apache.spark.util.SerializableBuffer@272a69c8) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:24 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_33, runningTasks: 2
15/08/11 10:19:24 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.898978 ms) StatusUpdate(0,101,FINISHED,org.apache.spark.util.SerializableBuffer@272a69c8) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:24 INFO TaskSetManager: Finished task 2.0 in stage 33.0 (TID 101) in 162 ms on 192.168.130.131 (1/3)
15/08/11 10:19:24 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,99,FINISHED,org.apache.spark.util.SerializableBuffer@6d960d64) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:24 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_33, runningTasks: 1
15/08/11 10:19:24 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.697826 ms) StatusUpdate(0,99,FINISHED,org.apache.spark.util.SerializableBuffer@6d960d64) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:24 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,100,FINISHED,org.apache.spark.util.SerializableBuffer@16495871) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:24 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 99) in 206 ms on 192.168.130.131 (2/3)
15/08/11 10:19:24 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_33, runningTasks: 0
15/08/11 10:19:24 DEBUG SparkDeploySchedulerBackend: [actor] handled message (16.791946 ms) StatusUpdate(0,100,FINISHED,org.apache.spark.util.SerializableBuffer@16495871) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:24 INFO DAGScheduler: Stage 33 (collectAsMap at KMeansTest.scala:67) finished in 0.249 s
15/08/11 10:19:24 DEBUG DAGScheduler: After removal of stage 32, remaining stages = 1
15/08/11 10:19:24 DEBUG DAGScheduler: After removal of stage 33, remaining stages = 0
15/08/11 10:19:24 INFO DAGScheduler: Job 17 finished: collectAsMap at KMeansTest.scala:67, took 3.880067 s
Finished iteration (num = 15)
15/08/11 10:19:24 INFO TaskSetManager: Finished task 1.0 in stage 33.0 (TID 100) in 215 ms on 192.168.130.131 (3/3)
15/08/11 10:19:24 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool 
15/08/11 10:19:24 INFO SparkContext: Starting job: collectAsMap at KMeansTest.scala:67
15/08/11 10:19:24 INFO DAGScheduler: Registering RDD 52 (map at KMeansTest.scala:61)
15/08/11 10:19:24 INFO DAGScheduler: Got job 18 (collectAsMap at KMeansTest.scala:67) with 3 output partitions (allowLocal=false)
15/08/11 10:19:24 INFO DAGScheduler: Final stage: Stage 35(collectAsMap at KMeansTest.scala:67)
15/08/11 10:19:24 INFO DAGScheduler: Parents of final stage: List(Stage 34)
15/08/11 10:19:24 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD MapPartitionsRDD[54] at map at KMeansTest.scala:65
15/08/11 10:19:24 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:19:24 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@e4bab7a) from Actor[akka://sparkDriver/temp/$9i]
15/08/11 10:19:24 DEBUG BlockManagerMasterActor: [actor] handled message (0.203631 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@e4bab7a) from Actor[akka://sparkDriver/temp/$9i]
15/08/11 10:19:24 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:19:24 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@e4bab7a) from Actor[akka://sparkDriver/temp/$+i]
15/08/11 10:19:24 DEBUG BlockManagerMasterActor: [actor] handled message (1.904927 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@e4bab7a) from Actor[akka://sparkDriver/temp/$+i]
15/08/11 10:19:24 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:19:24 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:19:24 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|54|0,rdd_54_0,, null|54|1,rdd_54_1,, null|54|2,rdd_54_2,).
15/08/11 10:19:24 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:19:24 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$aj]
15/08/11 10:19:24 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:19:24 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:24 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:24 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:24 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:24 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:24 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:24 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:24 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:24 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:24 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:19:24 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:19:24 DEBUG BlockManagerMasterActor: [actor] handled message (20.779327 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$aj]
15/08/11 10:19:24 DEBUG BlockManager: Got multiple block location in  78 ms
15/08/11 10:19:24 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD ShuffledRDD[53] at reduceByKey at KMeansTest.scala:63
15/08/11 10:19:24 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:19:24 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@5d56bf8) from Actor[akka://sparkDriver/temp/$bj]
15/08/11 10:19:24 DEBUG BlockManagerMasterActor: [actor] handled message (0.279895 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@5d56bf8) from Actor[akka://sparkDriver/temp/$bj]
15/08/11 10:19:24 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:19:24 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@5d56bf8) from Actor[akka://sparkDriver/temp/$cj]
15/08/11 10:19:24 DEBUG BlockManagerMasterActor: [actor] handled message (0.296298 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@5d56bf8) from Actor[akka://sparkDriver/temp/$cj]
15/08/11 10:19:24 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:19:24 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:19:24 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|53|0,rdd_53_0,, null|53|1,rdd_53_1,, null|53|2,rdd_53_2,).
15/08/11 10:19:24 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:19:24 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$ej]
15/08/11 10:19:24 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:19:24 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:24 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:24 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:24 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:24 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:24 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:24 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:24 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:24 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:24 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:19:24 DEBUG BlockManagerMasterActor: [actor] handled message (0.909232 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$ej]
15/08/11 10:19:24 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:19:24 DEBUG BlockManager: Got multiple block location in  34 ms
15/08/11 10:19:24 INFO DAGScheduler: [SMSpark v1]Missing parents: List(Stage 34)
15/08/11 10:19:24 DEBUG DAGScheduler: submitStage(Stage 35)
15/08/11 10:19:24 DEBUG DAGScheduler: missing: List(Stage 34)
15/08/11 10:19:24 DEBUG DAGScheduler: submitStage(Stage 34)
15/08/11 10:19:24 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD MapPartitionsRDD[52] at map at KMeansTest.scala:61
15/08/11 10:19:24 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:19:24 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@203f76f2) from Actor[akka://sparkDriver/temp/$fj]
15/08/11 10:19:24 DEBUG BlockManagerMasterActor: [actor] handled message (1.317617 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@203f76f2) from Actor[akka://sparkDriver/temp/$fj]
15/08/11 10:19:24 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:19:24 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@203f76f2) from Actor[akka://sparkDriver/temp/$gj]
15/08/11 10:19:24 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:19:24 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:19:24 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|52|0,rdd_52_0,, null|52|1,rdd_52_1,, null|52|2,rdd_52_2,).
15/08/11 10:19:24 DEBUG BlockManagerMasterActor: [actor] handled message (3.732399 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@203f76f2) from Actor[akka://sparkDriver/temp/$gj]
15/08/11 10:19:24 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:19:24 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$ij]
15/08/11 10:19:24 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:19:24 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:24 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:24 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:24 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:24 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:24 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:24 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:24 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:24 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:24 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:19:24 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:19:24 DEBUG BlockManagerMasterActor: [actor] handled message (1.057988 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$ij]
15/08/11 10:19:24 DEBUG BlockManager: Got multiple block location in  24 ms
15/08/11 10:19:24 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD KMeans01 MapPartitionsRDD[2] at map at KMeansTest.scala:50
15/08/11 10:19:24 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:19:24 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@26eb3c5d) from Actor[akka://sparkDriver/temp/$jj]
15/08/11 10:19:24 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(ArrayBuffer(BlockManagerId(0, 192.168.130.131, 47921)), ArrayBuffer(BlockManagerId(0, 192.168.130.131, 47921)), ArrayBuffer(BlockManagerId(0, 192.168.130.131, 47921)))
15/08/11 10:19:24 DEBUG BlockManagerMasterActor: [actor] handled message (0.221049 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@26eb3c5d) from Actor[akka://sparkDriver/temp/$jj]
15/08/11 10:19:24 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@26eb3c5d) from Actor[akka://sparkDriver/temp/$kj]
15/08/11 10:19:24 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:19:24 DEBUG BlockManagerMasterActor: [actor] handled message (0.223009 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@26eb3c5d) from Actor[akka://sparkDriver/temp/$kj]
15/08/11 10:19:24 DEBUG DAGScheduler: missing: List()
15/08/11 10:19:24 INFO DAGScheduler: Submitting Stage 34 (MapPartitionsRDD[52] at map at KMeansTest.scala:61), which has no missing parents
15/08/11 10:19:24 DEBUG DAGScheduler: submitMissingTasks(Stage 34)
15/08/11 10:19:24 INFO MemoryStore: ensureFreeSpace(4768) called with curMem=192661, maxMem=278302556
15/08/11 10:19:24 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 4.7 KB, free 265.2 MB)
15/08/11 10:19:24 DEBUG BlockManager: Put block broadcast_35 locally took  1 ms
15/08/11 10:19:24 DEBUG BlockManager: Putting block broadcast_35 without replication took  1 ms
15/08/11 10:19:24 INFO MemoryStore: ensureFreeSpace(3206) called with curMem=197429, maxMem=278302556
15/08/11 10:19:24 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 3.1 KB, free 265.2 MB)
15/08/11 10:19:24 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_35_piece0,StorageLevel(false, true, false, false, 1),3206,0,0) from Actor[akka://sparkDriver/temp/$lj]
15/08/11 10:19:24 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 192.168.130.131:57830 (size: 3.1 KB, free: 265.4 MB)
15/08/11 10:19:24 DEBUG BlockManagerMasterActor: [actor] handled message (0.424258 ms) UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_35_piece0,StorageLevel(false, true, false, false, 1),3206,0,0) from Actor[akka://sparkDriver/temp/$lj]
15/08/11 10:19:24 INFO BlockManagerMaster: Updated info of block broadcast_35_piece0
15/08/11 10:19:24 DEBUG BlockManager: Told master about block broadcast_35_piece0
15/08/11 10:19:24 DEBUG BlockManager: Put block broadcast_35_piece0 locally took  2 ms
15/08/11 10:19:24 DEBUG BlockManager: Putting block broadcast_35_piece0 without replication took  2 ms
15/08/11 10:19:24 INFO SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:852
15/08/11 10:19:24 INFO DAGScheduler: Submitting 3 missing tasks from Stage 34 (MapPartitionsRDD[52] at map at KMeansTest.scala:61)
15/08/11 10:19:24 DEBUG DAGScheduler: New pending tasks: Set(ShuffleMapTask(34, 0), ShuffleMapTask(34, 2), ShuffleMapTask(34, 1))
15/08/11 10:19:24 INFO TaskSchedulerImpl: Adding task set 34.0 with 3 tasks
15/08/11 10:19:24 DEBUG TaskSetManager: Epoch for TaskSet 34.0: 16
15/08/11 10:19:24 DEBUG TaskSetManager: Valid locality levels for TaskSet 34.0: PROCESS_LOCAL, NODE_LOCAL, ANY
15/08/11 10:19:24 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/deadLetters]
15/08/11 10:19:24 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_34, runningTasks: 0
15/08/11 10:19:24 INFO TaskSetManager: Starting task 0.0 in stage 34.0 (TID 102, 192.168.130.131, PROCESS_LOCAL, 1361 bytes)
15/08/11 10:19:24 INFO TaskSetManager: Starting task 1.0 in stage 34.0 (TID 103, 192.168.130.131, PROCESS_LOCAL, 1361 bytes)
15/08/11 10:19:24 INFO TaskSetManager: Starting task 2.0 in stage 34.0 (TID 104, 192.168.130.131, PROCESS_LOCAL, 1361 bytes)
15/08/11 10:19:24 DEBUG TaskSetManager: No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
15/08/11 10:19:24 DEBUG TaskSetManager: No tasks for locality level NODE_LOCAL, so moving to locality level ANY
15/08/11 10:19:24 DEBUG DAGScheduler: submitStage(Stage 35)
15/08/11 10:19:24 DEBUG DAGScheduler: missing: List(Stage 34)
15/08/11 10:19:24 DEBUG DAGScheduler: submitStage(Stage 34)
15/08/11 10:19:24 DEBUG BlockManagerMasterActor: [actor] received message GetLocations(broadcast_35_piece0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$rc]
15/08/11 10:19:24 DEBUG BlockManagerMasterActor: [actor] handled message (0.130507 ms) GetLocations(broadcast_35_piece0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$rc]
15/08/11 10:19:24 DEBUG DAGScheduler: submitStage(Stage 35)
15/08/11 10:19:24 DEBUG SparkDeploySchedulerBackend: [actor] handled message (24.751049 ms) ReviveOffers from Actor[akka://sparkDriver/deadLetters]
15/08/11 10:19:24 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,102,RUNNING,org.apache.spark.util.SerializableBuffer@7d3b1eca) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:24 DEBUG DAGScheduler: missing: List(Stage 34)
15/08/11 10:19:24 DEBUG DAGScheduler: submitStage(Stage 34)
15/08/11 10:19:24 DEBUG BlockManager: Level for block broadcast_35_piece0 is StorageLevel(true, true, false, false, 1)
15/08/11 10:19:24 DEBUG BlockManager: Getting block broadcast_35_piece0 from memory
15/08/11 10:19:24 DEBUG SparkDeploySchedulerBackend: [actor] handled message (5.531537 ms) StatusUpdate(0,102,RUNNING,org.apache.spark.util.SerializableBuffer@7d3b1eca) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:24 DEBUG DAGScheduler: submitStage(Stage 35)
15/08/11 10:19:24 DEBUG DAGScheduler: missing: List(Stage 34)
15/08/11 10:19:24 DEBUG DAGScheduler: submitStage(Stage 34)
15/08/11 10:19:24 DEBUG DAGScheduler: submitStage(Stage 35)
15/08/11 10:19:24 DEBUG DAGScheduler: missing: List(Stage 34)
15/08/11 10:19:24 DEBUG DAGScheduler: submitStage(Stage 34)
15/08/11 10:19:24 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_35_piece0,StorageLevel(false, true, false, false, 1),3206,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$sc]
15/08/11 10:19:24 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 192.168.130.131:47921 (size: 3.1 KB, free: 245.7 MB)
15/08/11 10:19:24 DEBUG BlockManagerMasterActor: [actor] handled message (1.697749 ms) UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_35_piece0,StorageLevel(false, true, false, false, 1),3206,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$sc]
15/08/11 10:19:24 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,103,RUNNING,org.apache.spark.util.SerializableBuffer@50cc3bf1) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:24 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.172988 ms) StatusUpdate(0,103,RUNNING,org.apache.spark.util.SerializableBuffer@50cc3bf1) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:24 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,104,RUNNING,org.apache.spark.util.SerializableBuffer@107374a8) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:24 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.101721 ms) StatusUpdate(0,104,RUNNING,org.apache.spark.util.SerializableBuffer@107374a8) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:24 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:19:24 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_34, runningTasks: 3
15/08/11 10:19:24 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.58771 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:19:25 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,104,FINISHED,org.apache.spark.util.SerializableBuffer@befca08) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:25 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_34, runningTasks: 2
15/08/11 10:19:25 DEBUG SparkDeploySchedulerBackend: [actor] handled message (1.003612 ms) StatusUpdate(0,104,FINISHED,org.apache.spark.util.SerializableBuffer@befca08) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:25 DEBUG DAGScheduler: ShuffleMapTask finished on 0
15/08/11 10:19:25 DEBUG DAGScheduler: submitStage(Stage 35)
15/08/11 10:19:25 DEBUG DAGScheduler: missing: List(Stage 34)
15/08/11 10:19:25 DEBUG DAGScheduler: submitStage(Stage 34)
15/08/11 10:19:25 INFO TaskSetManager: Finished task 2.0 in stage 34.0 (TID 104) in 1217 ms on 192.168.130.131 (1/3)
15/08/11 10:19:25 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:19:25 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_34, runningTasks: 2
15/08/11 10:19:25 DEBUG SparkDeploySchedulerBackend: [actor] handled message (2.34352 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:19:26 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:19:26 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_34, runningTasks: 2
15/08/11 10:19:26 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.610037 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:19:27 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,103,FINISHED,org.apache.spark.util.SerializableBuffer@2bb8d957) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:27 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_34, runningTasks: 1
15/08/11 10:19:27 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.623165 ms) StatusUpdate(0,103,FINISHED,org.apache.spark.util.SerializableBuffer@2bb8d957) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:27 DEBUG DAGScheduler: ShuffleMapTask finished on 0
15/08/11 10:19:27 DEBUG DAGScheduler: submitStage(Stage 35)
15/08/11 10:19:27 DEBUG DAGScheduler: missing: List(Stage 34)
15/08/11 10:19:27 DEBUG DAGScheduler: submitStage(Stage 34)
15/08/11 10:19:27 INFO TaskSetManager: Finished task 1.0 in stage 34.0 (TID 103) in 2980 ms on 192.168.130.131 (2/3)
15/08/11 10:19:27 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,102,FINISHED,org.apache.spark.util.SerializableBuffer@74c4f52d) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:27 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_34, runningTasks: 0
15/08/11 10:19:27 DEBUG SparkDeploySchedulerBackend: [actor] handled message (1.216079 ms) StatusUpdate(0,102,FINISHED,org.apache.spark.util.SerializableBuffer@74c4f52d) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:27 DEBUG DAGScheduler: ShuffleMapTask finished on 0
15/08/11 10:19:27 INFO DAGScheduler: Stage 34 (map at KMeansTest.scala:61) finished in 3.021 s
15/08/11 10:19:27 INFO DAGScheduler: looking for newly runnable stages
15/08/11 10:19:27 INFO DAGScheduler: running: Set()
15/08/11 10:19:27 INFO DAGScheduler: waiting: Set(Stage 35)
15/08/11 10:19:27 INFO DAGScheduler: failed: Set()
15/08/11 10:19:27 DEBUG MapOutputTrackerMaster: Increasing epoch to 17
15/08/11 10:19:27 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD MapPartitionsRDD[54] at map at KMeansTest.scala:65
15/08/11 10:19:27 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@2ebc993f) from Actor[akka://sparkDriver/temp/$mj]
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: [actor] handled message (0.137406 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@2ebc993f) from Actor[akka://sparkDriver/temp/$mj]
15/08/11 10:19:27 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@2ebc993f) from Actor[akka://sparkDriver/temp/$nj]
15/08/11 10:19:27 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:19:27 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:19:27 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|54|0,rdd_54_0,, null|54|1,rdd_54_1,, null|54|2,rdd_54_2,).
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: [actor] handled message (1.762898 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@2ebc993f) from Actor[akka://sparkDriver/temp/$nj]
15/08/11 10:19:27 INFO TaskSetManager: Finished task 0.0 in stage 34.0 (TID 102) in 3023 ms on 192.168.130.131 (3/3)
15/08/11 10:19:27 INFO TaskSchedulerImpl: Removed TaskSet 34.0, whose tasks have all completed, from pool 
15/08/11 10:19:27 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$pj]
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:19:27 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:19:27 DEBUG BlockManager: Got multiple block location in  10 ms
15/08/11 10:19:27 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD ShuffledRDD[53] at reduceByKey at KMeansTest.scala:63
15/08/11 10:19:27 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: [actor] handled message (2.585318 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$pj]
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@495441ab) from Actor[akka://sparkDriver/temp/$qj]
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: [actor] handled message (0.178193 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@495441ab) from Actor[akka://sparkDriver/temp/$qj]
15/08/11 10:19:27 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@495441ab) from Actor[akka://sparkDriver/temp/$rj]
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: [actor] handled message (0.119468 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@495441ab) from Actor[akka://sparkDriver/temp/$rj]
15/08/11 10:19:27 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:19:27 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:19:27 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|53|0,rdd_53_0,, null|53|1,rdd_53_1,, null|53|2,rdd_53_2,).
15/08/11 10:19:27 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$tj]
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:19:27 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: [actor] handled message (1.114481 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$tj]
15/08/11 10:19:27 DEBUG BlockManager: Got multiple block location in  10 ms
15/08/11 10:19:27 INFO DAGScheduler: Missing parents for Stage 35: List()
15/08/11 10:19:27 INFO DAGScheduler: Submitting Stage 35 (MapPartitionsRDD[54] at map at KMeansTest.scala:65), which is now runnable
15/08/11 10:19:27 DEBUG DAGScheduler: submitMissingTasks(Stage 35)
15/08/11 10:19:27 INFO MemoryStore: ensureFreeSpace(2560) called with curMem=200635, maxMem=278302556
15/08/11 10:19:27 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 2.5 KB, free 265.2 MB)
15/08/11 10:19:27 DEBUG BlockManager: Put block broadcast_36 locally took  1 ms
15/08/11 10:19:27 DEBUG BlockManager: Putting block broadcast_36 without replication took  2 ms
15/08/11 10:19:27 INFO MemoryStore: ensureFreeSpace(1519) called with curMem=203195, maxMem=278302556
15/08/11 10:19:27 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 1519.0 B, free 265.2 MB)
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_36_piece0,StorageLevel(false, true, false, false, 1),1519,0,0) from Actor[akka://sparkDriver/temp/$uj]
15/08/11 10:19:27 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 192.168.130.131:57830 (size: 1519.0 B, free: 265.4 MB)
15/08/11 10:19:27 INFO BlockManagerMaster: Updated info of block broadcast_36_piece0
15/08/11 10:19:27 DEBUG BlockManager: Told master about block broadcast_36_piece0
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: [actor] handled message (0.3866 ms) UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_36_piece0,StorageLevel(false, true, false, false, 1),1519,0,0) from Actor[akka://sparkDriver/temp/$uj]
15/08/11 10:19:27 DEBUG BlockManager: Put block broadcast_36_piece0 locally took  1 ms
15/08/11 10:19:27 DEBUG BlockManager: Putting block broadcast_36_piece0 without replication took  2 ms
15/08/11 10:19:27 INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:852
15/08/11 10:19:27 INFO DAGScheduler: Submitting 3 missing tasks from Stage 35 (MapPartitionsRDD[54] at map at KMeansTest.scala:65)
15/08/11 10:19:27 DEBUG DAGScheduler: New pending tasks: Set(ResultTask(35, 2), ResultTask(35, 1), ResultTask(35, 0))
15/08/11 10:19:27 INFO TaskSchedulerImpl: Adding task set 35.0 with 3 tasks
15/08/11 10:19:27 DEBUG TaskSetManager: Epoch for TaskSet 35.0: 17
15/08/11 10:19:27 DEBUG TaskSetManager: Valid locality levels for TaskSet 35.0: NO_PREF, ANY
15/08/11 10:19:27 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/deadLetters]
15/08/11 10:19:27 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_35, runningTasks: 0
15/08/11 10:19:27 INFO TaskSetManager: Starting task 0.0 in stage 35.0 (TID 105, 192.168.130.131, PROCESS_LOCAL, 1116 bytes)
15/08/11 10:19:27 INFO TaskSetManager: Starting task 1.0 in stage 35.0 (TID 106, 192.168.130.131, PROCESS_LOCAL, 1116 bytes)
15/08/11 10:19:27 INFO TaskSetManager: Starting task 2.0 in stage 35.0 (TID 107, 192.168.130.131, PROCESS_LOCAL, 1116 bytes)
15/08/11 10:19:27 DEBUG TaskSetManager: No tasks for locality level NO_PREF, so moving to locality level ANY
15/08/11 10:19:27 DEBUG SparkDeploySchedulerBackend: [actor] handled message (4.27712 ms) ReviveOffers from Actor[akka://sparkDriver/deadLetters]
15/08/11 10:19:27 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,106,RUNNING,org.apache.spark.util.SerializableBuffer@85c3715) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:27 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.058664 ms) StatusUpdate(0,106,RUNNING,org.apache.spark.util.SerializableBuffer@85c3715) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:27 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,105,RUNNING,org.apache.spark.util.SerializableBuffer@5e2447fc) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:27 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.043839 ms) StatusUpdate(0,105,RUNNING,org.apache.spark.util.SerializableBuffer@5e2447fc) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:27 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,107,RUNNING,org.apache.spark.util.SerializableBuffer@1ff221ad) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:27 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.031037 ms) StatusUpdate(0,107,RUNNING,org.apache.spark.util.SerializableBuffer@1ff221ad) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: [actor] received message GetLocations(broadcast_36_piece0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$tc]
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: [actor] handled message (0.056048 ms) GetLocations(broadcast_36_piece0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$tc]
15/08/11 10:19:27 DEBUG BlockManager: Level for block broadcast_36_piece0 is StorageLevel(true, true, false, false, 1)
15/08/11 10:19:27 DEBUG BlockManager: Getting block broadcast_36_piece0 from memory
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_36_piece0,StorageLevel(false, true, false, false, 1),1519,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$uc]
15/08/11 10:19:27 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 192.168.130.131:47921 (size: 1519.0 B, free: 245.7 MB)
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: [actor] handled message (0.412985 ms) UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_36_piece0,StorageLevel(false, true, false, false, 1),1519,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$uc]
15/08/11 10:19:27 DEBUG MapOutputTrackerMasterActor: [actor] received message GetMapOutputStatuses(16) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$vc]
15/08/11 10:19:27 INFO MapOutputTrackerMasterActor: Asked to send map output locations for shuffle 16 to sparkExecutor@192.168.130.131:49489
15/08/11 10:19:27 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 16 is 162 bytes
15/08/11 10:19:27 DEBUG MapOutputTrackerMasterActor: [actor] handled message (0.586712 ms) GetMapOutputStatuses(16) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$vc]
15/08/11 10:19:27 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,107,FINISHED,org.apache.spark.util.SerializableBuffer@7b77f35e) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:27 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_35, runningTasks: 2
15/08/11 10:19:27 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.687073 ms) StatusUpdate(0,107,FINISHED,org.apache.spark.util.SerializableBuffer@7b77f35e) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:27 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,105,FINISHED,org.apache.spark.util.SerializableBuffer@adfa6) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:27 INFO TaskSetManager: Finished task 2.0 in stage 35.0 (TID 107) in 63 ms on 192.168.130.131 (1/3)
15/08/11 10:19:27 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_35, runningTasks: 1
15/08/11 10:19:27 DEBUG SparkDeploySchedulerBackend: [actor] handled message (5.428634 ms) StatusUpdate(0,105,FINISHED,org.apache.spark.util.SerializableBuffer@adfa6) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:27 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,106,FINISHED,org.apache.spark.util.SerializableBuffer@772d530c) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:27 INFO TaskSetManager: Finished task 0.0 in stage 35.0 (TID 105) in 78 ms on 192.168.130.131 (2/3)
15/08/11 10:19:27 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_35, runningTasks: 0
15/08/11 10:19:27 DEBUG SparkDeploySchedulerBackend: [actor] handled message (8.4558 ms) StatusUpdate(0,106,FINISHED,org.apache.spark.util.SerializableBuffer@772d530c) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:27 INFO TaskSetManager: Finished task 1.0 in stage 35.0 (TID 106) in 87 ms on 192.168.130.131 (3/3)
15/08/11 10:19:27 INFO DAGScheduler: Stage 35 (collectAsMap at KMeansTest.scala:67) finished in 0.092 s
15/08/11 10:19:27 INFO TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool 
15/08/11 10:19:27 DEBUG DAGScheduler: After removal of stage 35, remaining stages = 1
15/08/11 10:19:27 DEBUG DAGScheduler: After removal of stage 34, remaining stages = 0
15/08/11 10:19:27 INFO DAGScheduler: Job 18 finished: collectAsMap at KMeansTest.scala:67, took 3.338251 s
Finished iteration (num = 16)
15/08/11 10:19:27 INFO SparkContext: Starting job: collectAsMap at KMeansTest.scala:67
15/08/11 10:19:27 INFO DAGScheduler: Registering RDD 55 (map at KMeansTest.scala:61)
15/08/11 10:19:27 INFO DAGScheduler: Got job 19 (collectAsMap at KMeansTest.scala:67) with 3 output partitions (allowLocal=false)
15/08/11 10:19:27 INFO DAGScheduler: Final stage: Stage 37(collectAsMap at KMeansTest.scala:67)
15/08/11 10:19:27 INFO DAGScheduler: Parents of final stage: List(Stage 36)
15/08/11 10:19:27 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD MapPartitionsRDD[57] at map at KMeansTest.scala:65
15/08/11 10:19:27 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@72b17119) from Actor[akka://sparkDriver/temp/$vj]
15/08/11 10:19:27 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: [actor] handled message (0.200721 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@72b17119) from Actor[akka://sparkDriver/temp/$vj]
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@72b17119) from Actor[akka://sparkDriver/temp/$wj]
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: [actor] handled message (0.15024 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@72b17119) from Actor[akka://sparkDriver/temp/$wj]
15/08/11 10:19:27 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:19:27 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:19:27 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|57|0,rdd_57_0,, null|57|1,rdd_57_1,, null|57|2,rdd_57_2,).
15/08/11 10:19:27 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$yj]
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: [actor] handled message (0.908077 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$yj]
15/08/11 10:19:27 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:19:27 DEBUG BlockManager: Got multiple block location in  14 ms
15/08/11 10:19:27 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD ShuffledRDD[56] at reduceByKey at KMeansTest.scala:63
15/08/11 10:19:27 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@211b3993) from Actor[akka://sparkDriver/temp/$zj]
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: [actor] handled message (0.173356 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@211b3993) from Actor[akka://sparkDriver/temp/$zj]
15/08/11 10:19:27 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@211b3993) from Actor[akka://sparkDriver/temp/$Aj]
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: [actor] handled message (0.151045 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@211b3993) from Actor[akka://sparkDriver/temp/$Aj]
15/08/11 10:19:27 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:19:27 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:19:27 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|56|0,rdd_56_0,, null|56|1,rdd_56_1,, null|56|2,rdd_56_2,).
15/08/11 10:19:27 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$Cj]
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: [actor] handled message (0.70574 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$Cj]
15/08/11 10:19:27 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:19:27 DEBUG BlockManager: Got multiple block location in  10 ms
15/08/11 10:19:27 INFO DAGScheduler: [SMSpark v1]Missing parents: List(Stage 36)
15/08/11 10:19:27 DEBUG DAGScheduler: submitStage(Stage 37)
15/08/11 10:19:27 DEBUG DAGScheduler: missing: List(Stage 36)
15/08/11 10:19:27 DEBUG DAGScheduler: submitStage(Stage 36)
15/08/11 10:19:27 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD MapPartitionsRDD[55] at map at KMeansTest.scala:61
15/08/11 10:19:27 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@68d970a5) from Actor[akka://sparkDriver/temp/$Dj]
15/08/11 10:19:27 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: [actor] handled message (0.224088 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@68d970a5) from Actor[akka://sparkDriver/temp/$Dj]
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@68d970a5) from Actor[akka://sparkDriver/temp/$Ej]
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: [actor] handled message (0.157698 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@68d970a5) from Actor[akka://sparkDriver/temp/$Ej]
15/08/11 10:19:27 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:19:27 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:19:27 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|55|0,rdd_55_0,, null|55|1,rdd_55_1,, null|55|2,rdd_55_2,).
15/08/11 10:19:27 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$Gj]
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: [actor] handled message (0.53853 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$Gj]
15/08/11 10:19:27 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:19:27 DEBUG BlockManager: Got multiple block location in  7 ms
15/08/11 10:19:27 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD KMeans01 MapPartitionsRDD[2] at map at KMeansTest.scala:50
15/08/11 10:19:27 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@16faf4ef) from Actor[akka://sparkDriver/temp/$Hj]
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: [actor] handled message (0.172488 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@16faf4ef) from Actor[akka://sparkDriver/temp/$Hj]
15/08/11 10:19:27 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(ArrayBuffer(BlockManagerId(0, 192.168.130.131, 47921)), ArrayBuffer(BlockManagerId(0, 192.168.130.131, 47921)), ArrayBuffer(BlockManagerId(0, 192.168.130.131, 47921)))
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@16faf4ef) from Actor[akka://sparkDriver/temp/$Ij]
15/08/11 10:19:27 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: [actor] handled message (0.165933 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@16faf4ef) from Actor[akka://sparkDriver/temp/$Ij]
15/08/11 10:19:27 DEBUG DAGScheduler: missing: List()
15/08/11 10:19:27 INFO DAGScheduler: Submitting Stage 36 (MapPartitionsRDD[55] at map at KMeansTest.scala:61), which has no missing parents
15/08/11 10:19:27 DEBUG DAGScheduler: submitMissingTasks(Stage 36)
15/08/11 10:19:27 INFO MemoryStore: ensureFreeSpace(4768) called with curMem=204714, maxMem=278302556
15/08/11 10:19:27 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 4.7 KB, free 265.2 MB)
15/08/11 10:19:27 DEBUG BlockManager: Put block broadcast_37 locally took  4 ms
15/08/11 10:19:27 DEBUG BlockManager: Putting block broadcast_37 without replication took  4 ms
15/08/11 10:19:27 INFO MemoryStore: ensureFreeSpace(3200) called with curMem=209482, maxMem=278302556
15/08/11 10:19:27 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 3.1 KB, free 265.2 MB)
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_37_piece0,StorageLevel(false, true, false, false, 1),3200,0,0) from Actor[akka://sparkDriver/temp/$Jj]
15/08/11 10:19:27 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 192.168.130.131:57830 (size: 3.1 KB, free: 265.4 MB)
15/08/11 10:19:27 INFO BlockManagerMaster: Updated info of block broadcast_37_piece0
15/08/11 10:19:27 DEBUG BlockManager: Told master about block broadcast_37_piece0
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: [actor] handled message (0.484506 ms) UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_37_piece0,StorageLevel(false, true, false, false, 1),3200,0,0) from Actor[akka://sparkDriver/temp/$Jj]
15/08/11 10:19:27 DEBUG BlockManager: Put block broadcast_37_piece0 locally took  2 ms
15/08/11 10:19:27 DEBUG BlockManager: Putting block broadcast_37_piece0 without replication took  2 ms
15/08/11 10:19:27 INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:852
15/08/11 10:19:27 INFO DAGScheduler: Submitting 3 missing tasks from Stage 36 (MapPartitionsRDD[55] at map at KMeansTest.scala:61)
15/08/11 10:19:27 DEBUG DAGScheduler: New pending tasks: Set(ShuffleMapTask(36, 0), ShuffleMapTask(36, 1), ShuffleMapTask(36, 2))
15/08/11 10:19:27 INFO TaskSchedulerImpl: Adding task set 36.0 with 3 tasks
15/08/11 10:19:27 DEBUG TaskSetManager: Epoch for TaskSet 36.0: 17
15/08/11 10:19:27 DEBUG TaskSetManager: Valid locality levels for TaskSet 36.0: PROCESS_LOCAL, NODE_LOCAL, ANY
15/08/11 10:19:27 DEBUG DAGScheduler: submitStage(Stage 37)
15/08/11 10:19:27 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/deadLetters]
15/08/11 10:19:27 DEBUG DAGScheduler: missing: List(Stage 36)
15/08/11 10:19:27 DEBUG DAGScheduler: submitStage(Stage 36)
15/08/11 10:19:27 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_36, runningTasks: 0
15/08/11 10:19:27 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 108, 192.168.130.131, PROCESS_LOCAL, 1361 bytes)
15/08/11 10:19:27 DEBUG DAGScheduler: submitStage(Stage 37)
15/08/11 10:19:27 INFO TaskSetManager: Starting task 1.0 in stage 36.0 (TID 109, 192.168.130.131, PROCESS_LOCAL, 1361 bytes)
15/08/11 10:19:27 DEBUG DAGScheduler: missing: List(Stage 36)
15/08/11 10:19:27 DEBUG DAGScheduler: submitStage(Stage 36)
15/08/11 10:19:27 DEBUG DAGScheduler: submitStage(Stage 37)
15/08/11 10:19:27 INFO TaskSetManager: Starting task 2.0 in stage 36.0 (TID 110, 192.168.130.131, PROCESS_LOCAL, 1361 bytes)
15/08/11 10:19:27 DEBUG DAGScheduler: missing: List(Stage 36)
15/08/11 10:19:27 DEBUG TaskSetManager: No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
15/08/11 10:19:27 DEBUG DAGScheduler: submitStage(Stage 36)
15/08/11 10:19:27 DEBUG TaskSetManager: No tasks for locality level NODE_LOCAL, so moving to locality level ANY
15/08/11 10:19:27 DEBUG DAGScheduler: submitStage(Stage 37)
15/08/11 10:19:27 DEBUG DAGScheduler: missing: List(Stage 36)
15/08/11 10:19:27 DEBUG DAGScheduler: submitStage(Stage 36)
15/08/11 10:19:27 DEBUG SparkDeploySchedulerBackend: [actor] handled message (6.132384 ms) ReviveOffers from Actor[akka://sparkDriver/deadLetters]
15/08/11 10:19:27 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,108,RUNNING,org.apache.spark.util.SerializableBuffer@645f746a) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:27 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.045233 ms) StatusUpdate(0,108,RUNNING,org.apache.spark.util.SerializableBuffer@645f746a) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: [actor] received message GetLocations(broadcast_37_piece0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$wc]
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: [actor] handled message (2.806341 ms) GetLocations(broadcast_37_piece0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$wc]
15/08/11 10:19:27 DEBUG BlockManager: Level for block broadcast_37_piece0 is StorageLevel(true, true, false, false, 1)
15/08/11 10:19:27 DEBUG BlockManager: Getting block broadcast_37_piece0 from memory
15/08/11 10:19:27 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,109,RUNNING,org.apache.spark.util.SerializableBuffer@5a74961d) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:27 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.057997 ms) StatusUpdate(0,109,RUNNING,org.apache.spark.util.SerializableBuffer@5a74961d) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:27 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,110,RUNNING,org.apache.spark.util.SerializableBuffer@1c2b7850) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:27 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.036531 ms) StatusUpdate(0,110,RUNNING,org.apache.spark.util.SerializableBuffer@1c2b7850) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_37_piece0,StorageLevel(false, true, false, false, 1),3200,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$xc]
15/08/11 10:19:27 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 192.168.130.131:47921 (size: 3.1 KB, free: 245.7 MB)
15/08/11 10:19:27 DEBUG BlockManagerMasterActor: [actor] handled message (0.304036 ms) UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_37_piece0,StorageLevel(false, true, false, false, 1),3200,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$xc]
15/08/11 10:19:27 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:19:27 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_36, runningTasks: 3
15/08/11 10:19:27 DEBUG SparkDeploySchedulerBackend: [actor] handled message (1.249108 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:19:28 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,110,FINISHED,org.apache.spark.util.SerializableBuffer@69e7daa2) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:28 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_36, runningTasks: 2
15/08/11 10:19:28 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.469862 ms) StatusUpdate(0,110,FINISHED,org.apache.spark.util.SerializableBuffer@69e7daa2) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:28 DEBUG DAGScheduler: ShuffleMapTask finished on 0
15/08/11 10:19:28 DEBUG DAGScheduler: submitStage(Stage 37)
15/08/11 10:19:28 DEBUG DAGScheduler: missing: List(Stage 36)
15/08/11 10:19:28 DEBUG DAGScheduler: submitStage(Stage 36)
15/08/11 10:19:28 INFO TaskSetManager: Finished task 2.0 in stage 36.0 (TID 110) in 626 ms on 192.168.130.131 (1/3)
15/08/11 10:19:28 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:19:28 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_36, runningTasks: 2
15/08/11 10:19:28 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.644064 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:19:29 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,109,FINISHED,org.apache.spark.util.SerializableBuffer@2c27c23c) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:29 DEBUG DAGScheduler: ShuffleMapTask finished on 0
15/08/11 10:19:29 DEBUG DAGScheduler: submitStage(Stage 37)
15/08/11 10:19:29 DEBUG DAGScheduler: missing: List(Stage 36)
15/08/11 10:19:29 DEBUG DAGScheduler: submitStage(Stage 36)
15/08/11 10:19:29 INFO TaskSetManager: Finished task 1.0 in stage 36.0 (TID 109) in 2024 ms on 192.168.130.131 (2/3)
15/08/11 10:19:29 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_36, runningTasks: 1
15/08/11 10:19:29 DEBUG SparkDeploySchedulerBackend: [actor] handled message (6.94321 ms) StatusUpdate(0,109,FINISHED,org.apache.spark.util.SerializableBuffer@2c27c23c) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:29 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:19:29 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_36, runningTasks: 1
15/08/11 10:19:29 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.574085 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:19:29 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,108,FINISHED,org.apache.spark.util.SerializableBuffer@664107c9) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:29 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_36, runningTasks: 0
15/08/11 10:19:29 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.605628 ms) StatusUpdate(0,108,FINISHED,org.apache.spark.util.SerializableBuffer@664107c9) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:29 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 108) in 2169 ms on 192.168.130.131 (3/3)
15/08/11 10:19:29 DEBUG DAGScheduler: ShuffleMapTask finished on 0
15/08/11 10:19:29 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool 
15/08/11 10:19:29 INFO DAGScheduler: Stage 36 (map at KMeansTest.scala:61) finished in 2.173 s
15/08/11 10:19:29 INFO DAGScheduler: looking for newly runnable stages
15/08/11 10:19:29 INFO DAGScheduler: running: Set()
15/08/11 10:19:29 INFO DAGScheduler: waiting: Set(Stage 37)
15/08/11 10:19:29 INFO DAGScheduler: failed: Set()
15/08/11 10:19:29 DEBUG MapOutputTrackerMaster: Increasing epoch to 18
15/08/11 10:19:29 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD MapPartitionsRDD[57] at map at KMeansTest.scala:65
15/08/11 10:19:29 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:19:29 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@37665191) from Actor[akka://sparkDriver/temp/$Kj]
15/08/11 10:19:29 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:19:29 DEBUG BlockManagerMasterActor: [actor] handled message (0.215006 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@37665191) from Actor[akka://sparkDriver/temp/$Kj]
15/08/11 10:19:29 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@37665191) from Actor[akka://sparkDriver/temp/$Lj]
15/08/11 10:19:29 DEBUG BlockManagerMasterActor: [actor] handled message (0.211624 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@37665191) from Actor[akka://sparkDriver/temp/$Lj]
15/08/11 10:19:29 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:19:29 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:19:29 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|57|0,rdd_57_0,, null|57|1,rdd_57_1,, null|57|2,rdd_57_2,).
15/08/11 10:19:29 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:19:29 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$Nj]
15/08/11 10:19:29 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:19:29 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:29 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:29 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:29 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:29 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:29 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:29 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:29 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:29 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:29 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:19:29 DEBUG BlockManagerMasterActor: [actor] handled message (0.848174 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$Nj]
15/08/11 10:19:29 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:19:29 DEBUG BlockManager: Got multiple block location in  12 ms
15/08/11 10:19:29 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD ShuffledRDD[56] at reduceByKey at KMeansTest.scala:63
15/08/11 10:19:29 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:19:29 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@6119986f) from Actor[akka://sparkDriver/temp/$Oj]
15/08/11 10:19:29 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:19:29 DEBUG BlockManagerMasterActor: [actor] handled message (0.260356 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@6119986f) from Actor[akka://sparkDriver/temp/$Oj]
15/08/11 10:19:29 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@6119986f) from Actor[akka://sparkDriver/temp/$Pj]
15/08/11 10:19:29 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:19:29 DEBUG BlockManagerMasterActor: [actor] handled message (0.229185 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@6119986f) from Actor[akka://sparkDriver/temp/$Pj]
15/08/11 10:19:29 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:19:29 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|56|0,rdd_56_0,, null|56|1,rdd_56_1,, null|56|2,rdd_56_2,).
15/08/11 10:19:29 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:19:29 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$Rj]
15/08/11 10:19:29 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:19:29 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:29 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:29 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:29 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:29 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:29 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:29 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:29 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:29 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:29 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:19:29 DEBUG BlockManagerMasterActor: [actor] handled message (0.888979 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$Rj]
15/08/11 10:19:29 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:19:29 DEBUG BlockManager: Got multiple block location in  12 ms
15/08/11 10:19:29 INFO DAGScheduler: Missing parents for Stage 37: List()
15/08/11 10:19:29 INFO DAGScheduler: Submitting Stage 37 (MapPartitionsRDD[57] at map at KMeansTest.scala:65), which is now runnable
15/08/11 10:19:29 DEBUG DAGScheduler: submitMissingTasks(Stage 37)
15/08/11 10:19:29 INFO MemoryStore: ensureFreeSpace(2560) called with curMem=212682, maxMem=278302556
15/08/11 10:19:29 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 2.5 KB, free 265.2 MB)
15/08/11 10:19:29 DEBUG BlockManager: Put block broadcast_38 locally took  0 ms
15/08/11 10:19:29 DEBUG BlockManager: Putting block broadcast_38 without replication took  0 ms
15/08/11 10:19:29 INFO MemoryStore: ensureFreeSpace(1521) called with curMem=215242, maxMem=278302556
15/08/11 10:19:29 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 1521.0 B, free 265.2 MB)
15/08/11 10:19:29 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_38_piece0,StorageLevel(false, true, false, false, 1),1521,0,0) from Actor[akka://sparkDriver/temp/$Sj]
15/08/11 10:19:29 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 192.168.130.131:57830 (size: 1521.0 B, free: 265.4 MB)
15/08/11 10:19:29 INFO BlockManagerMaster: Updated info of block broadcast_38_piece0
15/08/11 10:19:29 DEBUG BlockManagerMasterActor: [actor] handled message (0.319051 ms) UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_38_piece0,StorageLevel(false, true, false, false, 1),1521,0,0) from Actor[akka://sparkDriver/temp/$Sj]
15/08/11 10:19:29 DEBUG BlockManager: Told master about block broadcast_38_piece0
15/08/11 10:19:29 DEBUG BlockManager: Put block broadcast_38_piece0 locally took  2 ms
15/08/11 10:19:29 DEBUG BlockManager: Putting block broadcast_38_piece0 without replication took  2 ms
15/08/11 10:19:29 INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:852
15/08/11 10:19:29 INFO DAGScheduler: Submitting 3 missing tasks from Stage 37 (MapPartitionsRDD[57] at map at KMeansTest.scala:65)
15/08/11 10:19:29 DEBUG DAGScheduler: New pending tasks: Set(ResultTask(37, 0), ResultTask(37, 2), ResultTask(37, 1))
15/08/11 10:19:29 INFO TaskSchedulerImpl: Adding task set 37.0 with 3 tasks
15/08/11 10:19:29 DEBUG TaskSetManager: Epoch for TaskSet 37.0: 18
15/08/11 10:19:29 DEBUG TaskSetManager: Valid locality levels for TaskSet 37.0: NO_PREF, ANY
15/08/11 10:19:29 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/deadLetters]
15/08/11 10:19:29 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_37, runningTasks: 0
15/08/11 10:19:29 INFO TaskSetManager: Starting task 0.0 in stage 37.0 (TID 111, 192.168.130.131, PROCESS_LOCAL, 1116 bytes)
15/08/11 10:19:29 INFO TaskSetManager: Starting task 1.0 in stage 37.0 (TID 112, 192.168.130.131, PROCESS_LOCAL, 1116 bytes)
15/08/11 10:19:29 INFO TaskSetManager: Starting task 2.0 in stage 37.0 (TID 113, 192.168.130.131, PROCESS_LOCAL, 1116 bytes)
15/08/11 10:19:29 DEBUG TaskSetManager: No tasks for locality level NO_PREF, so moving to locality level ANY
15/08/11 10:19:29 DEBUG SparkDeploySchedulerBackend: [actor] handled message (3.456124 ms) ReviveOffers from Actor[akka://sparkDriver/deadLetters]
15/08/11 10:19:29 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,111,RUNNING,org.apache.spark.util.SerializableBuffer@4bca74a4) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:29 DEBUG BlockManagerMasterActor: [actor] received message GetLocations(broadcast_38_piece0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$yc]
15/08/11 10:19:29 DEBUG BlockManagerMasterActor: [actor] handled message (0.087526 ms) GetLocations(broadcast_38_piece0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$yc]
15/08/11 10:19:29 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.175109 ms) StatusUpdate(0,111,RUNNING,org.apache.spark.util.SerializableBuffer@4bca74a4) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:29 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,112,RUNNING,org.apache.spark.util.SerializableBuffer@5f7ba84a) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:29 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.06105 ms) StatusUpdate(0,112,RUNNING,org.apache.spark.util.SerializableBuffer@5f7ba84a) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:29 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,113,RUNNING,org.apache.spark.util.SerializableBuffer@2f65c33f) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:29 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.057349 ms) StatusUpdate(0,113,RUNNING,org.apache.spark.util.SerializableBuffer@2f65c33f) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:29 DEBUG BlockManager: Level for block broadcast_38_piece0 is StorageLevel(true, true, false, false, 1)
15/08/11 10:19:29 DEBUG BlockManager: Getting block broadcast_38_piece0 from memory
15/08/11 10:19:29 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_38_piece0,StorageLevel(false, true, false, false, 1),1521,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$zc]
15/08/11 10:19:29 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 192.168.130.131:47921 (size: 1521.0 B, free: 245.7 MB)
15/08/11 10:19:29 DEBUG BlockManagerMasterActor: [actor] handled message (1.134499 ms) UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_38_piece0,StorageLevel(false, true, false, false, 1),1521,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$zc]
15/08/11 10:19:29 DEBUG MapOutputTrackerMasterActor: [actor] received message GetMapOutputStatuses(17) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$Ac]
15/08/11 10:19:29 INFO MapOutputTrackerMasterActor: Asked to send map output locations for shuffle 17 to sparkExecutor@192.168.130.131:49489
15/08/11 10:19:29 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 17 is 162 bytes
15/08/11 10:19:29 DEBUG MapOutputTrackerMasterActor: [actor] handled message (1.412786 ms) GetMapOutputStatuses(17) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$Ac]
15/08/11 10:19:29 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,113,FINISHED,org.apache.spark.util.SerializableBuffer@3c9f832d) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:29 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_37, runningTasks: 2
15/08/11 10:19:29 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.634446 ms) StatusUpdate(0,113,FINISHED,org.apache.spark.util.SerializableBuffer@3c9f832d) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:29 INFO TaskSetManager: Finished task 2.0 in stage 37.0 (TID 113) in 84 ms on 192.168.130.131 (1/3)
15/08/11 10:19:29 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,111,FINISHED,org.apache.spark.util.SerializableBuffer@62520d71) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:29 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_37, runningTasks: 1
15/08/11 10:19:29 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.795464 ms) StatusUpdate(0,111,FINISHED,org.apache.spark.util.SerializableBuffer@62520d71) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:29 INFO TaskSetManager: Finished task 0.0 in stage 37.0 (TID 111) in 93 ms on 192.168.130.131 (2/3)
15/08/11 10:19:29 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,112,FINISHED,org.apache.spark.util.SerializableBuffer@3ea6f0f2) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:29 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_37, runningTasks: 0
15/08/11 10:19:29 DEBUG SparkDeploySchedulerBackend: [actor] handled message (1.048316 ms) StatusUpdate(0,112,FINISHED,org.apache.spark.util.SerializableBuffer@3ea6f0f2) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:29 INFO TaskSetManager: Finished task 1.0 in stage 37.0 (TID 112) in 109 ms on 192.168.130.131 (3/3)
15/08/11 10:19:29 INFO DAGScheduler: Stage 37 (collectAsMap at KMeansTest.scala:67) finished in 0.114 s
15/08/11 10:19:29 INFO TaskSchedulerImpl: Removed TaskSet 37.0, whose tasks have all completed, from pool 
15/08/11 10:19:29 DEBUG DAGScheduler: After removal of stage 37, remaining stages = 1
15/08/11 10:19:29 DEBUG DAGScheduler: After removal of stage 36, remaining stages = 0
15/08/11 10:19:29 INFO DAGScheduler: Job 19 finished: collectAsMap at KMeansTest.scala:67, took 2.372420 s
Finished iteration (num = 17)
15/08/11 10:19:30 INFO SparkContext: Starting job: collectAsMap at KMeansTest.scala:67
15/08/11 10:19:30 INFO DAGScheduler: Registering RDD 58 (map at KMeansTest.scala:61)
15/08/11 10:19:30 INFO DAGScheduler: Got job 20 (collectAsMap at KMeansTest.scala:67) with 3 output partitions (allowLocal=false)
15/08/11 10:19:30 INFO DAGScheduler: Final stage: Stage 39(collectAsMap at KMeansTest.scala:67)
15/08/11 10:19:30 INFO DAGScheduler: Parents of final stage: List(Stage 38)
15/08/11 10:19:30 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD MapPartitionsRDD[60] at map at KMeansTest.scala:65
15/08/11 10:19:30 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:19:30 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@494d1b96) from Actor[akka://sparkDriver/temp/$Tj]
15/08/11 10:19:30 DEBUG BlockManagerMasterActor: [actor] handled message (0.225514 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@494d1b96) from Actor[akka://sparkDriver/temp/$Tj]
15/08/11 10:19:30 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:19:30 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@494d1b96) from Actor[akka://sparkDriver/temp/$Uj]
15/08/11 10:19:30 DEBUG BlockManagerMasterActor: [actor] handled message (0.775588 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@494d1b96) from Actor[akka://sparkDriver/temp/$Uj]
15/08/11 10:19:30 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:19:30 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:19:30 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|60|0,rdd_60_0,, null|60|1,rdd_60_1,, null|60|2,rdd_60_2,).
15/08/11 10:19:30 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:19:30 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$Wj]
15/08/11 10:19:30 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:19:30 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:30 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:30 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:30 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:30 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:30 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:30 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:30 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:30 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:30 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:19:30 DEBUG BlockManagerMasterActor: [actor] handled message (2.215418 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$Wj]
15/08/11 10:19:30 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:19:30 DEBUG BlockManager: Got multiple block location in  17 ms
15/08/11 10:19:30 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD ShuffledRDD[59] at reduceByKey at KMeansTest.scala:63
15/08/11 10:19:30 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:19:30 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@17cc3847) from Actor[akka://sparkDriver/temp/$Xj]
15/08/11 10:19:30 DEBUG BlockManagerMasterActor: [actor] handled message (0.177233 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@17cc3847) from Actor[akka://sparkDriver/temp/$Xj]
15/08/11 10:19:30 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:19:30 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@17cc3847) from Actor[akka://sparkDriver/temp/$Yj]
15/08/11 10:19:30 DEBUG BlockManagerMasterActor: [actor] handled message (0.149044 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@17cc3847) from Actor[akka://sparkDriver/temp/$Yj]
15/08/11 10:19:30 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:19:30 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:19:30 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|59|0,rdd_59_0,, null|59|1,rdd_59_1,, null|59|2,rdd_59_2,).
15/08/11 10:19:30 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:19:30 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$0j]
15/08/11 10:19:30 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:19:30 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:30 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:30 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:30 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:30 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:30 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:30 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:30 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:30 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:30 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:19:30 DEBUG BlockManagerMasterActor: [actor] handled message (1.432235 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$0j]
15/08/11 10:19:30 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:19:30 DEBUG BlockManager: Got multiple block location in  14 ms
15/08/11 10:19:30 INFO DAGScheduler: [SMSpark v1]Missing parents: List(Stage 38)
15/08/11 10:19:30 DEBUG DAGScheduler: submitStage(Stage 39)
15/08/11 10:19:30 DEBUG DAGScheduler: missing: List(Stage 38)
15/08/11 10:19:30 DEBUG DAGScheduler: submitStage(Stage 38)
15/08/11 10:19:30 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD MapPartitionsRDD[58] at map at KMeansTest.scala:61
15/08/11 10:19:30 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:19:30 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@4b353142) from Actor[akka://sparkDriver/temp/$1j]
15/08/11 10:19:30 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:19:30 DEBUG BlockManagerMasterActor: [actor] handled message (0.226007 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@4b353142) from Actor[akka://sparkDriver/temp/$1j]
15/08/11 10:19:30 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@4b353142) from Actor[akka://sparkDriver/temp/$2j]
15/08/11 10:19:30 DEBUG BlockManagerMasterActor: [actor] handled message (0.217806 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@4b353142) from Actor[akka://sparkDriver/temp/$2j]
15/08/11 10:19:30 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:19:30 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:19:30 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|58|0,rdd_58_0,, null|58|1,rdd_58_1,, null|58|2,rdd_58_2,).
15/08/11 10:19:30 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:19:30 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$4j]
15/08/11 10:19:30 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:19:30 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:30 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:30 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:30 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:30 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:30 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:30 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:30 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:30 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:30 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:19:30 DEBUG BlockManagerMasterActor: [actor] handled message (0.78827 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$4j]
15/08/11 10:19:30 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:19:30 DEBUG BlockManager: Got multiple block location in  10 ms
15/08/11 10:19:30 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD KMeans01 MapPartitionsRDD[2] at map at KMeansTest.scala:50
15/08/11 10:19:30 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:19:30 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@773d3f4a) from Actor[akka://sparkDriver/temp/$5j]
15/08/11 10:19:30 DEBUG BlockManagerMasterActor: [actor] handled message (0.454709 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@773d3f4a) from Actor[akka://sparkDriver/temp/$5j]
15/08/11 10:19:30 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(ArrayBuffer(BlockManagerId(0, 192.168.130.131, 47921)), ArrayBuffer(BlockManagerId(0, 192.168.130.131, 47921)), ArrayBuffer(BlockManagerId(0, 192.168.130.131, 47921)))
15/08/11 10:19:30 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@773d3f4a) from Actor[akka://sparkDriver/temp/$6j]
15/08/11 10:19:30 DEBUG BlockManagerMasterActor: [actor] handled message (0.24471 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@773d3f4a) from Actor[akka://sparkDriver/temp/$6j]
15/08/11 10:19:30 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:19:30 DEBUG DAGScheduler: missing: List()
15/08/11 10:19:30 INFO DAGScheduler: Submitting Stage 38 (MapPartitionsRDD[58] at map at KMeansTest.scala:61), which has no missing parents
15/08/11 10:19:30 DEBUG DAGScheduler: submitMissingTasks(Stage 38)
15/08/11 10:19:30 INFO MemoryStore: ensureFreeSpace(4768) called with curMem=216763, maxMem=278302556
15/08/11 10:19:30 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 4.7 KB, free 265.2 MB)
15/08/11 10:19:30 DEBUG BlockManager: Put block broadcast_39 locally took  1 ms
15/08/11 10:19:30 DEBUG BlockManager: Putting block broadcast_39 without replication took  1 ms
15/08/11 10:19:30 INFO MemoryStore: ensureFreeSpace(3203) called with curMem=221531, maxMem=278302556
15/08/11 10:19:30 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 3.1 KB, free 265.2 MB)
15/08/11 10:19:30 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_39_piece0,StorageLevel(false, true, false, false, 1),3203,0,0) from Actor[akka://sparkDriver/temp/$7j]
15/08/11 10:19:30 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 192.168.130.131:57830 (size: 3.1 KB, free: 265.4 MB)
15/08/11 10:19:30 INFO BlockManagerMaster: Updated info of block broadcast_39_piece0
15/08/11 10:19:30 DEBUG BlockManager: Told master about block broadcast_39_piece0
15/08/11 10:19:30 DEBUG BlockManagerMasterActor: [actor] handled message (0.463199 ms) UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_39_piece0,StorageLevel(false, true, false, false, 1),3203,0,0) from Actor[akka://sparkDriver/temp/$7j]
15/08/11 10:19:30 DEBUG BlockManager: Put block broadcast_39_piece0 locally took  1 ms
15/08/11 10:19:30 DEBUG BlockManager: Putting block broadcast_39_piece0 without replication took  2 ms
15/08/11 10:19:30 INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:852
15/08/11 10:19:30 INFO DAGScheduler: Submitting 3 missing tasks from Stage 38 (MapPartitionsRDD[58] at map at KMeansTest.scala:61)
15/08/11 10:19:30 DEBUG DAGScheduler: New pending tasks: Set(ShuffleMapTask(38, 0), ShuffleMapTask(38, 1), ShuffleMapTask(38, 2))
15/08/11 10:19:30 INFO TaskSchedulerImpl: Adding task set 38.0 with 3 tasks
15/08/11 10:19:30 DEBUG TaskSetManager: Epoch for TaskSet 38.0: 18
15/08/11 10:19:30 DEBUG TaskSetManager: Valid locality levels for TaskSet 38.0: PROCESS_LOCAL, NODE_LOCAL, ANY
15/08/11 10:19:30 DEBUG DAGScheduler: submitStage(Stage 39)
15/08/11 10:19:30 DEBUG DAGScheduler: missing: List(Stage 38)
15/08/11 10:19:30 DEBUG DAGScheduler: submitStage(Stage 38)
15/08/11 10:19:30 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/deadLetters]
15/08/11 10:19:30 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_38, runningTasks: 0
15/08/11 10:19:30 INFO TaskSetManager: Starting task 0.0 in stage 38.0 (TID 114, 192.168.130.131, PROCESS_LOCAL, 1361 bytes)
15/08/11 10:19:30 INFO TaskSetManager: Starting task 1.0 in stage 38.0 (TID 115, 192.168.130.131, PROCESS_LOCAL, 1361 bytes)
15/08/11 10:19:30 INFO TaskSetManager: Starting task 2.0 in stage 38.0 (TID 116, 192.168.130.131, PROCESS_LOCAL, 1361 bytes)
15/08/11 10:19:30 DEBUG TaskSetManager: No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
15/08/11 10:19:30 DEBUG TaskSetManager: No tasks for locality level NODE_LOCAL, so moving to locality level ANY
15/08/11 10:19:30 DEBUG BlockManagerMasterActor: [actor] received message GetLocations(broadcast_39_piece0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$Bc]
15/08/11 10:19:30 DEBUG BlockManagerMasterActor: [actor] handled message (0.065194 ms) GetLocations(broadcast_39_piece0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$Bc]
15/08/11 10:19:30 DEBUG DAGScheduler: submitStage(Stage 39)
15/08/11 10:19:30 DEBUG SparkDeploySchedulerBackend: [actor] handled message (14.653258 ms) ReviveOffers from Actor[akka://sparkDriver/deadLetters]
15/08/11 10:19:30 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,114,RUNNING,org.apache.spark.util.SerializableBuffer@d31e29a) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:30 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.121402 ms) StatusUpdate(0,114,RUNNING,org.apache.spark.util.SerializableBuffer@d31e29a) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:30 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,115,RUNNING,org.apache.spark.util.SerializableBuffer@4613f33a) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:30 DEBUG DAGScheduler: missing: List(Stage 38)
15/08/11 10:19:30 DEBUG DAGScheduler: submitStage(Stage 38)
15/08/11 10:19:30 DEBUG DAGScheduler: submitStage(Stage 39)
15/08/11 10:19:30 DEBUG DAGScheduler: missing: List(Stage 38)
15/08/11 10:19:30 DEBUG DAGScheduler: submitStage(Stage 38)
15/08/11 10:19:30 DEBUG DAGScheduler: submitStage(Stage 39)
15/08/11 10:19:30 DEBUG BlockManager: Level for block broadcast_39_piece0 is StorageLevel(true, true, false, false, 1)
15/08/11 10:19:30 DEBUG BlockManager: Getting block broadcast_39_piece0 from memory
15/08/11 10:19:30 DEBUG DAGScheduler: missing: List(Stage 38)
15/08/11 10:19:30 DEBUG DAGScheduler: submitStage(Stage 38)
15/08/11 10:19:30 DEBUG SparkDeploySchedulerBackend: [actor] handled message (6.941622 ms) StatusUpdate(0,115,RUNNING,org.apache.spark.util.SerializableBuffer@4613f33a) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:30 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,116,RUNNING,org.apache.spark.util.SerializableBuffer@21bda9bd) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:30 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.044454 ms) StatusUpdate(0,116,RUNNING,org.apache.spark.util.SerializableBuffer@21bda9bd) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:30 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_39_piece0,StorageLevel(false, true, false, false, 1),3203,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$Cc]
15/08/11 10:19:30 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 192.168.130.131:47921 (size: 3.1 KB, free: 245.7 MB)
15/08/11 10:19:30 DEBUG BlockManagerMasterActor: [actor] handled message (0.40723 ms) UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_39_piece0,StorageLevel(false, true, false, false, 1),3203,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$Cc]
15/08/11 10:19:30 DEBUG HeartbeatReceiver: [actor] received message Heartbeat(0,[Lscala.Tuple2;@2ad2c899,BlockManagerId(0, 192.168.130.131, 47921)) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$Dc]
15/08/11 10:19:30 DEBUG BlockManagerMasterActor: [actor] received message BlockManagerHeartbeat(BlockManagerId(0, 192.168.130.131, 47921)) from Actor[akka://sparkDriver/temp/$8j]
15/08/11 10:19:30 DEBUG BlockManagerMasterActor: [actor] handled message (0.097853 ms) BlockManagerHeartbeat(BlockManagerId(0, 192.168.130.131, 47921)) from Actor[akka://sparkDriver/temp/$8j]
15/08/11 10:19:30 DEBUG HeartbeatReceiver: [actor] handled message (0.851891 ms) Heartbeat(0,[Lscala.Tuple2;@2ad2c899,BlockManagerId(0, 192.168.130.131, 47921)) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$Dc]
15/08/11 10:19:30 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:19:30 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_38, runningTasks: 3
15/08/11 10:19:30 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.547396 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:19:31 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,116,FINISHED,org.apache.spark.util.SerializableBuffer@79cd2a20) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:31 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_38, runningTasks: 2
15/08/11 10:19:31 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.574372 ms) StatusUpdate(0,116,FINISHED,org.apache.spark.util.SerializableBuffer@79cd2a20) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:31 DEBUG DAGScheduler: ShuffleMapTask finished on 0
15/08/11 10:19:31 DEBUG DAGScheduler: submitStage(Stage 39)
15/08/11 10:19:31 DEBUG DAGScheduler: missing: List(Stage 38)
15/08/11 10:19:31 DEBUG DAGScheduler: submitStage(Stage 38)
15/08/11 10:19:31 INFO TaskSetManager: Finished task 2.0 in stage 38.0 (TID 116) in 948 ms on 192.168.130.131 (1/3)
15/08/11 10:19:31 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:19:31 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_38, runningTasks: 2
15/08/11 10:19:31 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.712218 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:19:32 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,115,FINISHED,org.apache.spark.util.SerializableBuffer@c88d959) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:32 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_38, runningTasks: 1
15/08/11 10:19:32 DEBUG SparkDeploySchedulerBackend: [actor] handled message (1.821815 ms) StatusUpdate(0,115,FINISHED,org.apache.spark.util.SerializableBuffer@c88d959) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:32 DEBUG DAGScheduler: ShuffleMapTask finished on 0
15/08/11 10:19:32 DEBUG DAGScheduler: submitStage(Stage 39)
15/08/11 10:19:32 DEBUG DAGScheduler: missing: List(Stage 38)
15/08/11 10:19:32 DEBUG DAGScheduler: submitStage(Stage 38)
15/08/11 10:19:32 INFO TaskSetManager: Finished task 1.0 in stage 38.0 (TID 115) in 2450 ms on 192.168.130.131 (2/3)
15/08/11 10:19:32 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,114,FINISHED,org.apache.spark.util.SerializableBuffer@101edc85) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:32 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_38, runningTasks: 0
15/08/11 10:19:32 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.775542 ms) StatusUpdate(0,114,FINISHED,org.apache.spark.util.SerializableBuffer@101edc85) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:32 DEBUG DAGScheduler: ShuffleMapTask finished on 0
15/08/11 10:19:32 INFO DAGScheduler: Stage 38 (map at KMeansTest.scala:61) finished in 2.604 s
15/08/11 10:19:32 INFO DAGScheduler: looking for newly runnable stages
15/08/11 10:19:32 INFO DAGScheduler: running: Set()
15/08/11 10:19:32 INFO DAGScheduler: waiting: Set(Stage 39)
15/08/11 10:19:32 INFO DAGScheduler: failed: Set()
15/08/11 10:19:32 DEBUG MapOutputTrackerMaster: Increasing epoch to 19
15/08/11 10:19:32 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD MapPartitionsRDD[60] at map at KMeansTest.scala:65
15/08/11 10:19:32 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@5a1fa807) from Actor[akka://sparkDriver/temp/$9j]
15/08/11 10:19:32 INFO TaskSetManager: Finished task 0.0 in stage 38.0 (TID 114) in 2600 ms on 192.168.130.131 (3/3)
15/08/11 10:19:32 INFO TaskSchedulerImpl: Removed TaskSet 38.0, whose tasks have all completed, from pool 
15/08/11 10:19:32 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: [actor] handled message (0.218006 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@5a1fa807) from Actor[akka://sparkDriver/temp/$9j]
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@5a1fa807) from Actor[akka://sparkDriver/temp/$+j]
15/08/11 10:19:32 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:19:32 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:19:32 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|60|0,rdd_60_0,, null|60|1,rdd_60_1,, null|60|2,rdd_60_2,).
15/08/11 10:19:32 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: [actor] handled message (10.017017 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@5a1fa807) from Actor[akka://sparkDriver/temp/$+j]
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$ak]
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: [actor] handled message (0.838053 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$ak]
15/08/11 10:19:32 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:19:32 DEBUG BlockManager: Got multiple block location in  20 ms
15/08/11 10:19:32 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD ShuffledRDD[59] at reduceByKey at KMeansTest.scala:63
15/08/11 10:19:32 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@38183a1c) from Actor[akka://sparkDriver/temp/$bk]
15/08/11 10:19:32 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: [actor] handled message (0.169368 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@38183a1c) from Actor[akka://sparkDriver/temp/$bk]
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@38183a1c) from Actor[akka://sparkDriver/temp/$ck]
15/08/11 10:19:32 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: [actor] handled message (0.127729 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@38183a1c) from Actor[akka://sparkDriver/temp/$ck]
15/08/11 10:19:32 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:19:32 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|59|0,rdd_59_0,, null|59|1,rdd_59_1,, null|59|2,rdd_59_2,).
15/08/11 10:19:32 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$ek]
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: [actor] handled message (1.375459 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$ek]
15/08/11 10:19:32 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:19:32 DEBUG BlockManager: Got multiple block location in  13 ms
15/08/11 10:19:32 INFO DAGScheduler: Missing parents for Stage 39: List()
15/08/11 10:19:32 INFO DAGScheduler: Submitting Stage 39 (MapPartitionsRDD[60] at map at KMeansTest.scala:65), which is now runnable
15/08/11 10:19:32 DEBUG DAGScheduler: submitMissingTasks(Stage 39)
15/08/11 10:19:32 INFO MemoryStore: ensureFreeSpace(2560) called with curMem=224734, maxMem=278302556
15/08/11 10:19:32 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 2.5 KB, free 265.2 MB)
15/08/11 10:19:32 DEBUG BlockManager: Put block broadcast_40 locally took  3 ms
15/08/11 10:19:32 DEBUG BlockManager: Putting block broadcast_40 without replication took  3 ms
15/08/11 10:19:32 INFO MemoryStore: ensureFreeSpace(1521) called with curMem=227294, maxMem=278302556
15/08/11 10:19:32 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 1521.0 B, free 265.2 MB)
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_40_piece0,StorageLevel(false, true, false, false, 1),1521,0,0) from Actor[akka://sparkDriver/temp/$fk]
15/08/11 10:19:32 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 192.168.130.131:57830 (size: 1521.0 B, free: 265.4 MB)
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: [actor] handled message (0.443245 ms) UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_40_piece0,StorageLevel(false, true, false, false, 1),1521,0,0) from Actor[akka://sparkDriver/temp/$fk]
15/08/11 10:19:32 INFO BlockManagerMaster: Updated info of block broadcast_40_piece0
15/08/11 10:19:32 DEBUG BlockManager: Told master about block broadcast_40_piece0
15/08/11 10:19:32 DEBUG BlockManager: Put block broadcast_40_piece0 locally took  2 ms
15/08/11 10:19:32 DEBUG BlockManager: Putting block broadcast_40_piece0 without replication took  2 ms
15/08/11 10:19:32 INFO SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:852
15/08/11 10:19:32 INFO DAGScheduler: Submitting 3 missing tasks from Stage 39 (MapPartitionsRDD[60] at map at KMeansTest.scala:65)
15/08/11 10:19:32 DEBUG DAGScheduler: New pending tasks: Set(ResultTask(39, 2), ResultTask(39, 1), ResultTask(39, 0))
15/08/11 10:19:32 INFO TaskSchedulerImpl: Adding task set 39.0 with 3 tasks
15/08/11 10:19:32 DEBUG TaskSetManager: Epoch for TaskSet 39.0: 19
15/08/11 10:19:32 DEBUG TaskSetManager: Valid locality levels for TaskSet 39.0: NO_PREF, ANY
15/08/11 10:19:32 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/deadLetters]
15/08/11 10:19:32 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_39, runningTasks: 0
15/08/11 10:19:32 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 117, 192.168.130.131, PROCESS_LOCAL, 1116 bytes)
15/08/11 10:19:32 INFO TaskSetManager: Starting task 1.0 in stage 39.0 (TID 118, 192.168.130.131, PROCESS_LOCAL, 1116 bytes)
15/08/11 10:19:32 INFO TaskSetManager: Starting task 2.0 in stage 39.0 (TID 119, 192.168.130.131, PROCESS_LOCAL, 1116 bytes)
15/08/11 10:19:32 DEBUG TaskSetManager: No tasks for locality level NO_PREF, so moving to locality level ANY
15/08/11 10:19:32 DEBUG SparkDeploySchedulerBackend: [actor] handled message (5.138041 ms) ReviveOffers from Actor[akka://sparkDriver/deadLetters]
15/08/11 10:19:32 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,117,RUNNING,org.apache.spark.util.SerializableBuffer@c45ea92) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:32 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.11068 ms) StatusUpdate(0,117,RUNNING,org.apache.spark.util.SerializableBuffer@c45ea92) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:32 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,118,RUNNING,org.apache.spark.util.SerializableBuffer@422b1d89) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:32 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.152915 ms) StatusUpdate(0,118,RUNNING,org.apache.spark.util.SerializableBuffer@422b1d89) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:32 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,119,RUNNING,org.apache.spark.util.SerializableBuffer@1ca02f4f) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:32 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.197852 ms) StatusUpdate(0,119,RUNNING,org.apache.spark.util.SerializableBuffer@1ca02f4f) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: [actor] received message GetLocations(broadcast_40_piece0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$Ec]
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: [actor] handled message (0.342737 ms) GetLocations(broadcast_40_piece0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$Ec]
15/08/11 10:19:32 DEBUG BlockManager: Level for block broadcast_40_piece0 is StorageLevel(true, true, false, false, 1)
15/08/11 10:19:32 DEBUG BlockManager: Getting block broadcast_40_piece0 from memory
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_40_piece0,StorageLevel(false, true, false, false, 1),1521,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$Fc]
15/08/11 10:19:32 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 192.168.130.131:47921 (size: 1521.0 B, free: 245.7 MB)
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: [actor] handled message (0.555146 ms) UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_40_piece0,StorageLevel(false, true, false, false, 1),1521,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$Fc]
15/08/11 10:19:32 DEBUG MapOutputTrackerMasterActor: [actor] received message GetMapOutputStatuses(18) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$Gc]
15/08/11 10:19:32 INFO MapOutputTrackerMasterActor: Asked to send map output locations for shuffle 18 to sparkExecutor@192.168.130.131:49489
15/08/11 10:19:32 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 18 is 162 bytes
15/08/11 10:19:32 DEBUG MapOutputTrackerMasterActor: [actor] handled message (1.765931 ms) GetMapOutputStatuses(18) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$Gc]
15/08/11 10:19:32 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,119,FINISHED,org.apache.spark.util.SerializableBuffer@6c0ae521) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:32 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_39, runningTasks: 2
15/08/11 10:19:32 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.445836 ms) StatusUpdate(0,119,FINISHED,org.apache.spark.util.SerializableBuffer@6c0ae521) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:32 INFO TaskSetManager: Finished task 2.0 in stage 39.0 (TID 119) in 70 ms on 192.168.130.131 (1/3)
15/08/11 10:19:32 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:19:32 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_39, runningTasks: 2
15/08/11 10:19:32 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.71442 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:19:32 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,118,FINISHED,org.apache.spark.util.SerializableBuffer@63689a4b) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:32 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_39, runningTasks: 1
15/08/11 10:19:32 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.751245 ms) StatusUpdate(0,118,FINISHED,org.apache.spark.util.SerializableBuffer@63689a4b) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:32 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,117,FINISHED,org.apache.spark.util.SerializableBuffer@6869e4e9) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:32 INFO TaskSetManager: Finished task 1.0 in stage 39.0 (TID 118) in 87 ms on 192.168.130.131 (2/3)
15/08/11 10:19:32 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_39, runningTasks: 0
15/08/11 10:19:32 DEBUG SparkDeploySchedulerBackend: [actor] handled message (4.590019 ms) StatusUpdate(0,117,FINISHED,org.apache.spark.util.SerializableBuffer@6869e4e9) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:32 INFO DAGScheduler: Stage 39 (collectAsMap at KMeansTest.scala:67) finished in 0.098 s
15/08/11 10:19:32 DEBUG DAGScheduler: After removal of stage 38, remaining stages = 1
15/08/11 10:19:32 DEBUG DAGScheduler: After removal of stage 39, remaining stages = 0
15/08/11 10:19:32 INFO DAGScheduler: Job 20 finished: collectAsMap at KMeansTest.scala:67, took 2.827986 s
Finished iteration (num = 18)
15/08/11 10:19:32 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 117) in 94 ms on 192.168.130.131 (3/3)
15/08/11 10:19:32 INFO TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool 
15/08/11 10:19:32 INFO SparkContext: Starting job: collectAsMap at KMeansTest.scala:67
15/08/11 10:19:32 INFO DAGScheduler: Registering RDD 61 (map at KMeansTest.scala:61)
15/08/11 10:19:32 INFO DAGScheduler: Got job 21 (collectAsMap at KMeansTest.scala:67) with 3 output partitions (allowLocal=false)
15/08/11 10:19:32 INFO DAGScheduler: Final stage: Stage 41(collectAsMap at KMeansTest.scala:67)
15/08/11 10:19:32 INFO DAGScheduler: Parents of final stage: List(Stage 40)
15/08/11 10:19:32 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD MapPartitionsRDD[63] at map at KMeansTest.scala:65
15/08/11 10:19:32 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@44593b0d) from Actor[akka://sparkDriver/temp/$gk]
15/08/11 10:19:32 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: [actor] handled message (0.173012 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@44593b0d) from Actor[akka://sparkDriver/temp/$gk]
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@44593b0d) from Actor[akka://sparkDriver/temp/$hk]
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: [actor] handled message (0.14853 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@44593b0d) from Actor[akka://sparkDriver/temp/$hk]
15/08/11 10:19:32 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:19:32 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:19:32 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|63|0,rdd_63_0,, null|63|1,rdd_63_1,, null|63|2,rdd_63_2,).
15/08/11 10:19:32 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$jk]
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: [actor] handled message (0.756402 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$jk]
15/08/11 10:19:32 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:19:32 DEBUG BlockManager: Got multiple block location in  10 ms
15/08/11 10:19:32 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD ShuffledRDD[62] at reduceByKey at KMeansTest.scala:63
15/08/11 10:19:32 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@3344006c) from Actor[akka://sparkDriver/temp/$kk]
15/08/11 10:19:32 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: [actor] handled message (0.155127 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@3344006c) from Actor[akka://sparkDriver/temp/$kk]
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@3344006c) from Actor[akka://sparkDriver/temp/$lk]
15/08/11 10:19:32 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: [actor] handled message (0.143551 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@3344006c) from Actor[akka://sparkDriver/temp/$lk]
15/08/11 10:19:32 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:19:32 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|62|0,rdd_62_0,, null|62|1,rdd_62_1,, null|62|2,rdd_62_2,).
15/08/11 10:19:32 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$nk]
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: [actor] handled message (0.947852 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$nk]
15/08/11 10:19:32 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:19:32 DEBUG BlockManager: Got multiple block location in  10 ms
15/08/11 10:19:32 INFO DAGScheduler: [SMSpark v1]Missing parents: List(Stage 40)
15/08/11 10:19:32 DEBUG DAGScheduler: submitStage(Stage 41)
15/08/11 10:19:32 DEBUG DAGScheduler: missing: List(Stage 40)
15/08/11 10:19:32 DEBUG DAGScheduler: submitStage(Stage 40)
15/08/11 10:19:32 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD MapPartitionsRDD[61] at map at KMeansTest.scala:61
15/08/11 10:19:32 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@5b0d6a3f) from Actor[akka://sparkDriver/temp/$ok]
15/08/11 10:19:32 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: [actor] handled message (0.265382 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@5b0d6a3f) from Actor[akka://sparkDriver/temp/$ok]
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@5b0d6a3f) from Actor[akka://sparkDriver/temp/$pk]
15/08/11 10:19:32 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: [actor] handled message (0.234941 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@5b0d6a3f) from Actor[akka://sparkDriver/temp/$pk]
15/08/11 10:19:32 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:19:32 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|61|0,rdd_61_0,, null|61|1,rdd_61_1,, null|61|2,rdd_61_2,).
15/08/11 10:19:32 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$rk]
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: [actor] handled message (1.107896 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$rk]
15/08/11 10:19:32 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:19:32 DEBUG BlockManager: Got multiple block location in  10 ms
15/08/11 10:19:32 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD KMeans01 MapPartitionsRDD[2] at map at KMeansTest.scala:50
15/08/11 10:19:32 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@442a559d) from Actor[akka://sparkDriver/temp/$sk]
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: [actor] handled message (0.305025 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@442a559d) from Actor[akka://sparkDriver/temp/$sk]
15/08/11 10:19:32 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(ArrayBuffer(BlockManagerId(0, 192.168.130.131, 47921)), ArrayBuffer(BlockManagerId(0, 192.168.130.131, 47921)), ArrayBuffer(BlockManagerId(0, 192.168.130.131, 47921)))
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@442a559d) from Actor[akka://sparkDriver/temp/$tk]
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: [actor] handled message (0.109841 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@442a559d) from Actor[akka://sparkDriver/temp/$tk]
15/08/11 10:19:32 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:19:32 DEBUG DAGScheduler: missing: List()
15/08/11 10:19:32 INFO DAGScheduler: Submitting Stage 40 (MapPartitionsRDD[61] at map at KMeansTest.scala:61), which has no missing parents
15/08/11 10:19:32 DEBUG DAGScheduler: submitMissingTasks(Stage 40)
15/08/11 10:19:32 INFO MemoryStore: ensureFreeSpace(4768) called with curMem=228815, maxMem=278302556
15/08/11 10:19:32 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 4.7 KB, free 265.2 MB)
15/08/11 10:19:32 DEBUG BlockManager: Put block broadcast_41 locally took  1 ms
15/08/11 10:19:32 DEBUG BlockManager: Putting block broadcast_41 without replication took  1 ms
15/08/11 10:19:32 INFO MemoryStore: ensureFreeSpace(3207) called with curMem=233583, maxMem=278302556
15/08/11 10:19:32 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 3.1 KB, free 265.2 MB)
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_41_piece0,StorageLevel(false, true, false, false, 1),3207,0,0) from Actor[akka://sparkDriver/temp/$uk]
15/08/11 10:19:32 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on 192.168.130.131:57830 (size: 3.1 KB, free: 265.4 MB)
15/08/11 10:19:32 INFO BlockManagerMaster: Updated info of block broadcast_41_piece0
15/08/11 10:19:32 DEBUG BlockManager: Told master about block broadcast_41_piece0
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: [actor] handled message (0.438412 ms) UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_41_piece0,StorageLevel(false, true, false, false, 1),3207,0,0) from Actor[akka://sparkDriver/temp/$uk]
15/08/11 10:19:32 DEBUG BlockManager: Put block broadcast_41_piece0 locally took  2 ms
15/08/11 10:19:32 DEBUG BlockManager: Putting block broadcast_41_piece0 without replication took  2 ms
15/08/11 10:19:32 INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:852
15/08/11 10:19:32 INFO DAGScheduler: Submitting 3 missing tasks from Stage 40 (MapPartitionsRDD[61] at map at KMeansTest.scala:61)
15/08/11 10:19:32 DEBUG DAGScheduler: New pending tasks: Set(ShuffleMapTask(40, 2), ShuffleMapTask(40, 0), ShuffleMapTask(40, 1))
15/08/11 10:19:32 INFO TaskSchedulerImpl: Adding task set 40.0 with 3 tasks
15/08/11 10:19:32 DEBUG TaskSetManager: Epoch for TaskSet 40.0: 19
15/08/11 10:19:32 DEBUG TaskSetManager: Valid locality levels for TaskSet 40.0: PROCESS_LOCAL, NODE_LOCAL, ANY
15/08/11 10:19:32 DEBUG DAGScheduler: submitStage(Stage 41)
15/08/11 10:19:32 DEBUG DAGScheduler: missing: List(Stage 40)
15/08/11 10:19:32 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/deadLetters]
15/08/11 10:19:32 DEBUG DAGScheduler: submitStage(Stage 40)
15/08/11 10:19:32 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_40, runningTasks: 0
15/08/11 10:19:32 INFO TaskSetManager: Starting task 0.0 in stage 40.0 (TID 120, 192.168.130.131, PROCESS_LOCAL, 1361 bytes)
15/08/11 10:19:32 DEBUG DAGScheduler: submitStage(Stage 41)
15/08/11 10:19:32 DEBUG DAGScheduler: missing: List(Stage 40)
15/08/11 10:19:32 DEBUG DAGScheduler: submitStage(Stage 40)
15/08/11 10:19:32 INFO TaskSetManager: Starting task 1.0 in stage 40.0 (TID 121, 192.168.130.131, PROCESS_LOCAL, 1361 bytes)
15/08/11 10:19:32 DEBUG DAGScheduler: submitStage(Stage 41)
15/08/11 10:19:32 DEBUG DAGScheduler: missing: List(Stage 40)
15/08/11 10:19:32 DEBUG DAGScheduler: submitStage(Stage 40)
15/08/11 10:19:32 INFO TaskSetManager: Starting task 2.0 in stage 40.0 (TID 122, 192.168.130.131, PROCESS_LOCAL, 1361 bytes)
15/08/11 10:19:32 DEBUG TaskSetManager: No tasks for locality level PROCESS_LOCAL, so moving to locality level NODE_LOCAL
15/08/11 10:19:32 DEBUG TaskSetManager: No tasks for locality level NODE_LOCAL, so moving to locality level ANY
15/08/11 10:19:32 DEBUG SparkDeploySchedulerBackend: [actor] handled message (7.499836 ms) ReviveOffers from Actor[akka://sparkDriver/deadLetters]
15/08/11 10:19:32 DEBUG DAGScheduler: submitStage(Stage 41)
15/08/11 10:19:32 DEBUG DAGScheduler: missing: List(Stage 40)
15/08/11 10:19:32 DEBUG DAGScheduler: submitStage(Stage 40)
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: [actor] received message GetLocations(broadcast_41_piece0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$Hc]
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: [actor] handled message (0.057039 ms) GetLocations(broadcast_41_piece0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$Hc]
15/08/11 10:19:32 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,120,RUNNING,org.apache.spark.util.SerializableBuffer@31e7080c) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:32 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.046097 ms) StatusUpdate(0,120,RUNNING,org.apache.spark.util.SerializableBuffer@31e7080c) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:32 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,121,RUNNING,org.apache.spark.util.SerializableBuffer@6c86c3e5) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:32 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.052276 ms) StatusUpdate(0,121,RUNNING,org.apache.spark.util.SerializableBuffer@6c86c3e5) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:32 DEBUG BlockManager: Level for block broadcast_41_piece0 is StorageLevel(true, true, false, false, 1)
15/08/11 10:19:32 DEBUG BlockManager: Getting block broadcast_41_piece0 from memory
15/08/11 10:19:32 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,122,RUNNING,org.apache.spark.util.SerializableBuffer@448db742) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:32 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.089881 ms) StatusUpdate(0,122,RUNNING,org.apache.spark.util.SerializableBuffer@448db742) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_41_piece0,StorageLevel(false, true, false, false, 1),3207,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$Ic]
15/08/11 10:19:32 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on 192.168.130.131:47921 (size: 3.1 KB, free: 245.7 MB)
15/08/11 10:19:32 DEBUG BlockManagerMasterActor: [actor] handled message (0.327142 ms) UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_41_piece0,StorageLevel(false, true, false, false, 1),3207,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$Ic]
15/08/11 10:19:33 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,122,FINISHED,org.apache.spark.util.SerializableBuffer@33fa7137) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:33 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_40, runningTasks: 2
15/08/11 10:19:33 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.547821 ms) StatusUpdate(0,122,FINISHED,org.apache.spark.util.SerializableBuffer@33fa7137) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:33 DEBUG DAGScheduler: ShuffleMapTask finished on 0
15/08/11 10:19:33 DEBUG DAGScheduler: submitStage(Stage 41)
15/08/11 10:19:33 DEBUG DAGScheduler: missing: List(Stage 40)
15/08/11 10:19:33 DEBUG DAGScheduler: submitStage(Stage 40)
15/08/11 10:19:33 INFO TaskSetManager: Finished task 2.0 in stage 40.0 (TID 122) in 706 ms on 192.168.130.131 (1/3)
15/08/11 10:19:33 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:19:33 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_40, runningTasks: 2
15/08/11 10:19:33 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.550668 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:19:34 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:19:34 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_40, runningTasks: 2
15/08/11 10:19:34 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.66298 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1928610557]
15/08/11 10:19:34 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,121,FINISHED,org.apache.spark.util.SerializableBuffer@7f1eec89) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:34 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_40, runningTasks: 1
15/08/11 10:19:34 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.71238 ms) StatusUpdate(0,121,FINISHED,org.apache.spark.util.SerializableBuffer@7f1eec89) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:34 DEBUG DAGScheduler: ShuffleMapTask finished on 0
15/08/11 10:19:34 DEBUG DAGScheduler: submitStage(Stage 41)
15/08/11 10:19:34 DEBUG DAGScheduler: missing: List(Stage 40)
15/08/11 10:19:34 DEBUG DAGScheduler: submitStage(Stage 40)
15/08/11 10:19:34 INFO TaskSetManager: Finished task 1.0 in stage 40.0 (TID 121) in 1920 ms on 192.168.130.131 (2/3)
15/08/11 10:19:34 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,120,FINISHED,org.apache.spark.util.SerializableBuffer@473b5792) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:34 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_40, runningTasks: 0
15/08/11 10:19:34 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.471033 ms) StatusUpdate(0,120,FINISHED,org.apache.spark.util.SerializableBuffer@473b5792) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:34 INFO TaskSetManager: Finished task 0.0 in stage 40.0 (TID 120) in 2013 ms on 192.168.130.131 (3/3)
15/08/11 10:19:34 DEBUG DAGScheduler: ShuffleMapTask finished on 0
15/08/11 10:19:34 INFO TaskSchedulerImpl: Removed TaskSet 40.0, whose tasks have all completed, from pool 
15/08/11 10:19:34 INFO DAGScheduler: Stage 40 (map at KMeansTest.scala:61) finished in 2.018 s
15/08/11 10:19:34 INFO DAGScheduler: looking for newly runnable stages
15/08/11 10:19:34 INFO DAGScheduler: running: Set()
15/08/11 10:19:34 INFO DAGScheduler: waiting: Set(Stage 41)
15/08/11 10:19:34 INFO DAGScheduler: failed: Set()
15/08/11 10:19:34 DEBUG MapOutputTrackerMaster: Increasing epoch to 20
15/08/11 10:19:34 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD MapPartitionsRDD[63] at map at KMeansTest.scala:65
15/08/11 10:19:34 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:19:34 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@8f256c7) from Actor[akka://sparkDriver/temp/$vk]
15/08/11 10:19:34 DEBUG BlockManagerMasterActor: [actor] handled message (0.177189 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@8f256c7) from Actor[akka://sparkDriver/temp/$vk]
15/08/11 10:19:34 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:19:34 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@8f256c7) from Actor[akka://sparkDriver/temp/$wk]
15/08/11 10:19:34 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:19:34 DEBUG BlockManagerMasterActor: [actor] handled message (0.136401 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@8f256c7) from Actor[akka://sparkDriver/temp/$wk]
15/08/11 10:19:34 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:19:34 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|63|0,rdd_63_0,, null|63|1,rdd_63_1,, null|63|2,rdd_63_2,).
15/08/11 10:19:34 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:19:34 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$yk]
15/08/11 10:19:34 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:19:34 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:34 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:34 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:34 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:34 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:34 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:34 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:34 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:34 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:34 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:19:34 DEBUG BlockManagerMasterActor: [actor] handled message (0.550596 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$yk]
15/08/11 10:19:34 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:19:34 DEBUG BlockManager: Got multiple block location in  9 ms
15/08/11 10:19:34 DEBUG DAGScheduler: [SMSpark]Not in cacheLocs, we will find locations of each partition of RDD ShuffledRDD[62] at reduceByKey at KMeansTest.scala:63
15/08/11 10:19:34 DEBUG BlockManager: [SMSpark]: Begin to get block locations.
15/08/11 10:19:34 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@1fd717cd) from Actor[akka://sparkDriver/temp/$zk]
15/08/11 10:19:34 DEBUG BlockManagerMasterActor: [actor] handled message (0.156657 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@1fd717cd) from Actor[akka://sparkDriver/temp/$zk]
15/08/11 10:19:34 DEBUG BlockManager: [SMSpark]: Get block locations from BlockManagerMaster: ArraySeq(List(), List(), List())
15/08/11 10:19:34 DEBUG BlockManagerMasterActor: [actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@1fd717cd) from Actor[akka://sparkDriver/temp/$Ak]
15/08/11 10:19:34 DEBUG BlockManagerMasterActor: [actor] handled message (0.124169 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@1fd717cd) from Actor[akka://sparkDriver/temp/$Ak]
15/08/11 10:19:34 INFO BlockManager: [SMSpark]: Begin to find block from shared memory space.
15/08/11 10:19:34 INFO BlockManager: [SMSpark-20150808]: Not found block in blockManagerMaster, we will find it in Shared Memory Manager.
15/08/11 10:19:34 DEBUG BlockManager: [SMSpark]: Connecting to BlockServerMaster for message ReqbsMasterGetLocations WrappedArray(null|62|0,rdd_62_0,, null|62|1,rdd_62_1,, null|62|2,rdd_62_2,).
15/08/11 10:19:34 DEBUG BlockManager: [SMSpark]: Connecting to BlockManagerMaster for message getBlockManagerIdForHost ArraySeq(List(), List(), List()).
15/08/11 10:19:34 DEBUG BlockManagerMasterActor: [actor] received message GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$Ck]
15/08/11 10:19:34 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for all host list: ArraySeq(List(), List(), List())
15/08/11 10:19:34 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:34 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:34 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:34 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:34 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:34 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:34 DEBUG BlockManagerMasterActor: [SMSpark]: getBlockManagerIdForHost for each list: List()
15/08/11 10:19:34 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(<driver>, 192.168.130.131, 57830), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:34 DEBUG BlockManagerMasterActor: host list: List(), blockManagerId: BlockManagerId(0, 192.168.130.131, 47921), blockManagerIdHost: 192.168.130.131, ifContains: false
15/08/11 10:19:34 DEBUG BlockManagerMasterActor: [SMSpark]: After finding blockManagerIds, we find: ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer())
15/08/11 10:19:34 DEBUG BlockManager: [SMSpark]: From BlockManagerMaster We have got ArraySeq(ArrayBuffer(), ArrayBuffer(), ArrayBuffer()) for such blocks.
15/08/11 10:19:34 DEBUG BlockManagerMasterActor: [actor] handled message (0.762529 ms) GetBlockManagerIdForHost(ArraySeq(List(), List(), List())) from Actor[akka://sparkDriver/temp/$Ck]
15/08/11 10:19:34 DEBUG BlockManager: Got multiple block location in  11 ms
15/08/11 10:19:34 INFO DAGScheduler: Missing parents for Stage 41: List()
15/08/11 10:19:34 INFO DAGScheduler: Submitting Stage 41 (MapPartitionsRDD[63] at map at KMeansTest.scala:65), which is now runnable
15/08/11 10:19:34 DEBUG DAGScheduler: submitMissingTasks(Stage 41)
15/08/11 10:19:34 INFO MemoryStore: ensureFreeSpace(2560) called with curMem=236790, maxMem=278302556
15/08/11 10:19:34 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 2.5 KB, free 265.2 MB)
15/08/11 10:19:34 DEBUG BlockManager: Put block broadcast_42 locally took  1 ms
15/08/11 10:19:34 DEBUG BlockManager: Putting block broadcast_42 without replication took  1 ms
15/08/11 10:19:34 INFO MemoryStore: ensureFreeSpace(1521) called with curMem=239350, maxMem=278302556
15/08/11 10:19:34 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 1521.0 B, free 265.2 MB)
15/08/11 10:19:34 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_42_piece0,StorageLevel(false, true, false, false, 1),1521,0,0) from Actor[akka://sparkDriver/temp/$Dk]
15/08/11 10:19:34 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on 192.168.130.131:57830 (size: 1521.0 B, free: 265.4 MB)
15/08/11 10:19:34 INFO BlockManagerMaster: Updated info of block broadcast_42_piece0
15/08/11 10:19:34 DEBUG BlockManager: Told master about block broadcast_42_piece0
15/08/11 10:19:34 DEBUG BlockManagerMasterActor: [actor] handled message (0.399302 ms) UpdateBlockInfo(BlockManagerId(<driver>, 192.168.130.131, 57830),broadcast_42_piece0,StorageLevel(false, true, false, false, 1),1521,0,0) from Actor[akka://sparkDriver/temp/$Dk]
15/08/11 10:19:34 DEBUG BlockManager: Put block broadcast_42_piece0 locally took  1 ms
15/08/11 10:19:34 DEBUG BlockManager: Putting block broadcast_42_piece0 without replication took  1 ms
15/08/11 10:19:34 INFO SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:852
15/08/11 10:19:34 INFO DAGScheduler: Submitting 3 missing tasks from Stage 41 (MapPartitionsRDD[63] at map at KMeansTest.scala:65)
15/08/11 10:19:34 DEBUG DAGScheduler: New pending tasks: Set(ResultTask(41, 0), ResultTask(41, 1), ResultTask(41, 2))
15/08/11 10:19:34 INFO TaskSchedulerImpl: Adding task set 41.0 with 3 tasks
15/08/11 10:19:34 DEBUG TaskSetManager: Epoch for TaskSet 41.0: 20
15/08/11 10:19:34 DEBUG TaskSetManager: Valid locality levels for TaskSet 41.0: NO_PREF, ANY
15/08/11 10:19:34 DEBUG SparkDeploySchedulerBackend: [actor] received message ReviveOffers from Actor[akka://sparkDriver/deadLetters]
15/08/11 10:19:34 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_41, runningTasks: 0
15/08/11 10:19:34 INFO TaskSetManager: Starting task 0.0 in stage 41.0 (TID 123, 192.168.130.131, PROCESS_LOCAL, 1116 bytes)
15/08/11 10:19:34 INFO TaskSetManager: Starting task 1.0 in stage 41.0 (TID 124, 192.168.130.131, PROCESS_LOCAL, 1116 bytes)
15/08/11 10:19:34 INFO TaskSetManager: Starting task 2.0 in stage 41.0 (TID 125, 192.168.130.131, PROCESS_LOCAL, 1116 bytes)
15/08/11 10:19:34 DEBUG TaskSetManager: No tasks for locality level NO_PREF, so moving to locality level ANY
15/08/11 10:19:34 DEBUG SparkDeploySchedulerBackend: [actor] handled message (2.722746 ms) ReviveOffers from Actor[akka://sparkDriver/deadLetters]
15/08/11 10:19:34 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,123,RUNNING,org.apache.spark.util.SerializableBuffer@55c91e8d) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:34 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.095415 ms) StatusUpdate(0,123,RUNNING,org.apache.spark.util.SerializableBuffer@55c91e8d) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:34 DEBUG BlockManagerMasterActor: [actor] received message GetLocations(broadcast_42_piece0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$Jc]
15/08/11 10:19:34 DEBUG BlockManagerMasterActor: [actor] handled message (0.081916 ms) GetLocations(broadcast_42_piece0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$Jc]
15/08/11 10:19:34 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,124,RUNNING,org.apache.spark.util.SerializableBuffer@4f9e91d0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:34 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.050577 ms) StatusUpdate(0,124,RUNNING,org.apache.spark.util.SerializableBuffer@4f9e91d0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:34 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,125,RUNNING,org.apache.spark.util.SerializableBuffer@33771786) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:34 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.057717 ms) StatusUpdate(0,125,RUNNING,org.apache.spark.util.SerializableBuffer@33771786) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:34 DEBUG BlockManager: Level for block broadcast_42_piece0 is StorageLevel(true, true, false, false, 1)
15/08/11 10:19:34 DEBUG BlockManager: Getting block broadcast_42_piece0 from memory
15/08/11 10:19:34 DEBUG BlockManagerMasterActor: [actor] received message UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_42_piece0,StorageLevel(false, true, false, false, 1),1521,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$Kc]
15/08/11 10:19:34 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on 192.168.130.131:47921 (size: 1521.0 B, free: 245.7 MB)
15/08/11 10:19:34 DEBUG BlockManagerMasterActor: [actor] handled message (0.359911 ms) UpdateBlockInfo(BlockManagerId(0, 192.168.130.131, 47921),broadcast_42_piece0,StorageLevel(false, true, false, false, 1),1521,0,0) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$Kc]
15/08/11 10:19:35 DEBUG MapOutputTrackerMasterActor: [actor] received message GetMapOutputStatuses(19) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$Lc]
15/08/11 10:19:35 INFO MapOutputTrackerMasterActor: Asked to send map output locations for shuffle 19 to sparkExecutor@192.168.130.131:49489
15/08/11 10:19:35 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 19 is 162 bytes
15/08/11 10:19:35 DEBUG MapOutputTrackerMasterActor: [actor] handled message (0.475521 ms) GetMapOutputStatuses(19) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/temp/$Lc]
15/08/11 10:19:35 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,125,FINISHED,org.apache.spark.util.SerializableBuffer@1791fe40) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:35 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_41, runningTasks: 2
15/08/11 10:19:35 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.464475 ms) StatusUpdate(0,125,FINISHED,org.apache.spark.util.SerializableBuffer@1791fe40) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:35 INFO TaskSetManager: Finished task 2.0 in stage 41.0 (TID 125) in 57 ms on 192.168.130.131 (1/3)
15/08/11 10:19:35 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,124,FINISHED,org.apache.spark.util.SerializableBuffer@6322d57d) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:35 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_41, runningTasks: 1
15/08/11 10:19:35 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.657353 ms) StatusUpdate(0,124,FINISHED,org.apache.spark.util.SerializableBuffer@6322d57d) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:35 INFO TaskSetManager: Finished task 1.0 in stage 41.0 (TID 124) in 68 ms on 192.168.130.131 (2/3)
15/08/11 10:19:35 DEBUG SparkDeploySchedulerBackend: [actor] received message StatusUpdate(0,123,FINISHED,org.apache.spark.util.SerializableBuffer@373a54bf) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:35 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_41, runningTasks: 0
15/08/11 10:19:35 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.836571 ms) StatusUpdate(0,123,FINISHED,org.apache.spark.util.SerializableBuffer@373a54bf) from Actor[akka.tcp://sparkExecutor@192.168.130.131:49489/user/Executor#796794250]
15/08/11 10:19:35 INFO TaskSetManager: Finished task 0.0 in stage 41.0 (TID 123) in 78 ms on 192.168.130.131 (3/3)
15/08/11 10:19:35 INFO DAGScheduler: Stage 41 (collectAsMap at KMeansTest.scala:67) finished in 0.084 s
15/08/11 10:19:35 INFO TaskSchedulerImpl: Removed TaskSet 41.0, whose tasks have all completed, from pool 
15/08/11 10:19:35 DEBUG DAGScheduler: After removal of stage 41, remaining stages = 1
15/08/11 10:19:35 DEBUG DAGScheduler: After removal of stage 40, remaining stages = 0
15/08/11 10:19:35 INFO DAGScheduler: Job 21 finished: collectAsMap at KMeansTest.scala:67, took 2.181531 s
Finished iteration (num = 19)
=====================Final centers:=================================
DenseVector(359627.0, 1.267038347227914, 1.8563404469830411, 0.31934488127518723, 1.6369561145040314, -0.2367309110588175, -0.959668246577165, 0.38092906759911377, 0.17883876918166625, 0.010849552521509336)
DenseVector(731188.5, 1.825991670355461, 1.6265231048000501, -0.46361004935912536, 0.8487282161250874, 0.4155098565657085, -0.3489056974437643, 0.31840464353600867, 0.4938353839882571, 0.5208549767918369)
DenseVector(176873.5, 1.7930538699599836, 1.4218020060404188, -0.19690335849964874, 1.5057475483360294, 0.37082545472850115, -0.893177640398631, -0.3853974440659503, 0.00852948008054129, 0.6805965354447356)
DenseVector(471740.50000000006, 1.755451828615772, 1.2266199678376943, -0.2839689230233908, 1.546277991925871, 1.0231642091724606, -1.6728119101114989, -0.1431124975014672, 0.12019437426847089, 0.4007692834325481)
DenseVector(261753.0, 1.530736872696637, 1.6410042479100317, 0.028886791895684178, 2.288658947505839, 0.034011567490174685, -1.679792926193129, -0.07286975160533499, -0.9377192935092896, 0.26795526120430674)
DenseVector(33315.0, 3.0405315029791753, 0.724944534977259, -0.9999136370499331, 1.5259570324333014, -0.2558343298113427, -0.9523337946089567, 0.12722929862372268, -0.1752606349337385, 0.3798799747857552)
DenseVector(102009.5, 2.3483537928490343, 1.5015645176794818, -0.9859904650650101, 1.7592482380158285, 0.3283364167891466, -0.9442848778971267, 0.06995223408705703, 0.3363823451667607, 0.6857918635387168)
DenseVector(596876.0, 2.260766933893629, 1.367310510583899, -1.2275130285188476, 1.5659886877046876, 0.22440190123739565, -1.359528909046503, 0.16284210385417097, 0.08798362604102349, 0.3960701969526938)
15/08/11 10:19:35 DEBUG AbstractLifeCycle: stopping org.spark-project.jetty.server.Server@1e6520b6
15/08/11 10:19:35 DEBUG AbstractLifeCycle: stopping SelectChannelConnector@0.0.0.0:4040
15/08/11 10:19:35 DEBUG AbstractLifeCycle: stopping org.spark-project.jetty.server.nio.SelectChannelConnector$ConnectorSelectorManager@53d4287
15/08/11 10:19:35 DEBUG nio: Stopped Thread[qtp21404753-42 Selector0,5,main] on org.spark-project.jetty.io.nio.SelectorManager$1@5437633c
15/08/11 10:19:35 DEBUG AbstractLifeCycle: STOPPED org.spark-project.jetty.server.nio.SelectChannelConnector$ConnectorSelectorManager@53d4287
15/08/11 10:19:35 DEBUG AbstractLifeCycle: stopping PooledBuffers [0/1024@6144,0/1024@16384,0/1024@-]/PooledBuffers [0/1024@6144,0/1024@32768,0/1024@-]
15/08/11 10:19:35 DEBUG AbstractLifeCycle: STOPPED null/null
15/08/11 10:19:35 DEBUG AbstractLifeCycle: STOPPED SelectChannelConnector@0.0.0.0:4040
15/08/11 10:19:35 DEBUG AbstractLifeCycle: stopping org.spark-project.jetty.server.handler.ContextHandlerCollection@42c08a7e
15/08/11 10:19:35 DEBUG AbstractHandler: stopping org.spark-project.jetty.server.handler.ContextHandlerCollection@42c08a7e
15/08/11 10:19:35 DEBUG AbstractLifeCycle: stopping o.s.j.s.ServletContextHandler{/metrics/json,null}
15/08/11 10:19:35 DEBUG AbstractLifeCycle: stopping org.spark-project.jetty.servlet.ServletHandler@5ce11915
15/08/11 10:19:35 DEBUG AbstractHandler: stopping org.spark-project.jetty.servlet.ServletHandler@5ce11915
15/08/11 10:19:35 DEBUG AbstractLifeCycle: stopping org.apache.spark.ui.JettyUtils$$anon$1-6eecdcff
15/08/11 10:19:35 DEBUG AbstractLifeCycle: STOPPED org.apache.spark.ui.JettyUtils$$anon$1-6eecdcff
15/08/11 10:19:35 DEBUG AbstractLifeCycle: STOPPED org.spark-project.jetty.servlet.ServletHandler@5ce11915
15/08/11 10:19:35 DEBUG AbstractHandler: stopping o.s.j.s.ServletContextHandler{/metrics/json,null}
15/08/11 10:19:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
15/08/11 10:19:35 DEBUG Container: Container o.s.j.s.ServletContextHandler{/metrics/json,null} - org.spark-project.jetty.servlet.ServletHandler@5ce11915 as handler
15/08/11 10:19:35 DEBUG AbstractLifeCycle: STOPPED o.s.j.s.ServletContextHandler{/metrics/json,null}
15/08/11 10:19:35 DEBUG AbstractLifeCycle: stopping o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
15/08/11 10:19:35 DEBUG AbstractLifeCycle: stopping org.spark-project.jetty.servlet.ServletHandler@eaca568
15/08/11 10:19:35 DEBUG AbstractHandler: stopping org.spark-project.jetty.servlet.ServletHandler@eaca568
15/08/11 10:19:35 DEBUG AbstractLifeCycle: stopping org.apache.spark.ui.JettyUtils$$anon$2-61b60992
15/08/11 10:19:35 DEBUG AbstractLifeCycle: STOPPED org.apache.spark.ui.JettyUtils$$anon$2-61b60992
15/08/11 10:19:35 DEBUG AbstractLifeCycle: STOPPED org.spark-project.jetty.servlet.ServletHandler@eaca568
15/08/11 10:19:35 DEBUG AbstractHandler: stopping o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
15/08/11 10:19:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
15/08/11 10:19:35 DEBUG Container: Container o.s.j.s.ServletContextHandler{/stages/stage/kill,null} - org.spark-project.jetty.servlet.ServletHandler@eaca568 as handler
15/08/11 10:19:35 DEBUG AbstractLifeCycle: STOPPED o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
15/08/11 10:19:35 DEBUG AbstractLifeCycle: stopping o.s.j.s.ServletContextHandler{/,null}
15/08/11 10:19:35 DEBUG AbstractLifeCycle: stopping org.spark-project.jetty.servlet.ServletHandler@4ad512e
15/08/11 10:19:35 DEBUG AbstractHandler: stopping org.spark-project.jetty.servlet.ServletHandler@4ad512e
15/08/11 10:19:35 DEBUG AbstractLifeCycle: stopping org.apache.spark.ui.JettyUtils$$anon$2-4347154c
15/08/11 10:19:35 DEBUG AbstractLifeCycle: STOPPED org.apache.spark.ui.JettyUtils$$anon$2-4347154c
15/08/11 10:19:35 DEBUG AbstractLifeCycle: STOPPED org.spark-project.jetty.servlet.ServletHandler@4ad512e
15/08/11 10:19:35 DEBUG AbstractHandler: stopping o.s.j.s.ServletContextHandler{/,null}
15/08/11 10:19:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}
15/08/11 10:19:35 DEBUG Container: Container o.s.j.s.ServletContextHandler{/,null} - org.spark-project.jetty.servlet.ServletHandler@4ad512e as handler
15/08/11 10:19:35 DEBUG AbstractLifeCycle: STOPPED o.s.j.s.ServletContextHandler{/,null}
15/08/11 10:19:35 DEBUG AbstractLifeCycle: stopping o.s.j.s.ServletContextHandler{/static,null}
15/08/11 10:19:35 DEBUG AbstractLifeCycle: stopping org.spark-project.jetty.servlet.ServletHandler@2c782889
15/08/11 10:19:35 DEBUG AbstractHandler: stopping org.spark-project.jetty.servlet.ServletHandler@2c782889
15/08/11 10:19:35 DEBUG AbstractLifeCycle: stopping org.spark-project.jetty.servlet.DefaultServlet-8216547
15/08/11 10:19:35 DEBUG AbstractLifeCycle: STOPPED org.spark-project.jetty.servlet.DefaultServlet-8216547
15/08/11 10:19:35 DEBUG AbstractLifeCycle: STOPPED org.spark-project.jetty.servlet.ServletHandler@2c782889
15/08/11 10:19:35 DEBUG AbstractHandler: stopping o.s.j.s.ServletContextHandler{/static,null}
15/08/11 10:19:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}
15/08/11 10:19:35 DEBUG Container: Container o.s.j.s.ServletContextHandler{/static,null} - org.spark-project.jetty.servlet.ServletHandler@2c782889 as handler
15/08/11 10:19:35 DEBUG AbstractLifeCycle: STOPPED o.s.j.s.ServletContextHandler{/static,null}
15/08/11 10:19:35 DEBUG AbstractLifeCycle: stopping o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
15/08/11 10:19:35 DEBUG AbstractLifeCycle: stopping org.spark-project.jetty.servlet.ServletHandler@1f9dbb5e
15/08/11 10:19:35 DEBUG AbstractHandler: stopping org.spark-project.jetty.servlet.ServletHandler@1f9dbb5e
15/08/11 10:19:35 DEBUG AbstractLifeCycle: stopping org.apache.spark.ui.JettyUtils$$anon$1-4b13237e
15/08/11 10:19:35 DEBUG AbstractLifeCycle: STOPPED org.apache.spark.ui.JettyUtils$$anon$1-4b13237e
15/08/11 10:19:35 DEBUG AbstractLifeCycle: STOPPED org.spark-project.jetty.servlet.ServletHandler@1f9dbb5e
15/08/11 10:19:35 DEBUG AbstractHandler: stopping o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
15/08/11 10:19:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
15/08/11 10:19:35 DEBUG Container: Container o.s.j.s.ServletContextHandler{/executors/threadDump/json,null} - org.spark-project.jetty.servlet.ServletHandler@1f9dbb5e as handler
15/08/11 10:19:35 DEBUG AbstractLifeCycle: STOPPED o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
15/08/11 10:19:35 DEBUG AbstractLifeCycle: stopping o.s.j.s.ServletContextHandler{/executors/threadDump,null}
15/08/11 10:19:35 DEBUG AbstractLifeCycle: stopping org.spark-project.jetty.servlet.ServletHandler@431535d
15/08/11 10:19:35 DEBUG AbstractHandler: stopping org.spark-project.jetty.servlet.ServletHandler@431535d
15/08/11 10:19:35 DEBUG AbstractLifeCycle: stopping org.apache.spark.ui.JettyUtils$$anon$1-41a4f616
15/08/11 10:19:35 DEBUG AbstractLifeCycle: STOPPED org.apache.spark.ui.JettyUtils$$anon$1-41a4f616
15/08/11 10:19:35 DEBUG AbstractLifeCycle: STOPPED org.spark-project.jetty.servlet.ServletHandler@431535d
15/08/11 10:19:35 DEBUG AbstractHandler: stopping o.s.j.s.ServletContextHandler{/executors/threadDump,null}
15/08/11 10:19:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
15/08/11 10:19:35 DEBUG Container: Container o.s.j.s.ServletContextHandler{/executors/threadDump,null} - org.spark-project.jetty.servlet.ServletHandler@431535d as handler
15/08/11 10:19:35 DEBUG AbstractLifeCycle: STOPPED o.s.j.s.ServletContextHandler{/executors/threadDump,null}
15/08/11 10:19:35 DEBUG AbstractLifeCycle: stopping o.s.j.s.ServletContextHandler{/executors/json,null}
15/08/11 10:19:35 DEBUG AbstractLifeCycle: stopping org.spark-project.jetty.servlet.ServletHandler@7a96cf9
15/08/11 10:19:35 DEBUG AbstractHandler: stopping org.spark-project.jetty.servlet.ServletHandler@7a96cf9
15/08/11 10:19:35 DEBUG AbstractLifeCycle: stopping org.apache.spark.ui.JettyUtils$$anon$1-46dcac12
15/08/11 10:19:35 DEBUG AbstractLifeCycle: STOPPED org.apache.spark.ui.JettyUtils$$anon$1-46dcac12
15/08/11 10:19:35 DEBUG AbstractLifeCycle: STOPPED org.spark-project.jetty.servlet.ServletHandler@7a96cf9
15/08/11 10:19:35 DEBUG AbstractHandler: stopping o.s.j.s.ServletContextHandler{/executors/json,null}
15/08/11 10:19:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}
15/08/11 10:19:35 DEBUG Container: Container o.s.j.s.ServletContextHandler{/executors/json,null} - org.spark-project.jetty.servlet.ServletHandler@7a96cf9 as handler
15/08/11 10:19:35 DEBUG AbstractLifeCycle: STOPPED o.s.j.s.ServletContextHandler{/executors/json,null}
15/08/11 10:19:35 DEBUG AbstractLifeCycle: stopping o.s.j.s.ServletContextHandler{/executors,null}
15/08/11 10:19:35 DEBUG AbstractLifeCycle: stopping org.spark-project.jetty.servlet.ServletHandler@2ee23f4b
15/08/11 10:19:35 DEBUG AbstractHandler: stopping org.spark-project.jetty.servlet.ServletHandler@2ee23f4b
15/08/11 10:19:35 DEBUG AbstractLifeCycle: stopping org.apache.spark.ui.JettyUtils$$anon$1-7b61a226
15/08/11 10:19:35 DEBUG AbstractLifeCycle: STOPPED org.apache.spark.ui.JettyUtils$$anon$1-7b61a226
15/08/11 10:19:35 DEBUG AbstractLifeCycle: STOPPED org.spark-project.jetty.servlet.ServletHandler@2ee23f4b
15/08/11 10:19:35 DEBUG AbstractHandler: stopping o.s.j.s.ServletContextHandler{/executors,null}
15/08/11 10:19:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}
15/08/11 10:19:35 DEBUG Container: Container o.s.j.s.ServletContextHandler{/executors,null} - org.spark-project.jetty.servlet.ServletHandler@2ee23f4b as handler
15/08/11 10:19:35 DEBUG AbstractLifeCycle: STOPPED o.s.j.s.ServletContextHandler{/executors,null}
15/08/11 10:19:35 DEBUG AbstractLifeCycle: stopping o.s.j.s.ServletContextHandler{/environment/json,null}
15/08/11 10:19:35 DEBUG AbstractLifeCycle: stopping org.spark-project.jetty.servlet.ServletHandler@7c39ae4c
15/08/11 10:19:35 DEBUG AbstractHandler: stopping org.spark-project.jetty.servlet.ServletHandler@7c39ae4c
15/08/11 10:19:35 DEBUG AbstractLifeCycle: stopping org.apache.spark.ui.JettyUtils$$anon$1-299e30c0
15/08/11 10:19:35 DEBUG AbstractLifeCycle: STOPPED org.apache.spark.ui.JettyUtils$$anon$1-299e30c0
15/08/11 10:19:35 DEBUG AbstractLifeCycle: STOPPED org.spark-project.jetty.servlet.ServletHandler@7c39ae4c
15/08/11 10:19:35 DEBUG AbstractHandler: stopping o.s.j.s.ServletContextHandler{/environment/json,null}
15/08/11 10:19:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}
15/08/11 10:19:35 DEBUG Container: Container o.s.j.s.ServletContextHandler{/environment/json,null} - org.spark-project.jetty.servlet.ServletHandler@7c39ae4c as handler
15/08/11 10:19:35 DEBUG AbstractLifeCycle: STOPPED o.s.j.s.ServletContextHandler{/environment/json,null}
15/08/11 10:19:35 DEBUG AbstractLifeCycle: stopping o.s.j.s.ServletContextHandler{/environment,null}
15/08/11 10:19:35 DEBUG AbstractLifeCycle: stopping org.spark-project.jetty.servlet.ServletHandler@5bd8e367
15/08/11 10:19:35 DEBUG AbstractHandler: stopping org.spark-project.jetty.servlet.ServletHandler@5bd8e367
15/08/11 10:19:35 DEBUG AbstractLifeCycle: stopping org.apache.spark.ui.JettyUtils$$anon$1-7ebb0a40
15/08/11 10:19:35 DEBUG AbstractLifeCycle: STOPPED org.apache.spark.ui.JettyUtils$$anon$1-7ebb0a40
15/08/11 10:19:35 DEBUG AbstractLifeCycle: STOPPED org.spark-project.jetty.servlet.ServletHandler@5bd8e367
15/08/11 10:19:35 DEBUG AbstractHandler: stopping o.s.j.s.ServletContextHandler{/environment,null}
15/08/11 10:19:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}
15/08/11 10:19:35 DEBUG Container: Container o.s.j.s.ServletContextHandler{/environment,null} - org.spark-project.jetty.servlet.ServletHandler@5bd8e367 as handler
15/08/11 10:19:35 DEBUG AbstractLifeCycle: STOPPED o.s.j.s.ServletContextHandler{/environment,null}
15/08/11 10:19:35 DEBUG AbstractLifeCycle: stopping o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
15/08/11 10:19:35 DEBUG AbstractLifeCycle: stopping org.spark-project.jetty.servlet.ServletHandler@3d6989d8
15/08/11 10:19:35 DEBUG AbstractHandler: stopping org.spark-project.jetty.servlet.ServletHandler@3d6989d8
15/08/11 10:19:35 DEBUG AbstractLifeCycle: stopping org.apache.spark.ui.JettyUtils$$anon$1-6555f670
15/08/11 10:19:35 DEBUG AbstractLifeCycle: STOPPED org.apache.spark.ui.JettyUtils$$anon$1-6555f670
15/08/11 10:19:35 DEBUG AbstractLifeCycle: STOPPED org.spark-project.jetty.servlet.ServletHandler@3d6989d8
15/08/11 10:19:35 DEBUG AbstractHandler: stopping o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
15/08/11 10:19:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
15/08/11 10:19:35 DEBUG Container: Container o.s.j.s.ServletContextHandler{/storage/rdd/json,null} - org.spark-project.jetty.servlet.ServletHandler@3d6989d8 as handler
15/08/11 10:19:35 DEBUG AbstractLifeCycle: STOPPED o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
15/08/11 10:19:35 DEBUG AbstractLifeCycle: stopping o.s.j.s.ServletContextHandler{/storage/rdd,null}
15/08/11 10:19:35 DEBUG AbstractLifeCycle: stopping org.spark-project.jetty.servlet.ServletHandler@573a6f6d
15/08/11 10:19:35 DEBUG AbstractHandler: stopping org.spark-project.jetty.servlet.ServletHandler@573a6f6d
15/08/11 10:19:35 DEBUG AbstractLifeCycle: stopping org.apache.spark.ui.JettyUtils$$anon$1-396828e9
15/08/11 10:19:35 DEBUG AbstractLifeCycle: STOPPED org.apache.spark.ui.JettyUtils$$anon$1-396828e9
15/08/11 10:19:35 DEBUG AbstractLifeCycle: STOPPED org.spark-project.jetty.servlet.ServletHandler@573a6f6d
15/08/11 10:19:35 DEBUG AbstractHandler: stopping o.s.j.s.ServletContextHandler{/storage/rdd,null}
15/08/11 10:19:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
15/08/11 10:19:35 DEBUG Container: Container o.s.j.s.ServletContextHandler{/storage/rdd,null} - org.spark-project.jetty.servlet.ServletHandler@573a6f6d as handler
15/08/11 10:19:35 DEBUG AbstractLifeCycle: STOPPED o.s.j.s.ServletContextHandler{/storage/rdd,null}
15/08/11 10:19:35 DEBUG AbstractLifeCycle: stopping o.s.j.s.ServletContextHandler{/storage/json,null}
15/08/11 10:19:35 DEBUG AbstractLifeCycle: stopping org.spark-project.jetty.servlet.ServletHandler@29967e3f
15/08/11 10:19:35 DEBUG AbstractHandler: stopping org.spark-project.jetty.servlet.ServletHandler@29967e3f
15/08/11 10:19:35 DEBUG AbstractLifeCycle: stopping org.apache.spark.ui.JettyUtils$$anon$1-22639b4a
15/08/11 10:19:35 DEBUG AbstractLifeCycle: STOPPED org.apache.spark.ui.JettyUtils$$anon$1-22639b4a
15/08/11 10:19:35 DEBUG AbstractLifeCycle: STOPPED org.spark-project.jetty.servlet.ServletHandler@29967e3f
15/08/11 10:19:35 DEBUG AbstractHandler: stopping o.s.j.s.ServletContextHandler{/storage/json,null}
15/08/11 10:19:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}
15/08/11 10:19:35 DEBUG Container: Container o.s.j.s.ServletContextHandler{/storage/json,null} - org.spark-project.jetty.servlet.ServletHandler@29967e3f as handler
15/08/11 10:19:35 DEBUG AbstractLifeCycle: STOPPED o.s.j.s.ServletContextHandler{/storage/json,null}
15/08/11 10:19:35 DEBUG AbstractLifeCycle: stopping o.s.j.s.ServletContextHandler{/storage,null}
15/08/11 10:19:35 DEBUG AbstractLifeCycle: stopping org.spark-project.jetty.servlet.ServletHandler@29a7584e
15/08/11 10:19:35 DEBUG AbstractHandler: stopping org.spark-project.jetty.servlet.ServletHandler@29a7584e
15/08/11 10:19:35 DEBUG AbstractLifeCycle: stopping org.apache.spark.ui.JettyUtils$$anon$1-3b7b65f8
15/08/11 10:19:35 DEBUG AbstractLifeCycle: STOPPED org.apache.spark.ui.JettyUtils$$anon$1-3b7b65f8
15/08/11 10:19:35 DEBUG AbstractLifeCycle: STOPPED org.spark-project.jetty.servlet.ServletHandler@29a7584e
15/08/11 10:19:35 DEBUG AbstractHandler: stopping o.s.j.s.ServletContextHandler{/storage,null}
15/08/11 10:19:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}
15/08/11 10:19:35 DEBUG Container: Container o.s.j.s.ServletContextHandler{/storage,null} - org.spark-project.jetty.servlet.ServletHandler@29a7584e as handler
15/08/11 10:19:35 DEBUG AbstractLifeCycle: STOPPED o.s.j.s.ServletContextHandler{/storage,null}
15/08/11 10:19:35 DEBUG AbstractLifeCycle: stopping o.s.j.s.ServletContextHandler{/stages/pool/json,null}
15/08/11 10:19:35 DEBUG AbstractLifeCycle: stopping org.spark-project.jetty.servlet.ServletHandler@50136664
15/08/11 10:19:35 DEBUG AbstractHandler: stopping org.spark-project.jetty.servlet.ServletHandler@50136664
15/08/11 10:19:35 DEBUG AbstractLifeCycle: stopping org.apache.spark.ui.JettyUtils$$anon$1-2b4ffed7
15/08/11 10:19:35 DEBUG AbstractLifeCycle: STOPPED org.apache.spark.ui.JettyUtils$$anon$1-2b4ffed7
15/08/11 10:19:35 DEBUG AbstractLifeCycle: STOPPED org.spark-project.jetty.servlet.ServletHandler@50136664
15/08/11 10:19:35 DEBUG AbstractHandler: stopping o.s.j.s.ServletContextHandler{/stages/pool/json,null}
15/08/11 10:19:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
15/08/11 10:19:35 DEBUG Container: Container o.s.j.s.ServletContextHandler{/stages/pool/json,null} - org.spark-project.jetty.servlet.ServletHandler@50136664 as handler
15/08/11 10:19:35 DEBUG AbstractLifeCycle: STOPPED o.s.j.s.ServletContextHandler{/stages/pool/json,null}
15/08/11 10:19:35 DEBUG AbstractLifeCycle: stopping o.s.j.s.ServletContextHandler{/stages/pool,null}
15/08/11 10:19:35 DEBUG AbstractLifeCycle: stopping org.spark-project.jetty.servlet.ServletHandler@2dc6b306
15/08/11 10:19:35 DEBUG AbstractHandler: stopping org.spark-project.jetty.servlet.ServletHandler@2dc6b306
15/08/11 10:19:35 DEBUG AbstractLifeCycle: stopping org.apache.spark.ui.JettyUtils$$anon$1-13609ac1
15/08/11 10:19:35 DEBUG AbstractLifeCycle: STOPPED org.apache.spark.ui.JettyUtils$$anon$1-13609ac1
15/08/11 10:19:35 DEBUG AbstractLifeCycle: STOPPED org.spark-project.jetty.servlet.ServletHandler@2dc6b306
15/08/11 10:19:35 DEBUG AbstractHandler: stopping o.s.j.s.ServletContextHandler{/stages/pool,null}
15/08/11 10:19:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
15/08/11 10:19:35 DEBUG Container: Container o.s.j.s.ServletContextHandler{/stages/pool,null} - org.spark-project.jetty.servlet.ServletHandler@2dc6b306 as handler
15/08/11 10:19:35 DEBUG AbstractLifeCycle: STOPPED o.s.j.s.ServletContextHandler{/stages/pool,null}
15/08/11 10:19:35 DEBUG AbstractLifeCycle: stopping o.s.j.s.ServletContextHandler{/stages/stage/json,null}
15/08/11 10:19:35 DEBUG AbstractLifeCycle: stopping org.spark-project.jetty.servlet.ServletHandler@7606a33b
15/08/11 10:19:35 DEBUG AbstractHandler: stopping org.spark-project.jetty.servlet.ServletHandler@7606a33b
15/08/11 10:19:35 DEBUG AbstractLifeCycle: stopping org.apache.spark.ui.JettyUtils$$anon$1-3bf02645
15/08/11 10:19:35 DEBUG AbstractLifeCycle: STOPPED org.apache.spark.ui.JettyUtils$$anon$1-3bf02645
15/08/11 10:19:35 DEBUG AbstractLifeCycle: STOPPED org.spark-project.jetty.servlet.ServletHandler@7606a33b
15/08/11 10:19:35 DEBUG AbstractHandler: stopping o.s.j.s.ServletContextHandler{/stages/stage/json,null}
15/08/11 10:19:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
15/08/11 10:19:35 DEBUG Container: Container o.s.j.s.ServletContextHandler{/stages/stage/json,null} - org.spark-project.jetty.servlet.ServletHandler@7606a33b as handler
15/08/11 10:19:35 DEBUG AbstractLifeCycle: STOPPED o.s.j.s.ServletContextHandler{/stages/stage/json,null}
15/08/11 10:19:35 DEBUG AbstractLifeCycle: stopping o.s.j.s.ServletContextHandler{/stages/stage,null}
15/08/11 10:19:35 DEBUG AbstractLifeCycle: stopping org.spark-project.jetty.servlet.ServletHandler@5f28e5cb
15/08/11 10:19:35 DEBUG AbstractHandler: stopping org.spark-project.jetty.servlet.ServletHandler@5f28e5cb
15/08/11 10:19:35 DEBUG AbstractLifeCycle: stopping org.apache.spark.ui.JettyUtils$$anon$1-5b229721
15/08/11 10:19:35 DEBUG AbstractLifeCycle: STOPPED org.apache.spark.ui.JettyUtils$$anon$1-5b229721
15/08/11 10:19:35 DEBUG AbstractLifeCycle: STOPPED org.spark-project.jetty.servlet.ServletHandler@5f28e5cb
15/08/11 10:19:35 DEBUG AbstractHandler: stopping o.s.j.s.ServletContextHandler{/stages/stage,null}
15/08/11 10:19:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
15/08/11 10:19:35 DEBUG Container: Container o.s.j.s.ServletContextHandler{/stages/stage,null} - org.spark-project.jetty.servlet.ServletHandler@5f28e5cb as handler
15/08/11 10:19:35 DEBUG AbstractLifeCycle: STOPPED o.s.j.s.ServletContextHandler{/stages/stage,null}
15/08/11 10:19:35 DEBUG AbstractLifeCycle: stopping o.s.j.s.ServletContextHandler{/stages/json,null}
15/08/11 10:19:35 DEBUG AbstractLifeCycle: stopping org.spark-project.jetty.servlet.ServletHandler@63629cde
15/08/11 10:19:35 DEBUG AbstractHandler: stopping org.spark-project.jetty.servlet.ServletHandler@63629cde
15/08/11 10:19:35 DEBUG AbstractLifeCycle: stopping org.apache.spark.ui.JettyUtils$$anon$1-568b6b12
15/08/11 10:19:35 DEBUG AbstractLifeCycle: STOPPED org.apache.spark.ui.JettyUtils$$anon$1-568b6b12
15/08/11 10:19:35 DEBUG AbstractLifeCycle: STOPPED org.spark-project.jetty.servlet.ServletHandler@63629cde
15/08/11 10:19:35 DEBUG AbstractHandler: stopping o.s.j.s.ServletContextHandler{/stages/json,null}
15/08/11 10:19:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}
15/08/11 10:19:35 DEBUG Container: Container o.s.j.s.ServletContextHandler{/stages/json,null} - org.spark-project.jetty.servlet.ServletHandler@63629cde as handler
15/08/11 10:19:35 DEBUG AbstractLifeCycle: STOPPED o.s.j.s.ServletContextHandler{/stages/json,null}
15/08/11 10:19:35 DEBUG AbstractLifeCycle: stopping o.s.j.s.ServletContextHandler{/stages,null}
15/08/11 10:19:35 DEBUG AbstractLifeCycle: stopping org.spark-project.jetty.servlet.ServletHandler@250ea0db
15/08/11 10:19:35 DEBUG AbstractHandler: stopping org.spark-project.jetty.servlet.ServletHandler@250ea0db
15/08/11 10:19:35 DEBUG AbstractLifeCycle: stopping org.apache.spark.ui.JettyUtils$$anon$1-18dd055e
15/08/11 10:19:35 DEBUG AbstractLifeCycle: STOPPED org.apache.spark.ui.JettyUtils$$anon$1-18dd055e
15/08/11 10:19:35 DEBUG AbstractLifeCycle: STOPPED org.spark-project.jetty.servlet.ServletHandler@250ea0db
15/08/11 10:19:35 DEBUG AbstractHandler: stopping o.s.j.s.ServletContextHandler{/stages,null}
15/08/11 10:19:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}
15/08/11 10:19:35 DEBUG Container: Container o.s.j.s.ServletContextHandler{/stages,null} - org.spark-project.jetty.servlet.ServletHandler@250ea0db as handler
15/08/11 10:19:35 DEBUG AbstractLifeCycle: STOPPED o.s.j.s.ServletContextHandler{/stages,null}
15/08/11 10:19:35 DEBUG AbstractLifeCycle: stopping o.s.j.s.ServletContextHandler{/jobs/job/json,null}
15/08/11 10:19:35 DEBUG AbstractLifeCycle: stopping org.spark-project.jetty.servlet.ServletHandler@2ea64162
15/08/11 10:19:35 DEBUG AbstractHandler: stopping org.spark-project.jetty.servlet.ServletHandler@2ea64162
15/08/11 10:19:35 DEBUG AbstractLifeCycle: stopping org.apache.spark.ui.JettyUtils$$anon$1-ed57bbe
15/08/11 10:19:35 DEBUG AbstractLifeCycle: STOPPED org.apache.spark.ui.JettyUtils$$anon$1-ed57bbe
15/08/11 10:19:35 DEBUG AbstractLifeCycle: STOPPED org.spark-project.jetty.servlet.ServletHandler@2ea64162
15/08/11 10:19:35 DEBUG AbstractHandler: stopping o.s.j.s.ServletContextHandler{/jobs/job/json,null}
15/08/11 10:19:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
15/08/11 10:19:35 DEBUG Container: Container o.s.j.s.ServletContextHandler{/jobs/job/json,null} - org.spark-project.jetty.servlet.ServletHandler@2ea64162 as handler
15/08/11 10:19:35 DEBUG AbstractLifeCycle: STOPPED o.s.j.s.ServletContextHandler{/jobs/job/json,null}
15/08/11 10:19:35 DEBUG AbstractLifeCycle: stopping o.s.j.s.ServletContextHandler{/jobs/job,null}
15/08/11 10:19:35 DEBUG AbstractLifeCycle: stopping org.spark-project.jetty.servlet.ServletHandler@be22fa6
15/08/11 10:19:35 DEBUG AbstractHandler: stopping org.spark-project.jetty.servlet.ServletHandler@be22fa6
15/08/11 10:19:35 DEBUG AbstractLifeCycle: stopping org.apache.spark.ui.JettyUtils$$anon$1-950aa31
15/08/11 10:19:35 DEBUG AbstractLifeCycle: STOPPED org.apache.spark.ui.JettyUtils$$anon$1-950aa31
15/08/11 10:19:35 DEBUG AbstractLifeCycle: STOPPED org.spark-project.jetty.servlet.ServletHandler@be22fa6
15/08/11 10:19:35 DEBUG AbstractHandler: stopping o.s.j.s.ServletContextHandler{/jobs/job,null}
15/08/11 10:19:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
15/08/11 10:19:35 DEBUG Container: Container o.s.j.s.ServletContextHandler{/jobs/job,null} - org.spark-project.jetty.servlet.ServletHandler@be22fa6 as handler
15/08/11 10:19:35 DEBUG AbstractLifeCycle: STOPPED o.s.j.s.ServletContextHandler{/jobs/job,null}
15/08/11 10:19:35 DEBUG AbstractLifeCycle: stopping o.s.j.s.ServletContextHandler{/jobs/json,null}
15/08/11 10:19:35 DEBUG AbstractLifeCycle: stopping org.spark-project.jetty.servlet.ServletHandler@69697a63
15/08/11 10:19:35 DEBUG AbstractHandler: stopping org.spark-project.jetty.servlet.ServletHandler@69697a63
15/08/11 10:19:35 DEBUG AbstractLifeCycle: stopping org.apache.spark.ui.JettyUtils$$anon$1-5cbd608
15/08/11 10:19:35 DEBUG AbstractLifeCycle: STOPPED org.apache.spark.ui.JettyUtils$$anon$1-5cbd608
15/08/11 10:19:35 DEBUG AbstractLifeCycle: STOPPED org.spark-project.jetty.servlet.ServletHandler@69697a63
15/08/11 10:19:35 DEBUG AbstractHandler: stopping o.s.j.s.ServletContextHandler{/jobs/json,null}
15/08/11 10:19:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
15/08/11 10:19:35 DEBUG Container: Container o.s.j.s.ServletContextHandler{/jobs/json,null} - org.spark-project.jetty.servlet.ServletHandler@69697a63 as handler
15/08/11 10:19:35 DEBUG AbstractLifeCycle: STOPPED o.s.j.s.ServletContextHandler{/jobs/json,null}
15/08/11 10:19:35 DEBUG AbstractLifeCycle: stopping o.s.j.s.ServletContextHandler{/jobs,null}
15/08/11 10:19:35 DEBUG AbstractLifeCycle: stopping org.spark-project.jetty.servlet.ServletHandler@73218274
15/08/11 10:19:35 DEBUG AbstractHandler: stopping org.spark-project.jetty.servlet.ServletHandler@73218274
15/08/11 10:19:35 DEBUG AbstractLifeCycle: stopping org.apache.spark.ui.JettyUtils$$anon$1-79d4583d
15/08/11 10:19:35 DEBUG AbstractLifeCycle: STOPPED org.apache.spark.ui.JettyUtils$$anon$1-79d4583d
15/08/11 10:19:35 DEBUG AbstractLifeCycle: STOPPED org.spark-project.jetty.servlet.ServletHandler@73218274
15/08/11 10:19:35 DEBUG AbstractHandler: stopping o.s.j.s.ServletContextHandler{/jobs,null}
15/08/11 10:19:35 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}
15/08/11 10:19:35 DEBUG Container: Container o.s.j.s.ServletContextHandler{/jobs,null} - org.spark-project.jetty.servlet.ServletHandler@73218274 as handler
15/08/11 10:19:35 DEBUG AbstractLifeCycle: STOPPED o.s.j.s.ServletContextHandler{/jobs,null}
15/08/11 10:19:35 DEBUG AbstractLifeCycle: STOPPED org.spark-project.jetty.server.handler.ContextHandlerCollection@42c08a7e
15/08/11 10:19:35 DEBUG AbstractHandler: stopping org.spark-project.jetty.server.Server@1e6520b6
15/08/11 10:19:35 DEBUG AbstractLifeCycle: stopping qtp21404753{8<=8<=8/254,0}
15/08/11 10:19:35 DEBUG AbstractLifeCycle: STOPPED qtp21404753{8<=0<=0/254,5}
15/08/11 10:19:35 DEBUG AbstractLifeCycle: STOPPED org.spark-project.jetty.server.Server@1e6520b6
15/08/11 10:19:35 INFO SparkUI: Stopped Spark web UI at http://192.168.130.131:4040
15/08/11 10:19:35 INFO DAGScheduler: Stopping DAGScheduler
15/08/11 10:19:35 INFO SparkDeploySchedulerBackend: Shutting down all executors
15/08/11 10:19:35 DEBUG SparkDeploySchedulerBackend: [actor] received message StopExecutors from Actor[akka://sparkDriver/temp/$Ek]
15/08/11 10:19:35 INFO SparkDeploySchedulerBackend: Asking each executor to shut down
15/08/11 10:19:35 DEBUG SparkDeploySchedulerBackend: [actor] handled message (2.776263 ms) StopExecutors from Actor[akka://sparkDriver/temp/$Ek]
15/08/11 10:19:35 DEBUG SparkDeploySchedulerBackend: [actor] received message StopDriver from Actor[akka://sparkDriver/temp/$Fk]
15/08/11 10:19:35 DEBUG SparkDeploySchedulerBackend: [actor] handled message (0.089957 ms) StopDriver from Actor[akka://sparkDriver/temp/$Fk]
15/08/11 10:19:35 DEBUG AppClient$ClientActor: [actor] received message StopAppClient from Actor[akka://sparkDriver/temp/$Gk]
15/08/11 10:19:35 DEBUG AppClient$ClientActor: [actor] handled message (0.194503 ms) StopAppClient from Actor[akka://sparkDriver/temp/$Gk]
15/08/11 10:19:35 DEBUG AbstractLifeCycle: stopping org.spark-project.jetty.server.Server@2c1da9b4
15/08/11 10:19:35 DEBUG AbstractLifeCycle: stopping SocketConnector@0.0.0.0:40555
15/08/11 10:19:35 DEBUG AbstractLifeCycle: stopping PooledBuffers [1/1024@6144,0/1024@16384,0/1024@-]/PooledBuffers [1/1024@6144,1/1024@32768,0/1024@-]
15/08/11 10:19:35 DEBUG AbstractLifeCycle: STOPPED null/null
15/08/11 10:19:35 DEBUG AbstractLifeCycle: STOPPED SocketConnector@0.0.0.0:0
15/08/11 10:19:35 DEBUG AbstractLifeCycle: stopping org.spark-project.jetty.server.handler.HandlerList@1f56e60b
15/08/11 10:19:35 DEBUG AbstractHandler: stopping org.spark-project.jetty.server.handler.HandlerList@1f56e60b
15/08/11 10:19:35 DEBUG AbstractLifeCycle: stopping org.spark-project.jetty.server.handler.DefaultHandler@323e5ed3
15/08/11 10:19:35 DEBUG AbstractHandler: stopping org.spark-project.jetty.server.handler.DefaultHandler@323e5ed3
15/08/11 10:19:35 DEBUG AbstractLifeCycle: STOPPED org.spark-project.jetty.server.handler.DefaultHandler@323e5ed3
15/08/11 10:19:35 DEBUG AbstractLifeCycle: stopping org.spark-project.jetty.server.handler.ResourceHandler@218ec40
15/08/11 10:19:35 DEBUG AbstractHandler: stopping org.spark-project.jetty.server.handler.ResourceHandler@218ec40
15/08/11 10:19:35 DEBUG AbstractLifeCycle: STOPPED org.spark-project.jetty.server.handler.ResourceHandler@218ec40
15/08/11 10:19:35 DEBUG AbstractLifeCycle: STOPPED org.spark-project.jetty.server.handler.HandlerList@1f56e60b
15/08/11 10:19:35 DEBUG AbstractHandler: stopping org.spark-project.jetty.server.Server@2c1da9b4
15/08/11 10:19:35 DEBUG AbstractLifeCycle: stopping qtp151884440{8<=8<=8/254,0}
15/08/11 10:19:35 DEBUG AbstractLifeCycle: STOPPED qtp151884440{8<=0<=0/254,6}
15/08/11 10:19:35 DEBUG AbstractLifeCycle: STOPPED org.spark-project.jetty.server.Server@2c1da9b4
15/08/11 10:19:35 DEBUG MapOutputTrackerMasterActor: [actor] received message StopMapOutputTracker from Actor[akka://sparkDriver/temp/$Hk]
15/08/11 10:19:35 INFO MapOutputTrackerMasterActor: MapOutputTrackerActor stopped!
15/08/11 10:19:35 DEBUG MapOutputTrackerMasterActor: [actor] handled message (11.87298 ms) StopMapOutputTracker from Actor[akka://sparkDriver/temp/$Hk]
15/08/11 10:19:35 DEBUG OutputCommitCoordinator$OutputCommitCoordinatorActor: [actor] received message StopCoordinator from Actor[akka://sparkDriver/deadLetters]
15/08/11 10:19:35 INFO OutputCommitCoordinator$OutputCommitCoordinatorActor: OutputCommitCoordinator stopped!
15/08/11 10:19:35 DEBUG OutputCommitCoordinator$OutputCommitCoordinatorActor: [actor] handled message (0.630648 ms) StopCoordinator from Actor[akka://sparkDriver/deadLetters]
15/08/11 10:19:35 INFO MemoryStore: MemoryStore cleared
15/08/11 10:19:35 INFO BlockManager: BlockManager stopped
15/08/11 10:19:35 DEBUG BlockManagerMasterActor: [actor] received message StopBlockManagerMaster from Actor[akka://sparkDriver/temp/$Ik]
15/08/11 10:19:35 DEBUG BlockManagerMasterActor: [actor] handled message (0.143803 ms) StopBlockManagerMaster from Actor[akka://sparkDriver/temp/$Ik]
15/08/11 10:19:35 INFO BlockManagerMaster: BlockManagerMaster stopped
15/08/11 10:19:35 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
15/08/11 10:19:35 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
15/08/11 10:19:35 INFO SparkContext: Successfully stopped SparkContext
15/08/11 10:19:35 DEBUG Utils: Shutdown hook called
15/08/11 10:19:35 DEBUG Client: Stopping client
